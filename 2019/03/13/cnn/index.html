<!DOCTYPE html>












  


<html class="theme-next pisces use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
































<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=6.6.0" rel="stylesheet" type="text/css">



  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.jpg?v=6.6.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.jpg?v=6.6.0">










<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '6.6.0',
    sidebar: {"position":"left","display":"always","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="Alexnet(2012) 论文名称：ImageNet Classification with Deep Convolutional Neural Networks 论文地址：http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf 概述 作者提出了一个卷">
<meta name="keywords" content="CNN,卷积神经网络,alexnet">
<meta property="og:type" content="article">
<meta property="og:title" content="CNN">
<meta property="og:url" content="http://mxxhcm.github.io/2019/03/13/cnn/index.html">
<meta property="og:site_name" content="mxxhcm&#39;s blog">
<meta property="og:description" content="Alexnet(2012) 论文名称：ImageNet Classification with Deep Convolutional Neural Networks 论文地址：http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf 概述 作者提出了一个卷">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="http://mxxhcm.github.io/2019/03/13/cnn/relu.png">
<meta property="og:image" content="http://mxxhcm.github.io/2019/03/13/cnn/sigmod.png">
<meta property="og:image" content="http://mxxhcm.github.io/2019/03/13/cnn/tanh.png">
<meta property="og:image" content="http://mxxhcm.github.io/2019/03/13/cnn/alexnet.png">
<meta property="og:image" content="http://mxxhcm.github.io/2019/03/13/cnn/alexnet_simple.png">
<meta property="og:image" content="http://mxxhcm.github.io/2019/03/13/cnn/fcn.png">
<meta property="og:image" content="http://mxxhcm.github.io/2019/03/13/cnn/fcn2.png">
<meta property="og:image" content="http://mxxhcm.github.io/2019/03/13/cnn/offset_maxpooling.png">
<meta property="og:image" content="http://mxxhcm.github.io/2019/03/13/cnn/overfeat_fast.png">
<meta property="og:image" content="http://mxxhcm.github.io/2019/03/13/cnn/overfeat_accuracy.png">
<meta property="og:image" content="http://mxxhcm.github.io/2019/03/13/cnn/multi_scale.png">
<meta property="og:image" content="http://mxxhcm.github.io/2019/03/13/cnn/vgg_conf.png">
<meta property="og:image" content="http://mxxhcm.github.io/2019/03/13/cnn/vgg_weights_num.png">
<meta property="og:image" content="http://mxxhcm.github.io/2019/03/13/cnn/fig1.png">
<meta property="og:updated_time" content="2019-06-09T04:40:51.256Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="CNN">
<meta name="twitter:description" content="Alexnet(2012) 论文名称：ImageNet Classification with Deep Convolutional Neural Networks 论文地址：http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf 概述 作者提出了一个卷">
<meta name="twitter:image" content="http://mxxhcm.github.io/2019/03/13/cnn/relu.png">



  <link rel="alternate" href="/atom.xml" title="mxxhcm's blog" type="application/atom+xml">




  <link rel="canonical" href="http://mxxhcm.github.io/2019/03/13/cnn/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>CNN | mxxhcm's blog</title>
  












  <noscript>
  <style>
    .use-motion .motion-element,
    .use-motion .brand,
    .use-motion .menu-item,
    .sidebar-inner,
    .use-motion .post-block,
    .use-motion .pagination,
    .use-motion .comments,
    .use-motion .post-header,
    .use-motion .post-body,
    .use-motion .collection-title { opacity: initial; }

    .use-motion .logo,
    .use-motion .site-title,
    .use-motion .site-subtitle {
      opacity: initial;
      top: initial;
    }

    .use-motion .logo-line-before i { left: initial; }
    .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">mxxhcm's blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>

      
      
    </ul>
  

  

  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mxxhcm.github.io/2019/03/13/cnn/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="马晓鑫爱马荟荟">
      <meta itemprop="description" content="记录硕士三年自己的积累">
      <meta itemprop="image" content="/images/favicon.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="mxxhcm's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">CNN

              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-03-13 15:21:27" itemprop="dateCreated datePublished" datetime="2019-03-13T15:21:27+08:00">2019-03-13</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-06-09 12:40:51" itemprop="dateModified" datetime="2019-06-09T12:40:51+08:00">2019-06-09</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/03/13/cnn/#comments" itemprop="discussionUrl">
                  <span class="post-meta-item-text">评论数：</span> <span class="post-comments-count gitment-comments-count" data-xid="/2019/03/13/cnn/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="alexnet-2012">Alexnet(2012)</h2>
<p>论文名称：ImageNet Classification with Deep Convolutional Neural Networks<br>
论文地址：<a href="http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" target="_blank" rel="noopener">http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf</a></p>
<h3 id="概述">概述</h3>
<p>作者提出了一个卷积神经网络架构对Imagenet中$1000$类中的$120$万张图片进行分类。网络架构包含$5$个卷积层，$3$个全连接层，和一个$1000$-way的softmax层，整个网络共有$6000$万参数，$65000$个神经元。作者提出了一些方法提高性能和减少训练的时间，并且介绍了一些防止过拟合的技巧。最后在imagenet测试集上，跑出$37.5%$的top-1 error以及$17.0%$的top-5 error。<br>
本文主要的contribution：</p>
<ol>
<li>给出了一个benchmark－Imagenet</li>
<li>提出了一个CNN架构</li>
<li>ReLU激活函数</li>
<li>dropout的使用</li>
<li>数据增强，四个角落和中心的crop以及对应的horizontial 翻转。</li>
</ol>
<h3 id="问题">问题</h3>
<p>1.数据集太小，都是数以万计的，需要更大的数据集。</p>
<h3 id="创新">创新</h3>
<h4 id="relu非线性激活函数">ReLU非线性激活函数</h4>
<h5 id="作用">作用</h5>
<p>作者说实验表明ReLU可以加速训练过程。</p>
<h5 id="saturating-nonlinearity">saturating nonlinearity</h5>
<p>一个饱和的激活函数会将输出挤压到一个区间内。</p>
<blockquote>
<p>A saturating activation function squeezes the input.</p>
</blockquote>
<p><strong>定义</strong><br>
f是non-saturating 当且仅当$|lim_{z\rightarrow -\infty} f(z)| \rightarrow + \infty$或者$|lim_{z\rightarrow +\infty} f(z)| \rightarrow + \infty$<br>
f是saturating 当且仅当f不是non-saturating<br>
<strong>例子</strong><br>
ReLU就是non-saturating nonlinearity的激活函数，因为$f(x) = max(0, x)$，如下图所示。<br>
<img src="/2019/03/13/cnn/relu.png" alt="relu"><br>
当$x$趋于无穷时，$f(x)$也趋于无穷。<br>
sigmod和tanh是saturating nonlinearity激活函数，如下图所示。<br>
<img src="/2019/03/13/cnn/sigmod.png" alt="sigmo"><br>
<img src="/2019/03/13/cnn/tanh.png" alt="tanh"></p>
<h4 id="多块gpu并行">多块GPU并行</h4>
<p>作者使用了两块GPU一块运行，每个GPU中的参数个数是一样的，在一些特定层中，两个GPU中的参数信息可以进行通信。</p>
<h4 id="overlapping-pooling">Overlapping Pooling</h4>
<p>就是Pooling kernel的size要比stride大。比如一个$12\times 12$的图片，用$5\times 5$的pooling kernel，步长为$3$，步长要比kernel核小，即$3$比$5$小。<br>
为什么这能减小过拟合？</p>
<ul>
<li>可能是减小了Pooling过程中信息的丢失。</li>
</ul>
<blockquote>
<p>If the pooling regions do not overlap, the pooling regions are disjointed and if that is the case, more information is lost in each pooling layer. If some overlap is allowed the pooling regions overlap with some degree and less spatial information is lost in each layer.[4]</p>
</blockquote>
<h4 id="数据增强">数据增强</h4>
<p>目的：防止过拟合</p>
<h5 id="裁剪和翻转">裁剪和翻转</h5>
<p>输入是$256\times 256 \times 3$的图像。<br>
训练：对每张图片都提取多个$224\times 224$大小的patch，这样子总共就多产生了$(256-224)\times (256-224) = 1024$个样本，然后对每个patch做一个水平翻转，就有$1024\times 2 = 2048$个样本。<br>
测试：通过对每张图片裁剪五个（四个角落加中间）$224\times 224$的patches，并且对它们做翻转，也就是有$10$个patches，网络对十个patch的softmax层输出做平均作为预测结果。</p>
<h5 id="在图片上调整rgb通道的密度">在图片上调整RGB通道的密度</h5>
<p>使用PCA对RGB值做主成分分析。对于每张训练图片，加上主成分，其大小正比于特征值乘上一个均值为$0$，方差为$0.1$的高斯分布产生的随机变量。对于一张图片$x,y$点处的像素值$I_{xy}=[I_{xy}^R, I_{xy}<sup>G,I_{xy}</sup>B]^T$，加上$[\bold{p_1},\bold{p_2},\bold{p_3}][\alpha_1\lambda_1,\alpha_2\lambda_2,\alpha_3\lambda_3]$，其中$[\bold{p_1},\bold{p_2},\bold{p_3}]$是特征向量，$\lambda_i$是特征值，$\alpha_i$就是前面说的随机变量。</p>
<h4 id="dropout">Dropout</h4>
<p>通过学习鲁棒的特征防止过拟合。<br>
在训练的时候，每个隐藏单元的输出有$p$的概率被设置为$0$，在该次训练中，如果这个神经元的输出被设置为$0$，它就对loss函数没有贡献，反向传播也不会被更新。对于一层有$N$个神经单元的全连接层，总共有$2^N$种神经元的组合结果，这就相当于训练了一系列共享参数的模型。<br>
在测试的时候，所有隐藏单元的输出都不丢弃，但是会乘上$p$的概率，相当于对一系列集成模型取平均。具体可见<a href="https://mxxhcm.github.io/2019/03/23/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-dropout/">dropout</a><br>
在该模型中，作者在三层全连接层的前两层输出上加了dropout。</p>
<h4 id="局部响应归一化-local-response-normalizaiton">局部响应归一化(Local Response Normalizaiton)</h4>
<p>事实上，后来发现这个东西没啥用。但是这里还是给出一个公式。</p>
<p>$$ b^i_{x,y} = \frac{a^i_{x,y}}{(k+\alpha \sum<sup>{min(N-1,\frac{i+n}{2})}_{j=max(0,\frac{i-n}{2})}(a</sup>j_{x,y})^2)^{\beta}}$$<br>
其中$a^i_{x,y}$是在点$(x,y)$处使用kernel $i$之后，在经过ReLU激活函数。$k,n,\alpha,\beta$是超参数。</p>
<blockquote>
<p>It seems that these kinds of layers have a minimal impact and are not used any more. Basically, their role have been outplayed by other regularization techniques (such as dropout and batch normalization), better initializations and training methods.</p>
</blockquote>
<h3 id="整体架构">整体架构</h3>
<h4 id="目标函数">目标函数</h4>
<p>多峰logistic回归。</p>
<h4 id="并行框架">并行框架</h4>
<p>下图是并行的架构，分为两层，上面一层用一个GPU，下面一层用一个GPU，它们只在第三个卷积层有交互。<br>
<img src="/2019/03/13/cnn/alexnet.png" alt="alexnet"></p>
<h4 id="简化框架">简化框架</h4>
<p>下图是简化版的结构，不需要使用两个GPU。<br>
<img src="/2019/03/13/cnn/alexnet_simple.png" alt="alexnet_simple"></p>
<h4 id="数据流-简化框架">数据流（简化框架）</h4>
<p>输入是$224\times 224 \times 3$的图片，第一层是$96$个stride为$4$的$11\times 11\times 3$卷积核构成的卷积层，输出经过max pooling(步长为2，kernel size为3)输入到第二层；第二层有$256$个$5\times 5\times 96$个卷积核，输出经过max pooling(步长为2，kernel size为3)输入到第三层；第三层到第四层，第四层到第五层之间没有经过pooling和normalization)，第三层有384个$3\times 3\times 256$个卷积核，第四层有$384$个$3\times 3\times 384$个卷积核，第五层有$256$个$3\times 3\times 384$个卷积核。然后接了两个$2048$个神经元的全连接层和一个$1000$个神经元的全连接层。</p>
<h3 id="实验">实验</h3>
<h4 id="datasets">Datasets</h4>
<p>ILSVRC-2010</p>
<h4 id="baselines">Baselines</h4>
<ul>
<li>Sparse coding</li>
<li>SIFT+FV</li>
<li>CNN</li>
</ul>
<h4 id="metric">Metric</h4>
<ul>
<li>top-1 error rate</li>
<li>top-5 error rate</li>
</ul>
<h3 id="代码">代码</h3>
<p>pytorch实现<br>
<a href="https://github.com/mxxhcm/myown_code/blob/master/CNN/alexnet.py" target="_blank" rel="noopener">https://github.com/mxxhcm/myown_code/blob/master/CNN/alexnet.py</a></p>
<h2 id="overfeat-2013">OverFeat(2013)</h2>
<p>论文名称：OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks<br>
论文地址：<a href="https://arxiv.org/pdf/1312.6229.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1312.6229.pdf</a></p>
<h3 id="概述-v2">概述</h3>
<p>本文提出了一个可用于classification, localization和detection等任务的CNN框架。<br>
ImageNet数据集中大部分选择的是几乎填满了整个image中心的object，image中我们感兴趣的objects的大小和位置也可能变化很大。为了解决这个问题，作者提出了三个方法：</p>
<ol>
<li>用sliding window和multiple scales在image的多个位置apply ConvNet。即使这样，许多window中可能包含能够完美识别object类型的一部分，比如一个狗头。。。最后的结果是classfication很好，但是localization和detection结果很差。</li>
<li>训练一个网络不仅仅预测每一个window的category distribution，还预测包含object的bounding box相对于window的位置和大小。</li>
<li>在每个位置和大小累加每个category的evidence</li>
</ol>
<h3 id="vision任务">Vision任务</h3>
<p>classification，localization和detection。classification和localization通常只有一个很大的object，而detection需要找到很多很小的objects。<br>
classification任务中，每个image都有一个label对应image中主要的object的类型。为了找到正确的label，每个图片可以猜$5$次（图片中可能包含了没有label的数据）。localization任务中，不仅要给出label，还需要找到这个label对应的bouding box，bounding box和groundtruth至少要有$50$匹配，label和bounding box也需要匹配。detection和localization不同的是，detection任务中可以有任何数量的objects，false positive会使用mean average precison measure。localization任务可以看成classification到detection任务的一个中间步。</p>
<h3 id="fcn">FCN</h3>
<p>用卷积层代替全连接层。具体是什么意思呢。<br>
alexnet中，有5层卷积层，3层全连接层。假设第五层的输出是$5\times 5 \times 512$，$512$是output channels number，$5\times 5$是第五层的feature maps大小。如果使用全连接的话，假设第六层的输出单元是$N$个，第六层权重总共是$(5\times 5\times 512) * (N)$，对于一个训练好的网络，图片的输入大小是固定的，因为第六层的输入需要固定。如果输入一个其他大小的图片，网络是会出错的，所以就有了Fully Convolutional networks，它可以处理不同大小的输入图片。<br>
如下所示，使用某个大小的image训练的网络，在classifier处用卷积层替换全连接层，如果使用全连接层，首先将$(5, 5, out_channels)$的feature map进行flatten $5\times 5\times out_channels$，然后经过三层全连接，最后输出一个softmax的结果。而fcn使用卷积层代替全连接，使用$N$个$5\times 5$的卷积核，直接得到$1\tims 1 \times N$的结果，最后得到一个$1\times 1\times C$的输出，$C$代表图像类别，$N$代表全连接层中隐藏节点的数量。<br>
<img src="/2019/03/13/cnn/fcn.png" alt="fcn"><br>
事实上，FCN和全连接的本质上都是一样的，只不过一个进行了flatten，一个直接对feature map进行操作，直接对feature map操作可以处理不同大小的输入，而flatten不行。<br>
当输入图片大小发生变化时，输出大小也会改变，但是网络并不会出错，如下所示：<br>
<img src="/2019/03/13/cnn/fcn2.png" alt="fcn2"><br>
最后输出的结果是$2\times 2 \times C$的结果，可以直接对它们取平均，最后得到一个$1\times 1\times C$的分类结果。</p>
<h3 id="offset-max-pooling">offset Max pooling</h3>
<p>我们之前做max pooling的时候，设$kernel_size=3, stride_size=1$，如果feature map是$3$的倍数，那么只有一个pooling的结果，但是如果不是$3$的倍数，max pooling会很多个结果，比如有个$20\times 20$的feature map，在$x,y$上做max pooling分别有三种结果，分别从$x,y$的位置$0$开始，位置$1$开始，位置$2$开始，排列组合有$9$中情况，这九种情况的结果是不同的。<br>
如下图所示，在一维的长为$20$的pixels上做maxpooling，有三种情况。<br>
<img src="/2019/03/13/cnn/offset_maxpooling.png" alt="offset_maxpooling"></p>
<h3 id="overfeat">overfeat</h3>
<p>这两个方法中，fcn是在输入图片上进行的window sliding，而offset maxpooling是在feature map进行的window sliding，这两个方法结合起来就是overfeat，要比alexnet直接在输入图片上进行window sliding 要好。</p>
<h3 id="classification">Classification</h3>
<h4 id="training">training</h4>
<ul>
<li>datset<br>
Image 2012 trainign set（1.2million iamges，C=$1000$ classes)。</li>
<li>data argumented<br>
对每张图片进行下采样，所以每个图片最小的dimension需要是$256$。<br>
提取$5$个random crops以及horizaontal flips，总共$10$个$221\times 221$的图片</li>
<li>batchsize<br>
$128$</li>
<li>初始权重<br>
$(\mu, \sigma)= (0, 1\times 10^{-2})$</li>
<li>momentum<br>
0.6</li>
<li>l2 weigth decay<br>
$1\times 10^{-5}$</li>
<li>lr<br>
初始是$5\times 10^{-2}$，在$(30,50,60,70,80)$个epoches后，乘以$0.5$</li>
<li>non-spatial<br>
这个说的是什么呢，在test的时候，会输出多个output maps，对他们的结果做平均，而在training的时候，output maps是$1\times 1$。</li>
</ul>
<h4 id="model架构">model架构</h4>
<p>下图展示的是fast model，spatial input size在train和test时候是不同的，这里展示的是train时的spatial seize。layer 5是最上层的CNN，receptive filed最大。后续是FC layers，在test时候使用了sliding window。在spatial设置中，FC-layers替换成了$1\times 1$的卷积。<br>
<img src="/2019/03/13/cnn/overfeat_fast.png" alt="overfeat_fast"><br>
下图给出了accuracy model的结构，<br>
<img src="/2019/03/13/cnn/overfeat_accuracy.png" alt="overfeat_accuracy"><br>
总的来说，这两个模型都在alexnet上做了一些修改，但是整体架构没有大的创新。</p>
<h4 id="多scale-classification">多scale classification</h4>
<p>alexnet中，对一张照片的$10$个views（中间，四个角和horizontal flip)的结果做了平均，这种方式可能会忽略很多趋于，同时如果不同的views有重叠的话，计算很redundant。此外，alexnet中只使用了一个scale。<br>
作者对每个iamge的每一个location和多个scale都进行计算。<br>
如下图，对应了不同大小的输入图片，layer 5 post pool中$(m\times n)\time(3\times 3)$，前面$m\times n$是fcn得到的不同位置的feature map，后面$3\times 3$是$kernel_size=3$的offset max pooling得到的featrue map。乘起来是所有的预测结果。<br>
<img src="/2019/03/13/cnn/multi_scale.png" alt="multi_scale"></p>
<h3 id="localization">localization</h3>
<h3 id="detection">Detection</h3>
<h2 id="vgg-2013">VGG(2013)</h2>
<p>论文名称：VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION<br>
论文地址：<a href="https://arxiv.org/pdf/1409.1556.pdf%20http://arxiv.org/abs/1409.1556.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1409.1556.pdf http://arxiv.org/abs/1409.1556.pdf</a></p>
<h3 id="概述-v3">概述</h3>
<p>这篇文章主要研究了CNN深度对大规模图像识别问题精度的影响。本文的主要contribution就是使用$3\times 3$的卷积核，增加网络深度，提高识别精度。</p>
<h3 id="方案">方案</h3>
<h4 id="架构">架构</h4>
<p><strong>训练</strong>，输入$224\times 224$大小的RGB图片。对每张图片减去训练集上所有图片RGB 像素的均值。预处理后的图片被输入多层CNN中，CNN的filter是$3\times 3$的，作何也试了$1\times 1$的filter，相当于对输入做了一个线性变换，紧跟着一个non-linear 激活函数。stride设为$1$，添加padding使得卷积后的输出大小不变。同时使用了$5$个max-pooling层（并不是每一层cnn后面都有max-pooling)，max-pooling在$2\times 2$大小的窗口上，stride是$2$。<br>
多层CNN后面接的是三个FC layers，前两个是$4096$单元，最后一层是$1000$个单元的softmax。所有隐藏层都使用ReLu非线性激活函数。</p>
<h4 id="配置">配置</h4>
<p>这篇文章给出了五个网络架构，用$A-E$表示，它们只有在深度上有所不同：从$11$层($8$个conv layers和$3$个FC layers)到$19$层（$16$个conv layers和$3$个FC layers）。Conv layers的channels很小，从第一层的$64$，每过一个max pooling layers，变成原理啊的两倍，直到$512$。具体如下表所示。<br>
<img src="/2019/03/13/cnn/vgg_conf.png" alt="vgg_conf"><br>
网络的参数个数如下表所示。<br>
<img src="/2019/03/13/cnn/vgg_weights_num.png" alt="vgg_weights_num"><br>
网络$A$的参数计算：<br>
\begin{align*}<br>
64\times 3\times 3\times 3 + \\<br>
128\times 3\times 3\times 64 + \\<br>
256\times 3\times 3\times 128 + \\<br>
256\times 3\times 3\times 256 + \\<br>
512\times 3\times 3\times 256 + \\<br>
512\times 3\times 3\times 512 + \\<br>
2\times 512\times 3\times 3\times 512 + \\<br>
7\times 7\times 512\times 4096 + \\<br>
4096\times 4096 + \\<br>
4096\times 1000 = \\<br>
132851392<br>
\end{align*}<br>
网络$B$的参数计算：<br>
\begin{align*}<br>
64\times 3\times 3\times 3 + \\<br>
128\times 3\times 3\times 64 + \\<br>
128\times 3\times 3\times 128 + \\<br>
256\times 3\times 3\times 128 + \\<br>
256\times 3\times 3\times 256 + \\<br>
256\times 3\times 3\times 256 + \\<br>
512\times 3\times 3\times 256 + \\<br>
512\times 3\times 3\times 512 + \\<br>
2\times 512\times 3\times 3\times 512 + \\<br>
7\times 7\times 512\times 4096 + \\<br>
4096\times 4096 + \\<br>
4096\times 1000 = \\<br>
133588672<br>
\end{align*}<br>
其实主要的网络参数还是在全连接层，$7\times 7\times 512\times 4096=102760448<br>
$。</p>
<h4 id="卷积核作用">卷积核作用</h4>
<ol>
<li>为什么要用三个$3\times 3$的conv layers替换$7\times 7$个conv layers？</li>
</ol>
<ul>
<li>使用三个激活函数而不是一个，让整个决策更discriminative。</li>
<li>减少了网络参数，三个有$C$个通道的$3\times 3$conv layers,总的参数是$3\tims(3<sup>2C</sup>2)=27C^2$，而一个$C$通道的$7\times 7$ conv layers，总参数是$49C^2$。可以看成是一种正则化。</li>
</ul>
<ol start="2">
<li>$1\times 1$ conv layers用来增加非线性程度，本文中使用的$1\times 1$的conv layers可以看成加了非线性激活函数的投影。</li>
</ol>
<h3 id="分类框架">分类框架</h3>
<h4 id="training-v2">training</h4>
<ul>
<li>目标函数<br>
多峰logistic regression</li>
<li>训练方法<br>
mini-batch gradient descent with momentum</li>
<li>batch size<br>
256</li>
<li>momentum<br>
0.9</li>
<li>正则化<br>
$L_2$参数正则化(5\codt 10^{-4})<br>
0.5 dorpout 用于前两个FC layers</li>
<li>lr<br>
初始值为$10^{-2}$，当验证集的accuracy不再提升时，除以$10$。学习率总共降了$3$次，$370K$次迭代后停止。</li>
<li>图像预处理<br>
从rescaled中随机cropped $224\times 224$的RGB图像。<br>
使用alexnet中的随机horizontal flipping和随机RGB colour shift。</li>
<li>iamge rescale<br>
用$S$表示training image的小边的大小，$S$也叫作train sacle。网络的输入是从training image中cropped得到的$224\times 224$的图像。所以只要$S$取任何不小于$224$的值即可，如果$S=224$，那么crop在统计上会captuer整个图片，完全包含training image最小的那边；$S&gt;&gt;224$的时候，crop会产生很小一部分的图像。<br>
作者尝试了固定$S$和不固定的$S$。对于固定$S$，设置$S=256$和$S=384$，首先在$S=256$上训练，然后用$S=256$训练的参数初始化$S=384$的参数，使用更小的初始学习率$10^{-3}$。不固定$S$时，$S$从$[S_{min}, S_{max}](S_{max}=512,S_{min}=256)$任意采样，然后crop。</li>
<li>VGG vs alexnet<br>
VGG参数多，深度深，但是收敛快，原因：</li>
</ul>
<ol>
<li>更小的filter带来的implicit regularisation</li>
<li>某些层的预先初始化。<br>
这个解决的是网络深度过深，某些初值使得网络不稳定的问题。解决方法：先随机初始化不是很深的网络A，进行训练。在训练更深网络的时候，使用A网络的值初始化前$4$个卷基层和最后三个FC layers。随机初始化的网络参数，从均值为$0$，方差为$10^{-2}$的高斯分布中采样得到。</li>
</ol>
<h4 id="testing">testing</h4>
<ol>
<li>测试的时候先把input image的窄边缩放到$Q$，$Q$也叫test scale，$Q$和$S$不一定需要相等。</li>
<li>这里和overfeat模型一样，在卷积网络之后采用了fcn，而不是fc layers。</li>
</ol>
<h3 id="classfication">classfication</h3>
<p>ILSVRC-2012，training($1.3M$张图片)，validation($50K张$)，testing($100K$张)<br>
两个metrics：top-1和top-5 error。top-1 error是multi-class classification error，不正确分类图像占的比例；top-5 error是预测的top-5都不是ground-truth。</p>
<h4 id="single-scale-evaluation">single scale evaluation</h4>
<p>$S$固定时，设置test image size $Q=S=256$；<br>
$S$抖动时，设置test image size $Q=0.5(S_{min}+S_{max})=0.5(256+512)=384$，$S\in [S_{min},S_{max}]$。</p>
<h4 id="multi-scale-evaluation">multi scale evaluation</h4>
<p>用同一个模型对不同rescaled大小的图片多次test，即对于不同的$Q$。<br>
固定$S$时，在三个不同大小的test image size $Q={S-32,S,S+32}$评估。<br>
$S$抖动时，模型是在$S\in [S_{min},S_{max}]$上训练的，在$Q={S_{min}, 0.5(S_{min}+S_{max}), S_{max}}$上进行test。</p>
<h4 id="多个crop-evaluation">多个crop evaluation</h4>
<p>这个是为了和alexnet做对比，alexnet网络在testing时，对每一张图片都进行多次cropped，对testing的结果做平均。</p>
<h4 id="convnet-funsion">convnet funsion</h4>
<p>之前作者的evaluation都是在单个的网络上进行的，作者还试了将不同网络的softmax输出做了平均。</p>
<h2 id="net">Net</h2>
<p>论文名称：Visualizing and Understanding Convolutional Networks<br>
论文地址：<a href="https://cs.nyu.edu/~fergus/papers/zeilerECCV2014.pdf" target="_blank" rel="noopener">https://cs.nyu.edu/~fergus/papers/zeilerECCV2014.pdf</a></p>
<h3 id="概述-v4">概述</h3>
<p>这篇文章从可视化的角度给出中间特征的和classifier的特点，分析如何改进alexnet来提高imagenet classification的accuracy。<br>
为什么CNN结果这么好？</p>
<ol>
<li>training set越来越大</li>
<li>GPU的性能越来越好</li>
<li>Dropout等正则化技术</li>
</ol>
<p>但是CNN还是一个黑盒子，我们不知道它为什么表现这么好？这篇文章给出了一个可视化方法可视化任意层的feature。</p>
<p>那么本文的contribution是什么呢？使用deconvnet进行可视化。</p>
<h3 id="使用deconvnet可视化">使用deconvnet可视化</h3>
<p>什么是deconvnet？可以看成和convnet拥有同样组成部分（pooling, filter)等，但是是反过来进行的。convnet是把pixels映射到feature，或者到底层features映射到高层features，而deconvnet是把高层features映射到底层features，或者把features映射到pixels。如下图所示：<br>
<img src="/2019/03/13/cnn/fig1.png" alt="fig1"><br>
图片左上为</p>
<h3 id="存在的问题">存在的问题</h3>
<h3 id="方案-v2">方案</h3>
<h4 id="背景">背景</h4>
<h4 id="算法">算法</h4>
<h4 id="代码-v2">代码</h4>
<h2 id="none"></h2>
<h3 id="概述-v5">概述</h3>
<h3 id="存在的问题-v2">存在的问题</h3>
<h3 id="方案-v3">方案</h3>
<h4 id="背景-v2">背景</h4>
<h4 id="算法-v2">算法</h4>
<h4 id="代码-v3">代码</h4>
<h2 id="none-v2"></h2>
<h3 id="概述-存在的问题">概述 ### 存在的问题</h3>
<h3 id="方案-v4">方案</h3>
<h4 id="背景-v3">背景</h4>
<h4 id="算法-v3">算法</h4>
<h4 id="代码-v4">代码</h4>
<h2 id="none-v3"></h2>
<h3 id="概述-v6">概述</h3>
<h3 id="存在的问题-v3">存在的问题</h3>
<h3 id="方案-v5">方案</h3>
<h4 id="背景-v4">背景</h4>
<h4 id="算法-v4">算法</h4>
<h4 id="代码-v5">代码</h4>
<h2 id="参考文献">参考文献</h2>
<p>1.<a href="https://stats.stackexchange.com/a/174438" target="_blank" rel="noopener">https://stats.stackexchange.com/a/174438</a><br>
2.<a href="https://www.zhihu.com/question/264163033/answer/277481519" target="_blank" rel="noopener">https://www.zhihu.com/question/264163033/answer/277481519</a><br>
3.<a href="https://stats.stackexchange.com/questions/145768/importance-of-local-response-normalization-in-cnn" target="_blank" rel="noopener">https://stats.stackexchange.com/questions/145768/importance-of-local-response-normalization-in-cnn</a><br>
4.<a href="https://stats.stackexchange.com/a/386304" target="_blank" rel="noopener">https://stats.stackexchange.com/a/386304</a><br>
5.<a href="https://blog.csdn.net/luoyang224/article/details/78088582/" target="_blank" rel="noopener">https://blog.csdn.net/luoyang224/article/details/78088582/</a><br>
6.<a href="https://zhum.in/blog/project/TrafficSignRecognition/OverFeat%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/" target="_blank" rel="noopener">https://zhum.in/blog/project/TrafficSignRecognition/OverFeat论文阅读笔记/</a></p>

      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/CNN/" rel="tag"># CNN</a>
          
            <a href="/tags/卷积神经网络/" rel="tag"># 卷积神经网络</a>
          
            <a href="/tags/alexnet/" rel="tag"># alexnet</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/03/13/python-常见问题/" rel="next" title="python 常见问题（不定期更新）">
                <i class="fa fa-chevron-left"></i> python 常见问题（不定期更新）
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/03/14/神经网络-激活函数/" rel="prev" title="神经网络-激活函数">
                神经网络-激活函数 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  
    <div class="comments" id="comments">
      
        <div id="gitment-container"></div>
      
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/favicon.jpg" alt="马晓鑫爱马荟荟">
            
              <p class="site-author-name" itemprop="name">马晓鑫爱马荟荟</p>
              <p class="site-description motion-element" itemprop="description">记录硕士三年自己的积累</p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">139</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  <a href="/categories/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">13</span>
                    <span class="site-state-item-name">分类</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  <a href="/tags/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">120</span>
                    <span class="site-state-item-name">标签</span>
                  </a>
                </div>
              
            </nav>
          

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://github.com/mxxhcm" title="GitHub &rarr; https://github.com/mxxhcm" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="mailto:mxxhcm@gmail.com" title="E-Mail &rarr; mailto:mxxhcm@gmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                </span>
              
            </div>
          

          

          
          

          
            
          
          

        </div>
      </div>

      
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#alexnet-2012"><span class="nav-number">1.</span> <span class="nav-text">Alexnet(2012)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#概述"><span class="nav-number">1.1.</span> <span class="nav-text">概述</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#问题"><span class="nav-number">1.2.</span> <span class="nav-text">问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#创新"><span class="nav-number">1.3.</span> <span class="nav-text">创新</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#relu非线性激活函数"><span class="nav-number">1.3.1.</span> <span class="nav-text">ReLU非线性激活函数</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#作用"><span class="nav-number">1.3.1.1.</span> <span class="nav-text">作用</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#saturating-nonlinearity"><span class="nav-number">1.3.1.2.</span> <span class="nav-text">saturating nonlinearity</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#多块gpu并行"><span class="nav-number">1.3.2.</span> <span class="nav-text">多块GPU并行</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#overlapping-pooling"><span class="nav-number">1.3.3.</span> <span class="nav-text">Overlapping Pooling</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#数据增强"><span class="nav-number">1.3.4.</span> <span class="nav-text">数据增强</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#裁剪和翻转"><span class="nav-number">1.3.4.1.</span> <span class="nav-text">裁剪和翻转</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#在图片上调整rgb通道的密度"><span class="nav-number">1.3.4.2.</span> <span class="nav-text">在图片上调整RGB通道的密度</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#dropout"><span class="nav-number">1.3.5.</span> <span class="nav-text">Dropout</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#局部响应归一化-local-response-normalizaiton"><span class="nav-number">1.3.6.</span> <span class="nav-text">局部响应归一化(Local Response Normalizaiton)</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#整体架构"><span class="nav-number">1.4.</span> <span class="nav-text">整体架构</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#目标函数"><span class="nav-number">1.4.1.</span> <span class="nav-text">目标函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#并行框架"><span class="nav-number">1.4.2.</span> <span class="nav-text">并行框架</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#简化框架"><span class="nav-number">1.4.3.</span> <span class="nav-text">简化框架</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#数据流-简化框架"><span class="nav-number">1.4.4.</span> <span class="nav-text">数据流（简化框架）</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#实验"><span class="nav-number">1.5.</span> <span class="nav-text">实验</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#datasets"><span class="nav-number">1.5.1.</span> <span class="nav-text">Datasets</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#baselines"><span class="nav-number">1.5.2.</span> <span class="nav-text">Baselines</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#metric"><span class="nav-number">1.5.3.</span> <span class="nav-text">Metric</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#代码"><span class="nav-number">1.6.</span> <span class="nav-text">代码</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#overfeat-2013"><span class="nav-number">2.</span> <span class="nav-text">OverFeat(2013)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#概述-v2"><span class="nav-number">2.1.</span> <span class="nav-text">概述</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#vision任务"><span class="nav-number">2.2.</span> <span class="nav-text">Vision任务</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#fcn"><span class="nav-number">2.3.</span> <span class="nav-text">FCN</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#offset-max-pooling"><span class="nav-number">2.4.</span> <span class="nav-text">offset Max pooling</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#overfeat"><span class="nav-number">2.5.</span> <span class="nav-text">overfeat</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#classification"><span class="nav-number">2.6.</span> <span class="nav-text">Classification</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#training"><span class="nav-number">2.6.1.</span> <span class="nav-text">training</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#model架构"><span class="nav-number">2.6.2.</span> <span class="nav-text">model架构</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#多scale-classification"><span class="nav-number">2.6.3.</span> <span class="nav-text">多scale classification</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#localization"><span class="nav-number">2.7.</span> <span class="nav-text">localization</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#detection"><span class="nav-number">2.8.</span> <span class="nav-text">Detection</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#vgg-2013"><span class="nav-number">3.</span> <span class="nav-text">VGG(2013)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#概述-v3"><span class="nav-number">3.1.</span> <span class="nav-text">概述</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#方案"><span class="nav-number">3.2.</span> <span class="nav-text">方案</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#架构"><span class="nav-number">3.2.1.</span> <span class="nav-text">架构</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#配置"><span class="nav-number">3.2.2.</span> <span class="nav-text">配置</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#卷积核作用"><span class="nav-number">3.2.3.</span> <span class="nav-text">卷积核作用</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#分类框架"><span class="nav-number">3.3.</span> <span class="nav-text">分类框架</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#training-v2"><span class="nav-number">3.3.1.</span> <span class="nav-text">training</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#testing"><span class="nav-number">3.3.2.</span> <span class="nav-text">testing</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#classfication"><span class="nav-number">3.4.</span> <span class="nav-text">classfication</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#single-scale-evaluation"><span class="nav-number">3.4.1.</span> <span class="nav-text">single scale evaluation</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#multi-scale-evaluation"><span class="nav-number">3.4.2.</span> <span class="nav-text">multi scale evaluation</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#多个crop-evaluation"><span class="nav-number">3.4.3.</span> <span class="nav-text">多个crop evaluation</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#convnet-funsion"><span class="nav-number">3.4.4.</span> <span class="nav-text">convnet funsion</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#net"><span class="nav-number">4.</span> <span class="nav-text">Net</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#概述-v4"><span class="nav-number">4.1.</span> <span class="nav-text">概述</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#使用deconvnet可视化"><span class="nav-number">4.2.</span> <span class="nav-text">使用deconvnet可视化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#存在的问题"><span class="nav-number">4.3.</span> <span class="nav-text">存在的问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#方案-v2"><span class="nav-number">4.4.</span> <span class="nav-text">方案</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#背景"><span class="nav-number">4.4.1.</span> <span class="nav-text">背景</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#算法"><span class="nav-number">4.4.2.</span> <span class="nav-text">算法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#代码-v2"><span class="nav-number">4.4.3.</span> <span class="nav-text">代码</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#none"><span class="nav-number">5.</span> <span class="nav-text"></span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#概述-v5"><span class="nav-number">5.1.</span> <span class="nav-text">概述</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#存在的问题-v2"><span class="nav-number">5.2.</span> <span class="nav-text">存在的问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#方案-v3"><span class="nav-number">5.3.</span> <span class="nav-text">方案</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#背景-v2"><span class="nav-number">5.3.1.</span> <span class="nav-text">背景</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#算法-v2"><span class="nav-number">5.3.2.</span> <span class="nav-text">算法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#代码-v3"><span class="nav-number">5.3.3.</span> <span class="nav-text">代码</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#none-v2"><span class="nav-number">6.</span> <span class="nav-text"></span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#概述-存在的问题"><span class="nav-number">6.1.</span> <span class="nav-text">概述 ### 存在的问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#方案-v4"><span class="nav-number">6.2.</span> <span class="nav-text">方案</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#背景-v3"><span class="nav-number">6.2.1.</span> <span class="nav-text">背景</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#算法-v3"><span class="nav-number">6.2.2.</span> <span class="nav-text">算法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#代码-v4"><span class="nav-number">6.2.3.</span> <span class="nav-text">代码</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#none-v3"><span class="nav-number">7.</span> <span class="nav-text"></span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#概述-v6"><span class="nav-number">7.1.</span> <span class="nav-text">概述</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#存在的问题-v3"><span class="nav-number">7.2.</span> <span class="nav-text">存在的问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#方案-v5"><span class="nav-number">7.3.</span> <span class="nav-text">方案</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#背景-v4"><span class="nav-number">7.3.1.</span> <span class="nav-text">背景</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#算法-v4"><span class="nav-number">7.3.2.</span> <span class="nav-text">算法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#代码-v5"><span class="nav-number">7.3.3.</span> <span class="nav-text">代码</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#参考文献"><span class="nav-number">8.</span> <span class="nav-text">参考文献</span></a></li></ol></div>
            

          </div>
        </div>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">马晓鑫爱马荟荟</span>

  

  
</div>


  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.8.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> v6.6.0</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  
    <script src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  


  


  <script src="/js/src/utils.js?v=6.6.0"></script>

  <script src="/js/src/motion.js?v=6.6.0"></script>



  
  


  <script src="/js/src/affix.js?v=6.6.0"></script>

  <script src="/js/src/schemes/pisces.js?v=6.6.0"></script>



  
  <script src="/js/src/scrollspy.js?v=6.6.0"></script>
<script src="/js/src/post-details.js?v=6.6.0"></script>



  


  <script src="/js/src/bootstrap.js?v=6.6.0"></script>



  



  






<!-- LOCAL: You can save these files to your site and update links -->
    
        
        <link rel="stylesheet" href="https://aimingoo.github.io/gitmint/style/default.css">
        <script src="https://aimingoo.github.io/gitmint/dist/gitmint.browser.js"></script>
    
<!-- END LOCAL -->

    

    
      <script>
      function renderGitment(){
        var gitment = new Gitmint({
            id: window.location.pathname,
            owner: 'mxxhcm',
            repo: 'mxxhcm.github.io',
            
            lang: "" || navigator.language || navigator.systemLanguage || navigator.userLanguage,
            
            oauth: {
            
            
                client_secret: '9a33d210d29f526a771d47bff6940b5798b2631f',
            
                client_id: '61a64228cba52787dea0'
            }});
        gitment.render('gitment-container');
      }

      
      renderGitment();
      
      </script>
    







  





  

  

  

  

  
  

  
  

  
    
      <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      },
      TeX: {equationNumbers: { autoNumber: "AMS" }}
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<script src="//cdn.jsdelivr.net/npm/mathjax@2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<style>
.MathJax_Display {
    overflow: auto hidden;
}
</style>

    
  


  
  

  

  

  

  

  

  

</body>
</html>
