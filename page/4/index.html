<!DOCTYPE html>












  


<html class="theme-next pisces use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
































<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=6.6.0" rel="stylesheet" type="text/css">



  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.jpg?v=6.6.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.jpg?v=6.6.0">










<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '6.6.0',
    sidebar: {"position":"left","display":"always","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="è®°å½•ç¡•å£«ä¸‰å¹´è‡ªå·±çš„ç§¯ç´¯">
<meta property="og:type" content="website">
<meta property="og:title" content="mxxhcm&#39;s blog">
<meta property="og:url" content="http://mxxhcm.github.io/page/4/index.html">
<meta property="og:site_name" content="mxxhcm&#39;s blog">
<meta property="og:description" content="è®°å½•ç¡•å£«ä¸‰å¹´è‡ªå·±çš„ç§¯ç´¯">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="mxxhcm&#39;s blog">
<meta name="twitter:description" content="è®°å½•ç¡•å£«ä¸‰å¹´è‡ªå·±çš„ç§¯ç´¯">



  <link rel="alternate" href="/atom.xml" title="mxxhcm's blog" type="application/atom+xml">




  <link rel="canonical" href="http://mxxhcm.github.io/page/4/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>mxxhcm's blog</title>
  












  <noscript>
  <style>
    .use-motion .motion-element,
    .use-motion .brand,
    .use-motion .menu-item,
    .sidebar-inner,
    .use-motion .post-block,
    .use-motion .pagination,
    .use-motion .comments,
    .use-motion .post-header,
    .use-motion .post-body,
    .use-motion .collection-title { opacity: initial; }

    .use-motion .logo,
    .use-motion .site-title,
    .use-motion .site-subtitle {
      opacity: initial;
      top: initial;
    }

    .use-motion .logo-line-before i { left: initial; }
    .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">mxxhcm's blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="åˆ‡æ¢å¯¼èˆªæ ">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>é¦–é¡µ</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>æ ‡ç­¾</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>åˆ†ç±»</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>å½’æ¡£</a>

  </li>

      
      
    </ul>
  

  

  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mxxhcm.github.io/2019/09/15/gym-retro/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="é©¬æ™“é‘«çˆ±é©¬èŸèŸ">
      <meta itemprop="description" content="è®°å½•ç¡•å£«ä¸‰å¹´è‡ªå·±çš„ç§¯ç´¯">
      <meta itemprop="image" content="/images/favicon.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="mxxhcm's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/09/15/gym-retro/" class="post-title-link" itemprop="http://mxxhcm.github.io/page/4/index.html">gym retro</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">å‘è¡¨äº</span>
              

              
                
              

              <time title="åˆ›å»ºæ—¶é—´ï¼š2019-09-15 20:28:55" itemprop="dateCreated datePublished" datetime="2019-09-15T20:28:55+08:00">2019-09-15</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">æ›´æ–°äº</span>
                
                <time title="ä¿®æ”¹æ—¶é—´ï¼š2019-10-21 23:32:24" itemprop="dateModified" datetime="2019-10-21T23:32:24+08:00">2019-10-21</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">åˆ†ç±»äº</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/gym/" itemprop="url" rel="index"><span itemprop="name">gym</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="gym-retro">Gym Retro</h2>
<h3 id="ä»€ä¹ˆæ˜¯gym-retroï¼Ÿ">ä»€ä¹ˆæ˜¯Gym Retroï¼Ÿ</h3>
<p>å°†ä¸åŒå¹³å°çš„video gameséƒ½è½¬æ¢æˆgym environmentsã€‚Gym-retroåŒ…æ‹¬äº†RLEå’ŒALEä¸¤ä¸ªç¯å¢ƒï¼Œå¯ä»¥ä½¿ç”¨ç»Ÿä¸€çš„gymæ¥å£è¿›è¡Œç®¡ç†ï¼Œæ›´çµæ´»ï¼Œæ›´å®¹æ˜“æ‰©å±•ã€‚</p>
<h3 id="åˆ›å»ºgym-retroçš„ç›®çš„">åˆ›å»ºgym retroçš„ç›®çš„</h3>
<p>æ­¤å‰transfer learning in RLï¼Œæœ‰ä¸¤ç§é€šç”¨çš„evaluationï¼š</p>
<ul>
<li>åœ¨äººå·¥åˆæˆçš„taskä¸Šè¿›è¡Œevaluation</li>
<li>åœ¨ALEç¯å¢ƒä¸Šè¿›è¡Œevaluation<br>
è¿™ä¸¤ç§æ–¹å¼éƒ½æœ‰ç¼ºé™·ï¼šå‰è€…çš„è¯ä¸åŒçš„ç®—æ³•ä¹‹é—´å¾ˆéš¾æ¯”è¾ƒï¼Œåè€…çš„è¯ï¼Œæ•ˆæœå¾ˆå·®ï¼Œå› ä¸ºä¸åŒçš„æ¸¸æˆä¹‹é—´å·®å¼‚å¯èƒ½å¾ˆå¤§ã€‚<br>
æœ¬æ–‡çš„æå‡ºçš„gym-retroå¯ä»¥ï¼š</li>
</ul>
<ol>
<li>ä½œä¸ºfew-shot RLçš„benchmarkï¼Œä»ä¸€ä¸ªsingle task distributionä¸­samplingè®¸å¤šsimlar tasksã€‚</li>
<li>ä½œä¸ºtransfer learningçš„benchmarkï¼Œæä¾›cross-taskçš„datasetã€‚åˆ’åˆ†train/testè®©agentå­¦ä¼šåœ¨some levelsè¿›è¡Œexploreï¼Œè¿ç§»åˆ°å…¶ä»–levelsã€‚</li>
</ol>
<h3 id="åŒ…å«å“ªäº›å¹³å°">åŒ…å«å“ªäº›å¹³å°</h3>
<ul>
<li>Atari</li>
<li>NEC</li>
<li>Nintndo</li>
<li>Sega</li>
</ul>
<h3 id="åŒ…å«å“ªäº›roms">åŒ…å«å“ªäº›ROMs</h3>
<ul>
<li>the 128 sine-dot by Anthrox</li>
<li>Sega Tween by Ben Ryves</li>
<li>Happy 10! by Blind IO</li>
<li>512-Colour Test Demo by Chris Covell</li>
<li>Dekadrive by Dekadence</li>
<li>Automaton by Derek Ledbetter</li>
<li>Fire by dox</li>
<li>FamiCON intro by dr88</li>
<li>Airstriker by Electrokinesis</li>
<li>Lost Marbles by Vantage</li>
</ul>
<h2 id="sonic-benchmark">Sonic benchmark</h2>
<h3 id="gym-retro-v2">Gym Retro</h3>
<p>Sonich benchmarkçš„åº•å±‚å®ç°æ˜¯Gym Retroï¼Œå®ƒå¯ä»¥æä¾›æ¥å£ç»™è¯¸å¦‚RLE gameå°†å…¶å°è£…æˆgym environmentã€‚<br>
æ¯ä¸ªgameç”±ROM, ä¸€ä¸ªæˆ–è€…å¤šä¸ªsave statesï¼Œä¸€ä¸ªæˆ–è€…å¤šä¸ªscenariosï¼Œè¿˜æœ‰ä¸€ä¸ªdata fileã€‚</p>
<ul>
<li>ROMï¼šç»„æˆgameçš„ä»£ç å’Œæ•°æ®ã€‚</li>
<li>Save stateï¼šconsoleâ€™s stateçš„æˆªå›¾ã€‚</li>
<li>Data fileï¼šæè¿°å„ç§å„æ ·çš„informationåœ¨console memoryçš„å“ªä¸ªåœ°æ–¹å­˜ç€ã€‚</li>
<li>Scenarioï¼šæè¿°done conditionså’Œreward functionsã€‚</li>
</ul>
<h3 id="sonic-game">Sonic game</h3>
<p>Sonic benchmarkä¸­æœ‰ä¸‰ä¸ªç›¸ä¼¼çš„æ¸¸æˆï¼š$Sonic The Hedgehog^{TM} $, $Sonic The Hedgehog^{T} 2$, $Sonic 3 Knuckles$ï¼Œè¿™äº›æ¸¸æˆå…·æœ‰ç›¸ä¼¼çš„è§„åˆ™ï¼Œå¯èƒ½æœ‰ä¸€äº›å·®åˆ«ï¼Œä½†æ˜¯ä¸å¤§ã€‚<br>
æ¯ä¸ªSonic gameéƒ½æœ‰zonesï¼Œæ¯ä¸ªzoneåˆè¢«åˆ’åˆ†æˆactsã€‚æ¯ä¸ªzoneæœ‰ç‹¬ç‰¹çš„çº¹ç†å’Œç‰©ä½“ï¼›æ¯ä¸ªzoneä¸­çš„actæœ‰ç›¸åŒçš„é—®é¢˜ï¼Œä½†æ˜¯å¸ƒå±€ä¸åŒã€‚ä¸€ä¸ª(ROM, zone, act)è¢«ç§°ä¸ºä¸€ä¸ªlevelã€‚</p>
<h3 id="games-and-levels">Games and Levels</h3>
<p>Sonic benchmarkä¸­æ‰€æœ‰çš„gamesæ€»å…±æœ‰$58$ä¸ªsave statesï¼Œæ¯ä¸€ä¸ªsave stateå¯¹åº”ä¸€ä¸ªä¸åŒçš„levelã€‚<br>
é€‰å–test setçš„æ—¶å€™éšæœºé€‰å–è¶…è¿‡$1$ä¸ªactçš„zonesï¼Œç„¶åä»ä¸­éšæœºé€‰å–ä¸€ä¸ªactã€‚è¿™æ ·å­ï¼Œtest setä¸­å·¨å¤§éƒ¨åˆ†çš„çº¹ç†å’Œç‰©ä½“éƒ½åœ¨training setä¸­å‡ºç°è¿‡ï¼Œåªä¸è¿‡layoutsä¸åŒã€‚æ‰€æœ‰çš„test levelså¦‚ä¸‹ï¼š</p>
<table>
<thead>
<tr>
<th style="text-align:center">ROM</th>
<th style="text-align:center">Zone</th>
<th style="text-align:center">Act</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Sonic The Hedgehog</td>
<td style="text-align:center">SpringYardZone</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">Sonic The Hedgehog</td>
<td style="text-align:center">GreenHillZone</td>
<td style="text-align:center">2</td>
</tr>
<tr>
<td style="text-align:center">Sonic The Hedgehog</td>
<td style="text-align:center">StarLightZone</td>
<td style="text-align:center">3</td>
</tr>
<tr>
<td style="text-align:center">Sonic The Hedgehog</td>
<td style="text-align:center">ScrapBrainZone</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">Sonic The Hedgehog 2</td>
<td style="text-align:center">MetropolisZone</td>
<td style="text-align:center">3</td>
</tr>
<tr>
<td style="text-align:center">Sonic The Hedgehog 2</td>
<td style="text-align:center">HillTopZone</td>
<td style="text-align:center">2</td>
</tr>
<tr>
<td style="text-align:center">Sonic The Hedgehog 2</td>
<td style="text-align:center">CasinoNightZone</td>
<td style="text-align:center">2</td>
</tr>
<tr>
<td style="text-align:center">Sonic 3 &amp; Knuckles</td>
<td style="text-align:center">LavaReefZone</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">Sonic 3 &amp; Knuckles</td>
<td style="text-align:center">FlyingBatteryZone</td>
<td style="text-align:center">2</td>
</tr>
<tr>
<td style="text-align:center">Sonic 3 &amp; Knuckles</td>
<td style="text-align:center">HydrocityZone</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">Sonic 3 &amp; Knuckles</td>
<td style="text-align:center">AngelIslandZone</td>
<td style="text-align:center">2</td>
</tr>
</tbody>
</table>
<h3 id="frame-skip">Frame skip</h3>
<p>step()æ–¹æ³•çš„è°ƒç”¨é¢‘ç‡æ˜¯$60$hzï¼Œdqnä¸­ç»å¸¸ä½¿ç”¨çš„frames skipä¸º$4$ï¼ŒSonic benchmarkä¹Ÿç”¨äº†ï¼Œç”¨timestepè¡¨ç¤ºä½¿ç”¨äº†frame skipä¹‹åä¸€æ­¥çš„æ—¶é•¿ï¼Œä¹Ÿå°±æ˜¯$\frac{4}{60}$ã€‚<br>
Sonic benmearkå¯¹frame skipåšäº†ä¸€äº›æ”¹å˜ï¼Œå«åšstick frame skipã€‚å¯¹äºagentçš„actionåŠ äº†ä¸€äº›éšæœºæ€§ï¼šæ¯éš”$n$å¸§ä¹‹åçš„é‚£ä¸€å¸§ï¼Œæœ‰$0.25$çš„æ¦‚ç‡ç»§ç»­åº”ç”¨ä¹‹å‰çš„é‚£ä¸ªactionã€‚</p>
<h3 id="episode-boundaries">Episode boundaries</h3>
<p>æ¸¸æˆä¸­çš„experienceåˆ’åˆ†ä¸ºepisodesï¼Œå¤§æ¦‚å¯¹åº”æœ‰å‡ æ¡å‘½ã€‚æ¯ä¸€ä¸ªepisodeç»“æŸï¼Œé‡ç½®åˆ°ç›¸åº”çš„save stateã€‚æ¯ä¸ªepisodesç»“æŸçš„æ¡ä»¶æœ‰ä»¥ä¸‹å‡ ç§ï¼š</p>
<ul>
<li>é€šå…³ï¼Œå»æ‰äº†bossï¼Œé€šè¿‡æ°´å¹³æ–¹å‘ä¸Šä¸€ä¸ªç‰¹å®šçš„åç§»é‡å°±ç®—é€šå…³ã€‚</li>
<li>å°‘äº†ä¸€æ¡å‘½</li>
<li>å½“å‰episodeç´¯è®¡ç©äº†$4500$ä¸ªtimestepsï¼Œå¤§æ¦‚æ˜¯$5$åˆ†é’Ÿã€‚</li>
</ul>
<h3 id="observations">Observations</h3>
<p>24ä½RBGå›¾åƒï¼ŒSonicæ˜¯$320 \times 224 $</p>
<h3 id="actions">Actions</h3>
<p>æ‰€æœ‰çš„Sega Genesisæ¸¸æˆçš„action spaceåŒ…å«ï¼š<br>
B, A, MODE, START, UP, DOWN, LEFT, RIGHT, C, Y, X, Z<br>
Sonic gameä¸­æœ‰å…«ä¸ªå¾ˆé‡è¦çš„buttion combinations:<br>
{ {}, {LEFT},  {RIGHT}, {LEFT, DOWN}, {RIGHT, DOWN}, {DOWN}, {DOWN, B}, {B} }</p>
<h3 id="rewards">Rewards</h3>
<p>åœ¨ä¸€ä¸ªepisodeä¸­ï¼Œcumulative rewardå’Œç©å®¶çš„åˆå§‹ä½ç½®åˆ°å½“å‰ä½ç½®çš„åç§»æ˜¯æˆæ­£æ¯”çš„ã€‚ä¹Ÿå°±æ˜¯è¯´å¾€å³èµ°äº§ç”Ÿæ­£çš„rewardï¼Œå¾€å·¦èµ°äº§ç”Ÿè´Ÿçš„rewardã€‚<br>
Rewardç”±horimontal offsetå’Œcompletion bonusæ„æˆã€‚Completion bonusæ˜¯$1000$ï¼Œåœ¨$4500$ä¸ªtimestepså†…çº¿æ€§é™ä¸º$0$ã€‚<br>
ä½†æ˜¯imediate rewardå¯èƒ½æ˜¯æœ‰æ¬ºéª—æ€§çš„ï¼Œæœ‰æ—¶å€™ä¸ºäº†è·å¾—æ›´å¤§çš„rewardå¾€å›èµ°æ˜¯å¿…é¡»çš„ã€‚</p>
<h3 id="evaluation">Evaluation</h3>
<p>ä½¿ç”¨test setä¸­æ‰€æœ‰levelsçš„mean scoreä½œä¸ºmetricã€‚æ­¥éª¤å…¥å¦‚ä¸‹ï¼š</p>
<ol>
<li>è®­ç»ƒæ—¶å€™ï¼Œä½¿ç”¨ä»»æ„æ•°é‡çš„è®­ç»ƒé›†ï¼ˆä½ å–œæ¬¢å¤šå°‘å°±ç”¨å¤šå°‘ï¼‰è®­ç»ƒ</li>
<li>æµ‹è¯•çš„æ—¶å€™ï¼Œæ¯ä¸€ä¸ªtest levelsæ‰§è¡Œ$100$ä¸‡ä¸ªtimestepsã€‚åœ¨testæ¯ä¸€ä¸ªlevelçš„æ—¶å€™éƒ½æ˜¯åˆ†å¼€çš„ã€‚</li>
<li>å¯¹æ¯ä¸ªlevelçš„$100$ä¸‡ä¸ªtimestepsä¸­æ‰€æœ‰episodeçš„total rewardsè¿›è¡Œå¹³å‡ã€‚</li>
<li>å¯¹æ‰€æœ‰test levelçš„scoresè¿›è¡Œå¹³å‡ã€‚</li>
</ol>
<p>è¿™ä¸ª$100$ä¸‡æ˜¯æ€ä¹ˆé€‰å‡ºæ¥çš„ï¼Ÿåœ¨æ— é™ä¸ªtimestepçš„åœºæ™¯ä¸‹ï¼Œæ²¡æœ‰è¯æ˜meta-learningæˆ–è€…transfer-learningæ˜¯å¿…è¦çš„ï¼Œä½†æ˜¯åœ¨æœ‰é™ä¸ªtimestepçš„åœºæ™¯ä¸‹ï¼Œtransfer learningå¯¹äºå¾—åˆ°å¥½çš„performanceæ˜¯å¾ˆå¿…è¦çš„ã€‚</p>
<h2 id="baselines">Baselines</h2>
<ul>
<li>Humansï¼šå››ä¸ªç©å®¶ï¼Œæ¯ä¸ªç©å®¶åœ¨training levelsä¸Šè®­ç»ƒä¸¤ä¸ªå°æ—¶ã€‚ç„¶ååœ¨æ¯ä¸ªtest levelç©ä¸€ä¸ªå°æ—¶ã€‚</li>
<li>RainBowï¼šè®¾ç½®$V_{max} = 200$ï¼Œreplay bufferä»$1M$æ”¹æˆäº†$0.5$Mï¼Œç›´æ¥ä½¿ç”¨Rainbowçš„åˆå€¼ã€‚Action spaceï¼š{ {LEFT}, {RIGHT}, {LEFT, DOWN}, {RIGHT, DOWN}, {DOWN}, {DOWN, B}, {B} }ã€‚Agentçš„rewardæ˜¯åŸºäºagentåˆ°è¿‡çš„æœ€å¤§$x$ï¼Œè¿™æ ·å­ä¸ä¼šæƒ©ç½šå®ƒå¾€å›èµ°ã€‚</li>
<li>JERKï¼šå¹¶æ²¡æœ‰ä½¿ç”¨depp learningï¼Œå«JERK(Just Enough Retained Knowledge)ã€‚ä½¿ç”¨ä¸€ä¸ªç®€å•çš„ç®—æ³•è¿›è¡Œexploreï¼Œç„¶åå›æ”¾è®­ç»ƒè¿‡ç¨‹ä¸­çš„best actionã€‚å› ä¸ºç¯å¢ƒæ˜¯stochasitcï¼Œä¸çŸ¥é“å“ªä¸ªactionæ˜¯æœ€å¥½çš„ï¼Œå› æ­¤æ¬¡ä»–ä»…ä»…æ˜¯ä¸€ä¸ªmeanã€‚</li>
<li>PPOï¼šåœ¨æ¯ä¸ªtest levelsä¸Šï¼Œå•ç‹¬çš„è°ƒç”¨PPOã€‚å’ŒRainbowçš„actionï¼Œobservation spacesä¸€æ ·ï¼ŒCNNæ¶æ„å’Œppoè®ºæ–‡ä¸­ä¸€æ ·ã€‚è¶…å‚æ•°ï¼š<br>
Hyper-parameter|Value<br>
:-ğŸ˜:-:<br>
Workers|1<br>
Horizon|8192<br>
Epochs|4<br>
Minibatch size|8192<br>
Discount ($\gamma$) | 0.99<br>
GAE parameter ($\lambda$) | 0.95<br>
Clipping parameter ($\epsilon$)|0.2<br>
Entropy coeff.|0.001<br>
Reward scale|0.005</li>
<li>Joint PPOï¼šä»training levelsè¿ç§»åˆ°test levelsï¼Œåœ¨training levelsä¸Šè®­ç»ƒä¸€ä¸ªpolicyï¼Œç„¶åç”¨å®ƒä½œä¸ºtest levelsçš„åˆå§‹åŒ–ã€‚<br>
åœ¨meta-learningè¿‡ç¨‹ä¸­ï¼Œè®­ç»ƒä¸€ä¸ªsingle-policyç©training setä¸­çš„æ¯ä¸€ä¸ªlevelã€‚å…·ä½“çš„ï¼Œè¿è¡Œ$188$ä¸ªparallel worksï¼Œæ¯ä¸ªworkerè¿è¡Œtraining setä¸­çš„ä¸€ä¸ªlevelã€‚åœ¨æ¯ä¸€ä¸ªgradient stepï¼Œå¯¹æ‰€æœ‰workersçš„gradientsè¿›è¡Œå¹³å‡ï¼Œç¡®ä¿policyåœ¨æ•´ä¸ªtraining setä¸Šçš„è®­ç»ƒæ˜¯å¹³ç¨³çš„ã€‚æ•´ä¸ªè¿‡ç¨‹éœ€è¦å‡ ç™¾ä¸ªmillions timestepsæ‰ä¼šæ”¶æ•›ã€‚å‚æ•°è®¾ç½®å’ŒPPOä¸€æ ·ã€‚<br>
åœ¨æ‰€æœ‰training setsä¸Šå®Œæˆè®­ç»ƒä»¥åï¼Œä½¿ç”¨è¿™ä¸ªç½‘ç»œåœ¨ä½œä¸ºtest setä¸­ç½‘ç»œçš„åˆå§‹åŒ–ï¼Œé™¤äº†ä½¿ç”¨meta-learningçš„ç»“æœè¿›è¡Œåˆå§‹åŒ–ï¼Œæ‰€æœ‰çš„å…¶ä»–è¿‡ç¨‹å’ŒPPOä¸€æ ·ã€‚</li>
<li>Joint Rainbowï¼šå’ŒJoint PPOçš„è®­ç»ƒè¿‡ç¨‹ä¸€æ ·ã€‚<br>
æ²¡æœ‰joint trainingçš„Rainbowè¶…è¿‡äº†PPOï¼Œä½†æ˜¯joint Rainbowæ²¡æœ‰è¶…è¿‡joint PPOã€‚åœ¨æ•´ä¸ªè®­ç»ƒé›†ä¸Šè®­ç»ƒå•ä¸ªRainbowçš„æ—¶å€™ï¼Œä½¿ç”¨äº†$32$ä¸ªGPUsã€‚æ¯ä¸€ä¸ªGPUå¯¹åº”ä¸€ä¸ªå•ä¸ªçš„workerï¼Œæ¯ä¸€ä¸ªworkeræœ‰è‡ªå·±çš„replay bufferå’Œ$8$ä¸ªç¯å¢ƒã€‚ç¯å¢ƒä¹Ÿæ˜¯joint environmentsï¼Œåœ¨æ¯ä¸€ä¸ªepisodeå¼€å§‹çš„æ—¶å€™é‡‡æ ·ä¸€ä¸ªæ–°çš„tranining levelã€‚<br>
é™¤äº†batch sizeå’Œdistributed workerï¼Œå…¶ä»–çš„è¶…å‚æ•°å’Œå¸¸è§„çš„Rainbowä¸€æ ·ã€‚</li>
</ul>
<h2 id="ç¤ºä¾‹">ç¤ºä¾‹</h2>
<h3 id="å®‰è£…gym-retro">å®‰è£…gym retro</h3>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 install gym-retro</span><br></pre></td></tr></table></figure>
<h3 id="åˆ›å»ºgym-env">åˆ›å»ºGym Env</h3>
<p>ä¸‹é¢ä»£ç åˆ›å»ºä¸€ä¸ªgymç¯å¢ƒ</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> retro</span><br><span class="line">env = retro.make(game=<span class="string">'Airstriker-Genesis'</span>)</span><br></pre></td></tr></table></figure>
<p>retroä¸­çš„environmentæ˜¯ä»gym.Envç±»ç»§æ‰¿è€Œæ¥çš„ã€‚</p>
<h3 id="é»˜è®¤rom">é»˜è®¤ROM</h3>
<p>Airstriker-Genesisçš„ROMæ˜¯é»˜è®¤åŒ…å«åœ¨gym-retroä¹‹ä¸­çš„ï¼Œå…¶ä»–çš„ä¸€äº›ROMséœ€è¦æ‰‹åŠ¨æ·»åŠ ã€‚</p>
<h3 id="æ‰€æœ‰çš„games">æ‰€æœ‰çš„games</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> retro</span><br><span class="line">retro.data.list_games()</span><br></pre></td></tr></table></figure>
<p>ä¸Šè¿°ä»£ç ä¼šåˆ—å‡ºæ‰€æœ‰çš„æ¸¸æˆï¼ŒåŒ…å«é‚£äº›é»˜è®¤æ²¡æœ‰é›†æˆçš„ROMSä¸­çš„ã€‚</p>
<h3 id="æ‰‹åŠ¨æ·»åŠ roms">æ‰‹åŠ¨æ·»åŠ ROMs</h3>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python3 -m retor.import /path/to/your/ROMs/directory</span><br></pre></td></tr></table></figure>
<p>ä¸Šè¿°ä»£ç å°†å­˜æ”¾åœ¨æŸä¸ªè·¯å¾„ä¸‹çš„ROMsæ‹·è´åˆ°Gym Retroçš„é›†æˆç›®å½•ä¸­å»ã€‚</p>
<h2 id="å‚è€ƒæ–‡çŒ®">å‚è€ƒæ–‡çŒ®</h2>
<p>1.<a href="https://retro.readthedocs.io/en/latest/" target="_blank" rel="noopener">https://retro.readthedocs.io/en/latest/</a><br>
2.<a href="https://arxiv.org/pdf/1804.03720.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1804.03720.pdf</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mxxhcm.github.io/2019/09/13/derivative-partial-derivative-directional-derivative-gradient/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="é©¬æ™“é‘«çˆ±é©¬èŸèŸ">
      <meta itemprop="description" content="è®°å½•ç¡•å£«ä¸‰å¹´è‡ªå·±çš„ç§¯ç´¯">
      <meta itemprop="image" content="/images/favicon.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="mxxhcm's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/09/13/derivative-partial-derivative-directional-derivative-gradient/" class="post-title-link" itemprop="http://mxxhcm.github.io/page/4/index.html">gradient, directional, derivative derivative, partial derivative</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">å‘è¡¨äº</span>
              

              
                
              

              <time title="åˆ›å»ºæ—¶é—´ï¼š2019-09-13 09:56:12" itemprop="dateCreated datePublished" datetime="2019-09-13T09:56:12+08:00">2019-09-13</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">æ›´æ–°äº</span>
                
                <time title="ä¿®æ”¹æ—¶é—´ï¼š2019-09-24 16:28:56" itemprop="dateModified" datetime="2019-09-24T16:28:56+08:00">2019-09-24</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">åˆ†ç±»äº</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/é«˜ç­‰æ•°å­¦/" itemprop="url" rel="index"><span itemprop="name">é«˜ç­‰æ•°å­¦</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="å¯¼æ•°">å¯¼æ•°</h2>
<p>å¯¼æ•°è¡¨ç¤ºå‡½æ•°åœ¨è¯¥ç‚¹çš„å˜åŒ–ç‡ã€‚<br>
$$fâ€™(x) = lim_{\Delta x\rightarrow 0}\frac{\Delta y}{\Delta x} = lim_{\Delta x\rightarrow 0} \frac{f(x+\Delta x) - f(x)}{ \Delta x}$$<br>
æ›´ç›´æ¥çš„æ¥è¯´ï¼Œå¯¼æ•°è¡¨ç¤ºè‡ªå˜é‡æ— ç©·å°æ—¶ï¼Œå‡½æ•°å€¼çš„å˜åŒ–ä¸è‡ªå˜é‡å˜åŒ–çš„æ¯”å€¼ï¼Œå‡ ä½•æ„ä¹‰æ˜¯è¯¥ç‚¹çš„åˆ‡çº¿ã€‚ç‰©ç†æ„ä¹‰è¡¨ç¤ºè¯¥æ—¶åˆ»çš„ç¬æ—¶å˜åŒ–ç‡ã€‚</p>
<h2 id="åå¯¼æ•°">åå¯¼æ•°</h2>
<p>åå¯¼æ•°æ˜¯å¤šå…ƒå‡½æ•°æ²¿ç€åæ ‡è½´çš„å˜åŒ–ç‡ã€‚<br>
åœ¨ä¸€å…ƒå‡½æ•°ä¸­ï¼Œåªæœ‰ä¸€ä¸ªè‡ªå˜é‡ï¼Œä¹Ÿå°±æ˜¯åªå­˜åœ¨ä¸€ä¸ªæ–¹å‘ä¸Šçš„å˜åŒ–ç‡ï¼Œå«åšå¯¼æ•°ã€‚å¯¹äºå¤šå…ƒå‡½æ•°ï¼Œæœ‰ä¸¤ä¸ªåŠä»¥ä¸Šçš„è‡ªå˜é‡ã€‚ä»å¯¼æ•°åˆ°åå¯¼æ•°ï¼Œç›¸å½“äºä»æ›²çº¿åˆ°äº†æ›²é¢ï¼Œæ›²çº¿ä¸Šçš„ä¸€ç‚¹åªæœ‰ä¸€æ¡åˆ‡çº¿ï¼Œè€Œæ›²é¢ä¸Šçš„ä¸€ç‚¹æœ‰æ— æ•°æ¡åˆ‡çº¿ã€‚æˆ‘ä»¬æŠŠæ²¿ç€åæ ‡è½´ä¸Šçš„åˆ‡çº¿çš„æ–œç‡å«åšåå¯¼æ•°ã€‚</p>
<h2 id="æ–¹å‘å¯¼æ•°">æ–¹å‘å¯¼æ•°</h2>
<p>å¤šå…ƒå‡½æ•°æ²¿ç€ä»»æ„å‘é‡çš„å˜åŒ–ç‡ã€‚</p>
<h2 id="æ¢¯åº¦">æ¢¯åº¦</h2>
<p>å¤šå…ƒå‡½æ•°å–æœ€å¤§å˜åŒ–ç‡æ—¶çš„æ–¹å‘å‘é‡ã€‚<br>
å¯¹äºä¸‰å…ƒå‡½æ•°ï¼Œè®¡ç®—å…¬å¼ï¼š<br>
$$\nabla f  = \frac{\partial f}{\partial x}i+\frac{\partial f}{\partial y}j + \frac{\partial f}{\partial z}j$$<br>
æ¢¯åº¦åˆ°åº•æ˜¯è¡Œå‘é‡è¿˜æ˜¯åˆ—å‘é‡ï¼Ÿå–å†³äºä½¿ç”¨ä»€ä¹ˆlayoutã€‚<br>
æ¢¯åº¦çš„å…¬å¼æ˜¯$\frac{\partial{y}}{\partial\mathbf{x}}$ï¼Œ<br>
å¦‚æœä½¿ç”¨numerator layoutï¼Œæ¢¯åº¦æ˜¯è¡Œå‘é‡ï¼›<br>
å¦‚æœä½¿ç”¨denominator layoutï¼Œæ¢¯åº¦æ˜¯åˆ—å‘é‡ã€‚</p>
<h2 id="å…¨å¾®åˆ†">å…¨å¾®åˆ†</h2>
<p>å‡½æ•°ä»$A$ç‚¹åˆ°ç¦»å®ƒæ— ç©·è¿‘çš„$B$ç‚¹çš„å˜åŒ–é‡ã€‚<br>
å¯¹äºäºŒå…ƒå‡½æ•°ï¼Œå®šä¹‰ä¸º<br>
$$dz = \frac{\partial f}{\partial x}dx+\frac{\partial f}{\partial y}dy$$</p>
<h2 id="åŒºåˆ«å’Œè”ç³»">åŒºåˆ«å’Œè”ç³»</h2>
<p>å¯¼æ•°ï¼Œåå¯¼æ•°å’Œæ–¹å‘å¯¼æ•°éƒ½æ˜¯ä¸ªå‘é‡ï¼Œå®ƒä»¬å…¶å®éƒ½æ˜¯ä¸€ä¸ªæ¦‚å¿µã€‚åå¯¼æ•°å’Œå¯¼æ•°éƒ½æ˜¯æ–¹å‘å¯¼æ•°çš„ç‰¹æ®Šæƒ…å†µã€‚<br>
æ¢¯åº¦æ˜¯ä¸ªå‘é‡ï¼Œå®ƒæŒ‡å‘æœ€é™¡å³­çš„ä¸Šå‡æ–¹å‘ï¼Œè¿™ä¸ªæ—¶å€™æ–¹å‘å¯¼æ•°æœ€å¤§ã€‚</p>
<h2 id="å‚è€ƒæ–‡çŒ®">å‚è€ƒæ–‡çŒ®</h2>
<p>1.<a href="https://www.zhihu.com/question/36301367/answer/142096153" target="_blank" rel="noopener">https://www.zhihu.com/question/36301367/answer/142096153</a><br>
2.<a href="https://math.stackexchange.com/questions/661195/what-is-the-difference-between-the-gradient-and-the-directional-derivative" target="_blank" rel="noopener">https://math.stackexchange.com/questions/661195/what-is-the-difference-between-the-gradient-and-the-directional-derivative</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mxxhcm.github.io/2019/09/13/bit_manipulation/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="é©¬æ™“é‘«çˆ±é©¬èŸèŸ">
      <meta itemprop="description" content="è®°å½•ç¡•å£«ä¸‰å¹´è‡ªå·±çš„ç§¯ç´¯">
      <meta itemprop="image" content="/images/favicon.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="mxxhcm's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/09/13/bit_manipulation/" class="post-title-link" itemprop="http://mxxhcm.github.io/page/4/index.html">ä½è¿ç®—</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">å‘è¡¨äº</span>
              

              
                
              

              <time title="åˆ›å»ºæ—¶é—´ï¼š2019-09-13 09:53:35" itemprop="dateCreated datePublished" datetime="2019-09-13T09:53:35+08:00">2019-09-13</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">æ›´æ–°äº</span>
                
                <time title="ä¿®æ”¹æ—¶é—´ï¼š2019-09-28 22:37:29" itemprop="dateModified" datetime="2019-09-28T22:37:29+08:00">2019-09-28</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">åˆ†ç±»äº</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/ç®—æ³•/" itemprop="url" rel="index"><span itemprop="name">ç®—æ³•</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="æŒ‰ä½å¼‚æˆ–">æŒ‰ä½å¼‚æˆ–</h2>
<h3 id="å®šä¹‰">å®šä¹‰</h3>
<p>ä¸¤ä¸ªè¿ç®—å¯¹è±¡ï¼Œç›¸åŒä¸º$0$ï¼Œä¸åŒä¸º$1$ã€‚</p>
<h3 id="åº”ç”¨">åº”ç”¨</h3>
<ul>
<li>ä»»æ„ä¸¤ä¸ªç›¸ç­‰çš„æ•°äº¦æˆ–éƒ½ä¸º$0$ã€‚</li>
<li>$0$ä¸ä»»ä½•æ•°äº¦æˆ–éƒ½ç­‰äºé‚£ä¸ªæ•°ã€‚</li>
<li>ä¸¤ä¸ªæœ‰ç¬¦å·æ•°å¼‚æˆ–ï¼Œå¦‚æœç¬¦å·ç›¸åŒï¼Œç»“æœå¤§äº$0$ï¼Œå¦åˆ™å°äº$0$ã€‚</li>
</ul>
<p>åªè¦è°¨è®°è¿™ä¸¤æ¡è§„åˆ™å°±å¥½ã€‚</p>
<h3 id="ç¤ºä¾‹">ç¤ºä¾‹</h3>
<p>$12 ^{} 7 = 11$</p>
<p>$12 = 1100$<br>
$7 = 0111$<br>
æŒ‰ä½å¼‚æˆ–å¾—åˆ°<br>
$1011 = 11$</p>
<h3 id="äº¤æ¢å¾‹">äº¤æ¢å¾‹</h3>
<p>$a$^$b$ = $b$^$a$</p>
<h3 id="ç»“åˆå¾‹">ç»“åˆå¾‹</h3>
<p>$a$ ^ $b$ ^ $c$ = $a$ ^ ($b$ ^ $c$)</p>
<h4 id="æ‰©å±•">æ‰©å±•</h4>
<p>$a$ ^ $b$ ^ $c$ ^ $d$ ^ $a$ ^ $b$ ^ $c$ ^ $d$ ^ $e$ = $a$ ^ $a$ ^ $b$ ^ $b$ ^ $c$ ^ $c$ ^ $d$ ^ $d$ ^ $e$</p>
<h4 id="ç¤ºä¾‹-v2">ç¤ºä¾‹</h4>
<p>ä¸ºä»€ä¹ˆå‘¢ï¼Ÿ<br>
$1$ ^ $2$ ^ $3$ ^ $4$ ^ $1$ ^ $2$ ^ $3$ ^ $4$ ^ $5$ = $1$ ^ $1$ ^ $2$ ^ $2$ ^ $3$ ^ $3$ ^ $4$ ^ $4$ ^ $5$<br>
å°±ç›¸å½“äº<br>
$1 = 0001$<br>
$2 = 0010$<br>
$3 = 0011$<br>
$4 = 0100$<br>
$1 = 0001$<br>
$2 = 0010$<br>
$3 = 0011$<br>
$4 = 0100$<br>
$5 = 0101$<br>
åˆ†åˆ«å¯¹æ¯ä¸€ä½å¼‚æˆ–ï¼Œå¯¹äºæ¯ä¸€ä½æ¥è¯´ï¼Œå…¶å®ä»–ä»¬éƒ½æ˜¯æ²¡æœ‰é¡ºåºçš„ï¼Œåªéœ€è¦ç»Ÿè®¡æ¯ä¸€ä½æœ‰å¤šå°‘ä¸ª$0$å’Œ$1$å³å¯äº†ï¼Œé‡å¤å¶æ•°æ¬¡çš„å€¼éƒ½ç›¸äº’æŠµæ¶ˆäº†ï¼Œå‰©ä¸‹çš„å°±æ˜¯æ²¡æœ‰æŠµæ¶ˆçš„é‚£äº›ã€‚</p>
<h2 id="ç§»ä½">ç§»ä½</h2>
<h3 id="å·¦ç§»ä½">å·¦ç§»ä½</h3>
<p>$1 \ll 2 $<br>
ç›¸å½“äº<br>
$0001 \ll 2 = 0100 = 4$</p>
<h3 id="å³ç§»ä½">å³ç§»ä½</h3>
<p>$8 \gg 2$<br>
ç›¸å½“äº<br>
$1000 \gg 2 = 0010 = 2$</p>
<h2 id="æŒ‰ä½ä¸">æŒ‰ä½ä¸</h2>
<h3 id="å®šä¹‰-v2">å®šä¹‰</h3>
<p>ä¸¤ä¸ªè¿ç®—å¯¹è±¡ï¼Œç›¸åŒä¸º$0$ï¼Œä¸åŒä¸º$1$ã€‚</p>
<h3 id="ç¤ºä¾‹-v3">ç¤ºä¾‹</h3>
<p>åè¿›åˆ¶çš„<br>
$0, 1, 2, 3, 4, 5, 6, 7, 8$<br>
å¯¹åº”çš„äºŒè¿›åˆ¶ä¸º<br>
$0000, 0001, 0010, 0011, 0100, 0101, 0110, 0111, 1000$<br>
åˆ¤æ–­åè¿›åˆ¶æ•°ä¸­æ¯ä¸€ä¸ªäºŒè¿›åˆ¶ä½æ˜¯å¦æ˜¯$1$ã€‚<br>
$1$åˆ†åˆ«å·¦ç§»$i=0,1,2,3$ä½ï¼Œç„¶åä¸è¦åˆ¤æ–­çš„äºŒè¿›åˆ¶æ•°è¿›è¡ŒæŒ‰ä½ä¸ï¼Œå¦‚æœä¸æ˜¯$0$ï¼Œåˆ™è¯´æ˜ç¬¬$i$ä½ä¸º$1$ã€‚</p>
<h3 id="åº”ç”¨-v2">åº”ç”¨</h3>
<p>åˆ¤æ–­ä¸€ä¸ªæ•°æ˜¯ä¸æ˜¯$2$çš„å¹‚ï¼Œå†è¿›ä¸€æ­¥å°±æ˜¯ç»Ÿè®¡ä¸€ä¸ªæ•°äºŒè¿›åˆ¶ä½ä¸º$1$çš„ä¸ªæ•°ã€‚<br>
$2$çš„å¹‚æœ‰ä¸€ä¸ªç‰¹å¾ï¼Œå°±æ˜¯åªæœ‰ä¸€ä¸ªäºŒè¿›åˆ¶æ˜¯$1$ï¼Œå…¶ä½™çš„æ‰€æœ‰ä½éƒ½æ˜¯$0$ã€‚<br>
è€Œ$2$çš„å¹‚å‡å»$1$ä¼šå¾—åˆ°æ‰€æœ‰çš„äºŒè¿›åˆ¶ä½éƒ½æ˜¯$1$ï¼Œä»–ä»¬æŒ‰ä½ä¸ï¼Œå¾—åˆ°æ‰€æœ‰çš„äºŒè¿›åˆ¶ä½æ˜¯$0$ï¼Œå³$(2$ ^ $n)$&amp;$(2$ ^ $n-1) = 0$ï¼Œå®é™…ä¸Šï¼Œè¿™ä¸ªå…¬å¼ä¼šæ¶ˆå»äºŒè¿›åˆ¶ä½æœ€å³è¾¹çš„ä¸€ä¸ª$1$ã€‚</p>
<h2 id="ç§»ä½å’Œä¸">ç§»ä½å’Œä¸</h2>
<p>ç§»ä½å’Œä¸ç»“åˆèµ·æ¥åˆ¤æ–­æŸä¸€ä½äºŒè¿›åˆ¶ä½æ˜¯å¦æ˜¯$1$ã€‚</p>
<h3 id="ç¤ºä¾‹-v4">ç¤ºä¾‹</h3>
<p>åˆ¤æ–­$13$ä»å³æ•°çš„çš„ç¬¬$3$ä¸ªäºŒè¿›åˆ¶ä½æ˜¯å¦ä¸º$1$ã€‚</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span>(<span class="number">13</span> &gt;&gt; <span class="number">1</span> &amp; <span class="number">1</span>)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"true\n"</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mxxhcm.github.io/2019/09/12/log-derivative-trick/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="é©¬æ™“é‘«çˆ±é©¬èŸèŸ">
      <meta itemprop="description" content="è®°å½•ç¡•å£«ä¸‰å¹´è‡ªå·±çš„ç§¯ç´¯">
      <meta itemprop="image" content="/images/favicon.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="mxxhcm's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/09/12/log-derivative-trick/" class="post-title-link" itemprop="http://mxxhcm.github.io/page/4/index.html">log derivative trick</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">å‘è¡¨äº</span>
              

              
                
              

              <time title="åˆ›å»ºæ—¶é—´ï¼š2019-09-12 19:21:10" itemprop="dateCreated datePublished" datetime="2019-09-12T19:21:10+08:00">2019-09-12</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">æ›´æ–°äº</span>
                
                <time title="ä¿®æ”¹æ—¶é—´ï¼š2019-09-13 11:01:21" itemprop="dateModified" datetime="2019-09-13T11:01:21+08:00">2019-09-13</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">åˆ†ç±»äº</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/é«˜ç­‰æ•°å­¦/" itemprop="url" rel="index"><span itemprop="name">é«˜ç­‰æ•°å­¦</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="ä»€ä¹ˆæ˜¯log-derivative-trick">ä»€ä¹ˆæ˜¯log derivative trick</h2>
<p>$$\nabla_{\theta} log p(\mathbf{x}; \theta) = \frac{\nabla_{\theta} p(\mathbf{x}; \theta)}{ p(\mathbf{x}; \theta)}$$</p>
<h2 id="ä¸ºä»€ä¹ˆï¼Ÿ">ä¸ºä»€ä¹ˆï¼Ÿ</h2>
<p>å¯¼æ•°å…¬å¼ï¼š<br>
$$(log_a x)â€™ = \frac{1}{x ln\ a}$$<br>
$$(ln\ x)â€™ = \frac{1}{x}$$<br>
æ‰€ä»¥ï¼š<br>
$$(ln\ p(\mathbf{x};\theta))â€™ = \frac{1}{p(\mathbf{x}; \theta)}$$<br>
\begin{align*}<br>
\nabla_{\theta} ln\ p(\mathbf{x};\theta) &amp;=\left[\frac{\partial ln\ p(\mathbf{x}; \theta)}{\partial \theta} \right]^T \\<br>
&amp;= \left[\frac{\partial ln\ p(\mathbf{x}; \theta)}{\partial p(\mathbf{x};\theta)}\frac{\partial p(\mathbf{x};\theta)}{\partial \theta} \right]^T  \\<br>
&amp;= \left[\frac{1}{ p(\mathbf{x};\theta)}\frac{\partial p(\mathbf{x};\theta)}{\partial \theta} \right]^T \\<br>
&amp;= \frac{1}{ p(\mathbf{x};\theta)}\left[\frac{\partial p(\mathbf{x};\theta)}{\partial \theta} \right]^T \\<br>
&amp;=\frac{\nabla_{\theta}p(\mathbf{x}; \theta)}{p(\mathbf{x}; \theta)}\\<br>
\end{align*}</p>
<p>å…¶å®å°±æ˜¯$\nabla log\ p = \frac{\nabla p}{p}$ã€‚</p>
<h2 id="å‚è€ƒæ–‡çŒ®">å‚è€ƒæ–‡çŒ®</h2>
<p>1.<a href="https://math.stackexchange.com/questions/2554749/whats-the-trick-in-log-derivative-trick" target="_blank" rel="noopener">https://math.stackexchange.com/questions/2554749/whats-the-trick-in-log-derivative-trick</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mxxhcm.github.io/2019/09/12/matrix-calculus/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="é©¬æ™“é‘«çˆ±é©¬èŸèŸ">
      <meta itemprop="description" content="è®°å½•ç¡•å£«ä¸‰å¹´è‡ªå·±çš„ç§¯ç´¯">
      <meta itemprop="image" content="/images/favicon.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="mxxhcm's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/09/12/matrix-calculus/" class="post-title-link" itemprop="http://mxxhcm.github.io/page/4/index.html">Matrix calculus</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">å‘è¡¨äº</span>
              

              
                
              

              <time title="åˆ›å»ºæ—¶é—´ï¼š2019-09-12 09:35:36" itemprop="dateCreated datePublished" datetime="2019-09-12T09:35:36+08:00">2019-09-12</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">æ›´æ–°äº</span>
                
                <time title="ä¿®æ”¹æ—¶é—´ï¼š2019-09-17 15:48:02" itemprop="dateModified" datetime="2019-09-17T15:48:02+08:00">2019-09-17</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">åˆ†ç±»äº</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/çº¿æ€§ä»£æ•°/" itemprop="url" rel="index"><span itemprop="name">çº¿æ€§ä»£æ•°</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="ç¬¦å·å£°æ˜">ç¬¦å·å£°æ˜</h2>
<p>å°å†™å­—æ¯$x,y$æ˜¯æ ‡é‡ï¼Œå°å†™åŠ ç²—å­—æ¯$\mathbf{x},\mathbf{y}$æ˜¯å‘é‡ï¼Œå¤§å†™åŠ ç²—$\mathbf{X},\mathbf{Y}$æ˜¯çŸ©é˜µã€‚æ ‡é‡å’Œå‘é‡éƒ½å¯ä»¥çœ‹æˆæ˜¯çŸ©é˜µï¼Œå°†vectorçœ‹æˆ$1\times n$æˆ–è€…$m\times 1$çš„çŸ©é˜µï¼Œå°†scalarçœ‹æˆ$1\times 1$çš„çŸ©é˜µã€‚$\mathbf{X}^T $è¡¨ç¤ºçŸ©é˜µ$\mathbf{X}$çš„è½¬ç½®ï¼Œ$tr(\mathbf{X})$è¡¨ç¤ºè¿¹ï¼Œå³å¯¹è§’çº¿å…ƒç´ ä¹‹å’Œã€‚$det(\mathbf{X})$æˆ–è€…$\vert \mathbf{X}\vert$è¡¨ç¤ºè¡Œåˆ—å¼ã€‚</p>
<h2 id="åŸºç¡€">åŸºç¡€</h2>
<h3 id="è¿¹">è¿¹</h3>
<p>$$ tr(\mathbf{A}) = tr(\mathbf{A}^T )$$<br>
$$ tr(\mathbf{A}\mathbf{B}) = tr(\mathbf{B}\mathbf{A})$$<br>
$$ tr(\mathbf{A}+\mathbf{B}) = tr(\mathbf{B})+tr(\mathbf{A})$$</p>
<h3 id="è¡Œåˆ—å¼">è¡Œåˆ—å¼</h3>
<p>â€¦</p>
<h2 id="ç®€ä»‹">ç®€ä»‹</h2>
<p>çŸ©é˜µå¾®ç§¯åˆ†å€¼å¾—æ˜¯ä½¿ç”¨çŸ©é˜µæˆ–è€…å‘é‡è¡¨ç¤ºå› å˜é‡ä¸­æ¯ä¸€ä¸ªå…ƒç´ ç›¸å¯¹äºè‡ªå˜é‡ä¸­æ¯ä¸€ä¸ªå…ƒç´ çš„å¯¼æ•°ã€‚ä¸€èˆ¬æ¥è¯´ï¼Œè‡ªå˜é‡å’Œå› å˜é‡éƒ½å¯ä»¥æ˜¯æ ‡é‡ï¼Œå‘é‡å’ŒçŸ©é˜µã€‚</p>
<h3 id="ç¤ºä¾‹">ç¤ºä¾‹</h3>
<p>è€ƒè™‘å‘é‡æ¢¯åº¦ï¼Œç»™å®šä¸‰ä¸ªè‡ªå˜é‡ï¼Œä¸€ä¸ªå› å˜é‡çš„å‡½æ•°ï¼š$f(x_1, x_2, x_3)$ï¼Œå‘é‡çš„æ¢¯åº¦æ˜¯ï¼š<br>
$$\nabla f= \frac{\partial f}{\partial x_1}\mathbf{i} + \frac{\partial f}{\partial x_2}\mathbf{j} + \frac{\partial f}{\partial x_3}\mathbf{k}$$<br>
å…¶ä¸­$\mathbf{i,j,k}$è¡¨ç¤ºåæ ‡è½´æ­£æ–¹å‘ä¸Šçš„å•ä½å‘é‡ã€‚è¿™ç±»é—®é¢˜å¯ä»¥çœ‹æˆæ ‡é‡$f$å¯¹å‘é‡$x$æ±‚å¯¼æ•°ï¼Œç»“æœä¾ç„¶æ˜¯ä¸€ä¸ªå‘é‡ï¼ˆæ¢¯åº¦ï¼‰ï¼š<br>
$$\nabla f=(\frac{\partial f }{\partial \mathbf{x}})^T = \left[\frac{\partial f}{\partial x_1} + \frac{\partial f}{\partial x_2} + \frac{\partial f}{\partial x_3}\right]^T $$</p>
<p>æ›´å¤æ‚çš„æƒ…å†µæ˜¯æ ‡é‡$f$å¯¹çŸ©é˜µ$\mathbf{X}$æ±‚å¯¼ï¼Œå«åšçŸ©é˜µæ¢¯åº¦(gradient matrix)ã€‚æ ‡é‡ï¼Œå‘é‡ï¼ŒçŸ©é˜µçš„ç»„åˆæ€»å…±æœ‰$9$ä¸­æƒ…å†µï¼Œå…¶ä¸­å…­ç§æƒ…å†µå¯ä»¥ç”¨ä»¥ä¸‹æ–¹å¼è¡¨ç¤ºå‡ºæ¥ï¼š</p>
<table>
<thead>
<tr>
<th style="text-align:center">ç§ç±»</th>
<th style="text-align:center">æ ‡é‡</th>
<th style="text-align:center">å‘é‡</th>
<th style="text-align:center">çŸ©é˜µ</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">æ ‡é‡</td>
<td style="text-align:center">$\frac{\partial{y}}{\partial{x}}$</td>
<td style="text-align:center">$\frac{\partial{\mathbf{y}}}{\partial{x}}$</td>
<td style="text-align:center">$\frac{\partial{\mathbf{Y}}}{\partial{x}}$</td>
</tr>
<tr>
<td style="text-align:center">å‘é‡</td>
<td style="text-align:center">$\frac{\partial{y}}{\partial{x}}$</td>
<td style="text-align:center">$\frac{\partial{\mathbf{y}}}{\partial{x}}$</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">çŸ©é˜µ</td>
<td style="text-align:center">$\frac{\partial{y}}{\partial{\mathbf{X}}}$</td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>
<h3 id="ç”¨é€”">ç”¨é€”</h3>
<p>Matrix calculusé€šå¸¸ç”¨äºä¼˜åŒ–ï¼Œå¸¸å¸¸ç”¨åœ¨æ‹‰æ ¼æœ—æ—¥ä¹˜å­æ³•ä¸­ã€‚åŒ…æ‹¬Kalmanæ»¤æ³¢ï¼Œé«˜æ–¯æ··åˆåˆ†å¸ƒçš„EMç®—æ³•ï¼Œæ¢¯åº¦ä¸‹é™æ³•çš„çš„å¯¼æ•°ã€‚</p>
<h2 id="å‘é‡å¯¼æ•°">å‘é‡å¯¼æ•°</h2>
<p>å‘é‡å¯ä»¥çœ‹æˆåªæœ‰ä¸€åˆ—çš„çŸ©é˜µï¼Œæœ€ç®€å•çš„çŸ©é˜µå¯¼æ•°åº”è¯¥æ˜¯æ ‡é‡å¯¼æ•°ï¼Œç„¶åæ˜¯å‘é‡å¯¼æ•°ã€‚è¿™ä¸€èŠ‚ä½¿ç”¨çš„æ˜¯numerator layoutï¼ˆåˆ†å­å¸ƒå±€ï¼‰ã€‚</p>
<h3 id="å‘é‡å¯¹æ ‡é‡æ±‚å¯¼">å‘é‡å¯¹æ ‡é‡æ±‚å¯¼</h3>
<h3 id="æ ‡é‡å¯¹å‘é‡æ±‚å¯¼">æ ‡é‡å¯¹å‘é‡æ±‚å¯¼</h3>
<h3 id="å‘é‡å¯¹å‘é‡æ±‚å¯¼">å‘é‡å¯¹å‘é‡æ±‚å¯¼</h3>
<h2 id="çŸ©é˜µå¯¼æ•°">çŸ©é˜µå¯¼æ•°</h2>
<h3 id="çŸ©é˜µå¯¹æ ‡é‡æ±‚å¯¼">çŸ©é˜µå¯¹æ ‡é‡æ±‚å¯¼</h3>
<h3 id="æ ‡é‡å¯¹çŸ©é˜µæ±‚å¯¼">æ ‡é‡å¯¹çŸ©é˜µæ±‚å¯¼</h3>
<h2 id="layout">Layout</h2>
<p>äº‹å®ä¸Šï¼Œæœ‰ä¸¤ç§å®šä¹‰çŸ©é˜µå¯¼æ•°çš„æ–¹å¼ï¼Œè¿™ä¸¤ç§æ–¹æ³•åˆšå¥½å·®ä¸€ä¸ªè½¬ç½®ã€‚è¿™ä¹Ÿæ˜¯æˆ‘ä»¬å¹³å¸¸çŸ©é˜µæ±‚å¯¼æœ€å®¹æ˜“è¿·æƒ‘çš„åœ°æ–¹ã€‚<br>
æ±‚å‘é‡å¯¹å‘é‡çš„å¯¼æ•°æ—¶ï¼Œå³$\frac{\partial \mathbf{y}}{\partial \mathbf{x}}, \partial \mathbf{x} \in \mathbb{R}^n , \partial \mathbf{y} \in \mathbb{R}^m $ï¼Œæœ‰ä¸¤ç§æ–¹å¼è¡¨ç¤ºï¼Œä¸€ç§ç»“æœæ˜¯$m\times n$çš„çŸ©é˜µï¼Œä¸€ç§æ˜¯$n\times m$çš„çŸ©é˜µã€‚è¿™å°±æœ‰ä»¥ä¸‹çš„layoutï¼š</p>
<ol>
<li>Numetator layoutï¼Œæ ¹æ®$\partial \mathbf{y}$å’Œ$\partial \mathbf{x}^T $è¿›è¡Œå¸ƒå±€ã€‚ä¹Ÿå«Jacobian å…¬å¼ï¼Œæœ€åæ˜¯ä¸€ä¸ª$m\times n$çš„çŸ©é˜µã€‚</li>
<li>Denominator layoutï¼Œæ ¹æ®$\partial \mathbf{y}^T $å’Œ$\partial \mathbf{x}$è¿›è¡Œå¸ƒå±€ã€‚ä¹Ÿå«Hessianå…¬å¼ï¼Œæœ€åæ˜¯ä¸€ä¸ª$n\times m$çš„çŸ©é˜µï¼Œæ˜¯numetator layoutçš„è½¬ç½®ã€‚ä¹Ÿæœ‰äººæŠŠå®ƒå«åšæ¢¯åº¦ï¼Œä½†æ˜¯æ¢¯åº¦é€šå¸¸æŒ‡çš„æ˜¯$\frac{\partial y}{\partial \mathbf{x}}$ï¼Œå³æ ‡é‡å¯¹å‘é‡æ±‚å¯¼ï¼Œä¸éœ€è¦è€ƒè™‘layoutã€‚</li>
</ol>
<p>åœ¨è®¡ç®—æ¢¯åº¦$\frac{\partial y}{\partial \mathbf{x}}$å’Œ$\frac{\partial\mathbf{y}}{\partial x}$çš„æ—¶å€™ï¼Œä¹Ÿä¼šæœ‰å†²çªã€‚</p>
<ol>
<li>é‡‡ç”¨åˆ†å­layoutï¼Œ$\frac{\partial y}{\partial \mathbf{x}}$æ˜¯è¡Œå‘é‡å’Œ$\frac{\partial\mathbf{y}}{\partial x}$æ˜¯åˆ—å‘é‡ã€‚</li>
<li>é‡‡ç”¨åˆ†æ¯layoutï¼Œ$\frac{\partial y}{\partial \mathbf{x}}$æ˜¯åˆ—å‘é‡å’Œ$\frac{\partial\mathbf{y}}{\partial x}$æ˜¯è¡Œå‘é‡ã€‚</li>
</ol>
<p>æœ€åè®¡ç®—æ ‡é‡å¯¹çŸ©é˜µæ±‚å¯¼$\frac{\partial y}{\partial \mathbf{X}}$å’ŒçŸ©é˜µå¯¹æ ‡é‡æ±‚å¯¼$\frac{\partial\mathbf{Y}}{\partial x}$ã€‚</p>
<ol>
<li>é‡‡ç”¨åˆ†å­layoutï¼Œ$\frac{\partial y}{\partial \mathbf{X}}$å’Œ$\mathbf{Y}$çš„shapeä¸€æ ·ï¼Œ$\frac{\partial\mathbf{Y}}{\partial x}$å’Œ$\mathbf{X}^T $çš„shapeä¸€æ ·ã€‚</li>
<li>é‡‡ç”¨åˆ†æ¯layoutï¼Œ$\frac{\partial y}{\partial \mathbf{X}}$å’Œ$\mathbf{Y}$çš„shapeä¸€æ ·ï¼Œè¿™é‡Œä¸ç”¨è½¬ç½®è¿™æ˜¯å› ä¸ºè¿™æ ·å­å¥½çœ‹ã€‚$\frac{\partial\mathbf{Y}}{\partial x}$å’Œ$\mathbf{X} $çš„shapeä¸€æ ·ã€‚</li>
</ol>
<p>æ¥ä¸‹æ¥çš„å…¬å¼ä¸»è¦å¯¹$\frac{\partial \mathbf{y}}{\partial x}, \frac{\partial y}{\partial \mathbf{x}}, \frac{\partial \mathbf{y}}{\partial \mathbf{x}}, \frac{\partial \mathbf{Y}}{\partial x},\frac{\partial y}{\partial \mathbf{X}}$è¿™ç§ç»„åˆåˆ†åˆ«è€ƒè™‘ã€‚</p>
<table>
<thead>
<tr>
<th style="text-align:center">ç§ç±»</th>
<th style="text-align:center">æ ‡é‡$y$</th>
<th style="text-align:center">$m\times 1$åˆ—å‘é‡$\mathbf{y}$</th>
<th style="text-align:center">$m\times n$çŸ©é˜µ$\mathbf{Y}$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">æ ‡é‡$x$,numetator layout</td>
<td style="text-align:center">$\frac{\partial{y}}{\partial{x}}$: æ ‡é‡</td>
<td style="text-align:center">$\frac{\partial{\mathbf{y}}}{\partial{x}}$: sizeä¸º$m$çš„åˆ—å‘é‡</td>
<td style="text-align:center">$\frac{\partial{\mathbf{Y}}}{\partial{x}}$: $m\times n$çš„çŸ©é˜µ</td>
</tr>
<tr>
<td style="text-align:center">æ ‡é‡$x$,denominator layout</td>
<td style="text-align:center">$\frac{\partial{y}}{\partial{x}}$: æ ‡é‡</td>
<td style="text-align:center">$\frac{\partial{\mathbf{y}}}{\partial{x}}$: sizeä¸º$m$çš„è¡Œå‘é‡</td>
<td style="text-align:center">$\frac{\partial{\mathbf{Y}}}{\partial{x}}$: $m\times n$çš„çŸ©é˜µ</td>
</tr>
<tr>
<td style="text-align:center">$n\times 1$åˆ—å‘é‡$\mathbf{x}$,numetator layout</td>
<td style="text-align:center">$\frac{\partial{y}}{\partial{x}}$: sizeä¸º$n$çš„è¡Œå‘é‡</td>
<td style="text-align:center">$\frac{\partial{\mathbf{y}}}{\partial{x}}$: $m\times n$çš„çŸ©é˜µ</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">$n\times 1$åˆ—å‘é‡$\mathbf{x}$,denominator layout</td>
<td style="text-align:center">$\frac{\partial{y}}{\partial{x}}$: sizeä¸º$n$çš„åˆ—å‘é‡</td>
<td style="text-align:center">$\frac{\partial{\mathbf{y}}}{\partial{x}}$: $n\times m$çš„çŸ©é˜µ</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">$p\times q$çŸ©é˜µ$\mathbf{Y}$ numetator layout</td>
<td style="text-align:center">$\frac{\partial{y}}{\partial{\mathbf{X}}}$: $q\times p$çš„çŸ©é˜µ</td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">$p\times q$çŸ©é˜µ$\mathbf{Y}$ denominator layout</td>
<td style="text-align:center">$\frac{\partial{y}}{\partial{\mathbf{X}}}$: $p\times q$çš„çŸ©é˜µ</td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>
<h3 id="numerator-layout">numerator layout</h3>
<p>æ ‡é‡å¯¹å‘é‡æ±‚å¯¼ï¼š<br>
$\frac{\partial y}{\partial \mathbf{x}} = \begin{bmatrix}\frac{\partial y}{\partial x_1} &amp; \cdots &amp;\frac{\partial y}{\partial x_n}\end{bmatrix}$<br>
å‘é‡å¯¹æ ‡é‡æ±‚å¯¼ï¼š<br>
$\frac{\partial \mathbf{y}}{\partial x} = \begin{bmatrix}\frac{\partial y_1}{\partial x} \\ \vdots \\ \frac{\partial y_m}{\partial x}\end{bmatrix}$<br>
å‘é‡å¯¹å‘é‡æ±‚å¯¼ï¼š<br>
$\frac{\partial \mathbf{y}}{\partial \mathbf{x}} = \begin{bmatrix}\frac{\partial y_1}{\partial x_1} &amp; \cdots &amp; \frac{\partial y_1}{\partial x_n}  \\ \vdots \\ \frac{\partial y_m}{\partial x_1} &amp; \cdots &amp; \frac{\partial y_m}{\partial x_n}\end{bmatrix}$<br>
æ ‡é‡å¯¹çŸ©é˜µæ±‚å¯¼ï¼š<br>
$\frac{\partial y}{\partial \mathbf{X}} = \begin{bmatrix}\frac{\partial y}{\partial x_{11}} &amp; \cdots &amp; \frac{\partial y}{\partial x_{p1}}  \\ \vdots \\ \frac{\partial y}{\partial x_{1q}} &amp; \cdots &amp;\frac{\partial y}{\partial x_{pq}}\end{bmatrix}$</p>
<p>ä¸‹åˆ—å…¬å¼åªæœ‰numerator layoutï¼Œæ²¡æœ‰denominator-layoutï¼š<br>
çŸ©é˜µå¯¹æ ‡é‡æ±‚å¯¼ï¼š<br>
$\frac{\partial \mathbf{Y}}{\partial x} = \begin{bmatrix}\frac{\partial y_{11}}{\partial x}&amp;\cdots \frac{\partial y_{1n}}{\partial x}  \\ \vdots \\ \frac{\partial y_{m1}}{\partial x} &amp; \cdots &amp; \frac{\partial y_{mn}}{\partial x}\end{bmatrix}$<br>
çŸ©é˜µå¾®åˆ†ï¼š<br>
$dx = \begin{bmatrix}dx_{11} &amp; \cdots &amp; dx_{1n} \\ \vdots \\ dx_{m1} &amp; \cdots &amp; dx_{mn}\end{bmatrix}$</p>
<h3 id="denominator-layout">denominator layout</h3>
<p>æ ‡é‡å¯¹å‘é‡æ±‚å¯¼ï¼š<br>
$\frac{\partial y}{\partial \mathbf{x}} = \begin{bmatrix}\frac{\partial y}{\partial x_1} &amp; \cdots &amp;\frac{\partial y}{\partial x_n}\end{bmatrix}$<br>
$\frac{\partial y}{\partial \mathbf{x}} = \begin{bmatrix}\frac{\partial y}{\partial x_1} \\ \cdots \\ \frac{\partial y}{\partial x_n}\end{bmatrix}$<br>
å‘é‡å¯¹æ ‡é‡æ±‚å¯¼ï¼š<br>
$\frac{\partial \mathbf{y}}{\partial x} = \begin{bmatrix}\frac{\partial y_1}{\partial x} &amp; \vdots &amp; \frac{\partial y_m}{\partial x}\end{bmatrix}$<br>
å‘é‡å¯¹å‘é‡æ±‚å¯¼ï¼š<br>
$\frac{\partial \mathbf{y}}{\partial \mathbf{x}} = \begin{bmatrix}\frac{\partial y_1}{\partial x_1} &amp; \cdots &amp; \frac{\partial y_m}{\partial x_1}  \\ \vdots \\ \frac{\partial y_1}{\partial x_n} &amp; \cdots &amp; \frac{\partial y_m}{\partial x_n}\end{bmatrix}$<br>
æ ‡é‡å¯¹çŸ©é˜µæ±‚å¯¼ï¼š<br>
$\frac{\partial y}{\partial \mathbf{X}} = \begin{bmatrix}\frac{\partial y}{\partial x_{11}} &amp;\cdots &amp; \frac{\partial y}{\partial x_{1q}}  \\ \vdots \\ \frac{\partial y}{\partial x_{p1}} &amp; \cdots &amp; \frac{\partial y}{\partial x_{pq}}\end{bmatrix}$</p>
<h2 id="å…¬å¼">å…¬å¼</h2>
<h3 id="å‘é‡å¯¹å‘é‡æ±‚å¯¼å…¬å¼">å‘é‡å¯¹å‘é‡æ±‚å¯¼å…¬å¼</h3>
<h3 id="æ ‡é‡å¯¹å‘é‡æ±‚å¯¼å…¬å¼">æ ‡é‡å¯¹å‘é‡æ±‚å¯¼å…¬å¼</h3>
<h3 id="å‘é‡å¯¹æ ‡é‡æ±‚å¯¼å…¬å¼">å‘é‡å¯¹æ ‡é‡æ±‚å¯¼å…¬å¼</h3>
<h3 id="æ ‡é‡å¯¹çŸ©é˜µæ±‚å¯¼å…¬å¼">æ ‡é‡å¯¹çŸ©é˜µæ±‚å¯¼å…¬å¼</h3>
<h3 id="çŸ©é˜µå¯¹æ ‡é‡æ±‚å¯¼å…¬å¼">çŸ©é˜µå¯¹æ ‡é‡æ±‚å¯¼å…¬å¼</h3>
<h3 id="æ ‡é‡å¯¹æ ‡é‡æ±‚å¯¼å…¬å¼">æ ‡é‡å¯¹æ ‡é‡æ±‚å¯¼å…¬å¼</h3>
<h3 id="å¾®åˆ†å½¢å¼çš„å…¬å¼">å¾®åˆ†å½¢å¼çš„å…¬å¼</h3>
<p>é€šå¸¸æ¥è¯´ä½¿ç”¨å¾®åˆ†å½¢å¼ç„¶åè½¬æ¢æˆå¯¼æ•°æ›´ç®€å•ã€‚ä½†æ˜¯åªæœ‰åœ¨ä½¿ç”¨numerator layoutæ‰èµ·ä½œç”¨ã€‚</p>
<table>
<thead>
<tr>
<th style="text-align:center">è¡¨è¾¾å¼</th>
<th style="text-align:center">ç»“æœ(numerator layout)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">$d(\mathbf{A})  $</td>
<td style="text-align:center">$0$</td>
</tr>
<tr>
<td style="text-align:center">$d(a\mathbf{X})$</td>
<td style="text-align:center">$ad\mathbf{A}$</td>
</tr>
<tr>
<td style="text-align:center">$d(\mathbf{X}+\mathbf{Y})$</td>
<td style="text-align:center">$d\mathbf{X}+d\mathbf{Y}$</td>
</tr>
<tr>
<td style="text-align:center">$d(tr(\mathbf{X}))$</td>
<td style="text-align:center">$tr(d\mathbf{X})$</td>
</tr>
<tr>
<td style="text-align:center">$d(\mathbf{X}\mathbf{Y})$</td>
<td style="text-align:center">$(d\mathbf{X})\mathbf{Y}+\mathbf{X}(d\mathbf{Y})$</td>
</tr>
<tr>
<td style="text-align:center">$d(\mathbf{X}^{-1} ) $</td>
<td style="text-align:center">$- \mathbf{X}^{-1} (d\mathbf{X}) \mathbf{X}^{-1} $</td>
</tr>
<tr>
<td style="text-align:center">$d(\vert\mathbf{X} \vert)$</td>
<td style="text-align:center">$\vert\mathbf{X}\vert tr(\mathbf{X}^{-1} d\mathbf{X}) = tr(adj(\mathbf{X})d\mathbf{X})$</td>
</tr>
<tr>
<td style="text-align:center">$d(ln \vert\mathbf{X} \vert)$</td>
<td style="text-align:center">$tr(\mathbf{X}^{-1} d\mathbf{X})$</td>
</tr>
<tr>
<td style="text-align:center">$d(\mathbf{X}^T) $</td>
<td style="text-align:center">$(d\mathbf{X})^T $</td>
</tr>
<tr>
<td style="text-align:center">$d(\mathbf{X}^H ) $</td>
<td style="text-align:center">$(d\mathbf{X})^T $</td>
</tr>
</tbody>
</table>
<p>å…¶ä¸­$\mathbf{A}$ä¸æ˜¯$\mathbf{X}$çš„å‡½æ•°ï¼Œ$a$ä¸æ˜¯$\mathbf{X}$çš„å‡½æ•°ï¼Œä¸Šé¢çš„å…¬å¼å¯ä»¥æ ¹æ®é“¾å¼æ³•åˆ™è¿­ä»£ä½¿ç”¨ã€‚<br>
ä¸Šé¢çš„ç»å¤§éƒ¨åˆ†å…¬å¼å¯ä»¥ä½¿ç”¨$\mathbf{F}(\mathbf{X} + d\mathbf{X}) - \mathbf{F}(\mathbf{X})$è®¡ç®—ï¼Œå–çº¿æ€§éƒ¨åˆ†å¯ä»¥å¾—åˆ°ï¼Œä¾‹å¦‚ï¼š<br>
$$(\mathbf{X} + d\mathbf{X}) (\mathbf{Y} + d\mathbf{Y}) = \mathbf{X}\mathbf{Y} + (d\mathbf{X})\mathbf{Y} + \mathbf{X}d\mathbf{Y} + (d\mathbf{X})(d\mathbf{Y})$$<br>
ç„¶åå¾—åˆ°$d(\mathbf{X}\mathbf{Y})= (d\mathbf{X})\mathbf{Y}+\mathbf{X}(d\mathbf{Y})$ã€‚<br>
è®¡ç®—$d\mathbf{X}^{-1} $ï¼Œæœ‰<br>
$$0 = d\mathbf{I} = d(\mathbf{X}^{-1} \mathbf{X}) = (d(\mathbf{X}^{-1}) \mathbf{X} + \mathbf{X}^{-1} d(\mathbf{X})$$<br>
ç§»é¡¹å¾—$d(\mathbf{X}^{-1} ) = - \mathbf{X}^{-1} (d\mathbf{X}) \mathbf{X}^{-1} $<br>
å…³äºè¿¹çš„å…¬å¼ï¼Œæœ‰ï¼š<br>
$$tr(\mathbf{X} + d\mathbf{X}) - tr(\mathbf{X}) = tr(d\mathbf{X})$$</p>
<p>ä¸‹é¢ç»™å‡ºå¯¼æ•°å’Œå¾®åˆ†ä¹‹é—´è½¬æ¢çš„æ ‡å‡†å…¬å¼ï¼Œæˆ‘ä»¬çš„ç›®æ ‡å°±æ˜¯ä½¿ç”¨ä¸Šé¢çš„å…¬å¼å°†ä¸€äº›å¤æ‚çš„å…¬å¼è½¬æ¢æˆä¸‹é¢çš„æ ‡å‡†å…¬å¼ã€‚</p>
<h4 id="å¾®åˆ†å’Œå¯¼æ•°çš„è½¬æ¢">å¾®åˆ†å’Œå¯¼æ•°çš„è½¬æ¢</h4>
<table>
<thead>
<tr>
<th style="text-align:center">æ ‡å‡†å¾®åˆ†å…¬å¼</th>
<th style="text-align:center">ç­‰ä»·çš„å¯¼æ•°å½¢å¼</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">$dy = a\ dx$</td>
<td style="text-align:center">$\frac{dy}{dx} = a$</td>
</tr>
<tr>
<td style="text-align:center">$dy = \mathbf{a}d\mathbf{x}$</td>
<td style="text-align:center">$\frac{dy}{d \mathbf{x}} = \mathbf{a}$</td>
</tr>
<tr>
<td style="text-align:center">$dy = tr(\mathbf{A}d\mathbf{A})$</td>
<td style="text-align:center">$\frac{dy}{d \mathbf{X}} = \mathbf{A}$</td>
</tr>
<tr>
<td style="text-align:center">$d\mathbf{y} = \mathbf{a}dx$</td>
<td style="text-align:center">$\frac{d\mathbf{y}}{d x} = \mathbf{a}$</td>
</tr>
<tr>
<td style="text-align:center">$d\mathbf{y} = \mathbf{A}d\mathbf{x}$</td>
<td style="text-align:center">$\frac{d\mathbf{y}}{d \mathbf{x}} = \mathbf{A}$</td>
</tr>
<tr>
<td style="text-align:center">$d\mathbf{Y} = \mathbf{A}dx$</td>
<td style="text-align:center">$\frac{d\mathbf{Y}}{dx} = \mathbf{A}$</td>
</tr>
</tbody>
</table>
<p>æœ‰ä¸€ä¸ªå¾ˆé‡è¦çš„å…¬å¼æ˜¯ï¼š<br>
$$tr(\mathbf{A}\mathbf{B}) = tr(\mathbf{B}\mathbf{A})$$</p>
<h4 id="ç¤ºä¾‹-v2">ç¤ºä¾‹</h4>
<p>$$\frac{d}{d\mathbf{X}} tr(\mathbf{A}\mathbf{X}\mathbf{B}) = tr(\mathbf{A}\mathbf{B})$$<br>
å› ä¸ºï¼š<br>
$$d tr(\mathbf{A}\mathbf{X}\mathbf{B}) = tr(d(\mathbf{A}\mathbf{X}\mathbf{B})) = tr(\mathbf{A}d(\mathbf{X})\mathbf{B}) =  tr(\mathbf{B}\mathbf{A}d(\mathbf{X})) $$<br>
å¯¹åº”$\frac{d\mathbf{Y}}{dx} = \mathbf{A}$ã€‚</p>
<h5 id="äºŒæ¬¡å‹">äºŒæ¬¡å‹</h5>
<p>è®¡ç®—äºŒæ¬¡å‹$\mathbf{x}^T \mathbf{A}\mathbf{x}$çš„å¯¼æ•°ï¼Œå› ä¸º$\mathbf{x}^T \mathbf{A}\mathbf{x}$æ˜¯ä¸€ä¸ªæ ‡é‡ï¼Œæ‰€ä»¥å¯ä»¥å¥—ä¸Šä¸€ä¸ª$tr$æ“ä½œï¼š<br>
$$\frac{d(\mathbf{x}^T \mathbf{A}\mathbf{x})}{d\mathbf{x}}= \mathbf{x}^T (\mathbf{A}^T + \mathbf{A})$$<br>
æ¨å¯¼ï¼š<br>
\begin{align*}<br>
d(\mathbf{x}^T \mathbf{A}\mathbf{x}) &amp;= tr(d(\mathbf{x}^T \mathbf{A}\mathbf{x})) \\<br>
&amp;= tr(d(\mathbf{x}^T) \mathbf{A}\mathbf{x} + \mathbf{x}^T d(\mathbf{A}) \mathbf{x} + \mathbf{x}^T \mathbf{A}d(\mathbf{x})) \\<br>
&amp;=  tr(\mathbf{x}^T \mathbf{A}^T  d(\mathbf{x}) + \mathbf{x}^T \mathbf{A}d(\mathbf{x})) \\<br>
&amp;= tr(\mathbf{x}^T (\mathbf{A}^T + \mathbf{A})d(\mathbf{x}))\\<br>
\end{align*}<br>
æ»¡è¶³$dy = \mathbf{a}d\mathbf{x}$ã€‚æ‰€ä»¥$\mathbf{x}^T \mathbf{A}\mathbf{x}$çš„å¯¼æ•°æ˜¯$\mathbf{x}^T (\mathbf{A}^T +\mathbf{A})$ã€‚</p>
<h2 id="å‚è€ƒæ–‡çŒ®">å‚è€ƒæ–‡çŒ®</h2>
<p>1.<a href="https://en.wikipedia.org/wiki/Matrix_calculus" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Matrix_calculus</a><br>
2.<a href="https://zhuanlan.zhihu.com/p/24709748" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/24709748</a><br>
3.<a href="https://zhuanlan.zhihu.com/p/24863977" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/24863977</a><br>
<a href="http://4.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf" target="_blank" rel="noopener">4.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf</a><br>
5.<a href="http://www.iro.umontreal.ca/~pift6266/A06/refs/minka-matrix.pdf" target="_blank" rel="noopener">http://www.iro.umontreal.ca/~pift6266/A06/refs/minka-matrix.pdf</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mxxhcm.github.io/2019/09/10/Jacobian-matrix-and-Hessian-matrix/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="é©¬æ™“é‘«çˆ±é©¬èŸèŸ">
      <meta itemprop="description" content="è®°å½•ç¡•å£«ä¸‰å¹´è‡ªå·±çš„ç§¯ç´¯">
      <meta itemprop="image" content="/images/favicon.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="mxxhcm's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/09/10/Jacobian-matrix-and-Hessian-matrix/" class="post-title-link" itemprop="http://mxxhcm.github.io/page/4/index.html">é›…å…‹æ¯”çŸ©é˜µå’Œæµ·å¡çŸ©é˜µ</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">å‘è¡¨äº</span>
              

              
                
              

              <time title="åˆ›å»ºæ—¶é—´ï¼š2019-09-10 19:22:54" itemprop="dateCreated datePublished" datetime="2019-09-10T19:22:54+08:00">2019-09-10</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">æ›´æ–°äº</span>
                
                <time title="ä¿®æ”¹æ—¶é—´ï¼š2019-09-24 16:45:24" itemprop="dateModified" datetime="2019-09-24T16:45:24+08:00">2019-09-24</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">åˆ†ç±»äº</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/çº¿æ€§ä»£æ•°/" itemprop="url" rel="index"><span itemprop="name">çº¿æ€§ä»£æ•°</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="é›…å…‹æ¯”çŸ©é˜µå’Œæµ·å¡çŸ©é˜µå¯¹æ¯”">é›…å…‹æ¯”çŸ©é˜µå’Œæµ·å¡çŸ©é˜µå¯¹æ¯”</h2>
<ol>
<li>é›…å…‹æ¯”çŸ©é˜µæ˜¯ä¸€é˜¶å¯¼æ•°ï¼Œæµ·å¡çŸ©é˜µæ˜¯äºŒé˜¶å¯¼æ•°ã€‚</li>
<li>é›…å…‹æ¯”çŸ©é˜µè¦æ±‚å‡½æ•°çš„è¾“å…¥æ˜¯å‘é‡ï¼Œè¾“å‡ºä¹Ÿæ˜¯å‘é‡ï¼Œè€Œæµ·å¡çŸ©é˜µè¦æ±‚è¾“å…¥æ˜¯å‘é‡ï¼Œè¾“å‡ºæ˜¯æ ‡é‡ã€‚</li>
<li>é›…å…‹æ¯”çŸ©é˜µä¸ä¸€å®šæ˜¯æ–¹é˜µï¼ˆå½“è¾“å…¥å’Œè¾“å‡ºçš„ç»´åº¦ç›¸ç­‰æ—¶æ˜¯æ–¹é˜µï¼‰ï¼Œä½†æ˜¯æµ·å¡çŸ©é˜µä¸€å®šæ˜¯æ–¹é˜µã€‚å½“å‡½æ•°çš„è¾“å‡ºæ˜¯æ ‡é‡çš„æ—¶å€™ï¼Œé›…å…‹æ¯”çŸ©é˜µé€€åŒ–æˆäº†æ¢¯åº¦å‘é‡ã€‚</li>
<li>æµ·å¡çŸ©é˜µå¯ä»¥çœ‹æˆæ¢¯åº¦çš„é›…å…‹æ¯”çŸ©é˜µã€‚</li>
</ol>
<h2 id="é›…å…‹æ¯”çŸ©é˜µ">é›…å…‹æ¯”çŸ©é˜µ</h2>
<p>å®šä¹‰ï¼š$f:\mathbb{R}^n \rightarrow \mathbb{R}^m $ï¼Œå³ä¸€ä¸ªå‡½æ•°çš„è¾“å…¥å’Œè¾“å‡ºéƒ½æ˜¯å‘é‡ï¼Œè®¡ç®—è¾“å‡ºå‘é‡å¯¹äºè¾“å…¥å‘é‡çš„åå¯¼æ•°ï¼ˆè¯¦æƒ…å¯è§<a href="https://mxxhcm.github.io/2019/09/12/matrix-calculus/">çŸ©é˜µæ±‚å¯¼</a>)ï¼Œå¾—åˆ°ä¸€ä¸ª$m\times n$çš„çŸ©é˜µï¼ˆnumerator layoutï¼‰ï¼Œè¿™å°±æ˜¯é›…å…‹æ¯”çŸ©é˜µã€‚<br>
$$J = \begin{bmatrix}\frac{\partial \mathbf{y}}{\partial x_1} &amp; \cdots &amp; \frac{\partial \mathbf{y}}{\partial x_n}\end{bmatrix} = \begin{bmatrix} \frac{\partial \mathbf{y_1}}{\partial x_1} &amp; \cdots &amp; \frac{\partial \mathbf{y_1}}{\partial x_n}\\ &amp; \cdots &amp; \\ \frac{\partial \mathbf{y_m}}{\partial x_1} &amp; \cdots &amp; \frac{\partial \mathbf{y_m}}{\partial x_n}\end{bmatrix}$$</p>
<h2 id="æµ·å¡çŸ©é˜µ">æµ·å¡çŸ©é˜µ</h2>
<p>å®šä¹‰ï¼š$f:\mathbb{R}^n \rightarrow \mathbb{R} $ï¼Œå³ä¸€ä¸ªå‡½æ•°çš„è¾“å…¥æ˜¯å‘é‡ï¼Œè¾“å‡ºæ˜¯æ ‡é‡æ—¶ï¼Œè®¡ç®—è¾“å‡ºå¯¹äºè¾“å…¥å‘é‡çš„äºŒé˜¶å¯¼æ•°ï¼ˆè¯¦æƒ…å¯è§<a href="https://mxxhcm.github.io/2019/09/12/matrix-calculus/">çŸ©é˜µæ±‚å¯¼</a>)ï¼Œå¾—åˆ°ä¸€ä¸ª$n\times n$çš„çŸ©é˜µï¼ˆnumerator layoutï¼‰ï¼Œè¿™å°±æ˜¯é›…å…‹æ¯”çŸ©é˜µã€‚<br>
$$ H = \begin{bmatrix} \frac{\partial^2 \mathbf{y}}{\partial x_1^2 }\cdots &amp; \cdots &amp; \frac{\partial^2 \mathbf{y}}{\partial x_1 x_n}\\ \cdots \\ \frac{\partial^2 \mathbf{y}}{\partial x_nx_1}\cdots &amp; \cdots &amp; \frac{\partial^2 \mathbf{y}}{\partial x_nx_n}\end{bmatrix}$$</p>
<h2 id="å‚è€ƒæ–‡çŒ®">å‚è€ƒæ–‡çŒ®</h2>
<p>1.<a href="https://zhuanlan.zhihu.com/p/67521774" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/67521774</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mxxhcm.github.io/2019/09/10/æ’åºä¸“é¢˜/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="é©¬æ™“é‘«çˆ±é©¬èŸèŸ">
      <meta itemprop="description" content="è®°å½•ç¡•å£«ä¸‰å¹´è‡ªå·±çš„ç§¯ç´¯">
      <meta itemprop="image" content="/images/favicon.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="mxxhcm's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/09/10/æ’åºä¸“é¢˜/" class="post-title-link" itemprop="http://mxxhcm.github.io/page/4/index.html">æ’åºä¸“é¢˜</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">å‘è¡¨äº</span>
              

              
                
              

              <time title="åˆ›å»ºæ—¶é—´ï¼š2019-09-10 19:22:40" itemprop="dateCreated datePublished" datetime="2019-09-10T19:22:40+08:00">2019-09-10</time>
            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            
          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mxxhcm.github.io/2019/09/08/gradient-method-trust-region-policy-optimization/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="é©¬æ™“é‘«çˆ±é©¬èŸèŸ">
      <meta itemprop="description" content="è®°å½•ç¡•å£«ä¸‰å¹´è‡ªå·±çš„ç§¯ç´¯">
      <meta itemprop="image" content="/images/favicon.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="mxxhcm's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/09/08/gradient-method-trust-region-policy-optimization/" class="post-title-link" itemprop="http://mxxhcm.github.io/page/4/index.html">gradient method trust region policy optimization</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">å‘è¡¨äº</span>
              

              
                
              

              <time title="åˆ›å»ºæ—¶é—´ï¼š2019-09-08 14:24:37" itemprop="dateCreated datePublished" datetime="2019-09-08T14:24:37+08:00">2019-09-08</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">æ›´æ–°äº</span>
                
                <time title="ä¿®æ”¹æ—¶é—´ï¼š2019-10-07 19:33:08" itemprop="dateModified" datetime="2019-10-07T19:33:08+08:00">2019-10-07</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">åˆ†ç±»äº</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/å¼ºåŒ–å­¦ä¹ /" itemprop="url" rel="index"><span itemprop="name">å¼ºåŒ–å­¦ä¹ </span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="trust-region-policy-optimization">Trust Region Policy Optimization</h2>
<p>ä½œè€…æå‡ºäº†optimizing policiesçš„ä¸€ä¸ªè¿­ä»£ç®—æ³•ï¼Œç†è®ºä¸Šä¿è¯å¯ä»¥ä»¥non-trivial stepså•è°ƒæ”¹å–„plicyã€‚å¯¹ç»è¿‡ç†è®ºéªŒè¯çš„ç®—æ³•åšä¸€äº›è¿‘ä¼¼ï¼Œäº§ç”Ÿä¸€ä¸ªå®ç”¨ç®—æ³•ï¼Œå«åšTrust Region Policy Optimization(TRPO)ã€‚è¿™ä¸ªç®—æ³•å’Œnatural policy gradientå¾ˆåƒï¼Œå¹¶ä¸”åœ¨å¤§çš„éçº¿æ€§ç½‘ç»œä¼˜åŒ–é—®é¢˜ä¸Šæœ‰å¾ˆé«˜çš„æ•ˆç‡ã€‚TRPOæœ‰ä¸¤ä¸ªå˜ç§ï¼Œsingle-pathæ–¹æ³•åº”ç”¨åœ¨model-freeç¯å¢ƒä¸­ï¼Œvineæ–¹æ³•ï¼Œéœ€è¦æ•´ä¸ªsystemèƒ½å¤Ÿèƒ½å¤Ÿä»ç‰¹å®šçš„statesé‡å¯ï¼Œé€šå¸¸åœ¨ä»¿çœŸç¯å¢ƒä¸­å¯ç”¨ã€‚</p>
<h2 id="introduction">Introduction</h2>
<p>ä¸ºä»€ä¹ˆè¦æœ‰TRPOï¼Ÿ</p>
<ol>
<li>policy gradientè®¡ç®—çš„æ˜¯expected rewardsæ¢¯åº¦çš„æœ€å¤§æ–¹å‘ï¼Œç„¶åæœç€è¿™ä¸ªæ–¹å‘æ›´æ–°policyçš„å‚æ•°ã€‚å› ä¸ºæ¢¯åº¦ä½¿ç”¨çš„æ˜¯ä¸€é˜¶å¯¼æ•°ï¼Œæ¢¯åº¦å¤ªå¤§æ—¶å®¹æ˜“failï¼Œæ¢¯åº¦å¤ªå°çš„è¯æ›´æ–°å¤ªæ…¢ã€‚</li>
<li>å­¦ä¹ ç‡å¾ˆéš¾é€‰æ‹©ï¼Œå­¦ä¹ ç‡å›ºå®šï¼Œæ¢¯åº¦å¤§å®¹æ˜“å¤±è´¥ï¼Œæ¢¯åº¦å°æ›´æ–°å¤ªæ…¢ã€‚</li>
<li>å¦‚ä½•é™åˆ¶policyï¼Œé˜²æ­¢å®ƒè¿›è¡Œå¤ªå¤§çš„moveã€‚ç„¶åå¦‚ä½•å°†policyçš„æ”¹å˜è½¬æ¢åˆ°model parameterçš„æ”¹å˜ä¸Šã€‚</li>
<li>é‡‡æ ·æ•ˆç‡å¾ˆä½ã€‚å¯¹æ•´ä¸ªtrajectoryè¿›è¡Œé‡‡æ ·ï¼Œä½†æ˜¯ä»…ä»…ç”¨äºä¸€æ¬¡policy updateã€‚åœ¨ä¸€ä¸ªtrajectoryä¸­çš„statesæ˜¯å¾ˆåƒçš„ï¼Œå°¤å…¶æ˜¯ç”¨pixelsè¡¨ç¤ºæ—¶ã€‚å¦‚æœåœ¨æ¯ä¸€ä¸ªtimestepéƒ½æ”¹è¿›policyçš„è¯ï¼Œä¼šä¸€ç›´åœ¨æŸä¸€ä¸ªå±€éƒ¨è¿›è¡Œæ›´æ–°ï¼Œè®­ç»ƒä¼šå˜å¾—å¾ˆä¸ç¨³å®šã€‚</li>
</ol>
<h2 id="motivation">Motivation</h2>
<p>æˆ‘ä»¬æƒ³è¦æ¯ä¸€æ¬¡ç­–ç•¥$\pi$çš„æ›´æ–°ï¼Œéƒ½èƒ½ä½¿å¾—$\eta(\pi)$å•è°ƒé€’å¢ã€‚è¦æ˜¯èƒ½å°†å®ƒå†™æˆold poliy $\pi_{old}$å’Œnew policy $\pi_{new}$çš„å…³ç³»å¼å°±å¥½å•¦ã€‚ç»™å‡ºè¿™æ ·ä¸€ä¸ªå…³ç³»å¼ï¼š<br>
$$\eta(\pi_{new}) = \eta(\pi_{old}) + \mathbb{E}_{s_0, a_0, \cdots \sim \pi_{new}} \left[\sum_{t=0}^{\infty} \gamma^t A^{\pi_{old}}(s_t,a_t)\right] \tag{1}$$<br>
è¯æ˜ï¼š<br>
\begin{align*}<br>
\mathbb{E}_{s_0, a_0,\cdots\sim \pi_{new} }\left[\sum_{t=0}^{\infty} \gamma^t A^{\pi_{old}} (s_t,a_t) \right] &amp;=\mathbb{E}_{s_0, a_0,\cdots\sim \pi_{new}}\left[\sum_{t=0}^{\infty} \gamma^t (Q^{\pi_{old}} (s_t,a_t) - V^{\pi_{old}} (s_t))\right]  \\<br>
&amp;=\mathbb{E}_{s_0, a_0,\cdots\sim \pi_{new}} \left[\sum_{t=0}^{\infty} \gamma^t ( R_{t+1} + \gamma V^{\pi_{old}} (s_{t+1}) -  V^{\pi_{old}} (s_t))\right]  \\<br>
&amp;=\mathbb{E}_{s_0, a_0,\cdots\sim \pi_{new}} \left[\sum_{t=0}^{\infty} \gamma^t R_{t+1} + \sum_{t=0}^{\infty} \gamma^t (\gamma V^{\pi_{old}} (s_{t+1}) -  V^{\pi_{old}} (s_t))\right]  \\<br>
&amp;=\mathbb{E}_{s_0, a_0,\cdots\sim \pi_{new}} \left[\sum_{t=0}^{\infty} \gamma^t R_{t+1} \right]+ \mathbb{E}_{s_0, a_0,\cdots\sim \pi_{new}} \left[\sum_{t=0}^{\infty} \gamma^t (\gamma V^{\pi_{old}} (s_{t+1}) -  V^{\pi_{old}} (s_t))\right]  \\<br>
&amp;=\eta(\pi_{new}) + \mathbb{E}_{s_0, a_0,\cdots\sim \pi_{new}} \left[ -  V^{\pi_{old}} (s_0))\right]  \\<br>
&amp;=\eta(\pi_{new}) - \mathbb{E}_{s_0, a_0,\cdots\sim \pi_{new}} \left[ V^{\pi_{old}} (s_0))\right]  \\<br>
&amp;=\eta(\pi_{new}) - \eta(\pi_{old})\\<br>
\end{align*}<br>
å°†new policy $\pi_{new}$çš„æœŸæœ›å›æŠ¥è¡¨ç¤ºä¸ºold policy $\pi_{old}$çš„æœŸæœ›å›æŠ¥åŠ ä¸Šå¦ä¸€é¡¹ï¼Œåªè¦ä¿è¯è¿™ä¸€é¡¹æ˜¯éè´Ÿçš„å³å¯ã€‚å…¶ä¸­$\mathbb{E}_{s_0, a_0,\cdots, \sim \pi_{new}}\left[\cdots\right]$è¡¨ç¤ºactionsæ˜¯ä»$a_t\sim\pi_{new}(\cdot|s_t)$å¾—åˆ°çš„ã€‚</p>
<h2 id="ç”¨æ±‚å’Œä»£æ›¿æœŸæœ›">ç”¨æ±‚å’Œä»£æ›¿æœŸæœ›</h2>
<p>ä»£å…¥$s$çš„æ¦‚ç‡åˆ†å¸ƒ$\rho_{\pi}(s) = P(s_0 = s) +\gamma P(s_1=s) + \gamma^2 P(s_2 = s)+\cdots, s_0\sim \rho_0$ï¼Œå¹¶å°†æœŸæœ›æ¢æˆæ±‚å’Œï¼š<br>
\begin{align*}<br>
\eta(\pi_{new}) &amp;= \eta(\pi_{old}) + \mathbb{E}_{s_0, a_0, \cdots \sim \pi_{new}} \left[\sum_{t=0}^{\infty} \gamma^t A^{\pi_{old}}(s_t,a_t)\right]\\<br>
&amp;=\eta(\pi_{old}) +\sum_{t=0}^{\infty} \sum_s P(s_t=s|\pi_{new}) \sum_a \pi_{new}(a|s)\gamma^t A^{\pi_{old}}(s,a)\\<br>
&amp;=\eta(\pi_{old}) +\sum_s\sum_{t=0}^{\infty} \gamma^t P(s_t=s|\pi_{new}) \sum_a \pi_{new}(a|s)A^{\pi_{old}}(s,a)\\<br>
&amp;=\eta(\pi_{old}) + \sum_s \rho_{\pi_{new}}(s) \sum_a \pi_{new}(a|s) A^{\pi_{old}} (s,a) \tag{2}\\<br>
\end{align*}<br>
ä»ä¸Šé¢çš„æ¨å¯¼å¯ä»¥çœ‹å‡ºæ¥ï¼Œä»»ä½•ä»$\pi_{old}$åˆ°$\pi_{new}$çš„æ›´æ–°ï¼Œåªè¦ä¿è¯æ¯ä¸ªstate $s$å¤„çš„expected advantageæ˜¯éè´Ÿçš„ï¼Œå³$\sum_a \pi_{new}(a|s) A_{\pi_{old}}(s,a)\ge 0$ï¼Œå°±èƒ½è¯´æ˜$\pi_{new}$è¦æ¯”$\pi_{old}$å¥½ï¼Œåœ¨$s$å¤„ï¼Œæ–°çš„policy $\pi_{new}$:<br>
$$\pi_{new}(s) = \arg\ \max_a A^{\pi_{old}} (s,a) \tag{3}$$<br>
ç›´åˆ°æ‰€æœ‰$s$å¤„çš„$A^{\pi_{old}} (s,a)$ä¸ºéæ­£åœæ­¢ã€‚å½“ç„¶ï¼Œåœ¨å®é™…åº”ç”¨ä¸­ï¼Œå› ä¸ºå„ç§è¯¯å·®ï¼Œå¯èƒ½ä¼šæœ‰ä¸€äº›stateçš„expected advantageæ˜¯è´Ÿçš„ã€‚</p>
<h2 id="rho-pi-old-s-è¿‘ä¼¼-rho-pi-new-s-ç¬¬ä¸€æ¬¡è¿‘ä¼¼">$\rho_{\pi_{old}}(s)$è¿‘ä¼¼$\rho_{\pi_{new}}(s)$ï¼ˆç¬¬ä¸€æ¬¡è¿‘ä¼¼ï¼‰</h2>
<p>å¼å­$(2)$ä¸­åŒ…å«çš„$\rho_{\pi_{new}}$ä¾èµ–äºæœªçŸ¥çš„$\pi_{new}$ï¼Œè€Œæˆ‘ä»¬å·²çŸ¥çš„æ˜¯$\pi_{old}$ï¼Œå¿½ç•¥å› ä¸ºpolicyæ”¹å˜å¯¼è‡´çš„stateè®¿é—®é¢‘ç‡çš„æ”¹å˜ï¼Œåœ¨$L_{\pi_{old}}(\pi_{new} )$ä¸­ç”¨$\rho_{\pi_{old}}(s)$è¿‘ä¼¼$\rho_{\pi_{new}}(s)$ã€‚<br>
\begin{align*}<br>
\eta(\pi_{new}) &amp;= \eta(\pi_{old}) + \sum_s\rho_{\pi_{new}}(s)\sum_a\pi_{new}(a|s)A^{\pi_{old}} (s,a)\\<br>
&amp; = \eta(\pi_{old}) + \mathbb{E}_{s\sim \pi_{new}, a\sim \pi_{new}}A^{\pi_{old}}(s,a)\\<br>
&amp; = \eta(\pi_{old}) + \mathbb{E}_{s\sim \pi_{new}, a\sim \pi_{old}}\left[\frac{\pi_{new}(a|s)}{\pi_{old}(a|s)}A^{\pi_{old}}(s,a)\right]\tag{4}\\<br>
\end{align*}</p>
<p>\begin{align*}<br>
L_{\pi_{old}}(\pi_{new}) &amp; = \eta(\pi_{old}) + \sum_s\rho_{\pi_{old}}(s)\sum_a\pi_{new}(a|s)A^{\pi_{old}} (s,a)\\<br>
&amp; = \eta(\pi_{old}) +\mathbb{E}_{s\sim \pi_{old}, a\sim \pi_{new}}A^{\pi_{old}}(s,a)\\<br>
&amp; = \eta(\pi_{old}) +\mathbb{E}_{s\sim \pi_{old}, a\sim \pi_{old}}\left[\frac{\pi_{new}(a|s)}{\pi_{old}(a|s)}A^{\pi_{old}}(s,a)\right]\tag{5}\\<br>
\end{align*}</p>
<p>ç”¨$\pi_{\theta}(a|s)$è¡¨ç¤ºå¯å¯¼policyï¼Œç”¨$\theta_{old}$è¡¨ç¤º$\pi_{old}$çš„å‚æ•°ã€‚å½“$\pi_{new} = \pi_{old}$æ—¶ï¼Œå³$\theta=\theta_{old}$æ—¶ï¼Œ$L_{\pi_{old}}(\pi_{new})$å’Œ$\eta(\pi_{new})$çš„ä¸€é˜¶å¯¼ç›¸ç­‰ï¼š<br>
$$L_{\pi_{old}}(\pi_{new}) = \eta(\pi_{old}) + \sum_s\rho_{\pi_{old}}(s)\sum_a\pi_{old}(a|s)A^\pi_{old}(s,a) = \eta(\pi_{new})\tag{6}$$<br>
$$\nabla_{\theta} L_{\pi_{old}}(\pi_{new})|_{\theta=\theta_{old}} = \mathbb{E}_{s\sim \pi_{old}, a\sim \pi_{old}}\left[\frac{\nabla_{\theta}\pi_{new}(a|s)}{\pi_{old}(a|s)}A^{\pi_{old}}(s,a)\right]|_{\theta_{old}}\tag{7} $$<br>
$$\nabla_{\theta} \eta(\pi_{new})|_{\theta=\theta_{old}} =\mathbb{E}_{s\sim \pi_{new}, a\sim \pi_{old}}\left[\nabla_{\theta}\log\pi_{new}(a|s)A^{\pi_{old}}(s,a)\right]|_{\theta_{old}} \tag{8}$$<br>
è¯æ˜ï¼š<br>
å¼å­$(6)$å°†$\pi_{new}=\pi_{old}$ä»£å…¥å³å¯ã€‚æˆ‘å¯¹äºå¼å­$7$å’Œ$8$ç›¸ç­‰æœ‰ç–‘é—®ï¼Œä¸ºä»€ä¹ˆï¼Ÿ<br>
ä¹Ÿå°±æ˜¯è¯´å½“$\pi_{new} = \pi_{old}$æ—¶ï¼Œ$L_{\pi_{old}}(\pi_{new})$å’Œ$\eta(\pi_{new})$æ˜¯ç›¸ç­‰çš„ï¼Œåœ¨$\pi_{old}$å¯¹åº”çš„å‚æ•°$\theta$å‘¨å›´çš„æ— ç©·å°èŒƒå›´å†…ï¼Œå¯ä»¥è¿‘ä¼¼è®¤ä¸ºå®ƒä»¬ä¾ç„¶ç›¸ç­‰ï¼Œ$\theta$è¿›è¡Œè¶³å¤Ÿå°çš„stepæ›´æ–°åˆ°è¾¾æ–°çš„policy $\pi_{new}$ï¼Œç›¸åº”å‚æ•°ä¸º$\theta_{\pi_{new}}$ï¼Œåœ¨æ”¹è¿›$L_{\pi_{old}}$åŒæ—¶ä¹Ÿæ”¹è¿›äº†$\eta$ï¼Œä½†æ˜¯è¿™ä¸ªè¶³å¤Ÿå°çš„stepæ˜¯å¤šå°‘æ˜¯ä¸çŸ¥é“çš„ã€‚</p>
<h2 id="conservative-policy-iteration">conservative policy iteration</h2>
<p>ä¸ºäº†æ±‚å‡ºè¿™ä¸ªstepåˆ°åº•æ˜¯å¤šå°‘ï¼Œæœ‰äººæå‡ºäº†conservative policy iterationç®—æ³•ï¼Œè¯¥ç®—æ³•æä¾›äº†$\eta$æé«˜çš„ä¸€ä¸ªlower boundã€‚ç”¨$\pi_{old}$è¡¨ç¤ºcurrent policyï¼Œç”¨$\piâ€™$è¡¨ç¤ºä½¿å¾—$L_{\pi_{old}}$å–å¾—æœ€å¤§å€¼çš„policyï¼Œ$\piâ€™ = \arg\ \min_{\piâ€™} L_{\pi_{old}}(\piâ€™)$ï¼Œæ–°çš„policy $\pi_{new}$å®šä¹‰ä¸ºï¼š<br>
$$\pi_{new}(a|s) = (1-\alpha) \pi_{old}(a|s)+\alpha\piâ€™(a|s) \tag{9}$$<br>
å¯ä»¥è¯æ˜ï¼Œæ–°çš„policy $\pi_{new}$å’Œè€çš„policy $\pi_{old}$ä¹‹é—´å­˜åœ¨ä»¥ä¸‹å…³ç³»ï¼š<br>
$$\eta(\pi_{new})\ge L_{\pi_{old}}(\pi_{new}) - \frac{2\epsilon \gamma}{(1-\gamma(1-\alpha))(1-\gamma)}\alpha^2 $$<br>
$$\epsilon = \max_s \vert\mathbb{E}_{a\sim\piâ€™}\left[A^{\pi} (s,a)\right]\vert \tag{10}, \alpha,\gamma\in [0,1]$$<br>
è¯æ˜ï¼š<br>
è¿›è¡Œç¼©æ”¾å¾—åˆ°ï¼š<br>
$$\eta(\pi_{new})\ge L_{\pi_{old}}(\pi_{new}) - \frac{2\epsilon \gamma}{(1-\gamma)^2 }\alpha^2 \tag{11}$$</p>
<h2 id="é€šç”¨éšæœºç­–ç•¥å•è°ƒå¢åŠ çš„è¯æ˜">é€šç”¨éšæœºç­–ç•¥å•è°ƒå¢åŠ çš„è¯æ˜</h2>
<p>ä»å…¬å¼$9$æˆ‘ä»¬å¯ä»¥çœ‹å‡ºæ¥ï¼Œæ”¹è¿›å³è¾¹å°±ä¸€å®šèƒ½æ”¹è¿›çœŸå®çš„performance $\eta$ã€‚ç„¶è€Œï¼Œè¿™ä¸ªboundåªé€‚ç”¨äºé€šè¿‡å…¬å¼$7$ç”Ÿæˆçš„æ··åˆpolicyï¼Œåœ¨å®è·µä¸­ï¼Œè¿™ç±»policyå¾ˆå°‘ç”¨åˆ°ï¼Œè€Œä¸”é™åˆ¶æ¡ä»¶å¾ˆå¤šã€‚æ‰€ä»¥æˆ‘ä»¬æƒ³è¦çš„æ˜¯ä¸€ä¸ªé€‚ç”¨äºä»»ä½•stochastic policyçš„lower boundï¼Œé€šè¿‡æå‡è¿™ä¸ªboundæå‡$\eta$ã€‚<br>
ä½œè€…ä½¿ç”¨$\pi_{old}$å’Œ$\pi_{new}$ä¹‹é—´çš„ä¸€ä¸ªè·ç¦»ä»£æ›¿$\alpha$ï¼Œå°†å…¬å¼$8$æ‰©å±•åˆ°äº†ä»»æ„stochastic policyï¼Œè€Œä¸ä»…ä»…æ˜¯æ··åˆpolicyã€‚è¿™é‡Œä½¿ç”¨çš„distance measureï¼Œå«åštotal variation divergenceï¼Œå¯¹äºç¦»æ•£çš„æ¦‚ç‡åˆ†å¸ƒ$p,q$æ¥è¯´ï¼Œå®šä¹‰ä¸ºï¼š<br>
$$D_{TV}(p||q) = \frac{1}{2} \sum_i \vert p_i -q_i \vert \tag{12}$$<br>
å®šä¹‰$D_{TV}^{max}(\pi_{old}, \pi_{new})$ä¸ºï¼š<br>
$$D_{TV}^{max} (\pi_{old}, \pi_{new}) = \max_s D_{TV}(\pi_{old}(\cdot|s) || \pi_{new}(\cdot|s))\tag{13}$$<br>
è®©$\alpha = D_{TV}^{max}(\pi_{old}, \pi_{new})$ï¼Œæ–°çš„boundå¦‚ä¸‹ï¼š<br>
$$\eta(\pi_{new})\ge L_{\pi_{old}}(\pi_{new}) - \frac{4\epsilon \gamma}{(1-\gamma)^2 }\alpha^2 , \qquad\epsilon = \max_{s,a} \vert A^{\pi_{old}}(s,a)\vert \tag{14}$$<br>
è¯æ˜ï¼š<br>
â€¦</p>
<p>Total variation divergenceå’ŒKLæ•£åº¦ä¹‹é—´æœ‰è¿™æ ·ä¸€ä¸ªå…³ç³»ï¼š<br>
$$D_{TV}(p||q)^2 \le D_{KL}(p||q) \tag{15}$$<br>
è¯æ˜ï¼š<br>
â€¦<br>
è®©<br>
$$D_{KL}^{max}(\pi_{old}, \pi_{new}) = \max_s D_{KL}(\pi_{old}(\cdot|s)||\pi_{new}(\cdot|s)) \tag{16}$$<br>
ä»å…¬å¼$12$ä¸­å¯ä»¥ç›´æ¥å¾—åˆ°ï¼š<br>
\begin{align*}<br>
\eta(\pi_{new}) &amp;\ge L_{\pi_{old}}(\pi_{new}) - \frac{4\epsilon \gamma}{(1-\gamma)^2 }\alpha^2 \\<br>
&amp;\ge L_{\pi_{old}}(\pi_{new}) - \frac{4\epsilon \gamma}{(1-\gamma)^2 }D_{KL}^{max}(\pi_{old}, \pi_{new}) \\<br>
&amp; \ge L_{\pi_{old}}(\pi_{new}) - CD_{KL}^{max}(\pi_{old}, \pi_{new})\\<br>
C &amp; =\frac{4\epsilon \gamma}{(1-\gamma)^2} \tag{17}<br>
\end{align*}<br>
æ ¹æ®å…¬å¼$12$ï¼Œæˆ‘ä»¬èƒ½ç”Ÿæˆä¸€ä¸ªå•è°ƒéé€’å‡çš„sequenceï¼š$\eta(\pi_0)\le \eta(\pi_1) \le \eta(\pi_2) \le \cdots$ï¼Œè®°$M_i(\pi) = L_{\pi_i}(\pi) - CD_{KL}^{max}(\pi_i, \pi)$ï¼Œæœ‰ï¼š<br>
å› ä¸ºï¼š<br>
$$\eta(\pi_{i+1}) \ge M_i(\pi_{i+1})\tag{18}$$<br>
$$\eta(\pi_i) = M_i(\pi_i)\tag{19}$$<br>
ä¸Šé¢çš„ç¬¬ä¸€ä¸ªå¼å­å‡å»ç¬¬äºŒä¸ªå¼å­å¾—åˆ°ï¼š<br>
$$\eta(\pi_{i+1}) - \eta(\pi_i)\ge M_i(\pi_{i+1})-M_i(\pi_i) \tag{20}$$<br>
åœ¨æ¯ä¸€æ¬¡è¿­ä»£çš„æ—¶å€™ï¼Œç¡®ä¿$M_i(\pi_{i+1}) - M_i(\pi_i)\ge 0$å°±èƒ½å¤Ÿä¿è¯$\eta$æ˜¯éé€’å‡çš„ï¼Œæœ€å¤§åŒ–$M_i$å°±èƒ½å®ç°è¿™ä¸ªç›®æ ‡ï¼Œ$M_i$æ˜¯miorize $\eta$çš„è¿‘ä¼¼ç›®æ ‡ã€‚è¿™ç§ç®—æ³•æ˜¯minorizaiton maximizationçš„ä¸€ç§ã€‚</p>
<h2 id="å‚æ•°åŒ–ç­–ç•¥çš„ä¼˜åŒ–-ç¬¬äºŒæ¬¡è¿‘ä¼¼">å‚æ•°åŒ–ç­–ç•¥çš„ä¼˜åŒ–ï¼ˆç¬¬äºŒæ¬¡è¿‘ä¼¼ï¼‰</h2>
<p>å‰é¢å‡ å°èŠ‚è€ƒè™‘çš„optimizationé—®é¢˜æ—¶æ²¡æœ‰è€ƒè™‘$\pi$çš„å‚æ•°åŒ–ï¼Œå¹¶ä¸”å‡è®¾æ‰€æœ‰çš„stateséƒ½å¯ä»¥è¢«evaluatedã€‚è¿™ä¸€èŠ‚ä»‹ç»å¦‚ä½•åœ¨æœ‰é™çš„æ ·æœ¬ä¸‹å’Œä»»æ„çš„å‚æ•°åŒ–ç­–ç•¥ä¸‹ï¼Œä»ç†è®ºåŸºç¡€æ¨å¯¼å‡ºä¸€ä¸ªå®ç”¨çš„ç®—æ³•ã€‚<br>
ç”¨$\theta$è¡¨ç¤ºå‚æ•°åŒ–ç­–ç•¥$\pi_{\theta}(a|s)$çš„å‚æ•°$\theta$ï¼Œå°†ç›®æ ‡è¡¨ç¤ºæˆ$\theta$è€Œä¸æ˜¯$\pi$çš„å‡½æ•°ï¼Œå³ç”¨$\eta(\theta)$è¡¨ç¤ºåŸæ¥çš„$\eta(\pi_\theta)$ï¼Œç”¨$L_{\theta}(\hat{\theta})$è¡¨ç¤º$L_{\pi_{\theta}}(\pi_{\hat{\theta}})$ï¼Œç”¨$D_{KL}(\theta||\hat{\theta})$è¡¨ç¤º$D_{KL}(\pi_{\theta}||\pi_{\hat{\theta}})$ã€‚ç”¨$\theta_{old}$è¡¨ç¤ºæˆ‘ä»¬æƒ³è¦æ”¹è¿›çš„policyå‚æ•°ã€‚<br>
ä¸Šä¸€å°èŠ‚æˆ‘ä»¬å¾—åˆ°$\eta(\theta) \ge L_{\theta_{old}}(\theta) - CD_{KL}^{max}(\theta_{old}, \theta)$ï¼Œå½“$\theta = \theta_{old}$æ—¶å–ç­‰ã€‚é€šè¿‡æœ€å¤§åŒ–ç­‰å¼å³è¾¹ï¼Œå¯ä»¥æé«˜$\eta$çš„ä¸‹ç•Œï¼š<br>
$$\max_{\theta}\left[L_{\theta_{old}}(\theta) - CD_{KL}^{max}(\theta_{old}, \theta)\right]\tag{21}$$<br>
åœ¨å®è·µä¸­ï¼Œå¦‚æœä½¿ç”¨ä¸Šè¿°ç†è®ºä¸­çš„penalty coefficient $C$ï¼Œä¼šå¯¼è‡´steps sizeå¾ˆå°ã€‚ä¸€ç§æ–¹æ³•æ˜¯ä½¿ç”¨new policy å’Œold policyä¹‹é—´çš„KLæ•£åº¦è¿›è¡Œçº¦æŸï¼Œå¯ä»¥é‡‡å–æ›´å¤§çš„stepsï¼Œè¿™ä¸ªçº¦æŸå«åštrust region constraint:<br>
$$\max_{\theta} L_{\theta_{old}} (\theta)$$<br>
$$ s.t. D_{KL}^{max}(\theta_{old},\theta) \le \delta \tag{22}$$<br>
è¿™æ ·ä¼šåœ¨state spaceçš„æ¯ä¸€ä¸ªstateéƒ½æœ‰ä¸€ä¸ªKLæ•£åº¦çº¦æŸã€‚ç”±äºçº¦æŸå¤ªå¤šï¼Œè¿™ä¸ªé—®é¢˜è¿˜æ˜¯ä¸èƒ½è§£ã€‚è¿™é‡Œä½¿ç”¨average KL divergenceè¿›è¡Œè¿‘ä¼¼:<br>
$$\bar{D}_{KL}^{\rho}(\theta_1, \theta_2) = \mathbb{E}_{s\sim \rho}\left[D_{KL}(\pi_{\theta_1}(\cdot|s) || \pi_{\theta_2}(\cdot|s))\right] \tag{23}$$<br>
å…¬å¼$22$å˜æˆï¼š<br>
$$\max_{\theta} L_{\theta_{old}} (\theta)$$<br>
$$s.t. \bar{D}_{KL}^{\rho_{\theta_{old}}}(\theta_{old},\theta) \le \delta \tag{24}$$</p>
<h2 id="ç›®æ ‡å‡½æ•°å’Œçº¦æŸçš„é‡‡æ ·ä¼°è®¡-ç¬¬ä¸‰æ¬¡è¿‘ä¼¼">ç›®æ ‡å‡½æ•°å’Œçº¦æŸçš„é‡‡æ ·ä¼°è®¡ï¼ˆç¬¬ä¸‰æ¬¡è¿‘ä¼¼ï¼‰</h2>
<p>ä¸Šä¸€èŠ‚ä»‹ç»çš„æ˜¯å…³äºpolicy parameterçš„æœ‰çº¦æŸä¼˜åŒ–é—®é¢˜ï¼Œçº¦æŸæ¡ä»¶ä¸ºæ¯ä¸€æ¬¡policyæ›´æ–°æ—¶é™åˆ¶policyå˜åŒ–çš„å¤§å°ï¼Œä¼˜åŒ–expected toral reward $\eta$çš„ä¸€ä¸ªä¼°è®¡å€¼ã€‚è¿™ä¸€èŠ‚ä½¿ç”¨Monte Carloä»¿çœŸè¿‘ä¼¼ç›®æ ‡å’Œçº¦æŸå‡½æ•°ã€‚<br>
ä»£å…¥$L_{\theta_{old}}$çš„ç­‰å¼ï¼Œå¾—åˆ°ï¼š<br>
$$\max_{\theta}\sum_s \rho_{\theta_{old}}(s) \sum_a\pi_{\theta}(a|s)A_{\theta_{old}}(s,a)$$<br>
$$s.t. \bar{D}_{KL}^{\rho_{\theta_{old}}}(\theta_{old},\theta) \le \delta \tag{25}$$<br>
é¦–å…ˆç”¨æœŸæœ›$\frac{1}{1-\gamma}\mathbb{E}_{s\sim \rho_{\theta_{old}}}\left[\cdots\right]$ä»£æ›¿ç›®æ ‡å‡½æ•°ä¸­çš„$\sum_s\rho_{\theta_{old}}(s) \left[\cdots\right]$ã€‚æ¥ä¸‹æ¥ç”¨$Q$å€¼$Q_{\theta_{old}}$ä»£æ›¿advantage $A_{\theta_{old}}$ï¼Œç»“æœå¤šäº†ä¸€ä¸ªå¸¸æ•°é¡¹ï¼Œä¸å½±å“ã€‚æœ€åä½¿ç”¨importance smaplingä»£æ›¿actionsä¸Šçš„æ±‚å’Œã€‚ä½¿ç”¨$q$è¡¨ç¤ºé‡‡æ ·åˆ†å¸ƒï¼Œ$q$åˆ†å¸ƒä¸­å•ä¸ªçš„$s_n$å¯¹äºlosså‡½æ•°çš„è´¡çŒ®åœ¨äºï¼š<br>
$$\sum_a \pi_{\theta}(a|s_n) A_{\theta_{old}}(s_n,a) = \mathbb{E}_{a\sim q}\left[\frac{\pi_{\theta} (a|s_n) }{q(a|s_n)}A_{\theta_{old}}(s_n,a) \right]\tag{26}$$<br>
ä¸Šé¢çš„å…¬å¼å°±æ˜¯ä½¿ç”¨importance samplingä»£æ›¿æ±‚å’Œã€‚å°†$A$å±•å¼€ï¼š<br>
\begin{align*}<br>
\sum_a \pi_{\theta}(a|s) A_{\theta_{old}}(s,a) &amp;= \sum_a \pi_{\theta}(a|s)\left( Q_{\theta_{old}}(s,a)  - V_{\theta_{old}}(s)\right)\\<br>
&amp;= \sum_a \pi_{\theta}(a|s)Q_{\theta_{old}}(s,a)- \sum_a \pi_{\theta}(a|s)V_{\theta_{old}}(s)\\<br>
&amp;= \sum_a \pi_{\theta}(a|s)Q_{\theta_{old}}(s,a)- V_{\theta_{old}}(s)\\<br>
\end{align*}<br>
å°†å…¬å¼$25$çš„ä¼˜åŒ–é—®é¢˜è½¬åŒ–ä¸ºï¼š<br>
$$\max_{\theta} \mathbb{E}_{s\sim\rho_{\theta_{old}}, a\sim q}\left[\frac{\pi_{\theta} (a|s) }{q(a|s)}Q_{\theta_{old}}(s,a)\right]$$<br>
$$s.t. \mathbb{E}_{s\sim \rho_{\theta_{old}}}\left[D_{KL}(\pi_{\theta_{old}}(\cdot|s)||\pi_{\theta}(\cdot|s))\right]\le \delta \tag{27}$$<br>
å¥½äº†ï¼Œå‰é¢ç»™å‡ºå„ç§è¯æ˜å’Œè¿‘ä¼¼ï¼Œç»ˆäºç»™å‡ºäº†æˆ‘ä»¬è¦è§£å†³çš„é—®é¢˜çš„æ•°å­¦å…¬å¼ï¼Œè¿™éƒ¨åˆ†æ˜¯ä¸ºäº†å¸®åŠ©æˆ‘ä»¬ç†è§£ã€‚æˆ‘ä»¬å®é™…éœ€è¦çš„æ˜¯è§£è¿™ä¸ªæœ‰çº¦æŸçš„ä¼˜åŒ–é—®é¢˜ï¼Œè¿™ä¹Ÿæ˜¯ä»£ç ä¸­è¦å®ç°çš„éƒ¨åˆ†ï¼Œå…·ä½“æ€ä¹ˆåšï¼Œä¸€å¥è¯ï¼Œé‡‡æ ·ç„¶åä¼°è®¡ã€‚ç”¨é‡‡æ ·ä»£æ›¿æœŸæœ›ï¼Œç”¨ç»éªŒä¼°è®¡ä»£æ›¿$Q$å€¼ã€‚<br>
ä»‹ç»ä¸¤ç§æ–¹æ³•è¿›è¡Œä¼°è®¡ã€‚ç¬¬ä¸€ä¸ªå«åšsingle pathï¼Œé€šå¸¸ç”¨åœ¨policy gradient estimationï¼ŒåŸºäºå•ä¸ªè½¨è¿¹çš„é‡‡æ ·ã€‚ç¬¬äºŒä¸ªå«åšvineï¼Œæ„å»ºä¸€ä¸ªrollout setï¼Œä»rollout setçš„æ¯ä¸€ä¸ªstateå¤„æ‰§è¡Œå¤šä¸ªactionsã€‚è¿™ç§æ–¹æ³•ç»å¸¸ç”¨åœ¨policy iterationæ–¹æ³•ä¸Šã€‚</p>
<h3 id="single-path">Single Path</h3>
<p>é‡‡æ ·$s_0\sim \rho_0$ï¼Œæ¨¡æ‹Ÿpolicy $\pi_{\theta_{old}}$ä¸€äº›timestepsç”Ÿæˆä¸€ä¸ªtrajectory $s_0, a_0, s_1, a_1, \cdots, s_{T-1}, a_{T-1}, s_T$ï¼Œå› æ­¤$q(a|s) = \pi_{\theta_{old}}(a|s)$ã€‚æ ¹æ®trajectoryå¯¹æ¯ä¸€ä¸ªstate action pair $(s_t,a_t)$è®¡ç®—$Q_{\theta_{old}}(s,a)$ã€‚</p>
<h3 id="vine">Vine</h3>
<p>é‡‡æ ·$s_0\sim \rho_0$ï¼Œæ¨¡æ‹Ÿpolicy $\pi_{\theta_i}$ç”Ÿæˆä¸€ç³»åˆ—trajectoriesã€‚åœ¨è¿™äº›trajectoriesé€‰æ‹©ä¸€ä¸ªå…·æœ‰$N$ä¸ªstatesçš„å­é›†ï¼Œè¡¨ç¤ºä¸º$s_1, c\dots, s_N$ï¼Œè¿™ä¸ªé›†åˆç§°ä¸ºrollout setã€‚å¯¹äºrollout setä¸­çš„æ¯ä¸€ä¸ªstate $s_n$ï¼Œæ ¹æ®$a_{n,k}\sim q(\cdot|s_n)$é‡‡æ ·$K$ä¸ªactionsã€‚ä»»ä½•$q(\cdot|s_n)$éƒ½è¡Œï¼Œåœ¨å®è·µä¸­ï¼Œ$q(\cdot|s_n) = \pi_{\theta_i}(\cdot|s_n)$é€‚ç”¨äºcontionous problemsï¼Œåƒæœºå™¨äººè¿åŠ¨ï¼›è€Œå‡åŒ€åˆ†å¸ƒé€‚ç”¨äºç¦»æ•£ä»»åŠ¡ï¼Œå¦‚Atariæ¸¸æˆã€‚<br>
å¯¹äº$s_n$å¤„çš„æ¯ä¸€ä¸ªaction $a_{n,k}$ï¼Œä»$s_n$å’Œ$a_{n,k}$å¤„è¿›è¡Œrolloutï¼Œä¼°è®¡$\hat{Q}_{\theta_i}(s_n, a_{n,k})$ã€‚åœ¨å°çš„æœ‰é™action spacesæƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¯ä»¥å¯¹ä»ç»™å®šçŠ¶æ€ä»»ä½•å¯èƒ½çš„actionç”Ÿæˆä¸€ä¸ªrolloutï¼Œå•ä¸ª$s_n$å¯¹$L_{\theta_{old}}$çš„è´¡çŒ®å¦‚ä¸‹ï¼š<br>
$$L_n(\theta) = \sum_{k=1}^K \pi_{\theta} (a_k|s_n) \hat{Q}(s_n, a_k)\tag{28}$$<br>
å…¶ä¸­action spaceæ˜¯$\mathcal{A} = {a_1, a_2,\cdots, a_K}$ã€‚åœ¨å¤§çš„è¿ç»­state spaceä¸­ï¼Œå¯ä»¥ä½¿ç”¨importance samplingæ„å»ºä¸€ä¸ªæ–°çš„ç›®æ ‡è¿‘ä¼¼ã€‚ä»$s_n$å¤„è®¡ç®—çš„$L_{\theta_{old}}$çš„self-normalized ä¼°è®¡æ˜¯ï¼š<br>
$$L_n(\theta) = \frac{\sum_{k=1}^K \frac{\pi_{\theta}(a_{n,k}|s_n)}{\pi_{\theta_{old}}(a_{n,k}|s_n)}\hat{Q}(s_n, a_{n,k})}{\sum_{k=1}^K \frac{\pi_{\theta}(a_{n,k}|s_n)}{\pi_{\theta_{old}}(a_{n,k}|s_n)}}\tag{29}$$<br>
å‡è®¾åœ¨$s_n$å¤„æ‰§è¡Œäº†$K$ä¸ªactions $a_{n,1}, a_{n,2}, \cdots, a_{n,K}$ã€‚Self-normalized ä¼°è®¡å»æ‰äº†$Q$å€¼baselineçš„éœ€è¦ã€‚åœ¨$s_n\sim \rho(\pi)$ä¸Šåšå¹³å‡ï¼Œå¯ä»¥å¾—åˆ°$L_{\theta_{old}}$å’Œå®ƒçš„gradientçš„ä¼°è®¡ã€‚<br>
Vineæ¯”single pathå¥½çš„åœ°æ–¹åœ¨äºï¼Œç»™å®šç›¸åŒæ•°é‡çš„$Q$æ ·æœ¬ï¼Œç›®æ ‡å‡½æ•°çš„å±€éƒ¨ä¼°è®¡æœ‰æ›´ä½çš„æ–¹å·®ï¼Œä¹Ÿå°±æ˜¯vineèƒ½æ›´å¥½çš„ä¼°è®¡advantageã€‚Vineçš„ç¼ºç‚¹åœ¨äºï¼Œéœ€è¦æ‰§è¡Œæ›´å¤šstepsçš„æ¨¡æ‹Ÿè®¡ç®—ç›¸åº”çš„advantageã€‚æ­¤å¤–ï¼Œvineæ–¹æ³•éœ€è¦å¯¹rollout set ä¸­çš„æ¯ä¸€ä¸ªstateéƒ½ç”Ÿæˆå¤šä¸ªtrajectoriesï¼Œè¿™å°±éœ€è¦æ•´ä¸ªsystemå¯ä»¥é‡ç½®åˆ°ä»»æ„çš„ä¸€ä¸ªstateï¼Œè€Œsingle pathç®—æ³•ä¸éœ€è¦ï¼Œå¯ä»¥ç›´æ¥åº”ç”¨åœ¨çœŸå®çš„systemä¸­ã€‚</p>
<h2 id="å®ç”¨ç®—æ³•">å®ç”¨ç®—æ³•</h2>
<p>ä½¿ç”¨ä¸Šé¢ä»‹ç»çš„single pathæˆ–è€…vineè¿›è¡Œé‡‡æ ·ï¼Œç»™å‡ºä¸¤ä¸ªç®—æ³•ã€‚é‡å¤æ‰§è¡Œä»¥ä¸‹æ­¥éª¤ï¼š</p>
<ol>
<li>ä½¿ç”¨single pathæˆ–è€…vineç®—æ³•äº§ç”Ÿä¸€ç³»åˆ—state-action pairsï¼Œä½¿ç”¨Monte Carloä¼°è®¡ç›¸åº”çš„$Q$å€¼ï¼›</li>
<li>åˆ©ç”¨æ ·æœ¬è®¡ç®—å…¬å¼$(27)$ä¸­ç›®æ ‡å‡½æ•°å’Œçº¦æŸå‡½æ•°çš„ä¼°è®¡å€¼</li>
<li>ä½¿ç”¨å…±è½­æ¢¯åº¦å’Œline searchæ±‚å‡ºæœ‰çº¦æŸä¼˜åŒ–é—®é¢˜çš„è¿‘ä¼¼è§£ï¼Œæ›´æ–°policyå‚æ•°$\theta$ï¼Œã€‚</li>
</ol>
<p>åœ¨ç¬¬$3$æ­¥ä¸­ï¼Œä½¿ç”¨KLæ•£åº¦çš„HessiançŸ©é˜µè€Œä¸æ˜¯åæ–¹å·®çŸ©é˜µçš„æ¢¯åº¦è®¡ç®—Fisher information matrixï¼Œå³ä½¿ç”¨$\frac{1}{N}\sum_{n=1}^N \frac{\partial^2}{\partial \theta_j}D_{KL}(\pi_{\theta_{old}}(\cdot|s_n)||\pi_{\theta}(\cdot|s_n))$è¿‘ä¼¼$A_{ij}$è€Œä¸æ˜¯$\frac{1}{N}\sum_{n=1}^N \frac{\partial}{\partial \theta_i}log(\pi_{\theta}(a_n|s_n))\frac{\partial}{\partial \partial_j}log(\pi_{\theta}(a_n|s_n))$ã€‚<br>
è¿™ä¸ªå®ç”¨ç®—æ³•å’Œå‰é¢çš„ç†è®ºå…³è”å¦‚ä¸‹ï¼š</p>
<ol>
<li>éªŒè¯äº†ä¼˜åŒ–ä½¿ç”¨KLæ•£åº¦è¿›è¡Œçº¦æŸçš„ç›®æ ‡å‡½æ•°å¯ä»¥ä¿è¯policy improvementæ˜¯å•è°ƒé€’å¢çš„ã€‚å¦‚æœpenaltyç³»æ•°$C$å¾ˆå¤§stepä¼šå¾ˆå°ï¼Œæˆ‘ä»¬æƒ³è¦å‡å°è¿™ä¸ªç³»æ•°ã€‚ç»éªŒä¸Šæ¥è®²ï¼Œå¾ˆéš¾é€‰æ‹©ä¸€ä¸ªé²é‚¦çš„penaltyç³»æ•°ï¼Œæ‰€ä»¥æˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªKLæ•£åº¦ä¸Šçš„ä¸€ä¸ªhard constraintè€Œä¸æ˜¯ä¸€ä¸ªpenaltyã€‚</li>
<li>$D_{KL}^{max}(\theta_{old}, \theta)$æ˜¯å¾ˆéš¾è®¡ç®—å’Œä¼°è®¡çš„ï¼Œæ‰€ä»¥å°†çº¦æŸæ¡ä»¶æ”¹æˆå¯¹æœŸæœ›$\bar{D}_{KL}(\theta_{old}, \theta)$è¿›è¡Œçº¦æŸã€‚</li>
<li>æœ¬æ–‡çš„ç†è®ºå¿½ç•¥äº†advantage functionçš„è¿‘ä¼¼è¯¯å·®ã€‚</li>
</ol>
<h2 id="å’Œpolicy-gradientä»¥åŠnatural-policy-gradientçš„å¯¹æ¯”">å’Œpolicy gradientä»¥åŠnatural policy gradientçš„å¯¹æ¯”</h2>
<p>Policy gradientå’Œnatural policy gradientå¯ä»¥çœ‹æˆç‰¹æ®Šçš„trpoï¼Œå®ƒä»¬å¯ä»¥ç»Ÿä¸€åœ¨policy updateæ¡†æ¶ä¸‹ã€‚<a href="http://mxxhcm.github.io/2019/09/07/gradient-method-natural-policy-gradient/">The natural policy gradient</a>å¯ä»¥çœ‹æˆå…¬å¼$(24)$çš„ä¸€ä¸ªç‰¹ä¾‹ï¼šä½¿ç”¨$L$çš„ä¸€ä¸ªlinear approximationï¼Œå’Œ$\bar{D}_{KL}$çš„ä¸€ä¸ªäºŒæ¬¡ä¼°è®¡ï¼Œå°±å˜æˆäº†ä¸‹é¢çš„ä¼˜åŒ–é—®é¢˜ï¼š<br>
$$\max_{\theta} \left[\nabla_{\theta}L_{\theta_{old}}(\theta)|_{\theta=\theta_{old}}\cdot (\theta-\theta_{old}) \right]$$<br>
$$s.t. \frac{1}{2}(\theta_{old}-\theta)^T A(\theta_{old})(\theta_{old} - \theta)\le\delta\tag{30}$$<br>
å…¶ä¸­$A(\theta_{old})_{ij} = \frac{\partial}{\partial\theta_i}\frac{\partial}{\partial \theta_j}\mathbb{E}_{s\sim \rho_{\pi}}\left[D_{KL}(\pi(\cdot|s, \theta_{old})||\pi(\cdot|s, \theta))\right]_{\theta=\theta_{old}}$ï¼Œæ›´æ–°å…¬å¼æ˜¯$\theta_{new} = \theta_{old}+\frac{1}{\lambda}A(\theta_{old})^{-1} \nabla_{\theta}L(\theta)|_{\theta=\theta_{old}}$ï¼Œå…¶ä¸­æ­¥é•¿$\frac{1}{\lambda}$å¯ä»¥çœ‹æˆç®—æ³•å‚æ•°ã€‚è¿™å’Œtrpoä¸åŒï¼Œåœ¨æ¯ä¸€æ¬¡æ›´æ–°éƒ½æœ‰constraintã€‚å°½ç®¡è¿™ä¸ªå·®åˆ«å¾ˆå°ï¼Œå®éªŒè¡¨æ˜å®ƒèƒ½æ”¹å–„åœ¨æ›´å¤§è§„æ¨¡é—®é¢˜ä¸Šç®—æ³•çš„æ€§èƒ½ã€‚<br>
åŒæ ·ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨$l2$çº¦æŸï¼Œæ¨å¯¼å‡ºæ ‡å‡†çš„<a href="http://mxxhcm.github.io/2019/09/07/gradient-method-policy-gradient/">policy gradient</a>å¦‚ä¸‹ï¼š<br>
$$\max_{\theta} \left[\nabla_{\theta} L_{\theta_{old}}(\theta)|_{\theta=\theta_{old}}\cdot (\theta - \theta_{old})\right] $$<br>
$$s.t. \frac{1}{2}\vert \theta-\theta_{old}\vert^2 \le \delta\tag{31}$$</p>
<h2 id="trpoç®—æ³•">TRPOç®—æ³•</h2>
<p>TRPOåº”ç”¨äº†conjugate gradientæ–¹æ³•åˆ°natural policy gradientï¼Œæ­¤å¤–ï¼Œnatural policy gradientçš„trusted regionå¾ˆå°ï¼Œä½œè€…å°†å®ƒæ¢æˆäº†ä¸€ä¸ªæ›´å¤§çš„å¯ä»¥è°ƒèŠ‚çš„å€¼ã€‚äºŒæ¬¡è¿‘ä¼¼å¯èƒ½ä¼šé™ä½accuracyï¼Œè¿™äº›å¯èƒ½ä¼šå¯¹policyçš„æ›´æ–°å¼•å…¥å…¶ä»–é—®é¢˜ï¼Œé€ æˆperformanceçš„degradeã€‚ä¸€ç§å¯èƒ½çš„è§£å†³åŠæ³•æ˜¯åœ¨è¿›è¡Œæ›´æ–°ä¹‹å‰å…ˆè¿›è¡ŒéªŒè¯ï¼š</p>
<ul>
<li>æ–°çš„policyå’Œè€çš„policyä¹‹é—´çš„çš„$\text{KL}$æ•£åº¦æ˜¯ä¸æ˜¯å°äº$\delta$</li>
<li>$L(\theta) \ge 0$</li>
</ul>
<p>å¦‚æœéªŒè¯å¤±è´¥äº†ï¼Œä½¿ç”¨è¡°å‡å› å­$0\lt \alpha \lt 1$ï¼Œå‡å°natural policy gradientç›´åˆ°æ»¡è¶³è¦æ±‚å³å¯ã€‚ä¸‹é¢çš„ç®—æ³•ä»‹ç»äº†è¿™ç§æ€æƒ³çš„line search solutionï¼š<br>
ç®—æ³• Line Search for TRPO<br>
è®¡ç®—$\Delta_k = \alpha \hat{\text{F}}_k^{-1} \nabla\eta$<br>
for $j=0,1,2,\cdots, t$ do<br>
$\qquad$è®¡ç®—$\theta = \theta_k + \alpha^j \Delta_k$<br>
$\qquad$If $L_{\theta_k}(\theta) \ge 0$æˆ–è€…$\bar{D}_{KL}(\theta||\theta_k) \le \delta$ then<br>
$\qquad\qquad$æ¥å—è¿™ä¸ªæ›´æ–°ï¼Œ $\theta_{k+1} = \theta_k + \alpha^j \Delta_k$<br>
$\qquad\qquad$break<br>
$\qquad$end if<br>
end for<br>
TRPOå°†truncated natural policiy gradient(ä½¿ç”¨conjugate gradient)å’Œline searchç»“åˆèµ·æ¥ï¼š<br>
ç®—æ³• Trust Region Policy Optimization<br>
è¾“å…¥ï¼šåˆå§‹çš„policyå‚æ•°$\theta_0$<br>
for $k=0,1,2,\cdots$ do<br>
$\qquad$ä½¿ç”¨policy $\pi_k = \pi(\theta_k)$æ”¶é›†trajectoriesåˆ°é›†åˆ$\mathbb{D}_k$<br>
$\qquad$ä¼°è®¡ä¼˜åŠ¿å‡½æ•°$\hat{A}_t^{\pi_k}$<br>
$\qquad$è®¡ç®—æ ·æœ¬ä¼°è®¡ï¼š<br>
$\qquad\qquad$ä½¿ç”¨ä¼˜åŠ¿å‡½æ•°ä¼°è®¡policy gradient $\nabla \eta(\theta)$<br>
$\qquad\qquad$è®¡ç®—$\text{KL}$æ•£åº¦çš„æµ·å¡çŸ©é˜µï¼ˆfisher informaction matrixï¼‰$\text{H}$<br>
$\qquad$ä½¿ç”¨å…±è½­æ¢¯åº¦ç®—æ³•è®¡ç®—$\hat{\nabla}\eta(\theta) \approx \text{H}^{-1} \nabla\eta(\theta)$<br>
$\qquad$æ›´æ–°$\theta_{k+1} = \theta_k + \alpha \hat{\nabla}\eta(\theta)$<br>
end for</p>
<h2 id="trpoçš„ç¼ºç‚¹">TRPOçš„ç¼ºç‚¹</h2>
<p>TRPOé€šè¿‡æœ€å°åŒ–äºŒæ¬¡æ³›å‡½è¿‘ä¼¼$\text{F}$çš„é€†ï¼Œå¾ˆå¤§ç¨‹åº¦å‡å°‘äº†è®¡ç®—é‡ã€‚ä½†æ˜¯æ¯ä¸€æ¬¡æ›´æ–°å‚æ•°è¿˜éœ€è¦è®¡ç®—$\text{F}$ã€‚TRPOå’Œå…¶ä»–policy gradientæ–¹æ³•ç›¸æ¯”ï¼Œé‡‡æ ·æ•ˆç‡å¾ˆä½ï¼Œå¹¶ä¸”æ‰©å±•æ€§ä¸å¥½ï¼Œå¯¹äºå¾ˆæ·±çš„ç½‘ç»œä¸é€‚ç”¨ï¼Œè¿™å°±æœ‰äº†åæ¥çš„<a href="https://mxxhcm.github.io/2019/09/23/gradient-method-proximal-policy-optimization/">PPO</a>å’ŒACKTRã€‚</p>
<h2 id="minorize-maximization-mmç®—æ³•"><a href="https://mxxhcm.github.io/2019/09/25/mm/">Minorize-Maximization MMç®—æ³•</a></h2>
<p><img src="/2019/09/08/gradient-method-trust-region-policy-optimization/mm.jpeg" alt="mm"><br>
å¦‚ä¸Šå›¾æ‰€ç¤ºï¼Œé€šè¿‡è¿­ä»£çš„æœ€å¤§åŒ–ä¸‹ç•Œå‡½æ•°å±€éƒ¨åœ°é€¼è¿‘expected rewardã€‚æ›´è¯¦ç»†çš„æ¥è¯´ï¼Œéšæœºçš„åˆå§‹åŒ–$\theta$ï¼Œåœ¨å½“å‰$\theta$ä¸‹ï¼Œæ‰¾åˆ°ä¸‹ç•Œ$M$æœ€æ¥è¿‘expected reward $\eta$çš„ç‚¹ï¼Œç„¶åå°†$M$çš„æœ€ä¼˜ç‚¹ä½œä¸ºä¸‹ä¸€æ¬¡çš„$\theta$ã€‚ä¸æ–­çš„è¿­ä»£ï¼Œç›´åˆ°æ”¶æ•›åˆ°optimal policyã€‚è¿™æ ·åšæœ‰ä¸€ä¸ªæ¡ä»¶ï¼Œå°±æ˜¯$M$è¦æ¯”$\eta$å®¹æ˜“ä¼˜åŒ–ã€‚æ¯”å¦‚$M$æ˜¯äºŒæ¬¡å‡½æ•°ï¼š<br>
$$ax^2 + bx+c\tag{32}$$<br>
ç”¨å‘é‡å½¢å¼è¡¨ç¤ºæ˜¯ï¼š<br>
$$g\cdot(\theta- \theta_{old}) - \frac{\beta}{2} (\theta- \theta_{old})^T F(\theta - \theta_{old})\tag{33}$$<br>
æ˜¯ä¸€ä¸ªconvex functionã€‚<br>
ä¸ºä»€ä¹ˆMMç®—æ³•ä¼šæ”¶æ•›åˆ°optimal policyï¼Œå¦‚æœ$M$æ˜¯ä¸‹ç•Œçš„è¯ï¼Œå®ƒä¸ä¼šè·¨è¿‡çº¢çº¿$\eta$ã€‚å‡è®¾æ–°çš„$\eta$ä¸­çš„new policyæ›´ä½ï¼Œé‚£ä¹ˆblueçº¿ä¸€å®šä¼šè¶Šè¿‡$\eta$ï¼Œå’Œ$M$æ˜¯ä¸‹ç•Œå†²çªã€‚</p>
<h2 id="trust-region">Trust Region</h2>
<p>æœ‰ä¸¤ç§ä¼˜åŒ–æ–¹æ³•ï¼šline searchå’Œtrust regionã€‚Gradient descentæ˜¯line searchæ–¹æ³•ã€‚é¦–å…ˆç¡®å®šä¸‹é™çš„æ–¹å‘ï¼Œç„¶åè¶…è¿™ä¸ªæ–¹å‘ç§»åŠ¨ä¸€æ­¥ã€‚è€Œtrust regionä¸­ï¼Œé¦–å…ˆç¡®å®šæˆ‘ä»¬æƒ³è¦æ¢ç´¢çš„step sizeï¼Œç„¶åç›´åˆ°åœ¨trust regionä¸­çš„optimal pointã€‚ç”¨$\delta$è¡¨ç¤ºåˆå§‹çš„maximum step sizeï¼Œä½œä¸ºtrust regionçš„åŠå¾„ï¼š<br>
$$max_{s\in \mathbb{R}^n} m_k(s), \qquad s.t. \vert s\vert \le \delta\tag{34}$$<br>
$m$æ˜¯åŸå§‹ç›®æ ‡å‡½æ•°$f$çš„è¿‘ä¼¼ï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯æ‰¾åˆ°åŠå¾„$\delta$èŒƒå›´$m$çš„æœ€ä¼˜ç‚¹ï¼Œè¿­ä»£ä¸‹å»ç›´åˆ°æœ€é«˜ç‚¹ã€‚åœ¨è¿è¡Œæ—¶å¯ä»¥æ ¹æ®è¡¨é¢çš„æ›²ç‡å»¶ä¼¸æˆ–è€…å‹ç¼©$\delta$æ§åˆ¶å­¦ä¹ çš„é€Ÿåº¦ã€‚å¦‚æœåœ¨optimal pointï¼Œ$m$æ˜¯$f$çš„ä¸€ä¸ªpoor approximatorï¼Œæ”¶ç¼©trust regionã€‚å¦‚æœapproximatationå¾ˆå¥½ï¼Œå°±expand trust regionã€‚å¦‚æœpolicyæ”¹å˜å¤ªå¤šçš„è¯ï¼Œå¯ä»¥æ”¶ç¼©trust regionã€‚</p>
<h2 id="å‚è€ƒæ–‡çŒ®">å‚è€ƒæ–‡çŒ®</h2>
<p>Trust Region Policy Optimization<br>
1.<a href="http://joschu.net/docs/thesis.pdf" target="_blank" rel="noopener">http://joschu.net/docs/thesis.pdf</a><br>
2.<a href="https://arxiv.org/pdf/1502.05477.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1502.05477.pdf</a><br>
3.<a href="https://medium.com/@jonathan_hui/rl-trust-region-policy-optimization-trpo-explained-a6ee04eeeee9" target="_blank" rel="noopener">https://medium.com/@jonathan_hui/rl-trust-region-policy-optimization-trpo-explained-a6ee04eeeee9</a><br>
4.<a href="https://medium.com/@jonathan_hui/rl-trust-region-policy-optimization-trpo-part-2-f51e3b2e373a" target="_blank" rel="noopener">https://medium.com/@jonathan_hui/rl-trust-region-policy-optimization-trpo-part-2-f51e3b2e373a</a><br>
5.<a href="https://people.eecs.berkeley.edu/~pabbeel/cs287-fa09/readings/KakadeLangford-icml2002.pdf" target="_blank" rel="noopener">https://people.eecs.berkeley.edu/~pabbeel/cs287-fa09/readings/KakadeLangford-icml2002.pdf</a><br>
6.<a href="https://drive.google.com/file/d/0BxXI_RttTZAhMVhsNk5VSXU0U3c/view" target="_blank" rel="noopener">https://drive.google.com/file/d/0BxXI_RttTZAhMVhsNk5VSXU0U3c/view</a><br>
7.<a href="https://zhuanlan.zhihu.com/p/26308073" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/26308073</a><br>
8.<a href="https://zhuanlan.zhihu.com/p/60257706" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/60257706</a><br>
9.<a href="http://rll.berkeley.edu/deeprlcourse/docs/lec5.pdf" target="_blank" rel="noopener">http://rll.berkeley.edu/deeprlcourse/docs/lec5.pdf</a><br>
10.<a href="https://www.zhihu.com/question/316004388" target="_blank" rel="noopener">https://www.zhihu.com/question/316004388</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mxxhcm.github.io/2019/09/07/gradient-method-natural-policy-gradient/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="é©¬æ™“é‘«çˆ±é©¬èŸèŸ">
      <meta itemprop="description" content="è®°å½•ç¡•å£«ä¸‰å¹´è‡ªå·±çš„ç§¯ç´¯">
      <meta itemprop="image" content="/images/favicon.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="mxxhcm's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/09/07/gradient-method-natural-policy-gradient/" class="post-title-link" itemprop="http://mxxhcm.github.io/page/4/index.html">gradient method natural policy gradient</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">å‘è¡¨äº</span>
              

              
                
              

              <time title="åˆ›å»ºæ—¶é—´ï¼š2019-09-07 19:38:03" itemprop="dateCreated datePublished" datetime="2019-09-07T19:38:03+08:00">2019-09-07</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">æ›´æ–°äº</span>
                
                <time title="ä¿®æ”¹æ—¶é—´ï¼š2019-09-27 15:57:58" itemprop="dateModified" datetime="2019-09-27T15:57:58+08:00">2019-09-27</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">åˆ†ç±»äº</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/å¼ºåŒ–å­¦ä¹ /" itemprop="url" rel="index"><span itemprop="name">å¼ºåŒ–å­¦ä¹ </span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="a-natural-policy-gradient">A Natural Policy Gradient</h2>
<p>è®ºæ–‡åç§°ï¼šA Natural Policy Gradient<br>
è®ºæ–‡åœ°å€ï¼š<a href="https://papers.nips.cc/paper/2073-a-natural-policy-gradient.pdf" target="_blank" rel="noopener">https://papers.nips.cc/paper/2073-a-natural-policy-gradient.pdf</a></p>
<h2 id="abstract">Abstract</h2>
<p>ä½œè€…åŸºäºå‚æ•°ç©ºé—´çš„åº•å±‚ç»“æ„æå‡ºäº†natural gradientæ–¹æ³•ï¼Œæ‰¾å‡ºä¸‹é™æœ€å¿«æ–¹å‘ã€‚å°½ç®¡gradientæ–¹æ³•ä¸èƒ½è¿‡å¤§çš„æ”¹å˜å‚æ•°ï¼Œå®ƒè¿˜æ˜¯èƒ½å¤Ÿæœç€é€‰æ‹©greedy optimal actionè€Œä¸æ˜¯æ›´å¥½çš„actionæ–¹å‘ç§»åŠ¨ã€‚åŸºäºå…¼å®¹å€¼å‡½æ•°çš„policy iterationï¼Œåœ¨æ¯ä¸€ä¸ªimprovement stepé€‰æ‹©greedy optimal actionã€‚</p>
<h2 id="introduction">Introduction</h2>
<p>ç›´æ¥çš„policy gradientåœ¨è§£å†³å¤§è§„æ¨¡çš„MDPsæ—¶å¾ˆæœ‰ç”¨ï¼Œè¿™ç§æ–¹æ³•åŸºäºfuture rewardçš„æ¢¯åº¦åœ¨æ»¡è¶³çº¦æŸæ¡ä»¶çš„ä¸€ç±»policesä¸­æ‰¾ä¸€ä¸ª$\pi$ï¼Œä½†æ˜¯è¿™ç§æ–¹æ³•æ˜¯non covariantçš„ï¼Œç®€å•æ¥è¯´ï¼Œå°±æ˜¯å·¦å³ä¸¤è¾¹çš„ç»´åº¦ä¸ä¸€è‡´ã€‚<br>
è¿™ç¯‡æ–‡ç« åŸºäºpolicyçš„åº•å±‚å‚æ•°ç»“æ„å®šä¹‰äº†ä¸€ä¸ªmetricï¼Œæå‡ºäº†ä¸€ä¸ªcovariant gradientæ–¹æ³•ï¼Œé€šè¿‡å°†å®ƒå’Œpolicy iterationè”ç³»èµ·æ¥ï¼Œå¯ä»¥è¯æ˜natural gradientæœç€é€‰æ‹©greedy optimal actionçš„æ–¹å‘ç§»åŠ¨ã€‚é€šè¿‡åœ¨ç®€å•å’Œå¤æ‚çš„MDPä¸­è¿›è¡Œæµ‹è¯•ï¼Œç»“æœè¡¨æ˜è¿™ç§æ–¹æ³•ä¸­æ²¡æœ‰å‡ºç°ä¸¥é‡çš„plateau phenomenonã€‚</p>
<h2 id="a-natural-gradient">A Natural Gradient</h2>
<p>å®šä¹‰average reward $\eta(\pi)$ä¸ºï¼š<br>
$$\eta(\pi) = \sum_{s,a}\rho^{\pi} (s) \pi(a;s) R(s, a) \tag{1}$$<br>
å…¶ä¸­$R(s,a) = \mathbb{E}\left[R_{t+1}\right|s_t=s, a_t = a]$ï¼Œstate action valueå’Œvalue functionå®šä¹‰å¦‚ä¸‹ï¼š<br>
$$Q^{\pi} (s,a) = \sum_{t=0}^{\infty} \mathbb{E}\left[R_t - \eta(\pi)|s_0=s,a_0=a,\pi\right], \forall s\in S, a\in A \tag{2}$$<br>
$$V^{\pi} (s) = \mathbb{E}_{\pi(aâ€™;s)}\left[Q^{\pi}(s,aâ€™)\right] \tag{3}$$<br>
è®¡ç®—average rewardçš„ç²¾ç¡®æ¢¯åº¦æ˜¯ï¼ˆå¯ä»¥çœ‹<a href="http://mxxhcm.github.io/2019/09/22/gradient-method-policy-gradient/">policy gradient</a>çš„æ¨å¯¼ï¼‰ï¼š<br>
$$\nabla\eta(\theta) = \sum_{s,a} \rho^{\pi} (s) \nabla \pi(a;s,\theta) Q^{\pi} (s,a) \tag{4}$$<br>
ä½¿ç”¨$\eta(\theta)$ä»£æ›¿äº†$\eta(\pi_{\theta})$ã€‚æœ¬æ–‡ä¸­å®šä¹‰$d\theta$çš„å¹³æ–¹é•¿åº¦$\vert d\theta\vert^2 $å’Œä¸€ä¸ªæ­£å®šçŸ©é˜µ$\text{G}(\theta)$æœ‰å…³ï¼š<br>
$$\vert d\theta\vert^2 = \sum_{ij} \text{G}_{ij} (\theta)d\theta_i d\theta_j = d\theta^T \text{G}(\theta) d\theta  \tag{5}$$<br>
åœ¨$d\theta$çš„å¹³æ–¹é•¿åº¦$\vert d\theta\vert^2 $ ç­‰äºä¸€ä¸ªå¸¸æ•°æ—¶ï¼Œæ±‚ä½¿å¾—$\eta(\theta+d\theta)$ä¸‹é™çš„æœ€å¿«çš„$d\theta$æ–¹å‘ã€‚å¯ä»¥è¯æ˜ï¼Œæœ€å¿«çš„æ¢¯åº¦ä¸‹é™æ–¹å‘æ˜¯$\text{G}^{-1} \nabla \eta(\theta)$ã€‚æ ‡å‡†çš„policy gradientå‡è®¾$\text{G}=\text{I}$ï¼Œæ‰€ä»¥æœ€é™¡çš„ä¸‹é™æ–¹å‘æ˜¯$\nabla\eta(\theta)$ã€‚æœ¬æ–‡ä½œè€…çš„æƒ³æ³•æ˜¯é€‰æ‹©ä¸€ä¸ªå…¶ä»–çš„$\text{G}$ï¼Œè¿™ä¸ªæ–°çš„$G$å¯¹åº”çš„metricä¸æ ¹æ®åæ ‡è½´çš„å˜åŒ–è€Œå˜åŒ–ï¼Œè€Œæ˜¯è·Ÿç€åæ ‡å‚æ•°åŒ–çš„mainfoldå˜åŒ–ï¼Œæ ¹æ®æ–°çš„metricå®šä¹‰natural gradientã€‚<br>
ç»™å‡ºç­–ç•¥$\pi(a;s,\theta)$çš„fisher informationï¼š<br>
$$\text{F}_s(\theta) = \mathbb{E}_{\pi(a;s,\theta)} \left[\frac{\partial \log \pi(a;s,\theta)}{\partial \theta_i} \frac{\partial \log \pi(a;s,\theta)}{\partial \theta_j}\right] \tag{6}$$<br>
æ˜¾ç„¶$\text{F}_s$æ˜¯æ­£å®šçŸ©é˜µï¼Œå¯ä»¥è¯æ˜ï¼ŒFIMæ˜¯æ¦‚ç‡åˆ†å¸ƒå‚æ•°ç©ºé—´ä¸Šçš„ä¸€ä¸ªinvariant metricã€‚ä¸è®ºä¸¤ä¸ªç‚¹çš„åæ ‡æ€ä¹ˆé€‰æ‹©ï¼Œå®ƒéƒ½èƒ½è®¡ç®—å¤„ç›¸åŒçš„distanceï¼Œæ‰€ä»¥è¯´å®ƒæ˜¯invariantã€‚å½“ç„¶ï¼Œ$\text{F}_s$ä½¿ç”¨äº†å•ä¸ªçš„$s$ï¼Œè€Œåœ¨è®¡ç®—average rewardæ—¶ï¼Œä½¿ç”¨çš„æ˜¯ä¸€ä¸ªåˆ†å¸ƒï¼Œå®šä¹‰$\text{F}$ï¼š<br>
$$\text{F}(\theta) = \mathbb{E}_{\rho^{\pi} (s)} \left[\mathbb{F}_s (\theta)\right] \tag{7}$$<br>
æ¯ä¸€ä¸ª$s$å¯¹åº”çš„å•ä¸ª$\text{F}_s$éƒ½å’ŒMDPçš„transition modelæ²¡æœ‰å…³ç³»ï¼ŒæœŸæœ›æ“ä½œå¼•å…¥äº†å¯¹transition modelå‚æ•°çš„ä¾èµ–ã€‚ç›´è§‚ä¸Šæ¥è¯´ï¼Œ$\text{F}_s$æµ‹é‡çš„æ˜¯åœ¨$s$ä¸Šçš„probability manifoldçš„è·ç¦»ï¼Œ$\text{F}(\theta)$å¯¹å®ƒä»¬è¿›è¡Œäº†å¹³å‡ã€‚å¯¹åº”çš„ä¸‹é™æœ€å¿«çš„æ–¹å‘æ˜¯ï¼š<br>
$$\hat{\nabla}\eta(\theta) =\text{F}(\theta)^{-1} \nabla\eta(\theta)  \tag{8}$$<br>
ä¸ºä»€ä¹ˆnatural gradientä¸‹é™æœ€å¿«çš„æ–¹å‘æ˜¯è¿™ä¸ªæ–¹å‘ï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬è¿›è¡Œè¯æ˜ã€‚å…¶å®ä¸Šé¢å°±æ˜¯è¯´çš„è¿™äº›å°±æ˜¯ä½¿ç”¨$\text{KL}$æ•£åº¦å½“åšmetricï¼Œè€Œä¸æ˜¯ä½¿ç”¨æ¬§å‡ é‡Œå¾—metricã€‚ç„¶åå¯¹$\text{KL}$æ•£åº¦è¿›è¡Œçº¦æŸï¼Œè¦æ‰¾åˆ°ä½¿å¾—ç›®æ ‡å‡½æ•°$\eta(\theta)$æœ€å¤§çš„$d\theta$ï¼Œéœ€è¦çŸ¥é“å“ªä¸ªæ–¹å‘çš„$\text{KL}$æ•£åº¦ä¸Šå‡çš„æœ€å¿«ï¼Œç›®æ ‡å‡½æ•°ï¼š<br>
$$d\theta^{*} = \arg \max \eta(\theta +d\theta) \tag{9}$$<br>
$$s.t. \text{KL}\left[p_{\theta}||p_{\thetaâ€™}\right] = c \tag{10}$$<br>
å…¶ä¸­$c$æ˜¯å¸¸æ•°ï¼Œç¡®ä¿æ›´æ–°åœ¨ä¸€å®šèŒƒå›´å†…ï¼Œä¸å—curvatureçš„å½±å“ã€‚ç›®æ ‡å‡½æ•°çš„ä¸€é˜¶æ³°å‹’å±•å¼€å…¬å¼å¦‚ä¸‹ï¼š<br>
\begin{align*}<br>
\eta_{\thetaâ€™}(\theta) &amp; = \eta_{\thetaâ€™}(\thetaâ€™) + \left[\nabla_{\theta}\eta_{\thetaâ€™}(\theta)|_{\theta=\thetaâ€™}\right]^T (\thetaâ€™ + d\theta - \thetaâ€™) + \cdots \\<br>
&amp; = \eta_{\thetaâ€™}(\thetaâ€™) + \left[\nabla_{\theta}\eta_{\thetaâ€™}(\theta)|_{\theta=\thetaâ€™}\right]^T d\theta + \cdots  \tag{11}\\<br>
\end{align*}</p>
<p>å¼•ç†$1$ï¼š$\text{KL}$æ•£åº¦åœ¨$\theta=\thetaâ€™$é™„è¿‘$\thetaâ€™ +d\theta, d\theta\rightarrow 0$å¤„çš„äºŒé˜¶æ³°å‹’å±•å¼€æ˜¯ï¼š<br>
$$\text{KL}\left[p(x|\thetaâ€™)||p(x|\thetaâ€™+d\theta)\right] \approx \frac{1}{2}d\theta^T \text{F}d\theta \tag{12}$$<br>
è¯æ˜ï¼š<br>
\begin{align*}<br>
\text{KL}\left[p_{\thetaâ€™}||p_{\thetaâ€™+d\theta}\right] &amp;\approx \text{KL}\left[p_{\thetaâ€™}||p_{\thetaâ€™}\right] + (\nabla_{\theta}\text{KL}\left[p_{\theta}||p_{\thetaâ€™}\right]|_{\theta=\thetaâ€™})^T (\thetaâ€™+d\theta -\thetaâ€™) \\<br>
&amp;\qquad\qquad\qquad\qquad + \frac{1}{2} (\thetaâ€™ +d\theta -\thetaâ€™)^T (\nabla_{\theta}^2 \text{KL}\left[p_{\theta}||p_{\thetaâ€™}\right]|_{\theta=\thetaâ€™})(\thetaâ€™+d\theta-\thetaâ€™)\tag{13}\\<br>
&amp; = \text{KL}\left[p_{\thetaâ€™}||p_{\thetaâ€™}\right] + (\nabla_{\theta}\text{KL}\left[p_{\theta}||p_{\thetaâ€™}\right]|_{\theta=\thetaâ€™})^T d\theta \\<br>
&amp;\qquad\qquad\qquad\qquad + \frac{1}{2} d\theta^T (\nabla_{\theta}^2 \text{KL}\left[p_{\theta}||p_{\thetaâ€™}\right]|_{\theta=\thetaâ€™}) d\theta\tag{14}\\<br>
&amp; = \text{KL}\left[p_{\thetaâ€™}||p_{\thetaâ€™}\right] + (\int_x p(x|\thetaâ€™)\nabla \log (p|\theta)|_{\theta=\thetaâ€™} dx)^T d\theta \\<br>
&amp;\qquad\qquad\qquad\qquad + \frac{1}{2} d\theta^T (\nabla_{\theta}^2 \text{KL}\left[p_{\theta}||p_{\thetaâ€™}\right]|_{\theta=\thetaâ€™}) d\theta\tag{15}\\<br>
&amp; = \text{KL}\left[p_{\thetaâ€™}||p_{\thetaâ€™}\right] + (\mathbb{E}_{p(x|\thetaâ€™)} \nabla\log p(x|\theta) dx|_{\theta=\thetaâ€™})^T d\theta \\<br>
&amp;\qquad\qquad\qquad\qquad + \frac{1}{2} d\theta^T (\nabla_{\theta}^2 \text{KL}\left[p_{\theta}||p_{\thetaâ€™}\right]|_{\theta=\thetaâ€™}) d\theta\tag{16}\\<br>
&amp; = 0 + 0 + \frac{1}{2} d\theta^T (\nabla_{\theta}^2 \text{KL}\left[p_{\theta}||p_{\thetaâ€™}\right]|_{\theta=\thetaâ€™}) d\theta\tag{17}\\<br>
&amp; = \frac{1}{2} d\theta^T (\nabla_{\theta}^2 \text{KL}\left[p_{\theta}||p_{\thetaâ€™}\right]|_{\theta=\thetaâ€™}) d\theta\tag{18}\\<br>
&amp; = \frac{1}{2} d\theta^T \text{H} d\theta\tag{19}\\<br>
&amp; = \frac{1}{2} d\theta^T \text{F} d\theta\tag{20}\\<br>
\end{align*}<br>
è¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆ$\vert d\theta\vert^2 $å®šä¹‰ä¸º$d\theta^T\text{G}\theta$çš„åŸå› ã€‚ä½¿ç”¨æ‹‰æ ¼æœ—æ—¥ä¹˜å­æ³•å°†$\text{KL}$æ•£åº¦çº¦æŸæ¡ä»¶å¸¦å…¥ç›®æ ‡å‡½æ•°$\eta$ï¼š<br>
\begin{align*}<br>
d\theta^{*} &amp; = {\arg \min}_{d\theta} \eta(\thetaâ€™+d\theta) + \lambda(\text{KL}\left[p_{\thetaâ€™}||p_{\thetaâ€™+d\theta}\right] -c)\\<br>
&amp; = {\arg \min}_{d\theta} L_{\thetaâ€™}(\thetaâ€™) + \left[\nabla_{\theta}L_{\thetaâ€™}(\theta)|_{\theta=\thetaâ€™}\right]^T d\theta + \lambda(\left[\frac{1}{2} d\theta^T \text{F} d\theta\right] -c)\tag{21}\\<br>
\end{align*}<br>
å¯¹$d\theta$æ±‚å¯¼ï¼Œä»¤å…¶ç­‰äº$0$ï¼Œå¾—ï¼š<br>
\begin{align*}<br>
&amp;0 + \nabla_{\theta}\eta_{\thetaâ€™}(\theta)|_{\theta=\thetaâ€™} + \text{F}d\theta + 0\\<br>
=&amp; \nabla_{\theta}\eta_{\thetaâ€™}(\theta)|_{\theta=\thetaâ€™} + \text{F}d\theta \tag{22}\\<br>
=&amp; 0\\<br>
\end{align*}<br>
æ±‚è§£å¾—åˆ°ï¼š<br>
$$d\theta= - \frac{1}{\lambda}\text{F}^{-1} \nabla_{\theta} \eta_{\thetaâ€™}(\theta) \tag{23}$$<br>
æ‰€ä»¥natural gradientå®šä¹‰ä¸ºï¼š<br>
$$\hat{\nabla}\eta(\theta) = \text{F}^{-1} \nabla_{\theta}\eta(\theta) \tag{24}$$</p>
<h2 id="the-natural-gradient-å’Œ-policy-iteration">The Natural Gradient å’Œ Policy Iteration</h2>
<p>ä½¿ç”¨$\omega$å‚æ•°åŒ–çš„å€¼å‡½æ•°$f^{\pi} (s,a;\omega)$è¿‘ä¼¼$Q^{\pi} (s,a)$ã€‚</p>
<h3 id="natural-gradient-with-approximation-ä½¿ç”¨è¿‘ä¼¼çš„è‡ªç„¶æ¢¯åº¦">Natural Gradient with Approximationï¼ˆä½¿ç”¨è¿‘ä¼¼çš„è‡ªç„¶æ¢¯åº¦ï¼‰</h3>
<p>å®šä¹‰ï¼š<br>
$$\psi(s,a)^{\pi} = \nabla \log \pi(a;s, \theta)$$<br>
$$f^{\pi} (s,a;\omega) = \omega^T \psi^{\pi} (s,a) \tag{25}$$<br>
å…¶ä¸­$\left[\nabla \log \pi(a;s, \theta)\right]_i = \frac{\partial \log \pi(a;s, \theta)}{\partial \theta_i}$ã€‚æ‰¾åˆ°æœ€å°åŒ–å‡æ–¹æ ¹è¯¯å·®å‡½æ•°çš„$\omega$ï¼Œè®°ä¸º$\hat{\omega}$ï¼š<br>
$$\epsilon(\omega, \pi) = \sum_{s,a}\rho^{\pi} (s)\pi(a;s,\theta)(f^{\pi} (s,a;\omega) - Q^{\pi} (s,a))^2 \tag{26}$$<br>
å¦‚æœä½¿ç”¨$f^{\pi} $ä»£æ›¿$Q$è®¡ç®—å‡ºæ¥çš„grdientè¿˜æ˜¯exactçš„ï¼Œå°±ç§°$f$æ˜¯å…¼å®¹çš„ã€‚</p>
<h4 id="å®šç†1">å®šç†1</h4>
<p>å¦‚æœ$\hat{\omega}$æ˜¯ä½¿å¾—å‡æ–¹è¯¯å·®$\epsilon(\omega,\pi_\theta)$æœ€å°çš„$\omega$ï¼Œå¯ä»¥è¯æ˜ï¼š<br>
$$\hat{\omega} = \hat{\nabla} \eta(\theta) =\text{F}(\theta)^{-1} \nabla\eta(\theta) =\text{F}(\theta)^{-1} \nabla\eta(\theta) \tag{27}$$<br>
è¯æ˜ï¼š<br>
å› ä¸º$\hat{\omega}$ä½¿å¾—$\epsilon$æœ€å°ï¼Œæ‰€ä»¥å½“$\omega = \hat{\omega}$æ—¶ï¼Œ$\frac{\partial \epsilon}{\partial \omega} = 0$ï¼Œæœ‰ï¼š<br>
$$\frac{\partial \epsilon}{\partial \omega} = \sum_{s,a}\rho^{\pi} (s) \pi(a|s;\theta) \psi^{\pi} (s,a) (\psi^{\pi} (s,a)^T \hat{\omega} - Q^{\pi} (s,a)) = 0 \tag{28}$$<br>
ç§»é¡¹åˆå¹¶åŒç±»é¡¹å¾—ï¼š<br>
$$\sum_{s,a}\rho^{\pi} (s) \pi(a|s;\theta) \psi^{\pi} (s,a) \psi^{\pi} (s,a)^T \hat{\omega} = \sum_{s,a}\rho^{\pi} (s) \pi(a|s;\theta) \psi^{\pi} (s,a)  Q^{\pi} (s,a) \tag{29}$$<br>
æ ¹æ®å®šä¹‰$\psi(s,a)^{\pi} = \nabla \log \pi(a;s, \theta)$ï¼Œè€Œæ ¹æ®log-derativate trickï¼š$\pi(a|s) \nabla \log \pi(a|s;\theta) = \nabla \pi(a|s;\theta)$ï¼Œæ‰€ä»¥å¼å­$(29)$å³é¢å°±æ˜¯$\nabla \eta$ï¼Œè€Œå¼å­å·¦é¢$\sum_{s,a}\rho^{\pi} (s) \pi(a|s;\theta) \psi^{\pi} (s,a) \psi^{\pi} (s,a)^T = \text{F}(\theta)$ã€‚æœ€åå¾—åˆ°ï¼š<br>
$$ \text{F}(\theta)\hat{\omega} = \nabla\eta(\theta)$$</p>
<h3 id="greedy-policy-improvement">Greedy Policy Improvement</h3>
<p>åœ¨greedy policy improvementçš„æ¯ä¸€æ­¥ï¼Œåœ¨$s$å¤„ï¼Œé€‰æ‹©$a\in \arg \max_{aâ€™} f^{\pi}(s, aâ€™;\hat{\omega})$ã€‚è¿™ä¸€èŠ‚ä»‹ç»natural gradientèƒ½å¤Ÿæ‰¾åˆ°best actionï¼Œè€Œä¸ä»…ä»…æ˜¯ä¸€ä¸ªgood actionã€‚<br>
é¦–å…ˆè€ƒè™‘æŒ‡æ•°å‡½æ•°ï¼š$\pi(s;a,\theta) \propto e^{\theta^T \phi_{sa}}$ï¼Œå…¶ä¸­$\phi_{sa} \in \mathbb{R}^m $æ˜¯ç‰¹å¾å‘é‡ã€‚ä¸ºä»€ä¹ˆä½¿ç”¨æŒ‡æ•°å‡½æ•°ï¼Œå› ä¸ºå®ƒæ˜¯affine geometryã€‚ç®€å•æ¥è¯´ï¼Œå°±æ˜¯$\pi(a;s,\theta)$çš„probability manifoldå¯ä»¥è¢«å¼¯æ›²ã€‚æ¥ä¸‹æ¥è¯æ˜policyåœ¨natrual gradientæ–¹å‘ä¸Šæ”¹è¿›çš„ä¸€å¤§æ­¥ç­‰ä»·äºè¿›è¡Œä¸€æ­¥greedy policy improvementçš„policyã€‚</p>
<h4 id="å®šç†2">å®šç†2</h4>
<p>å‡è®¾$\pi(s;a,\theta) \propto e^{\theta^T \phi_{sa}} $ï¼Œ$\hat{\nabla}\eta(\theta)$æ˜¯éé›¶çš„ï¼Œå¹¶ä¸”$\hat{\omega}$æ˜¯æœ€å°åŒ–å‡æ–¹è¯¯å·®çš„$\omega$ã€‚ä»¤<br>
$$\pi_{\infty}(a;s) = lim_{\alpha\rightarrow \infty}\pi(a;s,\theta + \alpha\hat{\nabla}\eta(\theta)) \tag{30}$$<br>
å½“ä¸”ä»…å½“$a\in \arg\max_{aâ€™} f^{\pi} (s,aâ€™;\hat{\omega})$æ—¶ï¼Œæœ‰$\pi_{\infty}(a;s)\neq 0$ã€‚<br>
è¯æ˜ï¼š<br>
æ ¹æ®å®šä¹‰ï¼š$f^{\pi} (s,a,\omega) = \omega^T \psi^{\pi} (s,a)$ï¼Œç”±å®šç†$1$å¯çŸ¥ï¼š$\hat{\omega} = \text{F}^{-1} \nabla \eta(\theta) = \hat{\nabla} \eta(\theta)$ï¼Œæ‰€ä»¥$f^{\pi}(s,a,\hat{\omega}) = \hat{\nabla}\eta(\theta)^T \psi^{\pi} (s,a)$ã€‚è€Œæ ¹æ®å®šä¹‰$\psi^{\pi} (s,a) = \nabla \log \pi(a|s;\theta) = \phi_{sa} - \mathbb{E}_{\pi(aâ€™|s;\theta)}(\phi_{saâ€™})$ï¼Œ$\mathbb{E}_{\pi(aâ€™|s;\theta)}(\phi_{saâ€™})$ä¸æ˜¯$a$çš„å‡½æ•°ï¼Œæ‰€ä»¥å°±æœ‰ï¼š<br>
$$\arg\max_{aâ€™}f^{\pi} (s,aâ€™;\hat{\omega}) = \arg\max_{aâ€™} \hat{\nabla}\eta(\theta)^T \phi_{sa}\tag{31}$$<br>
å’Œ$\mathbb{E}_{\pi(aâ€™|s;\theta)}(\phi_{saâ€™})$æ— å…³ã€‚ã€‚ç»è¿‡ä¸€ä¸ªgradient stepï¼š<br>
$$\pi(a|s;\theta+\alpha \hat{\nabla}\eta(\theta)) \propto e^{(\theta+\alpha \hat{\nabla}\eta(\theta))^T \phi_{sa}} \tag{32}$$<br>
å› ä¸º$\hat{\nabla}\eta(\theta) \neq 0$ï¼Œå¾ˆæ˜æ˜¾ï¼Œå½“$\alpha\rightarrow \infty$æ—¶ï¼Œ$\hat{\nabla}\eta(\theta)^T\phi_{sa}$ä¼šdominateï¼Œæ‰€ä»¥åªæœ‰å½“ä¸”ä»…å½“$a\in \arg\max_{aâ€™} f^{\pi} (s,aâ€™;\hat{\omega})$æ—¶ï¼Œæœ‰$\pi_{\infty}(a;s)\neq 0$ã€‚<br>
å¯ä»¥çœ‹å‡ºæ¥natural gradientè¶‹å‘äºé€‰æ‹©æœ€å¥½çš„actionï¼Œè€Œæ™®é€šçš„gradientæ–¹æ³•åªèƒ½é€‰å‡ºæ¥ä¸€ä¸ªæ›´å¥½çš„actionã€‚<br>
ä½¿ç”¨æŒ‡æ•°å‡½æ•°çš„ç›®çš„åªæ˜¯ä¸ºäº†å±•ç¤ºåœ¨æç«¯æƒ…å†µä¸‹ï¼ï¼æœ‰æ— é™å¤§çš„learning rateæƒ…å†µä¸‹çš„ç»“æœï¼Œæ¥ä¸‹æ¥ç»™å‡ºçš„æ˜¯æ™®é€šçš„å‚æ•°åŒ–ç­–ç•¥çš„ç»“æœï¼Œnatural gradientå¯ä»¥æ ¹æ®$Q^{\pi} (s,a)$çš„å±€éƒ¨è¿‘ä¼¼ä¼°è®¡$f^{\pi}(s,a;\hat{\omega})$ï¼Œè¿‘ä¼¼æ‰¾åˆ°å±€éƒ¨best actionã€‚</p>
<h4 id="å®šç†3">å®šç†3</h4>
<p>å‡å¦‚$\hat{\omega}$æœ€å°åŒ–ä¼°è®¡è¯¯å·®ï¼Œä½¿ç”¨$\thetaâ€™ = \theta + \alpha \hat{\nabla}\eta(\theta)$æ›´æ–°å‚æ•°ï¼Œå¯ä»¥å¾—åˆ°ï¼š<br>
$$\pi(a;s,\thetaâ€™) = \pi(a;s,\theta)(1+f^{\pi}(a,s,\hat{\omega})) + O(\alpha^2)\tag{33}$$<br>
è¯æ˜ï¼š<br>
æ ¹æ®å®šç†$1$ï¼Œå¾—åˆ°$\Delta \theta = \alpha\hat{\nabla}\eta(\theta) = \alpha\hat{\omega}$ï¼Œç„¶ååˆ©ç”¨ä¸€é˜¶æ³°å‹’å±•å¼€ï¼š<br>
\begin{align*}<br>
\pi(a|s;\thetaâ€™) &amp;= \pi(a|s;\theta) + \frac{\partial \pi(a|s;\theta)^T }{\partial\theta}\Delta\theta + O(\theta^2 ) \\<br>
&amp;= \pi(a|s;\theta) + \frac{\partial\log \pi(a|s;\theta)^T }{\partial\theta}\pi(a|s;\theta)\Delta\theta + O(\theta^2 ) \\<br>
&amp;= \pi(a|s;\theta)(1 + \frac{\partial\log \pi(a|s;\theta)^T }{\partial\theta}\Delta\theta) + O(\theta^2 ) \\<br>
&amp;= \pi(a|s;\theta)(1 +  \psi(s, a)^T \Delta\theta) + O(\theta^2 ) \\<br>
&amp;= \pi(a|s;\theta)(1 +  \psi(s, a)^T \alpha\hat{\omega}) + O(\alpha^2 ) \\<br>
&amp;= \pi(a|s;\theta)(1 +  \alpha f^{\pi} (s, a, \hat{\omega})) + O(\alpha^2 ) \\<br>
\end{align*}<br>
è¿™ä¸ªç›¸å½“äºæ˜¯æ ¹æ®$f^{\pi}(s,a) $é€‰æ‹©æ¯ä¸ªstateçš„actionã€‚å½“ç„¶ï¼Œå¹¶ä¸æ˜¯é€‰æ‹©greedy actionå°±ä¸€å®šä¼šæ”¹å–„policyï¼Œè¿˜æœ‰è®¸å¤šä¾‹å¤–ï¼Œè¿™é‡Œå°±ä¸ç»†è¯´äº†ã€‚</p>
<h2 id="metricså’Œcurvatures">Metricså’ŒCurvatures</h2>
<p>åœ¨ä¸åŒçš„å‚æ•°ç©ºé—´ä¸­ï¼Œ<a href="https://mxxhcm.github.io/2019/09/16/fisher-information/">fisher information</a>éƒ½å¯ä»¥æ”¶æ•›åˆ°<a href="https://mxxhcm.github.io/2019/09/10/Jacobian-matrix-and-Hessian-matrix/">æµ·å¡çŸ©é˜µ</a>ï¼Œå› æ­¤ï¼Œå®ƒæ˜¯<a href="https://mxxhcm.github.io/2019/09/18/asymptotically-efficient-%E6%B8%90%E8%BF%9B%E6%9C%89%E6%95%88%E6%80%A7/">aymptotically efficient</a>ï¼Œå³åˆ°è¾¾äº†cramer-rao boundã€‚<br>
$\text{F}$æ˜¯$\log \pi$å¯¹åº”çš„fisher informationã€‚Fisher information å’Œæµ·å¡çŸ©é˜µæœ‰å…³ç³»ï¼Œä½†æ˜¯éƒ½éœ€è¦å’Œ$\pi$è”ç³»èµ·æ¥ã€‚æ˜¯è¿™é‡Œè€ƒè™‘$\eta(\theta)$çš„æµ·å¡çŸ©é˜µï¼Œå®ƒå’Œ$\text{F}$ä¸¤ä¸ªä¹‹é—´æœ‰ä¸€å®šè”ç³»ï¼Œä½†æ˜¯ä¸ä¸€æ ·ã€‚<br>
äº‹å®ä¸Šï¼Œå®šä¹‰çš„æ–°çš„$\text{F}$å¹¶ä¸ä¼šæ”¶æ•›åˆ°æµ·å¡çŸ©é˜µã€‚ä½†æ˜¯å› ä¸ºæµ·å¡çŸ©é˜µä¸€èˆ¬ä¸æ˜¯æ­£å®šçš„ï¼Œæ‰€ä»¥åœ¨éå±€éƒ¨æœ€å°å¤„é™„è¿‘ï¼Œå®ƒæä¾›çš„curvatureä¿¡æ¯ç”¨å¤„ä¸å¤§ã€‚åœ¨å±€éƒ¨æœ€å°å¤„ä½¿ç”¨conjugate methodsä¼šæ›´å¥½ã€‚</p>
<h2 id="truncated-natural-policy-gradient">Truncated Natural Policy Gradient</h2>
<p>Natural policy gradientéœ€è¦è®¡ç®—$\delta \theta = \alpha \hat{\nabla}\eta(\theta) = \alpha\text{F}^{-1}\nabla(\eta)$ã€‚<br>
éœ€è¦è®¡ç®—è´¹èˆå°”ä¿¡æ¯çŸ©é˜µï¼ˆ$\text{KL}$æ•£åº¦çš„æµ·å¡çŸ©é˜µï¼‰$\text{F}$ä»¥åŠé€†çŸ©é˜µ$\text{F}^{-1} $ã€‚å¯»æ‰¾deep networksé€†çš„ä»£ä»·å¾ˆå¤§ï¼Œè€Œä¸”é€šå¸¸æ˜¯æ•°å€¼ä¸ç¨³å®šçš„ï¼Œæˆ‘ä»¬æƒ³è¦ä¸è®¡ç®—FIMçš„é€†ï¼Œè€Œç›´æ¥è®¡ç®—ï¼š<br>
$$\hat{\nabla}\eta(\theta) = \text{F}^{-1} \nabla\eta(\theta)$$<br>
è¿›è€Œè½¬åŒ–æˆæ±‚è§£ï¼š<br>
$$\text{F}^{-1} \hat{\nabla}\eta(\theta) = \nabla\eta(\theta)$$<br>
å› ä¸º$\text{F}$æ˜¯ä¸€ä¸ªå¯¹ç§°çŸ©é˜µï¼Œå°†åŸé—®é¢˜è½¬åŒ–ä¸ºï¼š<br>
$$\min_{x\in \mathbb{R}^n } \frac{1}{2}x^T \text{F}x - g^T x$$<br>
è¿™ä¸ªé—®é¢˜å¯ä»¥ä½¿ç”¨<a href="https://mxxhcm.github.io/2019/09/23/conjugate-gradient/">conjugate method</a>æ±‚è§£ã€‚<br>
å³ç”¨æ±‚è§£å‡ºæ¥çš„$x$è¿‘ä¼¼$\hat{\nabla}\eta(\theta) = \text{F}^{-1}\nabla(\eta)$ï¼Œå¤§å¤§å‡å°‘äº†è®¡ç®—é‡ã€‚</p>
<h2 id="å‚è€ƒæ–‡çŒ®">å‚è€ƒæ–‡çŒ®</h2>
<p>1.<a href="https://papers.nips.cc/paper/2073-a-natural-policy-gradient.pdf" target="_blank" rel="noopener">https://papers.nips.cc/paper/2073-a-natural-policy-gradient.pdf</a><br>
2.<a href="https://wiseodd.github.io/techblog/2018/03/14/natural-gradient/" target="_blank" rel="noopener">https://wiseodd.github.io/techblog/2018/03/14/natural-gradient/</a><br>
3.<a href="https://medium.com/@jonathan_hui/rl-trust-region-policy-optimization-trpo-part-2-f51e3b2e373a" target="_blank" rel="noopener">https://medium.com/@jonathan_hui/rl-trust-region-policy-optimization-trpo-part-2-f51e3b2e373a</a><br>
4.<a href="https://medium.com/@jonathan_hui/rl-natural-policy-gradient-actor-critic-using-kronecker-factored-trust-region-acktr-58f3798a4a93" target="_blank" rel="noopener">https://medium.com/@jonathan_hui/rl-natural-policy-gradient-actor-critic-using-kronecker-factored-trust-region-acktr-58f3798a4a93</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mxxhcm.github.io/2019/09/07/gradient-method-policy-gradient/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="é©¬æ™“é‘«çˆ±é©¬èŸèŸ">
      <meta itemprop="description" content="è®°å½•ç¡•å£«ä¸‰å¹´è‡ªå·±çš„ç§¯ç´¯">
      <meta itemprop="image" content="/images/favicon.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="mxxhcm's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/09/07/gradient-method-policy-gradient/" class="post-title-link" itemprop="http://mxxhcm.github.io/page/4/index.html">gradient method policy gradient</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">å‘è¡¨äº</span>
              

              
                
              

              <time title="åˆ›å»ºæ—¶é—´ï¼š2019-09-07 19:37:52" itemprop="dateCreated datePublished" datetime="2019-09-07T19:37:52+08:00">2019-09-07</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">æ›´æ–°äº</span>
                
                <time title="ä¿®æ”¹æ—¶é—´ï¼š2019-10-07 22:19:39" itemprop="dateModified" datetime="2019-10-07T22:19:39+08:00">2019-10-07</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">åˆ†ç±»äº</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/å¼ºåŒ–å­¦ä¹ /" itemprop="url" rel="index"><span itemprop="name">å¼ºåŒ–å­¦ä¹ </span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="policy-gradient">Policy Gradient</h2>
<p>å¼ºåŒ–å­¦ä¹ æœ‰ä¸‰ç§å¸¸ç”¨çš„æ–¹æ³•ï¼Œç¬¬ä¸€ç§æ˜¯åŸºäºå€¼å‡½æ•°çš„ï¼Œç¬¬äºŒç§æ˜¯policy gradientï¼Œç¬¬ä¸‰ç§æ˜¯derivative-freeçš„æ–¹æ³•ï¼Œå³ä¸åˆ©ç”¨å¯¼æ•°çš„æ–¹æ³•ã€‚åŸºäºå€¼å‡½æ•°çš„æ–¹æ³•åœ¨ç†è®ºä¸Šè¯æ˜æ˜¯å¾ˆéš¾çš„ã€‚è¿™ç¯‡è®ºæ–‡æå‡ºäº†policy gradientçš„æ–¹æ³•ï¼Œç›´æ¥ç”¨å‡½æ•°å»è¡¨ç¤ºç­–ç•¥ï¼Œæ ¹æ®expected rewardå¯¹ç­–ç•¥å‚æ•°çš„æ¢¯åº¦è¿›è¡Œæ›´æ–°ï¼ŒREINFORCEå’Œactor-criticéƒ½æ˜¯policy gradientçš„æ–¹æ³•ã€‚<br>
æœ¬æ–‡ç»™å‡ºäº†policy gradient theoremçš„è¯æ˜ï¼Œä½¿ç”¨è¿‘ä¼¼çš„action-value functionæˆ–è€…advantageå‡½æ•°ï¼Œæ¢¯åº¦å¯ä»¥è¡¨ç¤ºæˆexperienceçš„ä¼°è®¡ã€‚åŒæ—¶è¯æ˜äº†ä»»æ„å¯å¯¼çš„å‡½æ•°è¡¨ç¤ºçš„policyé€šè¿‡policy iterationéƒ½å¯ä»¥æ”¶æ•›åˆ°locl optimal policyã€‚</p>
<h3 id="å€¼å‡½æ•°æ–¹æ³•çš„ç¼ºç‚¹">å€¼å‡½æ•°æ–¹æ³•çš„ç¼ºç‚¹</h3>
<p>åŸºäºå€¼å‡½æ•°çš„æ–¹æ³•ï¼Œåœ¨ä¼°è®¡å‡ºå€¼å‡½æ•°ä¹‹åï¼Œæ¯æ¬¡é€šè¿‡greedyç®—æ³•é€‰æ‹©actionã€‚è¿™ç§æ–¹æ³•æœ‰ä¸¤ä¸ªç¼ºç‚¹ã€‚</p>
<ul>
<li>åŸºäºå€¼å‡½æ•°çš„æ–¹æ³•ä¼šæ‰¾åˆ°ä¸€ä¸ªdeterministicçš„ç­–ç•¥ï¼Œä½†æ˜¯å¾ˆå¤šæ—¶å€™optimal policyå¯èƒ½æ˜¯stochasticçš„ã€‚</li>
<li>æŸä¸ªactionçš„ä¼°è®¡å€¼å‡½æ•°ç¨å¾®æ”¹å˜ä¸€ç‚¹å°±å¯èƒ½å¯¼è‡´è¿™ä¸ªåŠ¨ä½œè¢«é€‰ä¸­æˆ–è€…ä¸è¢«é€‰ä¸­ï¼Œè¿™ç§ä¸è¿ç»­æ˜¯ä¿è¯å€¼å‡½æ•°æ”¶æ•›çš„ä¸€å¤§éšœç¢ã€‚</li>
</ul>
<h3 id="ç”¨å‡½æ•°è¡¨ç¤ºstochastic-policy">ç”¨å‡½æ•°è¡¨ç¤ºstochastic policy</h3>
<p>Policy gradientç”¨å‡½æ•°è¡¨ç¤ºstochastic policyã€‚æ¯”å¦‚ç”¨ç¥ç»ç½‘ç»œè¡¨ç¤ºçš„ä¸€ä¸ªpolicyï¼Œè¾“å…¥æ˜¯stateï¼Œè¾“å‡ºæ˜¯æ¯ä¸ªactioné€‰æ‹©çš„æ¦‚ç‡ï¼Œç¥ç»ç½‘ç»œçš„å‚æ•°æ˜¯policyçš„å‚æ•°ã€‚ç”¨$\mathbf{\theta}$è¡¨ç¤ºpolicyå‚æ•°ï¼Œç”¨$J$è¡¨ç¤ºè¯¥ç­–ç•¥çš„performance measureã€‚ç„¶åå‚æ•°$\mathbf{\theta}$çš„æ›´æ–°æ­£æ¯”äºä»¥ä¸‹æ¢¯åº¦ï¼š<br>
$$\nabla\mathbf{\theta} \approx \alpha \frac{\partial J}{\partial \mathbf{\theta}} \tag{1}$$<br>
å…¶ä¸­$\alpha$æ˜¯æ­£å®šçš„step sizeï¼ŒæŒ‰ç…§å¼å­$(1)$è¿›è¡Œæ›´æ–°ï¼Œå¯ä»¥ç¡®ä¿$\theta$æ”¶æ•›åˆ°$J$çš„å±€éƒ¨æœ€ä¼˜å€¼å¯¹åº”çš„local optimal policyã€‚å’Œvalue basedæ–¹æ³•ç›¸æ¯”ï¼Œ$\mathbf{\theta}$çš„å¾®å°æ”¹å˜åªèƒ½é€ æˆpolicyå’Œstateåˆ†å¸ƒçš„å¾®å°æ”¹å˜ã€‚</p>
<h3 id="ä½¿ç”¨å€¼å‡½æ•°è¾…åŠ©å­¦ä¹ policy">ä½¿ç”¨å€¼å‡½æ•°è¾…åŠ©å­¦ä¹ policy</h3>
<p>ä½¿ç”¨æ»¡è¶³ç‰¹å®šå±æ€§çš„è¾…åŠ©è¿‘ä¼¼å€¼å‡½æ•°ï¼Œåˆ©ç”¨ä¹‹å‰çš„experienceå°±å¯ä»¥å¾—åˆ°å¼å­$(1)$çš„ä¸€ä¸ªæ— åä¼°è®¡ã€‚REINFORCEæ–¹æ³•ä¹Ÿæ‰¾åˆ°äº†å¼å­$(1)$çš„ä¸€ä¸ªæ— åä¼°è®¡ï¼Œä½†æ²¡æœ‰ä½¿ç”¨è¾…åŠ©å€¼å‡½æ•°ï¼Œæ­¤å¤–å®ƒçš„é€Ÿåº¦è¦æ¯”ä½¿ç”¨å€¼å‡½æ•°çš„æ–¹æ³•æ…¢å¾ˆå¤šã€‚å­¦ä¹ ä¸€ä¸ªå€¼å‡½æ•°ï¼Œå¹¶ç”¨å®ƒå–å‡å°‘æ–¹å·®å¯¹å¿«é€Ÿå­¦ä¹ æ˜¯å¾ˆé‡è¦çš„ã€‚</p>
<h3 id="è¯æ˜policy-iterationæ”¶æ•›æ€§">è¯æ˜policy iterationæ”¶æ•›æ€§</h3>
<p>æœ¬æ–‡è¿˜è¯æ˜äº†åŸºäºactor-criticå’Œpolicy-iterationæ¶æ„æ–¹æ³•çš„æ”¶æ•›æ€§ã€‚åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œä»–ä»¬åªè¯æ˜äº†ä½¿ç”¨é€šç”¨å‡½æ•°é€¼è¿‘çš„policy iterationå¯ä»¥æ”¶æ•›åˆ°local optimal policyã€‚</p>
<h2 id="objective-function">Objective Function</h2>
<h3 id="ä¸‰ç§å½¢å¼">ä¸‰ç§å½¢å¼</h3>
<p>æ™ºèƒ½ä½“æ¯ä¸€æ­¥çš„actionç”±policy $\pi$å†³å®šï¼š$\pi(s,a,\mathbf{\theta})=Pr\left[a_t=a|s_t=s,\mathbf{\theta}\right],\forall s\in S, \forall a\in A,\mathbf{\theta}\in \mathbb{R}^l $ã€‚ä¸ºäº†æ–¹ä¾¿ï¼Œé€šå¸¸æŠŠ$\pi(s,a,\mathbf{\theta})$ç®€å†™ä¸º$\pi(s,a)$ã€‚å‡è®¾$\pi$æ˜¯å¯å¯¼çš„ï¼Œå³$\frac{\partial\pi(s,a)}{\partial\mathbf{\theta}}$å­˜åœ¨ã€‚æœ‰ä¸‰ç§æ–¹å¼å®šä¹‰æ™ºèƒ½ä½“çš„objectiveï¼š</p>
<ul>
<li>è®¡ç®—policy $\pi$ä¸‹ä»åˆå§‹çŠ¶æ€$s_0$å¼€å§‹çš„accumulated rewardï¼š<br>
$$J(\theta) = V^{\pi}(s_0) = \mathbb{E}_{\pi}\left[G_0\right] = \mathbb{E}_{\pi} \left[\sum_{t=0}^{\infty} \gamma^{t-1} R_t | s_0 \right] \tag{2}$$<br>
å…¶ä¸­$0 \le \gamma \le 1$ï¼Œåœ¨continuing caseä¸­ï¼Œ$0 \le \gamma \lt 1$ï¼Œè€Œåœ¨episodicæƒ…å†µä¸‹ï¼Œ$\gamma$èƒ½å–åˆ°$1$ï¼Œ$0 \le \gamma \le 1$ã€‚</li>
<li>è®¡ç®—policy $\pi$æ¯ä¸ªtimestepçš„immediate rewardçš„å‡å€¼ï¼Œå³average rewardã€‚<br>
$$J(\theta) = \mathbb{E}_{\pi}\left[R(s, a)\right] = \sum_s d(s) \sum_a\pi(s, a)R(s,a) \tag{3}$$<br>
åœ¨connuting problemsæƒ…å†µä¸‹ï¼Œæ²¡æœ‰episode boundariesï¼Œå¦‚æœä¸ä½¿ç”¨discount factorï¼Œå¯ä»¥è¿™ä¹ˆåšï¼›äº‹å®ä¸Šï¼Œæˆ‘è§‰å¾—åœ¨episodicæƒ…å†µä¸‹ï¼Œä¹Ÿèƒ½è¿™ä¹ˆåšã€‚</li>
<li>å½“æ²¡æœ‰æ˜ç¡®çš„åˆå§‹çŠ¶æ€æ—¶ï¼Œè®¡ç®—policy $\pi$ä¸‹æ‰€æœ‰state valueçš„å‡å€¼ï¼š<br>
$$J(\theta) = \sum_s d(s) V^{\pi} (s) = \sum_s d(s) \sum_a\pi(s, a) Q^{\pi} (s, a) = \mathbb{E}_{\pi}\left[Q^{\pi}(s, a)\right] \tag{4}$$</li>
</ul>
<p>å…¶ä¸­$R(s,a) = \mathbb{E}\left[R_{t+1}|s_t=s, a_t=a\right]$ï¼Œ$d (s) = lim_{t\rightarrow \infty} Pr\left[s_t=s|s_0,\pi\right]$æ˜¯ç­–ç•¥$\pi$ä¸‹çš„stationary distributionã€‚<a href="http://mxxhcm.github.io/2019/07/31/markov-matrices/">Stationary distribution</a>çš„æ„æ€æ˜¯å°±æ˜¯ä¸è®ºåˆå§‹çŠ¶æ€æ˜¯ä»€ä¹ˆï¼Œç»è¿‡å¾ˆå¤šæ­¥ä¹‹åï¼Œéƒ½ä¼šè¾¾åˆ°ä¸€ä¸ªstable stateã€‚å…¶å®è¿™ä¸‰ä¸ªç›®æ ‡æœ¬è´¨ä¸Šéƒ½æ˜¯ä¸€æ ·çš„ï¼Œéƒ½æ˜¯è¦æœ€å¤§åŒ–æ¯ä¸ªæ—¶åˆ»agentå¾—åˆ°çš„rewardã€‚</p>
<h3 id="accumated-reward-from-designated-state-ä»æŒ‡å®šçŠ¶æ€å¼€å§‹çš„ç´¯è®¡å¥–åŠ±">Accumated Reward from Designated State(ä»æŒ‡å®šçŠ¶æ€å¼€å§‹çš„ç´¯è®¡å¥–åŠ±)</h3>
<p>æˆ‘ä»¬å¯ä»¥æŒ‡å®šä¸€ä¸ªåˆå§‹çŠ¶æ€$s_0$ï¼Œè®¡ç®—ä»è¿™ä¸ªåˆå§‹çŠ¶æ€å¼€å§‹å¾—åˆ°çš„accumulated rewardï¼š<br>
$$\eta(\pi) = V^{\pi} (s_0) = \mathbb{E}_{\pi}\left[\sum_{t=0}^{\infty} \gamma^{t-1} R_t|s_0\right] = \mathbb{E}_{\pi}\left[G_0 \right]\tag{5}$$<br>
å®šä¹‰return $G_t$å¦‚ä¸‹ï¼š<br>
$$ G_t = \sum_{k=0}^{\infty} R_{t+k+1} \tag{6}$$<br>
å®šä¹‰state-action value functionå’Œstate value functionå¦‚ä¸‹ï¼š<br>
\begin{align*}<br>
Q^{\pi} (s,a) = \mathbb{E}_{\pi}\left[G_t|s_t=s, a_t=a\right] &amp; = \mathbb{E}_{\pi}\left[\sum_{k=0}^{\infty} R_{t+k+1}|s_t=s,a_t=a\right] \\<br>
V^{\pi} (s) = \mathbb{E}_{\pi}\left[G_t|s_t=s\right] &amp; = \mathbb{E}_{\pi}\left[\sum_{k=0}^{\infty} R_{t+k+1}|s_t=s\right]\\<br>
\tag{7}<br>
\end{align*}<br>
å…¶ä¸­$\gamma\in[0,1]$æ˜¯æŠ˜æ‰£å› å­ï¼Œåªæœ‰åœ¨episodicä»»åŠ¡ä¸­æ‰å…è®¸å–$\gamma=1$ã€‚å®ƒä»¬ä¹‹é—´çš„å…³ç³»å¦‚ä¸‹ï¼š<br>
\begin{align*}<br>
V^{\pi} (s) = \mathbb{E}_{\pi}\left[Q^{\pi} (s,a)|S_t=s\right] &amp; = \sum_a \pi(a|s) Q^{\pi} (s,a) \\<br>
Q^{\pi} (s, a) = \mathbb{E}_{\pi}\left[R_{t+1} + \gamma V^{\pi}(s)|S_t=s, A_t=a\right] &amp; = \sum_{sâ€™,r}p(sâ€™,r|s,a) (r+\gamma V^{\pi} (sâ€™))\\<br>
\tag{8}<br>
\end{align*}<br>
å®šä¹‰$\rho^{\pi} (s)$æ˜¯ä»æŒ‡å®šçš„åˆå§‹çŠ¶æ€$s_0$å¼€å§‹ï¼Œæ‰§è¡Œç­–ç•¥$\pi$åœ¨$t=\infty$ä¹‹é—´çš„ä»»æ„æ—¶åˆ»æ‰€æœ‰èƒ½åˆ°è¾¾state $s$çš„æŠ˜æ‰£æ¦‚ç‡ä¹‹å’Œï¼š<br>
$$\rho^{\pi} (s) = \sum_{t=1}^{\infty} \gamma^t Pr\left[s_t = s|s_0,\pi\right]  =  \sum_{t=0}^{\infty} \gamma^{t} p(s_0\rightarrow s, t,\pi) \tag{9}$$<br>
æŠŠ$\rho^{\pi} (s) $æ¢ä¸€ç§å†™æ³•å°±å®¹æ˜“ç†è§£äº†ï¼š<br>
$$\rho^{\pi} (s) = P(s_0 = s) +\gamma P(s_1=s) + \gamma^2 P(s_2 = s)+\cdots \tag{10}$$</p>
<h3 id="average-reward-å¹³å‡å¥–åŠ±">Average Reward(å¹³å‡å¥–åŠ±)</h3>
<p>Average rewardæ˜¯æ ¹æ®æ¯ä¸€ä¸ªstepçš„çš„expected reward $\eta(\pi)$å¯¹ä¸åŒçš„policyè¿›è¡Œæ’åï¼š<br>
$$\eta(\pi) = lim_{t\rightarrow \infty}\frac{1}{t}\mathbb{E}\left[R_1+R_2+\cdots+R_t|\pi\right] = \int_S d(s) \int_A \pi(s,a) R(s,a)dads \tag{11}$$<br>
ç¬¬ä¸€ä¸ªç­‰å·ä¸­ï¼Œ$R_t$è¡¨ç¤º$t$æ—¶åˆ»çš„immediate rewardï¼Œæ‰€ä»¥ç¬¬ä¸€ä¸ªç­‰å·è¡¨ç¤ºçš„æ˜¯åœ¨ç­–ç•¥$\pi$ä¸‹$t$ä¸ªæ—¶é—´æ­¥çš„imediate rewardå¹³å‡å€¼çš„æœŸæœ›ã€‚ç¬¬äºŒä¸ªç­‰å·åï¼Œç¬¬ä¸€ä¸ªç§¯åˆ†æ˜¯å¯¹$s$ç§¯åˆ†ï¼Œç›¸å½“äºæ±‚çš„æ˜¯$s$çš„æœŸæœ›ï¼›ç„¶åå¯¹$a$çš„ç§¯åˆ†ï¼Œæ±‚çš„æ˜¯æ¯ä¸€ä¸ª$s$å¤„å¯¹åº”å„ä¸ªåŠ¨ä½œ$a$å‡ºç°æ¦‚ç‡çš„æœŸæœ›ï¼Œæ‰€ä»¥ç¬¬äºŒä¸ªç­‰å¼åé¢æ±‚çš„å…¶å®å°±æ˜¯æ¯ä¸€æ­¥$R(s,a)$å¹³å‡å€¼çš„æœŸæœ›ã€‚<br>
Returnçš„å®šä¹‰å’Œaccumulated rewardä¸åŒï¼š<br>
$$G_t = \sum_{k=0}^{\infty} \left[R_{t+k+1} - \eta(\pi)\right] \tag{12}$$<br>
å› ä¸º$G_t$ä¸åŒï¼ŒState-action value $Q^{\pi} (s,a)$ä»¥åŠstate value $V^{\pi} (s)$çš„å®šä¹‰å’Œaccumulated rewardä¹Ÿå°±ä¸åŒäº†ï¼š<br>
\begin{align*}<br>
Q^{\pi} (s,a) = \mathbb{E}_{\pi}\left[G_t|s_t=s, a_t=a\right] &amp; = \mathbb{E}_{\pi}\left[\sum_{k=0}^{\infty}\left( R_{t+k+1} - \eta(\pi)\right)|s_t=s,a_t=a\right]\\<br>
V^{\pi} (s) = \mathbb{E}_{\pi}\left[G_t|s_t=s\right] &amp; = \mathbb{E}_{\pi}\left[\sum_{k=0}^{\infty} \left(R_{t+k+1} - \eta(\pi) \right)|s_t=s\right] \\<br>
\tag{13}<br>
\end{align*}<br>
$Q^{\pi} (s,a)$å’Œ$V^{\pi} (s,a)$ä¹‹é—´çš„å…³ç³»æ»¡è¶³ï¼š<br>
\begin{align*}<br>
Q^{\pi} (s,a) = \sum_{sâ€™, r}p(sâ€™,r|s,a)(r - \eta(\pi) + V(sâ€™)) \tag{14}<br>
\end{align*}</p>
<h3 id="state-valueçš„å‡å€¼">State valueçš„å‡å€¼</h3>
<p>è¿™ä¸ªå’Œä¸Šé¢çš„accumulated rewardæœ‰ä¸€å®šå…³è”ï¼Œaccumulatedè®¡ç®—çš„æ˜¯$V^{\pi} (s_0)$ï¼Œè€Œè¿™é‡Œè®¡ç®—çš„æ˜¯$V^{\pi} (s_0)$çš„æœŸæœ›ï¼ˆå‡å€¼ï¼‰ï¼š<br>
$$ \eta(\pi) = \sum_s \rho_0(s_0) V^{\pi} (s) \tag{15}$$<br>
State action value functionå’Œstate value functionçš„å®šä¹‰å’Œaccumulated rewardä¸€æ ·ã€‚<br>
å®šä¹‰$\rho^{\pi} $ä¸ºä»ä»»æ„åˆå§‹çŠ¶æ€$s_0$ç»è¿‡$t$æ­¥ä¹‹åstate $s$å‡ºç°çš„æ¦‚ç‡ï¼š<br>
$$\rho^{\pi} (s) =\int_S \sum_{t=0}^{\infty} \gamma^t \rho_0^{\pi} (s_0) Pr\left[s_t = s|s_0,\pi\right] ds_0  = \int_S \sum_{t=0}^{\infty} \gamma^{t} \rho_0^{\pi} (s_0)p(s_0\rightarrow s, t,\pi)ds_0 \tag{16}$$</p>
<h3 id="policy-gradient-v2">Policy Gradient</h3>
<p>å¯¹äºå•æ­¥çš„MDPï¼Œä»åˆ†å¸ƒ$\rho^{\pi} (s)$ä¸­é‡‡æ ·å¾—åˆ°$s$ï¼Œé‡‡å–action $a$ï¼Œå¾—åˆ°immediate reward $R=R(s,a)$ï¼Œç»“æŸã€‚ä¸Šé¢ä¸‰ç§ç›®æ ‡å‡½æ•°æ˜¯ä¸€æ ·çš„ï¼š<br>
\begin{align*}<br>
J(\theta) &amp; = \mathbb{E}_{\pi}\left[R\right]\\<br>
&amp; = \sum_s d(s) \sum_a \pi(s,a) R(s,a) \tag{17}\\<br>
\end{align*}<br>
æ±‚å¯¼æœ‰é—®é¢˜ï¼ï¼ï¼ï¼æ€ä¹ˆæ±‚å¯¼å¾—åˆ°çš„ã€‚ã€‚ã€‚<br>
\begin{align*}<br>
\nabla_{\theta} J(\theta) &amp; = \sum_s d(s) \sum_a \nabla_{\theta}\pi(s,a) R(s,a)\\<br>
&amp; = \sum_s d(s) \sum_a\pi(s,a) \nabla_{\theta}\log \pi(s,a) R(s,a)\\<br>
&amp; = \mathbb{E}_{\pi}\left[\nabla_{\theta}\log \pi(s,a) R(s,a)\right] \tag{18}\\<br>
\end{align*}<br>
å¯¹äºå¤šæ­¥çš„MDPï¼Œåªéœ€è¦å°†$R$æ¢æˆ$Q^{\pi} (s, a)$å°±è¡Œäº†ï¼Œä¸Šé¢ä¸‰ç§ç›®æ ‡å‡½æ•°æœ€åéƒ½èƒ½å¤Ÿå¾—åˆ°ï¼š<br>
$$\nabla_{\theta} J(\theta) = \sum_s d(s) \sum_a\pi(a|s) \nabla_{\theta} \log\pi(s,a) Q^{\pi} (s,a) = \mathbb{E}_{\pi} \left[\nabla_{\theta} \log\pi(s,a) Q^{\pi} (s,a)\right] \tag{19}$$<br>
å…¶ä¸­$Q$æ˜¯æ ¹æ®ä¸åŒçš„ç›®æ ‡å‡½æ•°å®šä¹‰çš„state-action value functionï¼Œç›®æ ‡å‡½æ•°ä¸åŒï¼Œ$Q$å®šä¹‰ä¹Ÿä¸åŒã€‚åœ¨å…¶ä»–è®ºæ–‡ä¸­ï¼Œ$\nabla_{\theta} \log\pi_{\theta}(s,a)$ä¸å˜ï¼Œå¯ä»¥æŠŠ$Q$æ¢æˆå…¶ä»–ç›®æ ‡å‡½æ•°ï¼ŒGAEè¿™ç¯‡è®ºæ–‡å¯¹ä¸åŒçš„ç›®æ ‡å‡½æ•°è¿›è¡Œäº†æ€»ç»“ã€‚</p>
<h2 id="policy-gradient-theorem">Policy Gradient Theorem</h2>
<p>å¯¹äºä»»ä½•MDPï¼Œä¸è®ºæ˜¯average rewardè¿˜æ˜¯accumulated rewardçš„å½¢å¼ï¼Œéƒ½æœ‰ï¼š<br>
\begin{align*}<br>
\nabla_{\theta} \eta &amp; = \sum_s \rho^{\pi} (s)\sum_a{\nabla_{\theta}\pi(s,a)}Q^{\pi} (s,a) \\<br>
&amp; = \sum_s \rho^{\pi} (s)\sum_a{\pi(s,a)\nabla_{\theta}\log\pi(s,a)}Q^{\pi} (s,a), \tag{20}\\<br>
&amp; = \mathbb{E}_{\pi}\left[\nabla_{\theta}\log\pi(s,a)Q^{\pi} (s,a)\right], \tag{21}\\<br>
\end{align*}<br>
è¯æ˜ï¼š<br>
\begin{align*}<br>
\nabla V_{\pi}(s) &amp;= \nabla \left[ \sum_a \pi(a|s)Q_{\pi}(s,a)\right], \forall s\in S \\<br>
&amp;= \sum_a \left[\nabla\pi(a|s)Q_{\pi}(s,a)\right], \forall s\in S \\<br>
&amp;= \sum_a\left[\nabla\pi(a|s)Q_{\pi}(s,a) + \pi(a|s)\nabla Q_{\pi}(s,a)\right] \\<br>
&amp;= \sum_a\left[\nabla\pi(a|s)Q_{\pi}(s,a) + \pi(a|s)\nabla \left[\sum_{sâ€™,r}p(sâ€™,r|s,a)(R+\gamma V_{\pi}(sâ€™))\right]\right] \\<br>
&amp;= \sum_a\left[\nabla\pi(a|s)Q_{\pi}(s,a) + \pi(a|s)\nabla \left[\sum_{sâ€™,r}p(sâ€™,r|s,a)R +\sum_{sâ€™,r}p(sâ€™,r|s,a)\gamma V_{\pi}(sâ€™)\right]\right] \\<br>
&amp;= \sum_a\left[\nabla\pi(a|s)Q_{\pi}(s,a) + \pi(a|s)\left[0 +\sum_{sâ€™,r}p(sâ€™,r|s,a)\gamma\nabla V_{\pi}(sâ€™)\right]\right] \\<br>
&amp;= \sum_a\left[\nabla\pi(a|s)Q_{\pi}(s,a) + \pi(a|s)\sum_{sâ€™,r}p(sâ€™,r|s,a)\gamma \nabla V_{\pi}(sâ€™))\right] \\<br>
&amp;= \sum_a\left[\nabla\pi(a|s)Q_{\pi}(s,a) + \pi(a|s)\sum_{sâ€™}\gamma p(sâ€™|s,a)\nabla V_{\pi}(sâ€™) \right] \\<br>
&amp;= \sum_a\\<br>
&amp;\left[\nabla\pi(a|s)Q_{\pi}(s,a) + \pi(a|s)\sum_{sâ€™}\gamma p(sâ€™|s,a)\left( \sum_{aâ€™} \nabla\pi(aâ€™|sâ€™)Q_{\pi}(sâ€™,aâ€™) + \pi(aâ€™|sâ€™)\sum_{sâ€™â€™}\gamma p(sâ€™â€™|sâ€™,aâ€™)\nabla V_{\pi}(sâ€™â€™))\right) \right] \tag{22}\\<br>
&amp;= \sum_{x\in S}\sum_{k=0}^{\infty} Pr(s\rightarrow x, k,\pi)\sum_a\nabla\pi(a|x)Q_{\pi}(x,a) \tag{23}\\<br>
&amp;= \sum_{x\in S}\rho^{\pi} (x)\sum_a\nabla \pi(a|x) Q_{\pi}(x,a) \tag{24}\\<br>
\end{align*}</p>
<p>å¼å­$(23)$ä¸­çš„$Pr(s\rightarrow x, k, \pi)$æ˜¯åœ¨ç­–ç•¥$\pi$ä¸‹ä»state $s$ç»è¿‡$k$æ­¥è½¬æ¢åˆ°state $x$çš„æ¦‚ç‡ï¼Œå¯¹ç¬¬$(14)$æ­¥è¿›è¡Œå±•å¼€ä»¥åï¼Œä»çŠ¶æ€$s$å¼€å§‹ï¼Œåœ¨æ¯ä¸€ä¸ª$k$éƒ½æœ‰å¯èƒ½åˆ°è¾¾çŠ¶æ€$x$ï¼Œå¦‚æœä¸èƒ½åˆ°$x$ï¼Œæ¦‚ç‡ä¸º$0$å°±æ˜¯äº†ã€‚</p>
<h3 id="æŒ‡å®šåˆå§‹çŠ¶æ€-s-0-çš„accumulated-reward">æŒ‡å®šåˆå§‹çŠ¶æ€$s_0$çš„accumulated reward</h3>
<p>è¯æ˜æ€è·¯ï¼Œåœ¨ä¸Šé¢æˆ‘ä»¬å·²ç»æ±‚å¾—äº†$V^{\pi} (s)$çš„æ¢¯åº¦ï¼Œè€Œaccumulated rewardå…¶å®å°±æ˜¯$V^{\pi} (s_0)$ï¼Œå–$J(\mathbf{\theta}) = V_{\pi}(s_0)$ï¼Œåˆ™ï¼š<br>
\begin{align*}<br>
\nabla J(\mathbf{\theta}) &amp;= \nabla_{\theta}V_{\pi}(s_0)\\<br>
&amp;= \sum_{s\in S}( \sum_{k=0}^{\infty} Pr(s_0\rightarrow s,k,\pi) ) \sum_a\nabla{\pi}(a|s)Q_{\pi}(s,a)\qquad\qquad\qquad;\rho(s) = \sum_{k=0}^{\infty} Pr(s_0\rightarrow s,k,\pi) \tag{25}\\<br>
&amp;=\sum_{s\in S}\rho(s)\sum_a \nabla{\pi}(a|s)Q_{\pi}(s,a)\tag{26}\\<br>
&amp;=\sum_{sâ€™\in S}\rho(sâ€™)\sum_s\frac{\rho(s)}{\sum_{sâ€™}\rho(sâ€™)}\sum_a \nabla{\pi}(a|s)Q_{\pi}(s,a) \qquad\qquad\qquad\qquad; \text{normalize } \rho(s) \tag{27}\\<br>
&amp;=\sum_{sâ€™\in S}\rho(sâ€™)\sum_sd(s)\sum_a \nabla{\pi}(a|s)Q_{\pi}(s,a) \tag{28} \qquad\qquad\qquad\qquad\qquad; d(s) = \frac{\rho(s) }{\sum_{sâ€™} \rho(sâ€™)} \text{ is stationary distribution}\\<br>
&amp;\propto \sum_{s\in S}d(s)\sum_a\nabla\pi(a|s)Q_{\pi}(s,a)\tag{29},\qquad\qquad\qquad\qquad\qquad\qquad\qquad; \sum_s\rho(s)\text{æ˜¯å¸¸æ•°}\\<br>
&amp; = \sum_{s\in S}d(s)\sum_a\pi(s, a)\nabla\log\pi(a|s)Q_{\pi}(s,a) \tag{30}\\<br>
&amp; = \mathbb{E}_{\pi}\left[\nabla\log\pi(a|s)Q_{\pi}(s,a)\right] \tag{31}\\<br>
\end{align*}<br>
å…¶ä¸­$\mathbb{E}_{\pi}$è¡¨ç¤º$\mathbb{E}_{s\sim d_{\pi}, a\sim \pi}$ï¼Œå³stateå’Œaction distributionséƒ½éµå®ˆpolicy $\pi$ã€‚</p>
<h3 id="average-reward">Average Reward:</h3>
<p>è¯æ˜æ€è·¯ï¼Œé¦–å…ˆæ±‚$V$çš„æ¢¯åº¦ï¼Œå¸¦å…¥$Q, V$å’Œ$\eta$çš„å…³ç³»è¿›è¡Œè½¬æ¢ï¼Œèƒ½å¤Ÿå¾—åˆ°$\eta$çš„æ¢¯åº¦å’Œ$Q,V$æ¢¯åº¦ä¹‹é—´çš„å…³ç³»ï¼Œæœ€åè¿›è¡Œä¸€ç³»åˆ—åŒ–ç®€å³å¯ã€‚<br>
\begin{align*}<br>
\nabla V_{\pi}(s) &amp;= \nabla \left[ \sum_a \pi(a|s)Q_{\pi}(s,a)\right], \forall s\in S \tag{32}\\<br>
&amp;= \sum_a \left[\nabla\pi(a|s)Q_{\pi}(s,a)\right], \tag{33} \\<br>
&amp;= \sum_a \left[\nabla\pi(a|s)Q_{\pi}(s,a) + \pi(a|s)\nabla Q_{\pi}(s,a)\right] \tag{34}\\<br>
&amp;= \sum_a\left[\nabla\pi(a|s)Q_{\pi}(s,a) + \pi(a|s)\nabla \left[\sum_{sâ€™,r}p(sâ€™,r|s,a)\left(R(s,a)-\eta(\pi)+V_{\pi}(sâ€™)\right)\right]\right] \tag{35}\\<br>
&amp;= \sum_a\left[\nabla\pi(a|s)Q_{\pi}(s,a) + \pi(a|s)\left[-\nabla \eta(\pi)+ \sum_{sâ€™,r}p(sâ€™,r|s,a) \nabla V_{\pi}(sâ€™)\right]\right], \nabla R(s,a) = 0\tag{36}\\<br>
&amp;= \sum_a\left[\nabla\pi(a|s)Q_{\pi}(s,a) - \pi(a|s)\nabla \eta(\pi)+ \pi(a|s) \sum_{sâ€™,r}p(sâ€™,r|s,a) \nabla V_{\pi}(sâ€™)\right]\tag{37}\\<br>
&amp;= \sum_a\nabla\pi(a|s)Q_{\pi}(s,a) - \sum_a \pi(a|s)\nabla \eta(\pi) + \sum_a \pi(a|s) \sum_{sâ€™,r}p(sâ€™,r|s,a) \nabla V_{\pi}(sâ€™) \tag{38}\\<br>
&amp;= \sum_a\nabla\pi(a|s)Q_{\pi}(s,a) -\nabla \eta(\pi)+ \sum_a \pi(a|s)\sum_{sâ€™,r}p(sâ€™,r|s,a)\nabla V_{\pi}(sâ€™), \sum_s\pi(s,a)=1\tag{39}\\<br>
\end{align*}<br>
ç§»é¡¹åˆå¹¶åŒç±»é¡¹å¾—ï¼š<br>
$$\nabla \eta(\pi) = \sum_a\nabla\pi(a|s)Q_{\pi}(s,a) + \sum_a\pi(s,a) \sum_{sâ€™,r}p(sâ€™,r|s,a) \nabla V_{\pi}(sâ€™) - \nabla V_{\pi}(s) \tag{40}$$<br>
åŒæ—¶åœ¨ä¸Šå¼ä¸¤è¾¹å¯¹$d(s)$è¿›è¡Œæ±‚å’Œï¼Œå¾—åˆ°ï¼š<br>
\begin{align*}<br>
\sum_s d(s)\nabla \eta(\pi) &amp;= \sum_s d(s)\sum_a \nabla\pi(a|s)Q_{\pi}(s,a) \\<br>
&amp;\qquad\qquad\qquad + \sum_s d(s) \sum_a\pi(a|s) \sum_{sâ€™,r}p(sâ€™,r|s,a) \nabla V_{\pi}(sâ€™)\\<br>
&amp;\qquad\qquad\qquad - \sum_s d(s)\nabla V_{\pi}(s) \tag{41}\\<br>
\nabla \eta(\pi) &amp;= \sum_s d(s)\sum_a \nabla\pi(a|s)Q_{\pi}(s,a) + \sum_s d(sâ€™) \nabla V_{\pi}(sâ€™) - \sum_s d(s)\nabla V_{\pi}(s) \tag{42}\\<br>
&amp;= \sum_s d(s)\sum_a \nabla\pi(a|s)Q_{\pi}(s,a) \tag{43}\\<br>
&amp;= \sum_s d(s)\sum_a \pi(s,a) \nabla\log\pi(a|s)Q_{\pi}(s,a) \tag{44}\\<br>
&amp; = \mathbb{E}_{\pi}\left[\nabla_{\theta}\log\pi(s,a) Q_{\pi}(s,a)\right] \tag{45}\\<br>
\end{align*}<br>
å¼å­$(41)$åˆ°å¼å­$(42)$å…¶å®å°±æ˜¯$\sum_s d(s) \sum_a\pi(a|s) \sum_{sâ€™,r}p(sâ€™,r|s,a) = \sum_{sâ€™}d(sâ€™)$ï¼Œæ ¹æ®$\rho^{\pi} (s)$è¡¨ç¤ºçš„æ„ä¹‰ï¼Œæ˜¾ç„¶è¿™æ˜¯æˆç«‹çš„ã€‚<br>
\begin{align*}<br>
\end{align*}</p>
<h3 id="state-valueçš„æœŸæœ›">State valueçš„æœŸæœ›</h3>
<p>è¿˜ä¸ä¼šè¯æ˜ã€‚</p>
<h3 id="ç»“è®º">ç»“è®º</h3>
<p>ä»è¿™ä¸¤ç§æƒ…å†µçš„è¯æ˜å¯ä»¥çœ‹å‡ºæ¥ï¼Œpolicy gradientå’Œ$\frac{\partial \rho^{\pi} (s)}{\partial\mathbf{\theta}}$æ— å…³ï¼šå³å¯ä»¥é€šè¿‡è®¡ç®—ï¼Œè®©policyçš„æ”¹å˜ä¸å½±å“states distributionsï¼Œè¿™éå¸¸æœ‰åˆ©äºä½¿ç”¨é‡‡æ ·æ¥ä¼°è®¡æ¢¯åº¦ã€‚ä¸¾ä¸ªä¾‹å­æ¥è¯´ï¼Œå¦‚æœ$s$æ˜¯æ ¹æ®policy $\pi$çš„ä»$\rho$ä¸­é‡‡æ ·å¾—åˆ°çš„ï¼Œé‚£ä¹ˆ$\sum_a\frac{\partial\pi(s,a)}{\partial\mathbf{\theta}}Q^{\pi} (s,a)$å°±æ˜¯$\frac{\partial{\rho}}{\partial\mathbf{\theta}}$çš„ä¸€ä¸ªæ— åä¼°è®¡ã€‚é€šå¸¸$Q^{\pi}(s,a)$ä¹Ÿæ˜¯ä¸çŸ¥é“çš„ï¼Œéœ€è¦ä¼°è®¡ã€‚ä¸€ç§æ–¹æ³•æ˜¯ä½¿ç”¨returnsè¿‘ä¼¼ï¼Œå³$G_t = \sum_{k=0}^{\infty} R_{t+k+1}-\rho(\pi)$æˆ–è€…$R_t = \sum_{k=0}^{\infty} \gamma^{t} R_{t+k+1}$ï¼ˆåœ¨æŒ‡å®šåˆå§‹çŠ¶æ€æ¡ä»¶ä¸‹ï¼‰ï¼Œè¿™å°±æ˜¯REINFROCEæ–¹æ³•ã€‚$\nabla\mathbf{\theta}\propto\frac{\partial\pi(s_t,a_t)}{\partial\mathbf{\theta}}R_t\frac{1}{\pi(s_t,a_t)}$,$\frac{1}{\pi(s_t,a_t)}$çº æ­£äº†$\pi$çš„oversamplingï¼‰ã€‚</p>
<h2 id="policy-gradient-with-approximation-ä½¿ç”¨è¿‘ä¼¼çš„ç­–ç•¥æ¢¯åº¦">Policy Gradient with Approximation(ä½¿ç”¨è¿‘ä¼¼çš„ç­–ç•¥æ¢¯åº¦)</h2>
<p>å› ä¸º$Q^{\pi} $æ˜¯ä¸çŸ¥é“çš„ï¼Œæˆ‘ä»¬å¸Œæœ›ç”¨å‡½æ•°è¿‘ä¼¼å¼å­$(21)$ä¸­çš„$Q^{\pi} $ï¼Œå¤§è‡´æ±‚å‡ºæ¢¯åº¦çš„æ–¹å‘ã€‚ç”¨$f_w:S\times A \rightarrow \mathbb{R}$è¡¨ç¤º$Q^{\pi} $çš„ä¼°è®¡å€¼ã€‚åœ¨ç­–ç•¥$\pi$ä¸‹ï¼Œæ›´æ–°$w$çš„å€¼:<br>
$$\Delta w_t\propto \frac{\partial}{\partial w}\left[\hat{Q}^{\pi} (s_t,a_t) - f_w(s_t,a_t)\right]^2 \propto \left[\hat{Q}^{\pi} (s_t,a_t) - f_w(s_t,a_t)\right]\frac{\partial f_w(s_t,a_t)}{\partial w} \tag{67}$$<br>
$\hat{Q}^{\pi} (s_t,a_t)$æ˜¯$Q^{\pi} (s_t,a_t)$çš„ä¸€ä¸ªæ— åä¼°è®¡ï¼Œå½“è¿™æ ·ä¸€ä¸ªè¿‡ç¨‹æ”¶æ•›åˆ°local optimumï¼Œ$Q^{\pi} (s,a)$å’Œ$f_w(s,a)$çš„å‡æ–¹è¯¯å·®æœ€å°æ—¶ï¼š<br>
$$\epsilon(\omega, \pi) = \sum_{s,a}\rho^{\pi} (s)\pi(a|s;\theta)(Q^{\pi} (s,a))^2 - f^{\pi} (s,a;\omega) \tag{68}$$<br>
å³å¯¼æ•°ç­‰äº$0$:<br>
$$\sum_s \rho^{\pi} (s)\sum_a\pi(a|s;\theta)\left[Q^{\pi} (s,a) -f_w (s,a;w)\right]\frac{\partial f_w(s,a)}{\partial w}  = 0\tag{69}$$</p>
<h3 id="å®šç†2ï¼špolicy-gradient-with-approximation-theorem">å®šç†2ï¼šPolicy Gradient with Approximation Theorem</h3>
<p>å¦‚æœ$f_w$çš„å‚æ•°$w$æ»¡è¶³å¼å­$(69)$ï¼Œå¹¶ä¸”ï¼š<br>
$$\frac{\partial f_w(s,a)}{\partial w} = \frac{\partial \pi(s,a)}{\partial \mathbf{\theta}}\frac{1}{\pi(s,a)} = \frac{\partial \log \pi(s,a)}{\partial \mathbf{\theta}}\tag{70}$$<br>
é‚£ä¹ˆä½¿ç”¨$f_w(s,a)$è®¡ç®—çš„gradientå’Œ$Q^{\pi} (s,a)$è®¡ç®—çš„gradientæ˜¯ä¸€æ ·çš„ï¼š<br>
$$\frac{\partial \rho}{\partial \theta} = \sum_s\rho^{\pi} (s)\sum_a\frac{\partial \pi(s,a)}{\partial \mathbf{\theta}}f_w(s,a)\tag{71}$$</p>
<p>è¯æ˜ï¼š<br>
å°†å¼å­$(70)$ä»£å…¥$(69)$å¾—åˆ°ï¼š<br>
\begin{align*}<br>
&amp;\sum_s\rho^{\pi} (s)\sum_a\pi(s,a)\left[Q^{\pi} (s,a) -f_w(s,a)\right]\frac{\partial f_w(s,a)}{\partial w}\\<br>
= &amp;\sum_s\rho^{\pi} (s)\sum_a\pi(s,a)\left[Q^{\pi} (s,a) -f_w(s,a)\right]\frac{\partial \pi(s,a)}{\partial \mathbf{\theta}}\frac{1}{\pi(s,a)}\\<br>
= &amp;\sum_s\rho^{\pi} (s)\sum_a\frac{\partial \pi(s,a)}{\partial \mathbf{\theta}}\left[Q^{\pi} (s,a) -f_w(s,a)\right] \tag{72}\\<br>
= &amp; 0 \\<br>
\end{align*}<br>
å°†å¼å­$72$å¸¦å…¥å¼å­$(21)$ï¼š<br>
\begin{align*}<br>
\frac{\partial \eta}{\partial \mathbf{\theta}} &amp; = \sum_a \rho^{\pi} (s)\sum_a\frac{\partial\pi(s,a)}{\partial\mathbf{\theta}}Q^{\pi} (s,a)\\<br>
&amp;= \sum_a \rho^{\pi} (s)\sum_a\frac{\partial\pi(s,a)}{\partial\mathbf{\theta}}Q^{\pi} (s,a) - \sum_s\rho^{\pi} (s)\sum_a\frac{\partial \pi(s,a)}{\partial \mathbf{\theta}}\left[Q^{\pi} (s,a) -f_w(s,a)\right]\\<br>
&amp;= \sum_a \rho^{\pi} (s)\sum_a\frac{\partial\pi(s,a)}{\partial\mathbf{\theta}} \left[Q^{\pi} (s,a) - Q^{\pi} (s,a) +f_w(s,a)\right]\\<br>
&amp;= \sum_a \rho^{\pi} (s)\sum_a\frac{\partial\pi(s,a)}{\partial\mathbf{\theta}} f_w(s,a) \tag{73}\\<br>
\end{align*}<br>
å¾—è¯$\sum_a \rho^{\pi} (s)\sum_a\frac{\partial\pi(s,a)}{\partial\mathbf{\theta}}Q^{\pi} (s,a) = \sum_a \rho^{\pi} (s)\sum_a\frac{\partial\pi(s,a)}{\partial\mathbf{\theta}} f_w(s,a) $ã€‚</p>
<h2 id="application-to-deriving-algorithms-and-advantages">Application to Deriving Algorithms and Advantages</h2>
<p>ç»™å®šä¸€ä¸ªå‚æ•°åŒ–çš„policyï¼Œå¯ä»¥åˆ©ç”¨å®šç†2æ¨å¯¼å‡ºå‚æ•°åŒ–value functionçš„å½¢å¼ã€‚æ¯”å¦‚ï¼Œè€ƒè™‘åœ¨featuresä¸Šè¿›è¡Œçº¿æ€§ç»„åˆçš„Gibbsåˆ†å¸ƒæ„æˆçš„policyï¼š<br>
$$\pi(a|s) = \frac{e^{\theta^T \phi_{sa} } }{\sum_b e^{\theta^T \phi_{sb} }} , \forall s \in S, \forall a \in A \tag{74}$$<br>
å…¶ä¸­$\phi_{s,a}$æ˜¯state-action pair $s,a$çš„ç‰¹å¾å‘é‡ã€‚æ»¡è¶³å¼å­$(70)$çš„å…¬å¼å¦‚ä¸‹ï¼š<br>
$$\frac{\partial f_w(s,a)}{\partial w} = \frac{\partial \pi(a|s)}{\partial \theta}\frac{1}{\pi(a|s)} = \phi_{sa} - \sum_b\pi(b|s)\phi_{sb}\tag{75}$$<br>
æ‰€ä»¥ï¼š<br>
$$f_w(s,a) = w^T \left[\phi_{sa} - \sum_b\pi(b|s)\phi_{sb} \right]\tag{76}$$<br>
ä¹Ÿå°±æ˜¯è¯´ï¼Œ$f_w$å’Œpolicy $\pi$éƒ½æ˜¯featureçš„çº¿æ€§ç»„åˆï¼Œåªä¸è¿‡æ¯ä¸€ä¸ªstateå¤„$f_w$çš„å‡å€¼éƒ½ä¸º$0$ï¼Œ$\sum_a\pi(a|s)f_w(s,a) = 0,\forall s\in S$ã€‚æ‰€ä»¥ï¼Œå…¶å®æˆ‘ä»¬å¯ä»¥è®¤ä¸º$f_w$æ˜¯å¯¹advantage function $A^{\pi} (s,a) = Q^{\pi} (s,a)- V^{\pi} (s)$è€Œä¸æ˜¯$Q^{\pi} (s,a)$çš„ä¸€ä¸ªè¿‘ä¼¼ã€‚å¼å­$(70)$ä¸­$f_w$å…¶å®æ˜¯ä¸€ä¸ªç›¸å¯¹å€¼è€Œä¸æ˜¯ä¸€ä¸ªç»å¯¹å€¼ã€‚äº‹å®ä¸Šï¼Œä»–ä»¬éƒ½å¯å¯¹ä»¥æ¨å¹¿å˜æˆä¸€ä¸ªfunctionåŠ ä¸Šä¸€ä¸ªvalue functionã€‚æ¯”å¦‚å¼å­$(71)$å¯ä»¥å˜æˆ$\frac{\partial\eta}{\partial \theta} = \sum_s\rho^{\pi}(s) \sum_a \frac{\partial \pi(a|s)}{\partial \theta}\left[f_w(s,a) + v(s)\right]$ï¼Œå…¶ä¸­$v$æ˜¯ä¸€ä¸ªfunctionï¼Œ$v$çš„é€‰æ‹©ä¸å½±å“ç†è®ºç»“æœï¼Œä½†æ˜¯ä¼šå½±å“è¿‘ä¼¼æ¢¯åº¦çš„æ–¹å·®ã€‚</p>
<h2 id="convergence-of-policy-iteration-with-function-approximation-ä½¿ç”¨å‡½æ•°è¿‘ä¼¼çš„ç­–ç•¥è¿­ä»£çš„æ”¶æ•›æ€§">Convergence of Policy Iteration with Function Approximation(ä½¿ç”¨å‡½æ•°è¿‘ä¼¼çš„ç­–ç•¥è¿­ä»£çš„æ”¶æ•›æ€§)</h2>
<h3 id="å®šç†3ï¼špolicy-iteration-with-function-approximation">å®šç†3ï¼šPolicy Iteration with Function Approximation</h3>
<p>ç”¨$\pi$å’Œ$f_w$è¡¨ç¤ºpolicyå’Œvalue functionçš„å¯å¯¼å‡½æ•°ï¼Œå¹¶ä¸”æ»¡è¶³å¼å­$(70)$ã€‚$\max_{\theta,s,a,i,j} \vert\frac{\partial^2 \pi(a|s)}{\partial\theta_i \partial\theta_j} \vert\lt B\lt \infty$ï¼Œå‡è®¾$\left[\alpha_k\right]_{k=0}^{\infty}$æ˜¯æ­¥é•¿sequenceï¼Œ$\lim_{k\rightarrow \infty}\alpha_k = 0$ï¼Œ$\sum_k \alpha_k = \infty$ã€‚å¯¹äºä»»ä½•æœ‰ç•Œrewardsçš„MDPæ¥è¯´ï¼Œä»»æ„$\theta_0$ï¼Œ$\pi_k=\pi(\cdot, \theta_k)$å®šä¹‰çš„$\left[\eta(\pi_k)\right]_{k=0}^{\infty}$ï¼Œå¹¶ä¸”$w_k = w$æ»¡è¶³ï¼š<br>
$$\sum_s\rho^{\pi_k} (s) \sum_a\pi_k(a|s)\left[Q^{\pi_k} (s,a)-f_w(s,a) \right]\frac{\partial f_w(s,a)}{\partial w}=0 \tag{77}$$<br>
$$\theta_{k+1} = \theta_k + \alpha_k \sum_s\rho^{\pi_k}(s) \sum_a\frac{\partial\pi_k(s,a)}{\partial \theta}f_{w_k}(s,a) \tag{78}$$<br>
ä¸€å®šæ”¶æ•›ï¼š$\lim_{k\rightarrow \infty}\frac{\partial \rho(\pi_k)}{\partial \theta} = 0$ã€‚</p>
<h2 id="policy-gradient-algorithms">Policy Gradient Algorithms</h2>
<h3 id="reinforce">REINFORCE</h3>
<p>REINFORCEä½¿ç”¨Monte Carloæ–¹æ³•è¿‘ä¼¼return $G_t$ï¼Œå› ä¸º$Q^{\pi} (s,a) = \mathbb{E}_{\pi}\left[G_t|s_t=s, a_t=a\right]$ä½¿ç”¨$G_t$ä»£æ›¿policy gradient theoremä¸­çš„$Q$ï¼š<br>
\begin{align*}<br>
\nabla_{\theta}J(\theta) &amp; = \mathbb{E}_{\pi}\left[Q^{\pi} (s,a) \nabla_{\theta}\log\pi_{\theta}(a|s)\right]\\<br>
&amp; = \mathbb{E}_{\pi} \left[G_t\nabla_{\theta}\log\pi_{\theta}(a|s)\right]\\<br>
\end{align*}<br>
æ¥ä¸‹æ¥è¿›è¡Œsamplingï¼Œä½¿ç”¨Monte Carloæ–¹æ³•è®¡ç®—$G_t$å³å¯ã€‚å®Œæ•´ç®—æ³•å¦‚ä¸‹ï¼š<br>
<strong>REINFORCE ç®—æ³•</strong><br>
è¾“å…¥ï¼špolicy $\pi$çš„åˆå§‹åŒ–å‚æ•°$\theta$ï¼Œstep-size $\alpha$<br>
Loop<br>
$\qquad$ä½¿ç”¨$\pi_{\theta}$ç”Ÿæˆä¸€ä¸ªtrajectory $S_0, A_0, R_1, S_1, A_1, \cdots$<br>
$\qquad$for $t=1, 2, \cdots, T$<br>
$\qquad\qquad$ä¼°è®¡$G_t = \sum_{k=t}^T \gamma^{k-t} R_{t+1}$<br>
$\qquad\qquad$æ›´æ–°$\theta \leftarrow \theta + \alpha \gamma^t G_t \log\pi_{\theta}(a_t|s_t)$<br>
$\qquad$end for</p>
<h3 id="reinforce-with-baseline">REINFORCE with Baseline</h3>
<p>REINFROCEçš„ä¸€ç±»å˜ç§æ˜¯åœ¨$G_t$çš„åŸºç¡€ä¸Šå‡å»ä¸€ä¸ªå’Œ$\theta$æ— å…³çš„baselineï¼Œä½œç”¨æ˜¯åœ¨ä¸æ”¹å˜baisçš„å‰æä¸‹å‡å°‘æ–¹å·®ï¼š<br>
$$\sum_a \nabla_{\theta}\pi(a|s) b(s) = b(s)  \nabla_{\theta}\sum_a\pi(a|s) = b(s) \nabla_{\theta} 1 = 0$$<br>
å³åŠ äº†ä¸€ä¸ªbaselineä¹‹åï¼Œæ¢¯åº¦æ›´æ–°çš„æœŸæœ›å€¼ä¾ç„¶ä¿æŒä¸å˜ï¼Œä½†æ˜¯å¯ä»¥å‡å°‘æ–¹å·®ã€‚å…·ä½“çš„è¯æ˜å¯ä»¥è§<a href>why use baselinse in policy gradient</a>ã€‚åœ¨MDPsä¸­ï¼Œæœ‰çš„stateå¯èƒ½æ‰€æœ‰çš„actionséƒ½æœ‰å¾ˆé«˜çš„valuesï¼Œè¿™æ—¶å€™éœ€è¦ä¸€ä¸ªhigh baselineï¼Œè€Œæœ‰çš„actionså¯èƒ½éƒ½æœ‰ä½çš„valuesï¼Œè¿™æ—¶å€™éœ€è¦ä¸€ä¸ªlow baselineï¼Œä¸€ä¸ªå¸¸ç”¨çš„baselineå¯ä»¥é€‰æ‹©$V(s)$ï¼Œå¯ä»¥ä½¿ç”¨$G_t - V^{\pi} (s,a)$è®¡ç®—æ¢¯åº¦ã€‚<br>
ç›´è§‚ä¸Šæ¥é¦–ï¼ŒRLæ„Ÿå…´è¶£çš„æ˜¯é‚£äº›æ¯”å¹³å‡å€¼å¥½çš„actionã€‚å¦‚æœreturnséƒ½æ˜¯æ­£çš„$(R(\tau)\ge 0)$ï¼ŒPGæ€»æ˜¯ä¼šæé«˜è¿™ä¸ªtrajectoryå‘ç”Ÿçš„æ¦‚ç‡ï¼Œå³ä½¿å®ƒæ¯”å…¶ä»–çš„trajectoryè¦ä½ã€‚è€ƒè™‘ä»¥ä¸‹ä¸¤ä¸ªä¾‹å­ï¼š</p>
<ul>
<li>Trajectory $A$çš„returnæ˜¯$10$ï¼Œtrajectory $B$çš„rewardæ˜¯$-10$</li>
<li>Trajectory $A$çš„returnæ˜¯$10$ï¼Œtrajectory $B$çš„rewardæ˜¯$1$</li>
</ul>
<p>åœ¨ç¬¬ä¸€ä¸ªä¾‹å­ä¸­ï¼ŒPGä¼šæé«˜$A$å‘ç”Ÿçš„æ¦‚ç‡ï¼Œé™ä½$B$å‘ç”Ÿçš„æ¦‚ç‡ã€‚åœ¨ç¬¬äºŒä¸ªä¾‹å­ä¸­ï¼ŒPGä¼šæé«˜$A$å’Œ$B$çš„æ¦‚ç‡ã€‚ç„¶è€Œï¼Œå¯¹äºæˆ‘ä»¬æ¥è¯´ï¼Œåœ¨ä¸¤ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬éƒ½æƒ³è¦é™ä½$B$å‘ç”Ÿçš„æ¦‚ç‡ï¼Œæé«˜$A$å‘ç”Ÿçš„æ¦‚ç‡ã€‚é€šè¿‡å¼•å…¥ä¸€ä¸ªbaselineï¼Œæ¯”å¦‚$V$ï¼Œæˆ‘ä»¬å°±å¯ä»¥å®ç°è¿™æ ·çš„ç›®çš„ã€‚<br>
å®Œæ•´ç®—æ³•å¦‚ä¸‹ï¼š<br>
<strong>REINFORCE with Baseline ç®—æ³•</strong><br>
è¾“å…¥ï¼šå¯å¯¼çš„policy $\pi$çš„åˆå§‹åŒ–å‚æ•°$\theta$ï¼Œå¯å¯¼çš„state value function $\hat{v}(s, \mathbf{w})$ï¼Œstep-size $\alpha^{\theta} \gt 0, \alpha^{w} \gt 0 $<br>
Loop<br>
$\qquad$ä½¿ç”¨$\pi_{\theta}$ç”Ÿæˆä¸€ä¸ªtrajectory $S_0, A_0, R_1, S_1, A_1, \cdots$<br>
$\qquad$for $t=1, 2, \cdots, T$<br>
$\qquad\qquad$è¿‘ä¼¼$G_t = \sum_{k=t}^T \gamma^{k-t} R_{t+1}$<br>
$\qquad\qquad$è¿‘ä¼¼$\delta \leftarrow G-\hat{v}(s_t, w)$<br>
$\qquad\qquad$æ›´æ–°$w\leftarrow w + \alpha^{w} \delta \nabla\hat{v}(s_t, w)$<br>
$\qquad\qquad$æ›´æ–°$\theta \leftarrow \theta + \alpha^{\theta} \gamma^t\delta\log\pi_{\theta}(a_t|s_t)$<br>
$\qquad$end for<br>
å’Œä»‹ç»çš„åŸç†ä¸åŒçš„æ˜¯ï¼ŒREINFORCE with Baselienä½¿ç”¨äº†è¿‘ä¼¼çš„$\hat{v}(s, \mathbf{w}) \approx V(s)$ï¼Œå› ä¸ºæˆ‘ä»¬ä¸çŸ¥é“çœŸå®çš„$Q$ï¼Œå‰é¢ä¹Ÿå·²ç»è¯æ˜äº†ã€‚ã€‚</p>
<h3 id="actor-critic">Actor-Critic</h3>
<p>Policy gradientä¸­ä¸¤ä¸ªå¸¸ç”¨çš„componentsæ˜¯policyå’Œvalue functionï¼Œåœ¨å­¦ä¹ policyçš„åŒæ—¶å­¦ä¹ ä¸€ä¸ªvalue functionæ˜¯éå¸¸æœ‰ç”¨çš„ï¼Œvalue functionå¯ä»¥è¾…åŠ©policyè¿›è¡Œæ›´æ–°ï¼Œæ¯”å¦‚vanilla policy gradientä½¿ç”¨value functionè¾…åŠ©policyå‡å°æ–¹å·®ï¼Œæˆ‘ä»¬æŠŠè¿™ç±»æ–¹æ³•ç»Ÿç§°ä¸ºactor-criticæ–¹æ³•ã€‚Value functionå’Œpolicyå¯ä»¥å…±äº«å‚æ•°ï¼š</p>
<ul>
<li>Criticåˆ©ç”¨mean squared erroræ›´æ–°value function $Q_w(s,a)$æˆ–è€…$V_w(s)$çš„å‚æ•°$w$ï¼›</li>
<li>Actoræ ¹æ®criticç»™å‡ºçš„æ›´æ–°æ–¹å‘æ›´æ–°policy $\pi_{\theta}(a|s)$çš„å‚æ•°$\theta$ã€‚</li>
</ul>
<p>One-step actor-criticæ–¹æ³•ä½¿ç”¨one-step returnä»£æ›¿äº†full returnã€‚å®Œæ•´çš„ç®—æ³•æŒ‰å¦‚ä¸‹ï¼š<br>
<strong>One-step actor critic ç®—æ³•</strong><br>
è¾“å…¥ï¼špolicy $\pi$çš„å‚æ•°$\theta$ï¼Œåˆå§‹åŒ–state $s_0$<br>
é‡‡æ ·$a\sim \pi(a|s)$<br>
Loop<br>
$\qquad$for $t= 1,\cdots, T$:<br>
$\qquad\qquad$é‡‡æ ·reward $r_t \sum R(s,a)$å’Œnext state $sâ€™\sim P(sâ€™|s,a)$<br>
$\qquad\qquad$é‡‡æ ·next action $sâ€™\sim \pi(aâ€™|sâ€™)$<br>
$\qquad\qquad$æ›´æ–°policyå‚æ•°$\theta \leftarrow \theta + \alpha_{\theta} Q_w(s,a) \nabla_{\theta}\log\pi_{\theta}(a|s)$<br>
$\qquad\qquad$è®¡ç®—timestep $t$æ—¶åˆ»çš„TD-errorï¼š<br>
$\qquad\qquad\qquad \delta_t = r_t + \gamma Q_w(sâ€™, aâ€™) - Q_w(s,a)$<br>
$\qquad\qquad\qquad$ä½¿ç”¨mean squared erroræ›´æ–°$Q$å‡½æ•°ï¼š<br>
$\qquad\qquad\qquad w\leftarrow w + \alpha_w \delta_t \nabla_w Q_w(s, a)$<br>
$\qquad\qquad\qquad a\leftarrow aâ€™, s\leftarrow sâ€™$<br>
$\qquad$end for</p>
<p>REINFORCE with baselineçš„æ–¹æ³•åŒæ—¶å­¦ä¹ äº†policy $\pi$å’Œstate value function $V$ï¼Œä½†æ˜¯æˆ‘ä»¬ä¸€èˆ¬ä¸æŠŠå®ƒå«åšactor-criticæ–¹æ³•ï¼Œå› ä¸º$V$åœ¨è¿™é‡Œæ˜¯ä¸€ä¸ªbaselineè€Œä¸æ˜¯ä¸€ä¸ªcriticã€‚å®ƒæ²¡æœ‰è¢«ç”¨ä½œbootstrapingï¼Œåªæ˜¯ç”¨ä½œå¾…æ›´æ–°stateçš„ä¸€ä¸ªbaselineã€‚bootstrapingå’Œstate representationå¼•å…¥äº†biasï¼Œä½†æ˜¯èƒ½å‡å°æ–¹å·®å’ŒåŠ å¿«å­¦ä¹ é€Ÿåº¦ã€‚REINFORCE with baselineæ˜¯æ— åçš„ï¼Œå¹¶ä¸”æ”¶æ•›åˆ°local minimumï¼Œä½†æ˜¯åƒæ‰€æœ‰çš„MCæ–¹æ³•ä¸€æ ·ï¼Œå®ƒéƒ½æ”¶æ•›çš„å¾ˆæ…¢ï¼Œä¹Ÿæœ‰å¾ˆå¤§çš„æ–¹å·®ï¼Œå¹¶ä¸”å¾ˆéš¾åº”ç”¨åˆ°onlineå’Œcontinuingé—®é¢˜ã€‚ä½¿ç”¨TDæ–¹æ³•å¯ä»¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œå¹¶ä¸”é€šè¿‡multi-stepå¯ä»¥æ§åˆ¶boostrappingçš„åº¦ã€‚ä¸ºäº†å¾—åˆ°policy gradientçš„æ–¹æ³•ï¼Œå¯ä»¥ä½¿ç”¨boostrapping criticçš„actor criticæ–¹æ³•ã€‚</p>
<h3 id="off-policy-policy-gradient">Off-Policy Policy Gradient</h3>
<p>REINFORCEå’Œone-step actor-criticéƒ½æ˜¯on-policyçš„ï¼Œbehaviour policyå’Œtarget policyæ˜¯ç›¸åŒçš„ï¼Œå¾ˆä½æ•ˆã€‚Off-polciyç›¸å¯¹äºon-policyæœ‰å‡ ä¸ªå¥½å¤„ï¼š</p>
<ul>
<li>å¯ä»¥ä½¿ç”¨è¿‡å»çš„experienceï¼Œå³experience replayæé«˜é‡‡æ ·æ•ˆç‡ï¼›</li>
<li>behaviour policyå’Œtarget policyä¸åŒï¼Œèƒ½å¤Ÿæ›´å¥½çš„è¿›è¡Œexplorationã€‚</li>
</ul>
<p>å¦‚ä½•ä½¿ç”¨è®¡ç®—off policy graadientï¼Œè¿™å°±ç‰µæ¶‰åˆ°äº†<a href>importance sampling</a>ã€‚ç”¨$\beta(a|s)$è¡¨ç¤ºbehaviour oplicyï¼Œç›®æ ‡å‡½æ•°ä¸ºï¼š<br>
$$J(\theta) = \sum_s d^{\beta} (s) \sum_a Q^{\pi} (s,a) \pi(a|s) = \mathbb{E}_{s\sim d^{\beta} } \left[\sum_a Q^{\pi} (s,a) \pi(a|s)\right]$$<br>
å…¶ä¸­$d^{\beta} (s)$æ˜¯behaviour policy $\beta$çš„stationary distrbutionï¼Œ $\pi$æ˜¯target policyã€‚<br>
å®é™…ä¸Š$a\sim \beta(a|s)$ï¼Œå¯¹$J(\theta)$æ±‚åå¯¼å¾—åˆ°ï¼š<br>
\begin{align*}<br>
\nabla_{\theta}J(\theta) &amp; = \nabla_{\theta} \mathbb{E}_{s\sim d^{\beta} }\left[ \sum_a Q^{\pi} (s, a) \pi_{\theta} (a|s)\right]\\<br>
&amp; = \mathbb{E}_{s\sim d^{\beta} }\left[ \sum_a\left(\nabla_{\theta} Q^{\pi} (s, a) \pi_{\theta} (a|s) + Q^{\pi} (s, a) \nabla_{\theta}\pi_{\theta} (a|s)\right)\right]\\<br>
&amp; \approx \mathbb{E}_{s\sim d^{\beta} }\left[ \sum_a Q^{\pi} (s, a) \nabla_{\theta}\pi_{\theta} (a|s)\right]\\<br>
&amp; \approx \mathbb{E}_{s\sim d^{\beta} }\left[\sum_a \beta(a|s)\frac{ \pi(a|s)}{\beta(a|s)} Q^{\pi} (s, a) \frac{\nabla_{\theta}\pi_{\theta} (a|s)}{\pi_{\theta}(a|s)}\right]\\<br>
&amp; \approx \mathbb{E}_{\beta}\left[\sum_a \frac{ \pi(a|s)}{\beta(a|s)} Q^{\pi} (s, a) \nabla_{\theta}\log\pi_{\theta} (a|s)\right]\\<br>
\end{align*}<br>
å…¶ä¸­$\frac{ \pi(a|s)}{\beta(a|s)}$ç§°ä½œimportance sampling ratioã€‚å¼å­$(55)$åˆ°å¼å­$(44)$å¿½ç•¥äº†ç¬¬äºŒé¡¹ï¼Œæœ‰äººç‹°ç‹äº†å³ä½¿å¿½ç•¥äº†è¿™ä¸€é¡¹ï¼Œæœ€ç»ˆç»“æœè¿˜ä¼šæ”¶æ•›åˆ°å±€éƒ¨æœ€ä¼˜ã€‚<br>
å³é€šè¿‡importance samplingå¯ä»¥å°†è¿‡å»policyçš„experienceç”¨äºæ–°policyçš„è®­ç»ƒã€‚</p>
<h3 id="a3c">A3C</h3>
<p>è¯¦ç»†çš„è§£é‡Šå¯ä»¥è§<a href="http://mxxhcm.github.io/2019/04/19/a3c/">A3C</a>ã€‚<br>
A3Cæ˜¯Asynchronous advantage actor-criticï¼Œæ˜¯å¹¶è¡Œçš„policy gardientï¼Œå°±æ˜¯ä¸ºå¹¶è¡Œè®­ç»ƒè®¾è®¡çš„ã€‚åœ¨A3Cä¸­ï¼Œå¤šä¸ªactorså¹¶è¡Œé‡‡æ ·è¿›è¡Œè®­ç»ƒï¼Œä¸€ä¸ªcriticå­¦ä¹ value functionã€‚<br>
A3Cç®—æ³•çš„å®è´¨å°±æ˜¯ä½¿ç”¨å¤šä¸ªçº¿ç¨‹åŒæ­¥è®­ç»ƒã€‚åˆ†ä¸ºä¸»ç½‘ç»œå’Œçº¿ç¨‹ä¸­çš„ç½‘ç»œï¼Œä¸»ç½‘ç»œä¸éœ€è¦è®­ç»ƒï¼Œä¸»è¦ç”¨æ¥å­˜å‚¨å’Œä¼ é€’å‚æ•°ï¼Œæ¯ä¸ªçº¿ç¨‹ä¸­çš„ç½‘ç»œç”¨æ¥è®­ç»ƒå‚æ•°ã€‚æ€»çš„æ¥è¯´ï¼Œå¤šä¸ªçº¿ç¨‹åŒæ—¶è®­ç»ƒæé«˜äº†æ•ˆç‡ï¼Œå¦ä¸€æ–¹é¢ï¼Œå‡å°äº†æ•°æ®ä¹‹é—´çš„ç›¸å…³æ€§ï¼Œæ¯”å¦‚ï¼Œçº¿ç¨‹$1$å’Œ$2$ä¸­éƒ½ç”¨ä¸»ç½‘ç»œå¤åˆ¶æ¥çš„å‚æ•°è®¡ç®—æ¢¯åº¦ï¼Œä½†æ˜¯åŒä¸€æ—¶åˆ»åªèƒ½æœ‰ä¸€ä¸ªçº¿ç¨‹æ›´æ–°ä¸»ç½‘ç»œçš„å‚æ•°ï¼Œæ¯”å¦‚çº¿ç¨‹$1$æ›´æ–°ä¸»ç½‘ç»œçš„å‚æ•°ï¼Œé‚£ä¹ˆçº¿ç¨‹$2$åˆ©ç”¨åŸæ¥ä¸»ç½‘ç»œå‚æ•°è®¡ç®—çš„æ¢¯åº¦ä¼šæ›´æ–°åœ¨çº¿ç¨‹$1$æ›´æ–°å®Œä¹‹åçš„ä¸»ç½‘ç»œå‚æ•°ä¸Šã€‚</p>
<p><strong>A3Cç®—æ³•ï¼ï¼æ¯ä¸ªactor-learnçº¿ç¨‹çš„ä¼ªä»£ç </strong><br>
ç”¨$\theta, w$è¡¨ç¤ºå…¨å±€å…±äº«å‚æ•°ï¼Œç”¨$T=0$è¡¨ç¤ºå…¨å±€å…±äº«è®¡æ•°å™¨ï¼Œ<br>
ç”¨$\thetaâ€™,wâ€™$è¡¨ç¤ºæ¯ä¸ªçº¿ç¨‹ä¸­çš„å‚æ•°<br>
åˆå§‹åŒ–çº¿ç¨‹æ­¥è®¡æ•°å™¨$t\leftarrow 1$ï¼Œ<br>
<strong>while</strong> $T\le T_{max}$<br>
$\qquad$é‡ç½®æ¢¯åº¦$d\theta\leftarrow 0, dw\leftarrow 0$ï¼Œ<br>
$\qquad$åŒæ­¥çº¿ç¨‹å‚æ•°$\thetaâ€™=\theta,wâ€™=w$<br>
$\qquad t_{start}=t$<br>
$\qquad$é‡‡æ ·åˆå§‹çŠ¶æ€$s_t$ï¼Œ<br>
$\qquad$ <strong>while</strong> $s_t \neq$ terminalä¸”$t-t_{start} \le t_{max}$<br>
$\qquad\qquad$æ ¹æ®ç­–ç•¥é€‰æ‹©action$a_t \sim \pi_{\thetaâ€™}(a_t|s_t;\thetaâ€™)$ï¼Œ<br>
$\qquad\qquad$æ¥æ”¶ä¸‹ä¸€ä¸ªçŠ¶æ€$s_{t+1}$å’Œreward $r_{t+1}$ï¼Œ<br>
$\qquad\qquad T\leftarrow T+1, t\leftarrow t+1$<br>
$\qquad$è®¾ç½®å¥–åŠ±$R=\begin{cases}0,&amp;for\ terminal\ s_t\\ V(s_t,\thetaâ€™_v), &amp;for\ non-terminal\ s_t\end{cases}$<br>
$\qquad$<strong>for</strong> $i\in{t-1,\cdots,t_{start}}$ do<br>
$\qquad\qquad R\leftarrow r_i+\gamma R$<br>
$\qquad\qquad$ç´¯è®¡å’Œ$\thetaâ€™$ç›¸å…³çš„æ¢¯åº¦ï¼š$d\theta \leftarrow d\theta+\frac{\partial (y-Q(s,a;\theta))^2}{\partial \theta}$<br>
$\qquad\qquad$ç´¯è®¡å’Œ$\thetaâ€™_v$ç›¸å…³çš„æ¢¯åº¦ï¼š$d\theta_v \leftarrow d\theta_v+\frac{\partial (R-V(s_i;\thetaâ€™_v))^2}{\partial \thetaâ€™_v}$<br>
$\qquad$<strong>end for</strong><br>
$\qquad$ä½¿ç”¨$d\theta$å¼‚æ­¥æ›´æ–°$\theta$ï¼Œä½¿ç”¨$d\theta_v$å¼‚æ­¥æ›´æ–°$\theta_v$.</p>
<p>ç´¯è®¡æ¢¯åº¦$dw$å’Œ$d\theta$å…¶å®å¯ä»¥çœ‹æˆæ˜¯mini-batchçš„sgdã€‚</p>
<h3 id="a2c">A2C</h3>
<p>A2Cæ˜¯A3Cçš„åŒæ­¥ç‰ˆæœ¬ã€‚åœ¨A3Cä¸­æ¯ä¸€ä¸ªagentç‹¬ç«‹çš„å’Œglobal parametersè¿›è¡Œæ²Ÿé€šï¼Œæ‰€ä»¥å¯èƒ½åœ¨æŸäº›æ—¶å€™ï¼Œä¸åŒçš„threadä½¿ç”¨çš„policyå¯èƒ½éƒ½ä¼šä¸åŒï¼Œthread1ä»globalæ‹¿äº†å‚æ•°ï¼Œè®¡ç®—æ¢¯åº¦ï¼Œthread2ä»globalæ‹¿äº†å‚æ•°ï¼Œè®¡ç®—æ¢¯åº¦ï¼Œthread1æ›´æ–°äº†globalï¼Œè€Œè¿™ä¸ªæ—¶å€™thread2è¿˜åœ¨è®¡ç®—æ¢¯åº¦ï¼Œthread1å°±æ‹¿åˆ°äº†æ–°çš„globalå‚æ•°ï¼Œè®¡ç®—æ¢¯åº¦ï¼Œæ›´æ–°ã€‚è¿™æ—¶å€™thread2è¿˜æ²¡è®¡ç®—å®Œï¼Œå°±äº§ç”Ÿäº†ä¸ä¸€è‡´ã€‚<br>
A2Cå°±æ˜¯ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜çš„ï¼ŒA2Cä½¿ç”¨ä¸€ä¸ªè°ƒåº¦å™¨ï¼Œç­‰å¾…æ‰€æœ‰çš„actorså®Œæˆç›¸åº”çš„å·¥ä½œï¼Œç„¶åæ›´æ–°globalçš„å‚æ•°ï¼Œä¿è¯åœ¨ä¸‹ä¸€æ¬¡æ›´æ–°çš„æ—¶å€™æ¯ä¸€ä¸ªactorä½¿ç”¨çš„éƒ½æ˜¯ç›¸åŒçš„policyã€‚</p>
<h3 id="dpg">DPG</h3>
<p>å®Œæ•´è§£é‡Šè§<a href="http://localhost:4000/2019/07/16/gradient-method-deterministic-policy-gradient/" target="_blank" rel="noopener">deterministic policy gardient</a>ã€‚<br>
Deterministic policy gradient theoremï¼š<br>
\begin{align*}<br>
J(\mu_{\theta}) &amp; = \int_S\rho^{\mu} (s) R(s, \mu_{\theta}(s)) da ds\tag{48}\\<br>
&amp; = \mathbb{E}_{s\sim \rho^{\mu} } \left[R(s, \mu_{\theta}(s) \right]\tag{49}\\<br>
\end{align*}</p>
<p>\begin{align*}<br>
\nabla_{\theta} J(\mu_\theta) &amp; = \int_S\rho^{\mu} (s)\nabla_{\theta}\mu_{\theta}(s) \nabla_a Q^{\mu} (s, a)|_{\mu_{\theta}(s)} da ds\tag{50}\\<br>
&amp; = \mathbb{E}_{s\sim \rho^{\mu} (s)} \left[ \nabla_{\theta}\mu_{\theta}(s) \nabla_a Q^{\mu} (s, a)|_{\mu_{\theta}(s)} \right]\tag{51}\\<br>
\end{align*}</p>
<h3 id="ddpg">DDPG</h3>
<p>DDPGæ˜¯ä¸€ä¸ªmodel-free off-plicy actor criticæ–¹æ³•ï¼Œå°†DPGå’ŒDQNçš„æ€æƒ³ç›¸ç»“åˆã€‚DQNä½¿ç”¨replay bufferå’Œtarget networkç¨³å®šå­¦ä¹ è¿‡ç¨‹ï¼Œä½†æ˜¯DQNåªæœ‰åœ¨discrete spaceç©ºé—´ä¸­èµ·ä½œç”¨ï¼ŒDDPGå°†actor-criticæ¡†æ¶æ‰©å±•åˆ°äº†continousç©ºé—´ï¼Œå­¦ä¹ deterministic policyã€‚ä¸ºäº†æ›´å¥½çš„explorationï¼Œä½¿ç”¨$\mu$å’Œnoise $\mathbf{N}$æ„é€ exploration policy $\muâ€™$ï¼š<br>
$$\muâ€™(s) = \mu(s) + \mathbf{N} \tag{}$$<br>
æ­¤å¤–ï¼ŒDDPGå¯¹actorå’Œcriticå®è¡Œsoft updateï¼Œå³$\thetaâ€™ \leftarrow \tau \theta+(1-\tau) \thetaâ€™$ã€‚åŒæ—¶ä½¿ç”¨batch normalizionå¯¹æ¯å±‚çš„è¾“å…¥è¿›è¡Œå¤„ç†ï¼Œå®Œæ•´çš„ç®—æ³•å¦‚ä¸‹ï¼š<br>
<strong>DDPGç®—æ³•</strong><br>
ä½¿ç”¨$\theta^Q $å’Œ$\theta^\mu $ éšæœºåˆå§‹åŒ–criticç½‘ç»œ$Q(s,a|\theta^Q )$å’Œactorç½‘ç»œ$\mu(s|\theta^\mu )$ã€‚<br>
ä½¿ç”¨$\theta^ Q$å’Œ$\theta^\mu $åˆå§‹åŒ–target networkå‚æ•°$\theta^{Qâ€™} \leftarrow \theta^Q, \theta^{\muâ€™} \leftarrow \theta^\mu$ã€‚<br>
åˆå§‹åŒ–replay buffer<br>
for episode $= 1, \cdots, M$ do<br>
$\qquad$åˆå§‹åŒ–éšæœºè¿‡ç¨‹$\mathbf{N}$ç”¨äºexploration<br>
$\qquad$è·å¾—åˆå§‹çŠ¶æ€$s_0$<br>
$\qquad$for $t=0, \cdots, T$ do<br>
$\qquad\qquad$é€‰æ‹©action $a_t = \mu(s_t|\theta^\mu ) + \mathbf{N}_t$<br>
$\qquad\qquad$æ‰§è¡Œ$a_t$ï¼Œè·å¾—$r_{t+1}, s_{t+1}$<br>
$\qquad\qquad$å°†$(s_t, a_t, r_{t+1}, s_{t+1})$å­˜å…¥buffer<br>
$\qquad\qquad$ä»bufferä¸­è·å–ä¸€ä¸ªå¤§å°ä¸º$N$çš„batchï¼Œ$(s_i, a_i, r_{i+1}ï¼Œs_{i+1})$<br>
$\qquad\qquad$ä½¿ç”¨target networkè®¡ç®—TD targetï¼š$y_i = r_i + \gamma Qâ€™(s_{i+1}, \muâ€™(s_{i+1}|\theta^{\muâ€™} ) | \theta^{Qâ€™} )$<br>
$\qquad\qquad$ä½¿ç”¨TD-error lossæ›´æ–°criticï¼š $L=\frac{1}{N} \sum_i (y_i - Q(s_i,a_i|\theta^Q ) )^2 $<br>
$\qquad\qquad$ä½¿ç”¨æ ·æœ¬è®¡ç®—policy gradientæ›´æ–°actorï¼š<br>
$$\nabla_{\theta^{\mu} } J \approx \frac{1}{N} \sum_i \nabla_a Q(s, a|\theta^Q ) |_{s=s_i,a=\mu(s_i)} \nabla_{\theta^{\mu} }\mu(s|\theta^{\mu} )$$<br>
$\qquad\qquad$æ›´æ–°target networks:<br>
$$\theta^{Qâ€™} \leftarrow \tau \theta^Q + (1 - \tau) \theta^{Qâ€™} $$<br>
$$\theta^{\muâ€™} \leftarrow \tau \theta^\mu + (1 - \tau) \theta^{\muâ€™} $$<br>
$\qquad$end for<br>
end for</p>
<h3 id="maddpg">MADDPG</h3>
<p>MADDPGå°†DDPGæ‰©å±•åˆ°multi agentsé—®é¢˜ä¸Šã€‚å¤šä¸ªåªæœ‰local informactionçš„agentsåˆä½œå®Œæˆä»»åŠ¡ï¼Œä»å•ä¸ªagentæ¥çœ‹ï¼Œç¯å¢ƒæ˜¯non-stationaryï¼Œå› ä¸ºå…¶ä»–agentsçš„policesæ˜¯æœªçŸ¥çš„ã€‚MADDPGå°±æ˜¯è§£å†³è¿™æ ·ä¸€ç±»é—®é¢˜çš„æ–¹æ³•ã€‚<br>
å¯¹äº$N$ä¸ªagetnsçš„MADDPGç®—æ³•ï¼Œæ¯ä¸€ä¸ªagentéƒ½æœ‰ä¸€ä¸ªdecentralized actorå’Œä¸€ä¸ªcentralized criticã€‚æ¯ä¸€ä¸ªdecentralized actorè¾“å…¥ä¸ºå½“å‰agentçš„observationï¼Œè¾“å‡ºä¸ºå®ƒçš„actionï¼Œæ¯ä¸€ä¸ªcentralized criticè¾“å…¥ä¸ºæ‰€æœ‰agentsçš„observationï¼Œè¾“å‡ºä¸ºå½“å‰agentçš„$Q$å€¼ï¼Œå’Œæ¯ä¸ªæ™ºèƒ½ä½“çš„rewardç›¸å…³ã€‚</p>
<p>å®Œæ•´çš„ç®—æ³•å¦‚ä¸‹ï¼š<br>
<strong>Nä¸ªagentsçš„MADDPGç®—æ³•</strong><br>
for episode $= 1, \cdots, M$ do<br>
$\qquad$åˆå§‹åŒ–éšæœºè¿‡ç¨‹$\mathbf{N}$ç”¨æ¥exploration<br>
$\qquad$è·å¾—åˆå§‹çŠ¶æ€$\mathbf{s}$<br>
$\qquad$for $t=1, \cdots , T$ do<br>
$\qquad\qquad$for $i = 1, \cdots, N$<br>
$\qquad\qquad\qquad a_i = \mu_{\theta_i}(o_i) +\mathbf{N}_t$<br>
$\qquad\qquad$end for<br>
$\qquad\qquad$æ‰§è¡Œactions $\mathbf{a} = (a_1, \cdots, a_N)$ï¼Œè·å¾—$\mathbf{r}$å’Œ$\mathbf{sâ€™}$<br>
$\qquad\qquad$å°†$(\mathbf{s},\mathbf{a},\mathbf{r},\mathbf{sâ€™})$å­˜å…¥buffer<br>
$\qquad\qquad \mathbf{s}\leftarrow \mathbf{sâ€™}$<br>
$\qquad\qquad$for $i= 1, \cdots, N$ do<br>
$\qquad\qquad\qquad$ä»bufferä¸­é‡‡æ ·$S$ä¸ªsamples $(\mathbf{s}^j ,\mathbf{a}^j ,\mathbf{r}^j ,\mathbf{sâ€™}^j )$<br>
$\qquad\qquad\qquad$è®¡ç®—TD target $\mathbf{y}^j_i = \mathbf{r}^j_i + \gamma Q^{\muâ€™}_i (\mathbf{xâ€™}^j, a_1^{â€™},\cdots, a_N^{â€™} )|_{a_k^{â€™} = \mu_k^{â€™} (o_k^j ) }$<br>
$\qquad\qquad\qquad$ä½¿ç”¨å‡æ–¹è¯¯å·®æ›´æ–°criticï¼š<br>
$$L(\theta_i) = \frac{1}{S} \sum_j \left( y^j - Q_i^{\mu} (\mathbf{x}^j , a_1^j ,\cdots, a_N^j ) \right)^2 $$<br>
$\qquad\qquad\qquad$ä½¿ç”¨æ ·æœ¬è¿‘ä¼¼è®¡ç®—policy gradientï¼š<br>
$$\nabla_{\theta_i} J\approx \frac{1}{S} \sum_j\nabla_{\theta_i}\mu_i(o_i^j ) Q_i^{\mu} (\mathbf{x}^j , a_1^j ,\cdots, a_i^j, a_N^j)|_{a_i = \mu_i(o_i^j)} $$<br>
$\qquad\qquad$end for<br>
$\qquad\qquad$æ›´æ–°æ¯ä¸ªagent $i$çš„target network<br>
$$\qquad\qquad \theta_i^{â€™} \leftarrow \tau\theta_i + (1- \tau) \theta_i^{â€™}$$<br>
$\qquad$end for<br>
end for</p>
<h3 id="d4pg">D4PG</h3>
<h3 id="natural-pg">Natural PG</h3>
<h3 id="trpo">TRPO</h3>
<p>è¯¦ç»†ä»‹ç»å¯ä»¥æŸ¥çœ‹<a href="http://mxxhcmg.github.io/2019/09/08/gradient-method-trust-region-policy-optimization/" target="_blank" rel="noopener">trust region policy optimization</a>ã€‚<br>
TRPOå°†policyçš„æ›´æ–°è¡¨ç¤ºä¸ºä¸¤ä¸ªpolicyçš„performanceçš„ä¸€ä¸ªå…¬å¼ï¼š<br>
\begin{align*}<br>
\mathbb{E}_{s_0, a_0,\cdots\sim \pi_{new} }\left[\sum_{t=0}^{\infty} \gamma^t A^{\pi_{old}} (s_t,a_t) \right] &amp;=\mathbb{E}_{s_0, a_0,\cdots\sim \pi_{new}}\left[\sum_{t=0}^{\infty} \gamma^t (Q^{\pi_{old}} (s_t,a_t) - V^{\pi_{old}} (s_t))\right]  \\<br>
&amp;=\mathbb{E}_{s_0, a_0,\cdots\sim \pi_{new}} \left[\sum_{t=0}^{\infty} \gamma^t ( R_{t+1} + \gamma V^{\pi_{old}} (s_{t+1}) -  V^{\pi_{old}} (s_t))\right]  \\<br>
&amp;=\mathbb{E}_{s_0, a_0,\cdots\sim \pi_{new}} \left[\sum_{t=0}^{\infty} \gamma^t R_{t+1} + \sum_{t=0}^{\infty} \gamma^t (\gamma V^{\pi_{old}} (s_{t+1}) -  V^{\pi_{old}} (s_t))\right]  \\<br>
&amp;=\mathbb{E}_{s_0, a_0,\cdots\sim \pi_{new}} \left[\sum_{t=0}^{\infty} \gamma^t R_{t+1} \right]+ \mathbb{E}_{s_0, a_0,\cdots\sim \pi_{new}} \left[\sum_{t=0}^{\infty} \gamma^t (\gamma V^{\pi_{old}} (s_{t+1}) -  V^{\pi_{old}} (s_t))\right]  \\<br>
&amp;=\eta(\pi_{new}) + \mathbb{E}_{s_0, a_0,\cdots\sim \pi_{new}} \left[ -  V^{\pi_{old}} (s_0))\right]  \\<br>
&amp;=\eta(\pi_{new}) - \mathbb{E}_{s_0, a_0,\cdots\sim \pi_{new}} \left[ V^{\pi_{old}} (s_0))\right]  \\<br>
&amp;=\eta(\pi_{new}) - \eta(\pi_{old})\\<br>
\end{align*}<br>
æˆ‘ä»¬çš„ç›®æ ‡å°±æ˜¯æƒ³è¦æœ€å¤§åŒ–<br>
$$\mathbb{E}_{s_0, a_0,\cdots\sim \pi_{new} }\left[\sum_{t=0}^{\infty} \gamma^t A^{\pi_{old}} (s_t,a_t) \right]$$<br>
ç”¨$\rho_{\pi_{old}}(s)$è¿‘ä¼¼$\rho_{\pi_{new}}(s)$å¾—åˆ°<br>
$$\mathbb{E}_{s_0, a_0,\cdots\sim \pi_{new} }\left[\sum_{t=0}^{\infty} \gamma^t A^{\pi_{old}} (s_t,a_t) \right]$$</p>
<p>æœ€åå¾—åˆ°ç›®æ ‡å‡½æ•°ï¼š<br>
$$J = \mathbb{E}_{s\sim\rho_{\theta_{old}}, a\sim q}\left[\frac{\pi_{\theta} (a|s) }{q(a|s)}Q_{\theta_{old}}(s,a)\right] \tag{}$$</p>
<p>ä¸ºäº†è®­ç»ƒçš„ç¨³å®šæ€§ï¼Œæˆ‘ä»¬åº”è¯¥é¿å…åœ¨ä¸€ä¸ªstepå†…policyæ”¹å˜å¤ªå¤§ã€‚TRPOé€šè¿‡æ·»åŠ ä¸€ä¸ªKLæ•£åº¦çº¦æŸæ¯ä¸€æ¬¡è¿­ä»£ä¸­ï¼Œpolicyæ”¹å˜çš„å¤§å°ã€‚<br>
$$s.t. \mathbb{E}_{s\sim \rho_{\theta_{old}}}\left[D_{KL}(\pi_{\theta_{old}}(\cdot|s)||\pi_{\theta}(\cdot|s))\right]\le \delta \tag{}$$</p>
<h3 id="ppo">PPO</h3>
<h3 id="acer">ACER</h3>
<h3 id="actkr">ACTKR</h3>
<h3 id="sac">SAC</h3>
<h3 id="sac-with-automatically-adjusted-temperature">SAC with Automatically Adjusted Temperature</h3>
<h3 id="td3">TD3</h3>
<h3 id="svpg">SVPG</h3>
<h2 id="å¦ä¸€ç§policy-gradientçš„æ–¹æ³•">å¦ä¸€ç§policy gradientçš„æ–¹æ³•</h2>
<p>è¿™æ˜¯CS294ä¸Šçš„æ–¹æ³•ï¼Œæ„Ÿè§‰å’Œå‰é¢çš„æœ‰ä¸€äº›ä¸æˆä½“ç³»ï¼Œè€Œä¸”æœ‰ä¸€äº›åœ°æ–¹çš„è¯æ˜è®©æˆ‘ä¸èƒ½æ¥å—ã€‚<br>
ç›®æ ‡å‡½æ•°$J$å¦‚ä¸‹ï¼š<br>
\begin{align*}<br>
J(\theta) &amp; = \mathbb{E}_{\tau \sim \pi_{\theta}(\tau)} \left[R(\tau)\right] \tag{46}\\<br>
&amp; = \mathbb{E}_{\tau \sim \pi_{\theta}(\tau)} \left[\sum_t R(s_t, a_t)\right] \tag{47}\\<br>
&amp; = \int \pi_{\theta}(\tau) R(\tau) d\tau \tag{48}\\<br>
&amp; = \int \pi_{\theta}(\tau)\sum_t R(s_t, a_t) d\tau \tag{49}\\<br>
&amp; \approx \frac{1}{N}\sum_i \sum_t R(s_{i,t}, a_{i,t}) \tag{50}\\<br>
\end{align*}<br>
å…¶ä¸­$\tau = s_0, a_0, s_1, a_1,\cdots \sim \pi_{\theta}$è¡¨ç¤ºä¸€ä¸ªepisodeçš„trajectoryï¼Œ$R(\tau)$è¡¨ç¤ºè¿™ä¸ªtrajectoryçš„returns($G_0$)ã€‚Policy gradientå˜æˆä¸‹å¼ï¼Œï¼ˆä¸ºä»€ä¹ˆï¼Ÿï¼Ÿï¼Ÿè¿˜æ˜¯ä¸æ‡‚ï¼ï¼CS294ä¸Šé¢çš„æ¨å¯¼ï¼ï¼ï¼ä¸ºä»€ä¹ˆ$\nabla$å¯ä»¥å†™è¿›ç§¯åˆ†å·é‡Œé¢ï¼Œ$R(\tau)$ä¸ä¹Ÿå’Œ$\pi_{\theta}$æœ‰å…³ï¼Ÿï¼Ÿï¼Ÿï¼‰<br>
\begin{align*}<br>
\nabla_{\theta}J(\theta) &amp; = \int \nabla_{\theta} \pi_{\theta}(\tau) R(\tau)d\tau\\<br>
&amp; = \int \pi_{\theta}(\tau) \nabla_{\theta}\log\pi_{\theta}(\tau) R(\tau)d\tau\\<br>
&amp; = \mathbb{E}_{\tau\sim \pi_{\theta}(\tau)} \left[\nabla_{\theta} \log\pi_{\theta}(\tau) R(\tau) d\tau\right] \tag{51}<br>
\end{align*}<br>
å¯ä»¥å°†policy gradientè¡¨ç¤ºæˆæœŸæœ›çš„å½¢å¼ï¼Œç„¶åå°±å¯ä»¥é‡‡æ ·è¿›è¡Œä¼°è®¡ã€‚å¯¹$R(\tau)$è¿›è¡Œé‡‡æ ·ï¼Œä½†æ˜¯ä¸è¿›è¡Œæ±‚å¯¼ã€‚Returnsä¸ç›´æ¥å—$\pi_{\theta}$çš„å½±å“ï¼Œ$\tau$å—$\pi_{\theta}$çš„å½±å“ï¼Œä¸‹é¢æ˜¯$\log\pi(\tau)$çš„åå¯¼æ•°è®¡ç®—ã€‚<br>
$\pi(\tau)$å®šä¹‰ä¸ºï¼š<br>
$$\pi_{\theta}(s_0,a_0,\cdots, s_T,a_T) = p(s_0) \prod_{t=0}^T \pi_{\theta}(a_t|s_t)p(s_{t+1}|s_t,a_t) \tag{52}$$<br>
å–$\log$ï¼š<br>
$$\log\pi_{\theta}(s_0,a_0,\cdots, s_T,a_T) = \log p(s_0) + \sum_{t=0}^T\log \pi_{\theta}(a_t|s_t) + \log p(s_{t+1}|s_t,a_t) \tag{53}$$<br>
å¯¹$\theta$æ±‚åå¯¼ï¼Œå¾—åˆ°ï¼š<br>
$$\nabla_{\theta} \log\pi(\tau) = \nabla_{\theta}\left[\sum_{t=0}^T \log\pi_{\theta}(a_t|s_t) \right] = \left[\sum_{t=0}^T \nabla_{\theta} \log\pi_{\theta}(a_t|s_t) \right]\tag{54}$$<br>
æ‰€ä»¥ï¼Œpolicy gradientï¼š<br>
\begin{align*}<br>
\nabla_{\theta}J(\theta) &amp;= \mathbb{E}_{\tau \sim \pi_{\theta}(\tau)}\left[\nabla_{\theta}\log\pi_{\theta}(\tau) R(\tau) \right]\tag{55}\\<br>
&amp; = \mathbb{E}_{\tau \sim \pi_{\theta}(\tau)} \left[ \left(\sum_{t=1}^T\nabla_{\theta} \log\pi_{\theta}(a_{i,t}|s_{i,t})\right) \left(\sum_{t=1}^T R(s_{i,t}, a_{i,t})\right) \right] \tag{56}\\<br>
&amp; \approx \frac{1}{N}\sum_{i=1}^N \left(\sum_{t=1}^T\nabla_{\theta} \log\pi_{\theta}(a_{i,t}|s_{i,t})\right) \left(\sum_{t=1}^T R(s_{i,t}, a_{i,t})\right)\tag{57}\\<br>
\end{align*}<br>
$$ \theta \leftarrow \theta + \alpha \nabla_{\theta} J(\theta)\tag{58}$$<br>
å³ç”¨å¤šä¸ªtrajectoriesè¿‘ä¼¼è®¡ç®—policy gradietnï¼Œæ›´æ–°$\theta$ã€‚</p>
<h3 id="reinforce-policy-gradient-with-monte-carlo-rollouts">REINFORCE: Policy Gradient with Monte Carlo rollouts</h3>
<p>REINFROCEä½¿ç”¨Monte Carloè¿‘ä¼¼returnsï¼Œ$\nabla_{\theta}J(\theta)$è¿‘ä¼¼ä¸ºï¼š</p>
<p>$$\nabla_{\theta} J(\theta) \approx \frac{1}{N}\sum_{i=1}^N \left(\sum_{t=1}^T\nabla_{\theta} \log\pi_{\theta}(a_{i,t}|s_{i,t})\right) \left(\sum_{t=1}^T R(s_{i,t}, a_{i,t})\right)$$<br>
å®Œæ•´çš„ç®—æ³•å¦‚ä¸‹ï¼š<br>
REINFORCE ç®—æ³•<br>
Loop<br>
$\qquad 1.$ä½¿ç”¨policy $\pi_{\theta}(a_t|s_t)$ç”Ÿæˆä¸€ä¸ªtrajectory $\left[\tau^i \right]$<br>
$\qquad$ä¼°è®¡$\nabla_{\theta}J(\theta) \approx \sum_i (\sum_t \nabla_{\theta} \log\pi_{\theta}(a_t^i |s_t^i )) (\sum_t R(s_t^i , a_t^i ))$<br>
$\qquad \theta\leftarrow \theta+\alpha\nabla_{\theta}J(\theta)$<br>
Until æ”¶æ•›</p>
<h3 id="intution">Intution</h3>
<p>$\nabla_{\theta} \log\pi_{\theta}(a_{i,t}|s_{i,t})$æ˜¯æœ€å¤§å¯¹æ•°ä¼¼ç„¶ï¼Œè¡¨ç¤ºçš„æ˜¯å¯¹åº”çš„trajectoryåœ¨å½“å‰çš„policyä¸‹å‘ç”Ÿçš„å¯èƒ½æ€§ã€‚å°†å®ƒå’Œreturnsç›¸ä¹˜ï¼Œå¦‚æœäº§ç”Ÿhigh positive rewardï¼Œå¢åŠ policyçš„å¯èƒ½æ€§ï¼Œå¦‚æœæ˜¯high negetive rewardï¼Œå‡å°‘policyçš„å¯èƒ½æ€§ã€‚åœ¨ä¸€ä¸ªtrajectoryä¸­çš„stateså…·æœ‰å¾ˆå¼ºçš„ç›¸å…³æ€§ï¼Œè¿™ä¸ªtrajectoryå‘ç”Ÿçš„æ¦‚ç‡å®šä¹‰ä¸ºï¼š<br>
$$\pi(\tau) = p(s_0) \prod_{t=0}^T \pi_{\theta}(a_t|s_t)p(s_{t+1}|s_t,a_t) \tag{59}$$<br>
ä½†æ˜¯è¿ç»­çš„ä¹˜æ³•å¯èƒ½ä¼šäº§ç”Ÿæ¢¯åº¦æ¶ˆå¤±æˆ–è€…æ¢¯åº¦çˆ†ç‚¸é—®é¢˜ã€‚policy gradientå°†è¿ä¹˜å˜æˆäº†è¿åŠ ã€‚</p>
<h3 id="policy-gradients-improvements">Policy Gradients Improvements</h3>
<p>Policy gradientçš„æ–¹å·®å¾ˆå¤§ï¼Œè€Œä¸”å¾ˆéš¾æ”¶æ•›ï¼Œè¿™æ˜¯ä¸€å¤§é—®é¢˜ã€‚<br>
MCæ–¹æ³•æ ¹æ®æ•´ä¸ªtrajectoryè®¡ç®—exact rewardsï¼Œä½†æ˜¯stochastic policyå¯èƒ½ä¼šåœ¨ä¸åŒçš„episodeé‡‡å–ä¸åŒçš„actionsï¼Œä¸€ä¸ªå°çš„æ”¹å˜å¯èƒ½ä¼šå®Œå…¨æ”¹å˜ç»“æœï¼ŒMCæ–¹æ³•æ²¡æœ‰biasä½†æ˜¯æœ‰å¾ˆå¤§çš„æ–¹å·®ã€‚æ–¹å·®ä¼šå½±å“æ·±åº¦å­¦ä¹ çš„ä¼˜åŒ–ï¼Œä¸€ä¸ªé‡‡æ ·çš„rewardå¯èƒ½æƒ³è¦å¢åŠ ä¼¼ç„¶ï¼Œå¦ä¸€ä¸ªæ ·æœ¬rewardså¯èƒ½æƒ³è¦å‡å°‘ä¼¼ç„¶ï¼Œç»™å‡ºäº†å†²çªçš„æ¢¯åº¦æ–¹å‘ï¼Œå½±å“æ”¶æ•›æ€§ã€‚ä¸ºäº†å‡å°‘é€‰æ‹©actioné€ æˆçš„æ–¹å·®ï¼Œæˆ‘ä»¬éœ€è¦å‡å°‘æ ·æœ¬rewardsçš„æ–¹å·®ï¼š<br>
$$\left( \sum_{t=1}^T R(s_{i,t}, a_{i,t})\right)\tag{60}$$<br>
å¢å¤§PGä¸­çš„batch sizeä¼šå‡å°‘æ–¹å·®ã€‚<br>
ä½†æ˜¯å¢å¤§batch sizeä¼šé™ä½sample efficiencyã€‚æ‰€ä»¥batch sizeä¸èƒ½å¢åŠ å¤ªå¤šï¼Œæˆ‘ä»¬éœ€è¦æƒ³å…¶ä»–çš„æ–¹æ³•å‡å°‘æ–¹å·®ï¼š</p>
<h4 id="causality">Causality</h4>
<p>æœªæ¥çš„actionä¸åº”è¯¥æ”¹å˜è¿‡å»çš„decisionsï¼š<br>
$$\nabla_{\theta}J(\theta) \approx \frac{1}{N} \sum_{i=1}^N \sum_{t=1}^T \nabla_{\theta}\log\pi_{\theta}(a_{i,t}|s_{i,t}) \left(\sum_{tâ€™=t}^T R(s_{i,tâ€™};a_{i,tâ€™})\right)\tag{61}$$<br>
å¯ä»¥ç”¨$Q$ä»£æ›¿$\sum_t R(s,a)$ï¼Œ<br>
$$\nabla_{\theta}J(\theta) \approx \frac{1}{N} \sum_{i=1}^N \sum_{t=1}^T \nabla_{\theta}\log\pi_{\theta}(a_{i,t}|s_{i,t}) Q_{i,t}\tag{62}$$<br>
ä¸ºä»€ä¹ˆä¼šå‡å°‘æ–¹å·®ï¼Ÿ</p>
<h4 id="baseline">Baseline</h4>
<p>$$\nabla_{\theta}J(\theta) \approx \frac{1}{N}\sum_{i=1}^N \left(\sum_{t=1}^T\nabla_{\theta} \log\pi_{\theta}(a_{i,t}|s_{i,t}\right) \left(\sum_{t=1}^T R(s_{i,t}, a_{i,t})\right)\tag{63}$$<br>
ä¸­$\sum_{t=1}^T R(s_{i,t}, a_{i,t})$å…¶å®å°±æ˜¯$Q(s,a)$ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨ä¸Šé¢å‡å»ä¸€é¡¹ï¼Œåªè¦è¿™ä¸€é¡¹å’Œ$\theta$æ— å…³å°±å¥½ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥å‡å»$V(s)$ï¼š<br>
\begin{align*}<br>
\nabla_{\theta} J(\theta) &amp; \approx \frac{1}{N} \sum_{i=1}^N \sum_{t=1}^T \nabla_{\theta}\log\pi_{\theta}(a_{i,t}|s_{i,t})\left(Q(s_{i,t}, a_{i,t}) - V(s_{i,t})\right)\\<br>
&amp; = \frac{1}{N} \sum_{i=1}^N \sum_{t=1}^T \nabla_{\theta}\log\pi_{\theta}(a_{i,t}|s_{i,t})\left(A(s_{i,t}, a_{i,t})\right)\\<br>
\end{align*}</p>
<h4 id="vanilla-policy-gradient">Vanilla Policy Gradient</h4>
<p>ç»™å‡ºä¸€ä¸ªä½¿ç”¨baseline $b$çš„é€šç”¨ç®—æ³•ï¼š<br>
$$ \nabla\approx \hat{g} = \frac{1}{m} \sum_{i=1}^m \nabla_{\theta}\log P(\tau^{(i)} ;\theta)(R(\tau^{(i)} )-b)\tag{64}$$<br>
Vanilla policy gradientç®—æ³•<br>
åˆå§‹åŒ–policy å‚æ•°$\theta$ï¼Œbaselien $b$<br>
for $i = 1, 2, \cdots$ do<br>
$\qquad$ä½¿ç”¨å½“å‰policy $\pi_{\theta}$æ”¶é›†trajectories<br>
$\qquad$åœ¨æ¯ä¸ªtrajectoryçš„æ¯ä¸€ä¸ªtimestepï¼Œè®¡ç®—<br>
$\qquad\qquad$return $G_t = \sum_{tâ€™=t}^{T-1} \gamma^{tâ€™-t} R_{tâ€™}$<br>
$\qquad\qquad$advantageçš„ä¼°è®¡å€¼$\hat{A}_t = R_t - b(s_t)$<br>
$\qquad$é‡æ–°æ‹Ÿåˆbaselineï¼Œæœ€å°åŒ–$\vert b(s_t) - G_t\vert^2 $<br>
$\qquad$åœ¨æ‰€æœ‰trajectorieså’Œtimestepsä¸Šæ±‚å’Œä¼°è®¡$\hat{g}$<br>
$\qquad$ä½¿ç”¨policy gradient estimate $\hat{g}$çš„ä¼°è®¡$\hat{g}$æ›´æ–°policy å‚æ•°<br>
end for</p>
<h4 id="reward-discount">Reward discount</h4>
<p>åŠ ä¸ŠæŠ˜æ‰£å› å­ï¼š<br>
$$Q^{\pi,\gamma}(s, a) \leftarrow r_0 + \gamma r_1 + \gamma^2 r_2 + \cdots|s_0 = s, a_0 = a \tag{65}$$<br>
å¾—åˆ°ï¼š<br>
$$\nabla_{\theta}J(\theta) \approx \frac{1}{N} \sum_{i=1}^N \left(\sum_{t=1}^T \nabla_{\theta}\log\pi_{\theta}(a_{i,t}|s_{i,t}) \right) \left(\sum_{tâ€™=t}^T \gamma^{tâ€™-t} R(s_{i,tâ€™};a_{i,tâ€™})\right)\tag{66}$$</p>
<h2 id="å‚è€ƒæ–‡çŒ®">å‚è€ƒæ–‡çŒ®</h2>
<p>1.<a href="https://papers.nips.cc/paper/1713-policy-gradient-methods-for-reinforcement-learning-with-function-approximation.pdf" target="_blank" rel="noopener">https://papers.nips.cc/paper/1713-policy-gradient-methods-for-reinforcement-learning-with-function-approximation.pdf</a><br>
2.<a href="https://papers.nips.cc/paper/2073-a-natural-policy-gradient.pdf" target="_blank" rel="noopener">https://papers.nips.cc/paper/2073-a-natural-policy-gradient.pdf</a><br>
3.<a href="https://medium.com/@jonathan_hui/rl-policy-gradients-explained-9b13b688b146" target="_blank" rel="noopener">https://medium.com/@jonathan_hui/rl-policy-gradients-explained-9b13b688b146</a><br>
4.<a href="https://medium.com/@jonathan_hui/rl-policy-gradients-explained-advanced-topic-20c2b81a9a8b" target="_blank" rel="noopener">https://medium.com/@jonathan_hui/rl-policy-gradients-explained-advanced-topic-20c2b81a9a8b</a><br>
5.<a href="https://www.jianshu.com/p/af668c5d783d" target="_blank" rel="noopener">https://www.jianshu.com/p/af668c5d783d</a><br>
6.<a href="https://lilianweng.github.io/lil-log/2018/04/08/policy-gradient-algorithms.html#what-is-policy-gradient" target="_blank" rel="noopener">https://lilianweng.github.io/lil-log/2018/04/08/policy-gradient-algorithms.html#what-is-policy-gradient</a><br>
7.<a href="https://drive.google.com/file/d/0BxXI_RttTZAhY216RTMtanBpUnc/view" target="_blank" rel="noopener">https://drive.google.com/file/d/0BxXI_RttTZAhY216RTMtanBpUnc/view</a><br>
8.<a href="https://danieltakeshi.github.io/2017/03/28/going-deeper-into-reinforcement-learning-fundamentals-of-policy-gradients/" target="_blank" rel="noopener">https://danieltakeshi.github.io/2017/03/28/going-deeper-into-reinforcement-learning-fundamentals-of-policy-gradients/</a><br>
9.<a href="https://danieltakeshi.github.io/2017/04/02/notes-on-the-generalized-advantage-estimation-paper/" target="_blank" rel="noopener">https://danieltakeshi.github.io/2017/04/02/notes-on-the-generalized-advantage-estimation-paper/</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/3/"><i class="fa fa-angle-left" aria-label="ä¸Šä¸€é¡µ"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span><a class="page-number" href="/page/5/">5</a><span class="space">&hellip;</span><a class="page-number" href="/page/22/">22</a><a class="extend next" rel="next" href="/page/5/"><i class="fa fa-angle-right" aria-label="ä¸‹ä¸€é¡µ"></i></a>
  </nav>



          </div>
          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <div class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/favicon.jpg" alt="é©¬æ™“é‘«çˆ±é©¬èŸèŸ">
            
              <p class="site-author-name" itemprop="name">é©¬æ™“é‘«çˆ±é©¬èŸèŸ</p>
              <p class="site-description motion-element" itemprop="description">è®°å½•ç¡•å£«ä¸‰å¹´è‡ªå·±çš„ç§¯ç´¯</p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">216</span>
                    <span class="site-state-item-name">æ—¥å¿—</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  <a href="/categories/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">19</span>
                    <span class="site-state-item-name">åˆ†ç±»</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  <a href="/tags/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">289</span>
                    <span class="site-state-item-name">æ ‡ç­¾</span>
                  </a>
                </div>
              
            </nav>
          

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://github.com/mxxhcm" title="GitHub &rarr; https://github.com/mxxhcm" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="mailto:mxxhcm@gmail.com" title="E-Mail &rarr; mailto:mxxhcm@gmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                </span>
              
            </div>
          

          

          
          

          
            
          
          

        </div>
      </div>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">é©¬æ™“é‘«çˆ±é©¬èŸèŸ</span>

  

  
</div>


  <div class="powered-by">ç”± <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> å¼ºåŠ›é©±åŠ¨ v3.8.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">ä¸»é¢˜ â€“ <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> v6.6.0</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  
    <script src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  


  


  <script src="/js/src/utils.js?v=6.6.0"></script>

  <script src="/js/src/motion.js?v=6.6.0"></script>



  
  


  <script src="/js/src/affix.js?v=6.6.0"></script>

  <script src="/js/src/schemes/pisces.js?v=6.6.0"></script>



  

  


  <script src="/js/src/bootstrap.js?v=6.6.0"></script>



  



  






<!-- LOCAL: You can save these files to your site and update links -->
    
        
        <link rel="stylesheet" href="https://aimingoo.github.io/gitmint/style/default.css">
        <script src="https://aimingoo.github.io/gitmint/dist/gitmint.browser.js"></script>
    
<!-- END LOCAL -->

    

    







  





  

  

  

  

  
  

  
  
    
      
    
      
    
      
        
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
  

  
    
      <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      },
      TeX: {equationNumbers: { autoNumber: "AMS" }}
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<script src="//cdn.jsdelivr.net/npm/mathjax@2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<style>
.MathJax_Display {
    overflow: auto hidden;
}
</style>

    
  


  
  

  

  

  

  

  

  

</body>
</html>
