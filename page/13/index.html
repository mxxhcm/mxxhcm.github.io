<!DOCTYPE html>












  


<html class="theme-next pisces use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
































<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=6.6.0" rel="stylesheet" type="text/css">



  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.jpg?v=6.6.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.jpg?v=6.6.0">










<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '6.6.0',
    sidebar: {"position":"left","display":"always","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="记录硕士三年自己的积累">
<meta property="og:type" content="website">
<meta property="og:title" content="mxxhcm&#39;s blog">
<meta property="og:url" content="http://mxxhcm.github.io/page/13/index.html">
<meta property="og:site_name" content="mxxhcm&#39;s blog">
<meta property="og:description" content="记录硕士三年自己的积累">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="mxxhcm&#39;s blog">
<meta name="twitter:description" content="记录硕士三年自己的积累">



  <link rel="alternate" href="/atom.xml" title="mxxhcm's blog" type="application/atom+xml">




  <link rel="canonical" href="http://mxxhcm.github.io/page/13/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>mxxhcm's blog</title>
  












  <noscript>
  <style>
    .use-motion .motion-element,
    .use-motion .brand,
    .use-motion .menu-item,
    .sidebar-inner,
    .use-motion .post-block,
    .use-motion .pagination,
    .use-motion .comments,
    .use-motion .post-header,
    .use-motion .post-body,
    .use-motion .collection-title { opacity: initial; }

    .use-motion .logo,
    .use-motion .site-title,
    .use-motion .site-subtitle {
      opacity: initial;
      top: initial;
    }

    .use-motion .logo-line-before i { left: initial; }
    .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">mxxhcm's blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>

      
      
    </ul>
  

  

  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mxxhcm.github.io/2019/03/07/tensorflow-problems/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="马晓鑫爱马荟荟">
      <meta itemprop="description" content="记录硕士三年自己的积累">
      <meta itemprop="image" content="/images/favicon.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="mxxhcm's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/03/07/tensorflow-problems/" class="post-title-link" itemprop="http://mxxhcm.github.io/page/13/index.html">tensorflow 常见问题（不定期更新）</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-03-07 14:51:01" itemprop="dateCreated datePublished" datetime="2019-03-07T14:51:01+08:00">2019-03-07</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-07-18 20:27:16" itemprop="dateModified" datetime="2019-07-18T20:27:16+08:00">2019-07-18</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/tensorflow/" itemprop="url" rel="index"><span itemprop="name">tensorflow</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="问题1-the-value-of-a-feed-cannot-be-a-tf-tensor-object">问题1-The value of a feed cannot be a tf.Tensor object</h2>
<h3 id="报错">报错</h3>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">TypeError: The value of a feed cannot be a tf.Tensor object</span><br></pre></td></tr></table></figure>
<h3 id="问题原因">问题原因</h3>
<p>sess.run(op, feed_dict={})中的feed value不能是tf.Tensor类型。</p>
<h3 id="解决方法">解决方法</h3>
<p>sess.run(train, feed_dict={x:images, y:labels}的输入不能是tensor，可以使用sess.run(tensor)得到numpy.array形式的数据再喂给feed_dict。</p>
<blockquote>
<p>Once you have launched a sess, you can use your_tensor.eval(session=sess) or sess.run(your_tensor) to get you feed tensor into the format of numpy.array and then feed it to your placeholder.</p>
</blockquote>
<h2 id="问题2-could-not-create-cudnn-handle-cudnn-status-internal-error">问题2-Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR</h2>
<h3 id="配置">配置</h3>
<p>环境配置如下：</p>
<ul>
<li>Ubuntu 18.04</li>
<li>CUDA 10.0</li>
<li>CuDNN 7.4.2</li>
<li>Python3.7.3</li>
<li>Tensorflow 1.13.1</li>
<li>Nvidia Drivers 430.09</li>
<li>RTX2070</li>
</ul>
<h3 id="报错-v2">报错</h3>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">2019-05-12 14:45:59.355405: E tensorflow/stream_executor/cuda/cuda_dnn.cc:334] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR</span><br><span class="line">2019-05-12 14:45:59.357698: E tensorflow/stream_executor/cuda/cuda_dnn.cc:334] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<h3 id="问题原因-v2">问题原因</h3>
<p>GPU不够用了。</p>
<h3 id="解决方法-v2">解决方法</h3>
<p>在代码中添加下面几句：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">config = tf.ConfigProto()</span><br><span class="line">config.gpu_options.allow_growth = <span class="literal">True</span></span><br><span class="line">session = InteractiveSession(config=config)</span><br></pre></td></tr></table></figure>
<h2 id="问题3-libcublas-so-10-0-cannot-open-shared-object-file-no-such-file-or-directory">问题3-libcublas.so.10.0: cannot open shared object file: No such file or directory</h2>
<p>在命令行或者pycharm中import tensorflow报错</p>
<h3 id="报错-v3">报错</h3>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ImportError: libcublas.so.10.0: cannot open shared object file: No such file or directory</span><br><span class="line">Failed to load the native TensorFlow runtime.</span><br></pre></td></tr></table></figure>
<h3 id="问题原因-v3">问题原因</h3>
<p>没有配置CUDA环境变量</p>
<h3 id="解决方法-v3">解决方法</h3>
<h4 id="命令行中">命令行中</h4>
<p>在.bashrc文件中加入下列语句：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export PATH=/usr/local/cuda/bin$&#123;PATH:+:$&#123;PATH&#125;&#125;</span><br><span class="line">export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$&#123;LD_LIBRARY_PATH:+:$&#123;LD_LIBRARY_PATH&#125;&#125;</span><br><span class="line">export CUDA_HOME=/usr/local/cuda</span><br></pre></td></tr></table></figure>
<h4 id="pycharm中">pycharm中</h4>
<h5 id="方法1-这种方法我没有实验成功-不知道为什么">方法1（这种方法我没有实验成功，不知道为什么）</h5>
<p>在左上角选中<br>
File&gt;&gt;Settings&gt;&gt;Build.Execution,Deployment&gt;&gt;Console&gt;&gt;Python Console<br>
在Environment下的Environment variables中添加<br>
LD_LIBRARY_PATH=/usr/local/cuda/lib64:${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}即可。</p>
<h5 id="方法2">方法2</h5>
<p>修改完.bashrc文件后从终端中运行pycharm。</p>
<h2 id="问题4-dlerror-libcupti-so-10-0-cannot-open-shared-object-file-no-such-file-or-directory">问题4-dlerror: libcupti.so.10.0: cannot open shared object file: No such file or directory</h2>
<p>执行mnist_with_summary代码时报错</p>
<h3 id="报错-v4">报错</h3>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">I tensorflow/stream_executor/dso_loader.cc:142] Couldn&apos;t open CUDA library libcupti.so.10.0. LD_LIBRARY_PATH: /usr/local/cuda/lib64:</span><br><span class="line">2019-05-13 23:04:10.620149: F tensorflow/stream_executor/lib/statusor.cc:34] Attempting to fetch value instead of handling error Failed precondition: could not dlopen DSO: libcupti.so.10.0; dlerror: libcupti.so.10.0: cannot open shared object file: No such file or directory</span><br><span class="line">Aborted (core dumped)</span><br></pre></td></tr></table></figure>
<h3 id="问题问题问题问题问题问题问题问题问题原因">问题问题问题问题问题问题问题问题问题原因</h3>
<p>libcupti.so.10.0包没找到</p>
<h3 id="解决方法-v4">解决方法</h3>
<p>执行以下命令，找到相关的依赖包：<br>
~$:find /usr/local/cuda/ -name libcupti.so.10.0<br>
输出如下：</p>
<blockquote>
<p>/usr/local/cuda/extras/CUPTI/lib64/libcupti.so.10.0</p>
</blockquote>
<p>然后修改~/.bashrc文件中相应的环境变量:<br>
export LD_LIBRARY_PATH=/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64/😒{LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}<br>
重新运行即可。</p>
<h2 id="问题5-unhashable-type-list">问题5-unhashable type: ‘list’</h2>
<p>sess.run(op, feed_dict={})中feed的数据中包含有list的时候会报错。</p>
<h3 id="报错-v5">报错</h3>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">TypeError: unhashable type: &apos;list&apos;</span><br></pre></td></tr></table></figure>
<h3 id="问题原因-v4">问题原因</h3>
<p>feed_dict中不能的value不能是list。</p>
<h3 id="解决方法-v5">解决方法</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">feed_dict = &#123;</span><br><span class="line">               placeholder : value </span><br><span class="line">                  <span class="keyword">for</span> placeholder, value <span class="keyword">in</span> zip(placeholder_list, inputs_list))</span><br><span class="line">            &#125;</span><br></pre></td></tr></table></figure>
<h3 id="代码示例">代码示例</h3>
<p><a href="https://github.com/mxxhcm/code/blob/master/tf/ops/tf_placeholder_list.py" target="_blank" rel="noopener">代码地址</a></p>
<h2 id="问题6-attempting-to-use-uninitialized-value">问题6-Attempting to use uninitialized value</h2>
<p>tf.Session()和tf.InteractiveSession()混用问题。</p>
<h3 id="报错-v6">报错</h3>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tensorflow.python.framework.errors_impl.FailedPreconditionError: Attempting to use uninitialized value prediction/l1/w</span><br><span class="line">	 [[&#123;&#123;node prediction/l1/w/read&#125;&#125;]]</span><br><span class="line">	 [[&#123;&#123;node prediction/LogSoftmax&#125;&#125;]]</span><br></pre></td></tr></table></figure>
<h3 id="问题原因-v5">问题原因</h3>
<p>声明了如下session:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sess = tf.Session()</span><br><span class="line">sess.run(tf.global_variables_initializer())</span><br></pre></td></tr></table></figure>
<p>在接下来的代码中，因为我声明的是tf.Session()，使用了op.eval()函数，这种用法是tf.InteractiveSession的用法，所以就相当于没有初始化。<br>
result = op.eval(feed_dict={})<br>
然后就报了未初始化的错误。<br>
把代码改成：<br>
result = sess.run([op], feeed_dct={})<br>
即可，即上下文使用的session应该一致。</p>
<h3 id="解决方案">解决方案</h3>
<p>使用统一的session类型</p>
<h2 id="问题7-setting-an-array-element-with-a-sequence">问题7-setting an array element with a sequence</h2>
<p>feed_dict键值对中中值必须是numpy.ndarray，不能是其他类型。</p>
<h3 id="报错-v7">报错</h3>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">value error setting an array element with a sequence,</span><br></pre></td></tr></table></figure>
<h3 id="问题原因-v6">问题原因</h3>
<p>feed_dict中key-value的value必须是numpy.ndarray，不能是其他类型，尤其不能是tf.Variable。</p>
<h3 id="解决方法-v6">解决方法</h3>
<p>检查sess.run(op, feed_dict={})中的feed_dict，确保他们的类型，不能是tf.Variable()类型的对象，需要是numpy.ndarray。</p>
<h2 id="问题8-访问tf-variable-的值">问题8-访问tf.Variable()的值</h2>
<p>如何获得tf.Variable()对象的值</p>
<h3 id="解决方法-v7">解决方法</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">x = tf.Varialbe([<span class="number">1.0</span>, <span class="number">2.0</span>])</span><br><span class="line">sess = tf.Session()</span><br><span class="line">sess.run(tf.global_variables_initializer())</span><br><span class="line">value = sess.run(x)</span><br></pre></td></tr></table></figure>
<p>或者</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">x = tf.Varialbe([1.0, 2.0])</span><br><span class="line">sess = tf.InteractiveSession()</span><br><span class="line">sess.run(tf.global_variables_initializer())</span><br><span class="line">x.eval()</span><br></pre></td></tr></table></figure>
<h2 id="问题9-can-not-convert-a-ndarray-into-a-tensor-or-operation">问题9-Can not convert a ndarray into a Tensor or Operation</h2>
<h3 id="报错-v8">报错</h3>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Can not convert a ndarray into a Tensor or Operation.</span><br></pre></td></tr></table></figure>
<h3 id="问题原因-v7">问题原因</h3>
<p>原因是sess.run()前后参数名重了，比如outputs = sess.run(outputs)，outputs本来是自己定义的一个op，但是sess.run(outputs)之后outputs就成了一个变量，就把定义的outputs op覆盖了。</p>
<h3 id="解决方法-v8">解决方法</h3>
<p>换个变量名字就行</p>
<h2 id="问题10-本地使用gpu-server的tensorboard">问题10-本地使用gpu server的tensorboard</h2>
<h3 id="问题描述">问题描述</h3>
<p>在gpu server跑的实验结果，然后summary的记录也在server上，但是又没办法可视化，只好在本地可视化。</p>
<h3 id="解决方法-v9">解决方法</h3>
<p>使用ssh进行映射好了。</p>
<h4 id="本机设置">本机设置</h4>
<p>~$:ssh -L 12345:10.1.114.50:6006 <a href="mailto:mxxmhh@127.0.0.1" target="_blank" rel="noopener">mxxmhh@127.0.0.1</a><br>
将本机的12345端口映射到10.1.114.50的6006端口，中间服务器使用的是本机。<br>
或者可以使用10.1.114.50作为中间服务器。<br>
~$:ssh -L 12345:10.1.114.50:6006 <a href="mailto:liuchi@10.1.114.50" target="_blank" rel="noopener">liuchi@10.1.114.50</a><br>
或者可以使用如下方法：<br>
~$:ssh -L 12345:127.0.0.1:6006 <a href="mailto:liuchi@10.1.114.50" target="_blank" rel="noopener">liuchi@10.1.114.50</a><br>
从这个方法中，可以看出127.0.0.1这个ip是中间服务器可以访问的ip。<br>
以上三种方法中，-L后的端口号12345可以随意设置，只要不冲突即可。</p>
<h4 id="服务端设置">服务端设置</h4>
<p>然后在服务端运行以下命令：<br>
~$:tensorboard --logdir logdir -port 6006<br>
这个端口号也是可以任意设置的，不冲突即可。</p>
<h4 id="运行">运行</h4>
<p>然后在本机访问<br>
<a href="https://127.0.0.1:12345" target="_blank" rel="noopener">https://127.0.0.1:12345</a>即可。</p>
<h2 id="问题11-每一步summary一个list的每一个元素">问题11-每一步summary一个list的每一个元素</h2>
<h3 id="问题原因-v8">问题原因</h3>
<p>有一个tf list的placeholder，但是每一步只能生成其中的一个元素，所以怎么样summary中其中的某一个？</p>
<h3 id="解决方法-v10">解决方法</h3>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">number = 3</span><br><span class="line">x_ph_list = []</span><br><span class="line">for i in range(number):</span><br><span class="line">    x_ph_list.append(tf.placeholder(tf.float32, shape=None))</span><br><span class="line"></span><br><span class="line">x_summary_list = []</span><br><span class="line">for i in range(number):</span><br><span class="line">    x_summary_list.append(tf.summary.scalar("x%s" % i, x_ph_list[i]))</span><br><span class="line"></span><br><span class="line">writer = tf.summary.FileWriter("./tf_summary/scalar_list_summary/sep")</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    scope = 10</span><br><span class="line">    inputs = np.arange(scope*number)</span><br><span class="line">    inputs = inputs.reshape(scope, number)</span><br><span class="line">    # inputs = np.random.randn(scope, number)</span><br><span class="line">    for i in range(scope):</span><br><span class="line">        for j in range(number):</span><br><span class="line">            out, xj_s = sess.run([x_ph_list[j], x_summary_list[j]], feed_dict=&#123;x_ph_list[j]: inputs[i][j]&#125;)</span><br><span class="line">            writer.add_summary(xj_s, global_step=i)</span><br></pre></td></tr></table></figure>
<h2 id="问题12-for-value-in-summary-value-attributeerror-list-object-has-no-attribute-value">问题12- for value in summary.value: AttributeError: ‘list’ object has no attribute ‘value’</h2>
<h3 id="问题描述-v2">问题描述</h3>
<p>writer.add_summary时报错</p>
<h3 id="报错-v9">报错</h3>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">File &quot;/home/mxxmhh/anaconda3/lib/python3.7/site-packages/tensorflow/python/summary/writer/writer.py&quot;, line 127, in add_summary</span><br><span class="line">    for value in summary.value:</span><br><span class="line">AttributeError: &apos;list&apos; object has no attribute &apos;value&apos;</span><br></pre></td></tr></table></figure>
<h3 id="问题原因-v9">问题原因</h3>
<p>执行以下代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">s_ = sess.run([loss_summary], feed_dict=&#123;p_losses_ph: inputs1, q_losses_ph: inputs2&#125;)</span><br><span class="line">writer.add_summary(s_, global_step=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>因为[loss_summary]加了方括号，就把它当成了一个list。。返回值也是list，就报错了</p>
<h3 id="解决方法-v11">解决方法</h3>
<ul>
<li>方法1，在等号左边加一个逗号，取出list中的值</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">s_, = sess.run([loss_summary], feed_dict=&#123;p_losses_ph: inputs1, q_losses_ph: inputs2&#125;)</span><br></pre></td></tr></table></figure>
<ul>
<li>方法2，去掉loss_summary外面的中括号。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">s_ = sess.run(loss_summary, feed_dict=&#123;p_losses_ph: inputs1, q_losses_ph: inputs2&#125;)</span><br></pre></td></tr></table></figure>
<h2 id="问题13-tf-get-default-session-always-returns-none-type">问题13- tf.get_default_session() always returns None type:</h2>
<h3 id="问题描述-v3">问题描述</h3>
<p>调用tf.get_default_session()时，返回的是None</p>
<h3 id="报错-v10">报错</h3>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">    tf.get_default_session().run(y)</span><br><span class="line">AttributeError: &apos;NoneType&apos; object has no attribute &apos;run&apos;</span><br></pre></td></tr></table></figure>
<h3 id="问题原因-v10">问题原因</h3>
<p>只有在设定default session之后，才能使用tf.get_default_session()获得当前的默认session，在我们写代码的时候，一般会按照下面的方式写：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    some operations</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure>
<p>这种情况下已经把tf.Session()生成的session当做了默认session，但是如果仅仅使用以下代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">sess =  tf.Session()</span><br><span class="line">sess.run(some operations)</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>是没有把tf.Session()当成默认session的，即只有在with block内，才会将这个session当做默认session。</p>
<h3 id="解决方案-v2">解决方案</h3>
<h2 id="参考文献">参考文献</h2>
<p>1.<a href="https://github.com/tensorflow/tensorflow/issues/4842" target="_blank" rel="noopener">https://github.com/tensorflow/tensorflow/issues/4842</a><br>
2.<a href="https://github.com/tensorflow/tensorflow/issues/24496" target="_blank" rel="noopener">https://github.com/tensorflow/tensorflow/issues/24496</a><br>
3.<a href="https://github.com/tensorflow/tensorflow/issues/9530" target="_blank" rel="noopener">https://github.com/tensorflow/tensorflow/issues/9530</a><br>
4.<a href="https://stackoverflow.com/questions/51128427/how-to-feed-list-of-values-to-a-placeholder-list-in-tensorflow" target="_blank" rel="noopener">https://stackoverflow.com/questions/51128427/how-to-feed-list-of-values-to-a-placeholder-list-in-tensorflow</a><br>
5.<a href="https://github.com/tensorflow/tensorflow/issues/11897" target="_blank" rel="noopener">https://github.com/tensorflow/tensorflow/issues/11897</a><br>
6.<a href="https://stackoverflow.com/questions/34156639/tensorflow-python-valueerror-setting-an-array-element-with-a-sequence-in-t" target="_blank" rel="noopener">https://stackoverflow.com/questions/34156639/tensorflow-python-valueerror-setting-an-array-element-with-a-sequence-in-t</a><br>
7.<a href="https://stackoverflow.com/questions/33679382/how-do-i-get-the-current-value-of-a-variable" target="_blank" rel="noopener">https://stackoverflow.com/questions/33679382/how-do-i-get-the-current-value-of-a-variable</a><br>
8.<a href="https://blog.csdn.net/michael__corleone/article/details/79007425" target="_blank" rel="noopener">https://blog.csdn.net/michael__corleone/article/details/79007425</a><br>
9.<a href="https://stackoverflow.com/questions/47721792/tensorflow-tf-get-default-session-after-sess-tf-session-is-none" target="_blank" rel="noopener">https://stackoverflow.com/questions/47721792/tensorflow-tf-get-default-session-after-sess-tf-session-is-none</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mxxhcm.github.io/2019/03/04/linux-查看python-package的安装位置/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="马晓鑫爱马荟荟">
      <meta itemprop="description" content="记录硕士三年自己的积累">
      <meta itemprop="image" content="/images/favicon.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="mxxhcm's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/03/04/linux-查看python-package的安装位置/" class="post-title-link" itemprop="http://mxxhcm.github.io/page/13/index.html">linux-查看python package的安装位置</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-03-04 14:52:16" itemprop="dateCreated datePublished" datetime="2019-03-04T14:52:16+08:00">2019-03-04</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-05-12 12:03:26" itemprop="dateModified" datetime="2019-05-12T12:03:26+08:00">2019-05-12</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/linux/" itemprop="url" rel="index"><span itemprop="name">linux</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>使用pip install package-name之后，不知道该包存在了哪个路径下。<br>
可以再次使用pip install package-name，这时候就会给出该包存放在哪个路径下。</p>
<h2 id="参考文献">参考文献</h2>
<ol>
<li><a href="https://blog.csdn.net/weixin_41712059/article/details/82940516" target="_blank" rel="noopener">https://blog.csdn.net/weixin_41712059/article/details/82940516</a></li>
</ol>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mxxhcm.github.io/2019/03/04/linux-shadowsocks服务端以及客户端配置/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="马晓鑫爱马荟荟">
      <meta itemprop="description" content="记录硕士三年自己的积累">
      <meta itemprop="image" content="/images/favicon.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="mxxhcm's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/03/04/linux-shadowsocks服务端以及客户端配置/" class="post-title-link" itemprop="http://mxxhcm.github.io/page/13/index.html">shadowsocks服务端以及客户端配置</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-03-04 13:03:57" itemprop="dateCreated datePublished" datetime="2019-03-04T13:03:57+08:00">2019-03-04</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-06-19 11:39:56" itemprop="dateModified" datetime="2019-06-19T11:39:56+08:00">2019-06-19</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/linux/" itemprop="url" rel="index"><span itemprop="name">linux</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="服务器端配置">服务器端配置</h2>
<p>首先需要有一个VPS账号，vultr,digitalocean,搬瓦工等等都行。<br>
首先到下面两个网站检测22端口是否开启，如果关闭的话，vps换个ip把。。<br>
<a href="http://tool.chinaz.com/port" target="_blank" rel="noopener">http://tool.chinaz.com/port</a><br>
<a href="https://www.yougetsignal.com/tools/open-ports/" target="_blank" rel="noopener">https://www.yougetsignal.com/tools/open-ports/</a></p>
<h3 id="启用bbr加速">启用BBR加速</h3>
<p>~#:apt update<br>
~#:apt upgrade<br>
~#:echo “net.core.default_qdisc=fq” &gt;&gt; /etc/sysctl.conf<br>
~#:echo “net.ipv4.tcp_congestion_control=bbr” &gt;&gt; /etc/sysctl.conf<br>
~#:sysctl -p<br>
上述命令就完成了BBR加速，执行以下命令验证：<br>
~#:lsmod |grep bbr<br>
看到输出包含tcp_bbr就说明已经成功了。</p>
<h3 id="搭建shadowsocks-server">搭建shadowsocks server</h3>
<h4 id="安装shadowsocks-server">安装shadowsocks server</h4>
<p>~#:apt install python-pip<br>
~#:pip install shadowsocks<br>
需要说一下的是，shadowsocks目前还不支持python3.5及以上版本，上次我把/usr/bin/python指向了python3.6，就是系统默认的python指向了python3.6，然后就gg了。一定要使用Python 2.6,2.7,3.3,3.4中的一个版本才能使用。。</p>
<h4 id="创建shadowsocks配置文件">创建shadowsocks配置文件</h4>
<p>如果你的VPS支持ipv6的话，那么可以开多进程分别运行ipv4和ipv6的shadowsocks server。本地只有ipv4的话，可以用本地ipv4访问ipv6，从而访问byr等网站，但是六维空间对此做了屏蔽。如果本地有ipv6的话，还可以用本地的ipv6访问ipv6实现校园网不走ipv4流量。</p>
<h5 id="ipv4配置">ipv4配置</h5>
<p>~#:vim /etc/shadowsocks_v4.json<br>
配置文件如下</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line"><span class="attr">"server"</span>:<span class="string">"0.0.0.0"</span>,</span><br><span class="line"><span class="attr">"server_port"</span>:<span class="string">"你的端口号"</span>,</span><br><span class="line"><span class="attr">"local_address"</span>:<span class="string">"127.0.0.1"</span>,</span><br><span class="line"><span class="attr">"local_port"</span>:<span class="number">1080</span>,</span><br><span class="line"><span class="attr">"password"</span>:<span class="string">"你的密码"</span>,</span><br><span class="line"><span class="attr">"timeout"</span>:<span class="number">600</span>,</span><br><span class="line"><span class="attr">"method"</span>:<span class="string">"aes-256-cfb"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h5 id="ipv6配置">ipv6配置</h5>
<p>~#:vim /etc/shadowsocks_v6.json<br>
配置文件如下</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line"><span class="attr">"server"</span>:<span class="string">"::"</span>,</span><br><span class="line"><span class="attr">"server_port"</span>:<span class="string">"你的端口号"</span>,</span><br><span class="line"><span class="attr">"local_address"</span>:<span class="string">"127.0.0.1"</span>,</span><br><span class="line"><span class="attr">"local_port"</span>:<span class="number">1080</span>,</span><br><span class="line"><span class="attr">"password"</span>:<span class="string">"你的密码"</span>,</span><br><span class="line"><span class="attr">"timeout"</span>:<span class="number">600</span>,</span><br><span class="line"><span class="attr">"method"</span>:<span class="string">"aes-256-cfb"</span></span><br><span class="line">&#125;</span><br><span class="line">``` </span><br><span class="line">注意这两个文件的server_port一定要不同，以及双引号必须是英文引号。</span><br><span class="line">##### 1.2.2.3.手动运行shadowsocks server</span><br><span class="line">~#:ssserver -c /etc/shadowsock_v4.json -d start --pid-file ss1.pid</span><br><span class="line">~#:ssserver -c /etc/shadowsock_v6.json -d start --pid-file ss2.pid</span><br><span class="line">注意这里要给两条命令分配不同的进程号。</span><br><span class="line"></span><br><span class="line">### 设置shadowsocks server开机自启</span><br><span class="line">如果重启服务器的话，就需要重新手动执行上述命令，这里我们可以把它写成开机自启脚本。</span><br><span class="line">~#:vim /etc/init.d/shadowsocks_v4</span><br><span class="line">内容如下：</span><br><span class="line">``` shell</span><br><span class="line">#!/bin/sh</span><br><span class="line">### BEGIN INIT INFO</span><br><span class="line"># Provides:          apache2</span><br><span class="line"># Required-Start:    $local_fs $remote_fs $network $syslog</span><br><span class="line"># Required-Stop:     $local_fs $remote_fs $network $syslog</span><br><span class="line"># Default-Start:     2 3 4 5</span><br><span class="line"># Default-Stop:      0 1 6</span><br><span class="line"># Short-Description: apache2 service</span><br><span class="line"># Description:       apache2 service daemon</span><br><span class="line">### END INIT INFO</span><br><span class="line">start()&#123;</span><br><span class="line">  ssserver -c /etc/shadowsocks_v4.json -d start --pid-file ss2.pid</span><br><span class="line">&#125;</span><br><span class="line">stop()&#123;</span><br><span class="line">  ssserver -c /etc/shadowsocks_v4.json -d stop --pid-file ss2.pid</span><br><span class="line">&#125;</span><br><span class="line">case "$1" in</span><br><span class="line">start)</span><br><span class="line">  start</span><br><span class="line">  ;;</span><br><span class="line">stop)</span><br><span class="line">  stop</span><br><span class="line">  ;;</span><br><span class="line">restart)</span><br><span class="line">  stop</span><br><span class="line">  start</span><br><span class="line">  ;;</span><br><span class="line">*)</span><br><span class="line">  echo "Uasage: $0 &#123;start|reload|stop&#125;$"</span><br><span class="line">  exit 1</span><br><span class="line">  ;;</span><br><span class="line">esac</span><br></pre></td></tr></table></figure>
<p>~#:vim /etc/init.d/shadowsocks_v6<br>
内容如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>!/bin/sh</span><br><span class="line"><span class="meta">#</span>## BEGIN INIT INFO</span><br><span class="line"><span class="meta">#</span> Provides:          apache2</span><br><span class="line"><span class="meta">#</span> Required-Start:    $local_fs $remote_fs $network $syslog</span><br><span class="line"><span class="meta">#</span> Required-Stop:     $local_fs $remote_fs $network $syslog</span><br><span class="line"><span class="meta">#</span> Default-Start:     2 3 4 5</span><br><span class="line"><span class="meta">#</span> Default-Stop:      0 1 6</span><br><span class="line"><span class="meta">#</span> Short-Description: apache2 service</span><br><span class="line"><span class="meta">#</span> Description:       apache2 service daemon</span><br><span class="line"><span class="meta">#</span>## END INIT INFO</span><br><span class="line">start()&#123;</span><br><span class="line">  ssserver -c /etc/shadowsocks_v6.json -d start --pid-file ss1.pid</span><br><span class="line">&#125;</span><br><span class="line">stop()&#123;</span><br><span class="line">  ssserver -c /etc/shadowsocks_v6.json -d stop --pid-file ss1.pid</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">case "$1" in</span><br><span class="line">start)</span><br><span class="line">  start</span><br><span class="line">  ;;</span><br><span class="line">stop)</span><br><span class="line">  stop</span><br><span class="line">  ;;</span><br><span class="line">restart)</span><br><span class="line">  stop</span><br><span class="line">  start</span><br><span class="line">  ;;</span><br><span class="line">*)</span><br><span class="line">  echo "Uasage: $0 &#123;start|reload|stop&#125;$"</span><br><span class="line">  exit 1</span><br><span class="line">  ;;</span><br><span class="line">esac</span><br></pre></td></tr></table></figure>
<p>然后执行下列命令即可：<br>
~#:chmod a+x /etc/init.d/shadowsocks_v4<br>
~#:chmod a+x /etc/init.d/shadowsocks_v6<br>
~#:update-rc.d shadowsocks_v4 defaults<br>
~#:update-rc.d shadowsocks_v6 defaults</p>
<p>至此，服务器端配置完成。</p>
<h2 id="服务端自动配置脚本">服务端自动配置脚本</h2>
<p><a href="https://github.com/mxxhcm/code/tree/master/shell/ss" target="_blank" rel="noopener">地址</a><br>
首先将该文件中所有文件复制到vps上，然后执行<br>
~#:sh install_ss_server.sh<br>
即可</p>
<h3 id="补充说明">补充说明</h3>
<p>该文件夹共包含五个文件<br>
shadowsocks_v4.json为ipv4 ss配置文件，可根据自己的需要修改端口号和密码<br>
shadowsocks_v6.json为ipv6 ss配置文件，可根据自己的需要修改端口号和密码<br>
shadowsocks_v4为ipv4 ss自启动文件，无需修改<br>
shadowsocks_v6为ipv6 ss自启动文件，无需修改<br>
install_ss_server.sh为安装脚本，该脚本同时配置ipv4和ipv6 ss server。可根据自己需要自行选择。</p>
<h2 id="客户端配置">客户端配置</h2>
<h3 id="windows客户端配置">Windows客户端配置</h3>
<h4 id="安装shadowsock客户端">安装shadowsock客户端</h4>
<p>到该网址 <a href="https://github.com/shadowsocks/shadowsocks-windows/releases" target="_blank" rel="noopener">https://github.com/shadowsocks/shadowsocks-windows/releases</a> 下载相应的windows客户端程序。<br>
然后配置服务器即可～</p>
<h3 id="linux客户端配置">Linux客户端配置</h3>
<h4 id="安装shadowsocks程序">安装shadowsocks程序</h4>
<p>~$:sudo pip install shadowsocks</p>
<h4 id="运行shadowsocks客户端程序">运行shadowsocks客户端程序</h4>
<p>~$:sudo vim /etc/shadowsocks.json<br>
填入以下配置文件<br>
{<br>
“server”:“填上自己的shadowsocks server ip地址”,<br>
“server_port”:“8888”,//填上自己的shadowsocks server 端口&quot;<br>
“local_port”:1080,<br>
“password”:“mxxhcm150929”,<br>
“timeout”:600,<br>
“method”:“aes-256-cfb”<br>
}</p>
<p>接下来可以执行以下命令运行shadowsocks客户端：<br>
~$:sudo sslocal -c /etc/shadowsocks.json<br>
然后报错：</p>
<blockquote>
<p>INFO: loading config from /etc/shadowsocks.json<br>
2019-03-04 14:37:49 INFO     loading libcrypto from libcrypto.so.1.1<br>
Traceback (most recent call last):<br>
File “/usr/local/bin/sslocal”, line 11, in <module><br>
load_entry_point(‘shadowsocks==2.8.2’, ‘console_scripts’, ‘sslocal’)()<br>
File “/usr/local/lib/python2.7/dist-packages/shadowsocks/local.py”, line 39, in main<br>
config = shell.get_config(True)<br>
File “/usr/local/lib/python2.7/dist-packages/shadowsocks/shell.py”, line 262, in get_config<br>
check_config(config, is_local)<br>
File “/usr/local/lib/python2.7/dist-packages/shadowsocks/shell.py”, line 124, in check_config<br>
encrypt.try_cipher(config[‘password’], config[‘method’])<br>
File “/usr/local/lib/python2.7/dist-packages/shadowsocks/encrypt.py”, line 44, in try_cipher<br>
Encryptor(key, method)<br>
File “/usr/local/lib/python2.7/dist-packages/shadowsocks/encrypt.py”, line 83, in <strong>init</strong><br>
random_string(self._method_info[1]))<br>
File “/usr/local/lib/python2.7/dist-packages/shadowsocks/encrypt.py”, line 109, in get_cipher<br>
return m[2](method, key, iv, op)<br>
File “/usr/local/lib/python2.7/dist-packages/shadowsocks/crypto/openssl.py”, line 76, in <strong>init</strong><br>
load_openssl()<br>
File “/usr/local/lib/python2.7/dist-packages/shadowsocks/crypto/openssl.py”, line 52, in load_openssl<br>
libcrypto.EVP_CIPHER_CTX_cleanup.argtypes = (c_void_p,)<br>
File “/usr/lib/python2.7/ctypes/<strong>init</strong>.py”, line 379, in <strong>getattr</strong><br>
func = self.<strong>getitem</strong>(name)<br>
File “/usr/lib/python2.7/ctypes/<strong>init</strong>.py”, line 384, in <strong>getitem</strong><br>
func = self._FuncPtr((name_or_ordinal, self))<br>
AttributeError: /usr/lib/x86_64-linux-gnu/libcrypto.so.1.1: undefined symbol: EVP_CIPHER_CTX_cleanup</module></p>
</blockquote>
<p>按照参考文献4的做法，是在openssl 1.1.0版本中放弃了EVP_CIPHER_CTX_cleanup函数</p>
<blockquote>
<p>EVP_CIPHER_CTX was made opaque in OpenSSL 1.1.0. As a result, EVP_CIPHER_CTX_reset() appeared and EVP_CIPHER_CTX_cleanup() disappeared.<br>
EVP_CIPHER_CTX_init() remains as an alias for EVP_CIPHER_CTX_reset().</p>
</blockquote>
<p>将openssl库中的EVP_CIPHER_CTX_cleanup改为EVP_CIPHER_CTX_reset即可。<br>
再次执行以下命令，查看shadowsocks安装位置<br>
~#:pip install shadowsocks<br>
Requirement already satisfied: shadowsocks in /usr/local/lib/python2.7/dist-packages<br>
~#:cd /usr/local/lib/python2.7/dist-packages/shadowsocks<br>
~#:vim crypto/openssl.py<br>
搜索cleanup，将其替换为reset<br>
具体位置在第52行libcrypto.EVP_CIPHER_CTX_cleanup.argtypes = (c_void_p,)和第111行libcrypto.EVP_CIPHER_CTX_cleanup(self._ctx)</p>
<h4 id="手动运行后台挂起">手动运行后台挂起</h4>
<p>将所有的log重定向到~/.log/sslocal.log文件中<br>
~$:mkdir ~/.log<br>
~$:touch ~/.log/ss-local.log<br>
~$:nohup sslocal -c /etc/shadowsocks_v6.json &lt;/dev/null &amp;&gt;&gt;~/.log/ss-local.log &amp;</p>
<h4 id="开机自启shadowsocks-client">开机自启shadowsocks client</h4>
<p>但是这样子的话，每次开机都要重新运行上述命令，太麻烦了。可以写个开机自启脚本。执行以下命令：<br>
~$:sudo vim /etc/init.d/shadowsocks<br>
内容为以下shell脚本</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>!/bin/sh</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span>## BEGIN INIT INFO</span><br><span class="line"><span class="meta">#</span> Provides:          shadowsocks local</span><br><span class="line"><span class="meta">#</span> Required-Start:    $local_fs $remote_fs $network $syslog</span><br><span class="line"><span class="meta">#</span> Required-Stop:     $local_fs $remote_fs $network $syslog</span><br><span class="line"><span class="meta">#</span> Default-Start:     2 3 4 5</span><br><span class="line"><span class="meta">#</span> Default-Stop:      0 1 6</span><br><span class="line"><span class="meta">#</span> Short-Description: shadowsocks service</span><br><span class="line"><span class="meta">#</span> Description:       shadowsocks service daemon</span><br><span class="line"><span class="meta">#</span>## END INIT INFO</span><br><span class="line">start()&#123;</span><br><span class="line">　　  sslocal -c /etc/shadowsocks.json -d start</span><br><span class="line">&#125;</span><br><span class="line">stop()&#123;</span><br><span class="line">　　  sslocal -c /etc/shadowsocks.json -d stop</span><br><span class="line">&#125;</span><br><span class="line">case “$1” in</span><br><span class="line">start)</span><br><span class="line">　　　start</span><br><span class="line">　　　;;</span><br><span class="line">stop)</span><br><span class="line">　　　stop</span><br><span class="line">　　　;;</span><br><span class="line">reload)</span><br><span class="line">　　　stop</span><br><span class="line">　　　start</span><br><span class="line">　　　;;</span><br><span class="line">\*)</span><br><span class="line">　　　echo “Usage: $0 &#123;start|reload|stop&#125;”</span><br><span class="line">　　　exit 1</span><br><span class="line">　　　;;</span><br><span class="line">esac</span><br></pre></td></tr></table></figure>
<p>然后执行以下命令即可：<br>
~$:sudo chomod a+x /etc/init.d/shadowsocks<br>
~$:sudo update_rc.d shadowsocks defaults<br>
上述命令执行完成以后，进行测试<br>
~$:sudo service shadosowcks start</p>
<h4 id="配置代理">配置代理</h4>
<p>上一步的目的是建立了shadowsocks服务的本地客户端，socks5流量会走该通道，但是浏览器的网页的流量是https的，我们需要配置相应的代理，将https流量转换为socks5流量，走ss客户端到达ss服务端。当然，也可以把其他各种流量，如tcp,udp等各种流量都转换为socks5流量，这个可以通过全局代理实现，也可以通过添加特定的代理规则实现。</p>
<h5 id="配置全局代理">配置全局代理</h5>
<p>如下图所示，添加ubuntu socks5系统代理：</p>
<p>然后就可以成功上网了。</p>
<h5 id="使用switchyomega配置chrome代理">使用SwitchyOmega配置chrome代理</h5>
<p>首先到 <a href="https://github.com/FelisCatus/SwitchyOmega/releases" target="_blank" rel="noopener">https://github.com/FelisCatus/SwitchyOmega/releases</a> 下载SyitchyOmega.crx。然后在chrome的地址栏输入chrome://extensions，将刚才下载的插件拖进去。<br>
然后在浏览器右上角就有了这个插件，接下来配置插件。如下图：<br>
<img src="https:" alt="mxx"><br>
直接配置proxy，添加如图所示的规则，这样chrome打开的所有网站都是走代理的。</p>
<h4 id="使用privoxy让terminal走socks5">使用privoxy让terminal走socks5</h4>
<p>~$:sudo apt install privoxy<br>
~$:sudo vim /etc/privoxy/config<br>
取消下列行的注释，或者添加相应条目<br>
forward-socks5 / 127.0.0.1:1080 . # SOCKS5代理地址<br>
listen-address 127.0.0.1:8118     # HTTP代理地址<br>
forward 10.*.*.*/ .               # 内网地址不走代理<br>
forward .abc.com/ .             # 指定域名不走代理<br>
重启privoxy服务<br>
~$:sudo service privoxy restart<br>
在bashrc中添加如下环境变量<br>
export http_proxy=&quot;<a href="http://127.0.0.1:8118" target="_blank" rel="noopener">http://127.0.0.1:8118</a>&quot;<br>
export https_proxy=“<a href="http://127.0.0.1:8118" target="_blank" rel="noopener">http://127.0.0.1:8118</a>”</p>
<p>~$:source ~/.bashrc<br>
~$:curl.gs</p>
<h2 id="参考文献">参考文献</h2>
<ol>
<li><a href="http://godjose.com/2017/06/14/new-article/" target="_blank" rel="noopener">http://godjose.com/2017/06/14/new-article/</a></li>
<li><a href="https://www.polarxiong.com/archives/%E6%90%AD%E5%BB%BAipv6-VPN-%E8%AE%A9ipv4%E4%B8%8Aipv6-%E4%B8%8B%E8%BD%BD%E9%80%9F%E5%BA%A6%E6%8F%90%E5%8D%87%E5%88%B0100M.html" target="_blank" rel="noopener">https://www.polarxiong.com/archives/搭建ipv6-VPN-让ipv4上ipv6-下载速度提升到100M.html</a></li>
<li><a href="https://blog.csdn.net/li1914309758/article/details/86510127" target="_blank" rel="noopener">https://blog.csdn.net/li1914309758/article/details/86510127</a></li>
<li><a href="https://blog.csdn.net/blackfrog_unique/article/details/60320737" target="_blank" rel="noopener">https://blog.csdn.net/blackfrog_unique/article/details/60320737</a></li>
<li><a href="https://blog.csdn.net/qq_31851531/article/details/78410146" target="_blank" rel="noopener">https://blog.csdn.net/qq_31851531/article/details/78410146</a></li>
</ol>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mxxhcm.github.io/2019/01/03/linear-algebra-singular-value-decomposition/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="马晓鑫爱马荟荟">
      <meta itemprop="description" content="记录硕士三年自己的积累">
      <meta itemprop="image" content="/images/favicon.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="mxxhcm's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/01/03/linear-algebra-singular-value-decomposition/" class="post-title-link" itemprop="http://mxxhcm.github.io/page/13/index.html">singular value decomposition（奇异值分解）</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-01-03 15:19:54" itemprop="dateCreated datePublished" datetime="2019-01-03T15:19:54+08:00">2019-01-03</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-09-09 16:53:25" itemprop="dateModified" datetime="2019-09-09T16:53:25+08:00">2019-09-09</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/线性代数/" itemprop="url" rel="index"><span itemprop="name">线性代数</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="特征值分解-eigen-value-decomposition">特征值分解(eigen value decomposition)</h2>
<p>要谈奇异值分解，首先要从特征值分解(eigen value decomposition, EVD)谈起。<br>
矩阵的作用有三个：一个是旋转，一个是拉伸，一个是平移，都是线性操作。如果一个$n\times n$方阵$A$对某个向量$x$只产生拉伸变换，而不产生旋转和平移变换，那么这个向量就称为方阵$A$的特征向量(eigenvector)，对应的伸缩比例叫做特征值(eigenvalue)，即满足等式$Ax = \lambda x$。其中$A$是方阵，$x$是方阵$A$的一个特征向量，$\lambda$是方阵$A$对应特征向量$x$的特征值。<br>
假设$S$是由方阵$A$的$n$个线性无关的特征向量构成的方阵，$\Lambda$是方阵$A$的$n$个特征值构成的对角矩阵，则$A=S\Lambda S^{-1}$，这个过程叫做对角化过程。<br>
证明：<br>
因为$Ax_1 = \lambda_1 x_1,\cdots,Ax_n = \lambda_n x_n$,<br>
所以<br>
\begin{align*}AS &amp;= A\begin{bmatrix}x_1&amp; \cdots&amp;x_n\end{bmatrix}\\<br>
&amp;=\begin{bmatrix} \lambda_1x_1&amp;\cdots&amp;\lambda x_n\end{bmatrix}\\<br>
&amp;= \begin{bmatrix}x_1&amp; \cdots&amp;x_n\end{bmatrix} \begin{bmatrix}\lambda_1&amp; &amp; &amp;\\&amp;\lambda_2&amp;&amp;\\&amp;&amp;\cdots&amp;\\&amp;&amp;&amp;\lambda_n\end{bmatrix}\<br>
&amp;= S\Lambda<br>
\end{align*}<br>
所以$AS=S\Lambda, A=S\Lambda S^{-1}, S^{-1}AS=\Lambda$。<br>
若方阵$A$为对称矩阵，矩阵$A$的特征向量是正交的，将其单位化为$Q$，则$A=Q\Lambda Q^T$，这个过程就叫做特征值分解。</p>
<h2 id="奇异值分解-singular-value-decomposition">奇异值分解(singular value decomposition)</h2>
<p>特征值分解是一个非常好的分解，因为它能把一个方阵分解称两类非常好的矩阵，一个是正交阵，一个是对角阵，这些矩阵都便于进行各种计算，但是它对于原始矩阵的要求太严格了，必须要求矩阵是对称正定矩阵，这是一个很苛刻的条件。所以就产生了奇异值分解，奇异值分解可以看作特征值分解在$m\times n$维矩阵上的推广。对于对称正定矩阵来说，有特征值，对于其他一般矩阵，有奇异值。</p>
<p>奇异值分解可以看作将一组正交基映射到另一组正交基的变换。普通矩阵$A$不是对称正定矩阵，但是$AA^T $和$A^TA $一定是对称矩阵，且至少是半正定的。从对$A^TA $进行特征值分解开始，$A^T A=V\Sigma_1V^T $，$V$是一组正交的单位化特征向量${v_1,\cdots,v_n}$，则$Av_1,\cdots,Av_n$也是正交的。<br>
证明：<br>
\begin{align*}Av_1\cdot Av_2 &amp;=(Av_1)^T Av_2\\<br>
&amp;=v_1^T A^T Av_2\\<br>
&amp;=v_1^T \lambda v_2\\<br>
&amp;=\lambda v_1^T v_2\\<br>
&amp;=0<br>
\end{align*}<br>
所以$Av_1,Av_2$是正交的，同理可得$Av_1,\cdots,Av_n$都是正交的。<br>
而：<br>
\begin{align*}<br>
Av_i\cdot Av_i &amp;= v_i^T A^T Av_i\\<br>
&amp;=v_i \lambda v_i\\<br>
&amp;=\lambda v_i^2\\<br>
&amp;=\lambda<br>
\end{align*}<br>
将$Av_i$单位化为$u_i$，得$u_i = \frac{Av_i}{|Av_i|} = \frac{Av_i}{\sqrt{\lambda_i}}$，所以$Av_i = \sqrt{\lambda_i}u_i$。<br>
将向量组${v_1,\cdots,v_r}$扩充到$R^n $中的标准正交基${v_1,\cdots,v_n}$，将向量组${u_1,\cdots,u_r}$扩充到$R^n $中的标准正交基${u_1,\cdots,u_n}$，则$AV = U\Sigma$，$A=U\sigma V^T $。</p>
<p>事实上，奇异值分解可以看作将行空间的一组正交基加上零空间的一组基映射到列空间的一组正交基加上左零空间的一组基的变换。对一矩阵$A,A\in \mathbb{R}^{m\times n} $，若$r(A)=r$，取行空间的一组特殊正交基${v_1,\cdots,v_r}$，当矩阵$A$作用到这组基上，会得到另一组正交基${u_1,\cdots,u_r}$，即$Av_i = \sigma_iu_i$。<br>
矩阵表示是：<br>
\begin{align*}<br>
AV &amp;= A\begin{bmatrix}v_1&amp;\cdots&amp;v_r\end{bmatrix}\\<br>
&amp;= \begin{bmatrix}\sigma_1u_1 &amp; \cdots &amp; \sigma_ru_r\end{bmatrix}\\<br>
&amp;= \begin{bmatrix}u_1&amp;u_2&amp;\cdots&amp;u_r\end{bmatrix}\begin{bmatrix}\sigma_1&amp;&amp;&amp;\\&amp;\sigma_2&amp;&amp;\\&amp;&amp;\cdots&amp;\\&amp;&amp;&amp;\sigma_n\end{bmatrix}\\<br>
&amp;=U\Sigma<br>
\end{align*}<br>
其中$A\in \mathbb{R}^{m\times n}, V\in \mathbb{R}^{n\times r},U\in \mathbb{R}^{m\times r}, \Sigma \in \mathbb{R}^{r\times n}$。<br>
当有零空间的时候，行空间的一组基是$r$维，加上零空间的$n-r$维，构成$R^n $空间中的一组标准正交基。列空间的一组基也是$r$维的，加上左零空间的$m-r$维，构成$R^m $空间的一组标准正交基。零空间中的向量在对角矩阵$\Sigma$中体现为$0$，<br>
则$A=U\Sigma V^{-1} $，$V$是正交的，所以$A=U\Sigma V^T $，其中$V\in \mathbb{R}^{n\times n}, U\in \mathbb{R}^{m\times m}, \Sigma \in \mathbb{R}^{m\times n}$。</p>
<p>$A=U\Sigma V^T $,<br>
$A^T = V\Sigma^T U^T $,<br>
$AA^T = U\Sigma V^T V\Sigma^T U^T $,<br>
$A^T A = V\Sigma^T U^T U\Sigma V^T $<br>
对$A A^T $和$A^T A$作特征值分解，则$A A^T = U\Sigma_1U^T $,$A^T A=V\Sigma_2V^T $，所以对$AA^T $作特征值分解求出来的$U$和对$A^T A$作特征值分解求出来的$V$就是对$A$作奇异值分解求出来的$U$和$V$，$AA^T $和$A^T A$作特征值分解求出来的$\Sigma$的非零值是相等的，都是对$A$作奇异值分解的$\Sigma$的平方。</p>
<h3 id="a-t-a-和-aa-t-的非零特征值是相等的">$A^T A$和$AA^T $的非零特征值是相等的</h3>
<p>证明：对于任意的$m\times n$矩阵$A$，$A^T A$和$AA^T $的非零特征值相同的。 设$A^T A$的特征值为$\lambda_i$，对应的特征向量为$v_i$，即$A^T Av_i = \lambda_i v_i$。<br>
则$AA^T Av_i = A\lambda_iv_i = \lambda_i Av_i$。<br>
所以$AA^T $的特征值为$\lambda_i$，对应的特征向量为$Av_i$。<br>
因此$A^T A$和$AA^T $的非零特征值相等。</p>
<h3 id="几何意义">几何意义</h3>
<p>对于任意一个矩阵，找到其行空间(加上零空间)的一组正交向量，使得该矩阵作用在该向量序列上得到的新的向量序列保持两两正交。奇异值的几何意义就是这组变化后的新的向量序列的长度。</p>
<h3 id="物理意义">物理意义</h3>
<p>奇异值往往对应着矩阵隐含的重要信息，且重要性和奇异值大小正相关。每个矩阵都可以表示为一系列秩为$1$的“小矩阵”的和，而奇异值则衡量了这些秩一矩阵对$A$的权重。<br>
奇异值分解的物理意义可以通过图像压缩表现出来。给定一张$m\times n$像素的照片$A$，用奇异值分解将矩阵分解为若干个秩一矩阵之和，即：<br>
\begin{align*}<br>
A&amp;=\sigma_1 u_1v_1^T +\sigma_2 u_2v_2^T +\cdots+\sigma_r u_rv_r^T\\<br>
&amp;= \begin{bmatrix}u_1&amp;u_2&amp;\cdots&amp;u_r\end{bmatrix}\begin{bmatrix}\sigma_1&amp;&amp;&amp;\&amp;\sigma_2&amp;&amp;\&amp;&amp;\cdots&amp;\&amp;&amp;&amp;\sigma_n\end{bmatrix}\begin{bmatrix}v_1<sup>T\v_2</sup>T\ \vdots\v_r^T\end{bmatrix}\\<br>
&amp;=U\Sigma V^T<br>
\end{align*}</p>
<p>这个也叫部分奇异值分解。其中$V\in R^{r\times n}, U\in R^{m\times r}, \Sigma \in R^{r\times r}$。因为不含有零空间和左零空间的基，如果加上零空间的$n-r$维和左零空间的$m-r$维，就是奇异值分解。<br>
较大的奇异值保存了图片的主要信息，特别小的奇异值有时可能是噪声，或者对于图片的整体信息不是特别重要。做图像压缩的时候，可以只取一部分较大的奇异值，比如取前八个奇异值作为压缩后的图片：<br>
$$A = \sigma_1 u_1v_1^T +\sigma_2 u_2v_2^T + \cdots + \sigma_8 u_8v_8^T$$<br>
现实中常用的做法有两个：</p>
<ol>
<li>保留矩阵中$90%$的信息：将奇异值平方和累加到总值的%90%为止。</li>
<li>当矩阵有上万个奇异值的时候，取前面的$2000$或者$3000$个奇异值。。</li>
</ol>
<h2 id="参考文献-references">参考文献(references)</h2>
<p>1.Gilbert Strang, MIT Open course：Linear Algebra<br>
2.<a href="https://www.cnblogs.com/pinard/p/6251584.html" target="_blank" rel="noopener">https://www.cnblogs.com/pinard/p/6251584.html</a><br>
3.<a href="http://www.ams.org/publicoutreach/feature-column/fcarc-svd" target="_blank" rel="noopener">http://www.ams.org/publicoutreach/feature-column/fcarc-svd</a><br>
4.<a href="https://www.zhihu.com/question/22237507/answer/53804902" target="_blank" rel="noopener">https://www.zhihu.com/question/22237507/answer/53804902</a><br>
5.<a href="http://charleshm.github.io/2016/03/Singularly-Valuable-Decomposition/" target="_blank" rel="noopener">http://charleshm.github.io/2016/03/Singularly-Valuable-Decomposition/</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mxxhcm.github.io/2018/12/24/convex-optimization-chapter-2-Convex-sets/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="马晓鑫爱马荟荟">
      <meta itemprop="description" content="记录硕士三年自己的积累">
      <meta itemprop="image" content="/images/favicon.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="mxxhcm's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2018/12/24/convex-optimization-chapter-2-Convex-sets/" class="post-title-link" itemprop="http://mxxhcm.github.io/page/13/index.html">convex optimization chapter 2 Convex sets</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2018-12-24 16:28:45" itemprop="dateCreated datePublished" datetime="2018-12-24T16:28:45+08:00">2018-12-24</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-09-09 16:25:28" itemprop="dateModified" datetime="2019-09-09T16:25:28+08:00">2019-09-09</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/凸优化/" itemprop="url" rel="index"><span itemprop="name">凸优化</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="仿射集-affine-sets-和凸集-convex-sets">仿射集(affine sets)和凸集(convex sets)</h2>
<h3 id="直线-line-和线段-line-segmens">直线(line)和线段(line segmens)</h3>
<p>假设$x_1,x_2 \in \mathbb{R}^n $是n维空间中不重合$(x_1 \ne x_2)$的两点，给定：<br>
$$y = \theta x_1 + (1 - \theta)x_2,$$<br>
当$\theta\in R$时，$y$是经过点$x_1$和点$x_2$的直线。当$\theta=1$时，$y=x_1$,当$\theta=0$时，$y=x_2$。当$\theta\in[0,1]$时，$y$是$x_1$和$x_2$之间的线段(line segment)。 把$y$改写成如下形式： $$y = x_2 + \theta(x_1 - x_2)$$，可以给出另一种解释，$y$是点$x_2$和方向$x_1 - x_2$(从$x_2$到$x_1$的方向)乘上一个缩放因子$\theta$的和。<br>
如下图所示，可以将y看成$\theta$的函数。<br>
<img src="https://ws1.sinaimg.cn/large/006wtfMEly1fyhy7m4llij30mz0alwep.jpg" alt="line_line-segment"></p>
<h3 id="仿射集-affine-sets">仿射集(affine sets)</h3>
<h4 id="仿射集的定义">仿射集的定义</h4>
<p>给定一个集合$C\subset \mathbb{R}^n $,如果经过$C$中任意两个不同点的直线仍然在$C$中，那么$C$就是一个仿射集。即，对于任意$x_1,x_2\in C$和$\theta\in R$，都有$\theta x_1 + (1 - \theta)x_2 \in C$。换句话说，给定线性组合的系数和为$1$，$C$中任意两点的线性组合仍然在$C$中，我们就称这样的集合是仿射的(affine)。</p>
<h4 id="仿射组合-affine-combination">仿射组合(affine combination)</h4>
<p>我们可以把两个点的线性组合推广到多个点的线性组合，这里称它为仿射组合。<br>
仿射组合的定义：给定$\theta_1+\cdots+\theta_k = 1$,则$\theta_1 x_1 + \cdots + \theta_k x_k$是点$x_1,\cdots,x_k$的仿射组合(affine combination)。<br>
根据仿射集的定义，一个仿射集(affine set)包含集合中任意两个点的仿射（线性）组合，那么可以推导出仿射集包含集合中任意点（大于等于两个）的仿射组合，即：如果$C$是一个仿射集，$x_1,\cdots,x_k\in C$,且$\theta_1 x_1 + \cdots + \theta_k x_k = 1$,那么点$\theta_1 x_1 + \cdots + \theta_k x_k$仍然属于$C$。</p>
<h4 id="仿射集的子空间-subspce">仿射集的子空间(subspce)</h4>
<p>如果$C$是一个仿射集，$x_0 \in C$,那么集合<br>
$$V = C - x_0 = {x - x_0\big|x \in C}$$<br>
是一个子空间(subspace),因为$V$是加法封闭和数乘封闭的。<br>
证明：<br>
假设$v_1, v_2 \in V$，并且$\alpha,\beta \in R$。<br>
要证明V是一个子空间，那么只需要证明$\alpha v_1 + \beta v_2 \in V$即可。<br>
因为$v_1, v_2 \in V$，则$v_1+x_0, v_2+x_0 \in C$。<br>
而$x_0 \in C$，所以有<br>
$$\alpha(v_1+x_0) + \beta(v_2+x_0) + (1 - \alpha - \beta)x_0 \in C$$<br>
即：<br>
\begin{align*}<br>
\alpha v_1 + \beta v_2 + (\alpha + \beta + 1 - \alpha - \beta)x_0 &amp;\in C\\<br>
\alpha v_1 + \beta v_2 + x_0 &amp;\in C<br>
\end{align*}<br>
所以$\alpha v_1 + \beta v_2 \in V$。<br>
所以，仿射集$C$可以写成：<br>
$$C = V + x_0 = { v + x_0\big| v \in V},$$<br>
即，一个子空间加上一个偏移(offset)。而与仿射集$C$相关的子空间$V$与$x_0$的选择无关，即$x_0$可以为$C$中任意一点。</p>
<h4 id="示例">示例</h4>
<p>线性方程组的解。一个线性方程组的解可以表示为一个仿射集:$C={x\big|Ax = b}$,其中 $A\in \mathbb{R}^{m \times n}, b \in \mathbb{R}^m $。<br>
证明：<br>
设$x_1, x_2 \in C$,即$Ax_1 = b, Ax_2 = b$。对于任意$\theta \in R$,有:<br>
\begin{align*}<br>
A(\theta x_1 + (1-\theta x_2) &amp;= \theta Ax_1 + (1-\theta)Ax_2\\<br>
&amp;= \theta b + (1 - \theta) b\\<br>
&amp;= b \end{align*}<br>
所以线性方程组的解是一个仿射组合：$\theta x_1 + (1 - \theta) x_2$，这个仿射组合在集合$C$中，所以线性方程组的解集$C$是一个仿射集。<br>
和该仿射集$C$相关的子空间$V$是$A$的零空间(nullspace)。因为仿射集$C$中的任意点都是方程$Ax = b$的解，而$V = C - x_0 = {x - x_0\big|x \in C}$，有$Ax = b, Ax_0 = b$，则$Ax - Ax_0 = A(x - x_0) = b - b = 0$，所以$V$是$A$的零空间。</p>
<h4 id="仿射包-affine-hull">仿射包(affine hull)</h4>
<p>给定集合$C\subset \mathbb{R}^n $，集合中点的仿射组合称为集合$C$的仿射包(affine hull),表示为$aff C$:<br>
$aff C = {\theta_1 x_1 + \cdots + \theta_k x_k\big| x_1,\cdots,x_k \in C, \theta_1 + \cdots + \theta_k = 1}$<br>
集合$C$可以是任意集合。仿射包是包含集合$C$的最小仿射集（一个集合的仿射包只有一个，是不变的）。即如果$S$是任意仿射集，满足$C\subset S$，那么有$aff C \subset S$。或者说仿射包是所有包含集合$C$的仿射集的交集。</p>
<h3 id="仿射纬度-affine-dimension-和相对内部-relative-interior">仿射纬度(affine dimension)和相对内部(relative interior)</h3>
<h4 id="拓扑-topology">拓扑(topology)</h4>
<p>拓扑(topology)，开集(open sets),闭集(close sets),内部(interior),边界(boundary),闭包(closure),邻域(neighbood),相对内部(relative interior)<br>
同一个集合可以有很多个不同的拓扑。</p>
<h5 id="定义">定义</h5>
<p>给定一个集合$X$,$\tau$是$X$的一系列子集，如果$\tau$满足以下条件：</p>
<ol>
<li>空集(empty set)和全集X都是$\tau$的元素;</li>
<li>$\tau$中任意元素的并集(union)仍然是$\tau$的元素;</li>
<li>$\tau$中任意有限多个元素的交集(intersection)仍然是$\tau$中的元素。</li>
</ol>
<p>则称$\tau$是集合$X$上的一个拓扑。<br>
如果$\tau$是$X$上的一个拓扑，那么$(X,\tau)$对称为一个拓扑空间(topological space)。<br>
如果$X$的一个子集在$\tau$中，这个子集被称为开集(open set)。<br>
如果$X$的一个子集的补集是在$\tau$中，那么这个子集是闭集(closed set)。<br>
$X$的子集可能是开集，闭集，或者都是，都不是。<br>
空集和全集是开集，也是闭集（定义）。</p>
<h5 id="示例-v2">示例</h5>
<ol>
<li>给定集合$X={1,2,3,4}$, 集合$\tau = { {},{1,2,3,4} }$就是$X$上的一个拓扑。</li>
<li>给定集合$X={1,2,3,4}$, 集合$\tau = { {},{1}, {3,4},{1,3,4},{1,2,3,4} }$就是$X$上的另一个拓扑。</li>
<li>给定集合$X={1,2,3,4}$, $X$的幂集(power set)也是$X$上的另一个拓扑。</li>
</ol>
<p><strong>通常如果不说的话，默认是在欧式空间(1维，2维,…,n维欧式空间)的拓扑，即欧式拓扑。以下讲的一些概念是在欧式空间的拓扑（通常拓扑）上的定义和一般拓扑直观上可能不太一样，但实际上意义是相同的。</strong></p>
<h4 id="epsilon-disc-或-epsilon-邻域">$\epsilon-disc$或$\epsilon$邻域</h4>
<h5 id="定义-v2">定义</h5>
<p>给定$x\in \mathbb{R}^n $以及$\epsilon\gt 0$，集合<br>
$$D(x,\epsilon) = {y\in \mathbb{R}^n \big|d(x,y) \lt \epsilon}$$<br>
称为关于$x$的$\epsilon-disc$或者$\epsilon$邻域(neighbood)或者$\epsilon$球(ball)。即所有离点$x$距离小于$\epsilon$的点$y$的集合。</p>
<h4 id="开集-open-sets">开集(open sets)</h4>
<h5 id="定义-v3">定义</h5>
<p><strong>给定集合$A\subset \mathbb{R}^n $，对于$A$中的所有元素，即$\forall x\in A$，都存在$\epsilon \gt 0$使得$D(x,\epsilon)\subset A$，那么就称该集合是开的。</strong><br>
即集合$A$中所有元素的$spsilon$邻域都还在集合$A$中（定理$1$）。<br>
<strong>注意：必须满足$\epsilon \gt 0$</strong></p>
<h5 id="定理">定理</h5>
<h6 id="定理-1-epsilon-邻域是开集">定理$1$ $epsilon$邻域是开集</h6>
<ul>
<li>在$\mathbb{R}^n $中，对于一个$\epsilon \gt 0, x\in \mathbb{R}^n $,那么集合$x$的$\epsilon$邻域$D(x,\epsilon)$是开的，给定一个$\epsilon$，能找到一个更小的$epsilon$邻域。</li>
</ul>
<h6 id="定理-2">定理$2$</h6>
<ul>
<li>$\mathbb{R}^n $中有限个开子集的交集是$\mathbb{R}^n $的开子集。</li>
<li>$\mathbb{R}^n $中任意个开子集的并集是$\mathbb{R}^n $的开子集。</li>
</ul>
<p><strong>注意：任意开集的交可能不是开集，一个点不是开集，但是它是所有包含它的开集的交。</strong></p>
<h5 id="示例-v3">示例</h5>
<p><img src="/2018/12/24/convex-optimization-chapter-2-Convex-sets/unit_circle.png" alt="unit_circle"></p>
<ol>
<li>$\mathbb{R}^2 $中的不包含边界的球是开的，如图。</li>
<li>考虑一个$\mathbb{R}^1 $中的开区间，如$(0,1)$，它是一个开集，但是如果把它放在二维欧式空间中(是x轴上的一个线段)，它不是开的，不满足定义，所以开集是必须针对于某一个给定的集合$X$。</li>
<li>$\mathbb{R}^2 $上的包含边界的单位圆$X = {x\in \mathbb{R}^2 \big||x|\le 1}$不是开的。因为边界上的点$x$不满足$\epsilon \gt 0, D(x,\epsilon) \subset X$。</li>
<li>集合$S={(x,y) \in \mathbb{R}^2 \big|0 \lt x \lt 1}$是开集。对于每个点$(x,y)\in S$,我们可以画出半径$r = min{x,1-x}$的邻域并且其全部含于$S$，所以$S$是开集。</li>
<li>集合$S={(x,y) \in \mathbb{R}^2 \big|0 \lt x \le 1}$不是开集。因为点$(1,0) \in S$的邻域包含点$(x,0)$,其中$x\gt 1$。</li>
</ol>
<h4 id="内部-interior">内部(interior)</h4>
<h5 id="定义-v4">定义</h5>
<p><strong>给定集合$A\subset \mathbb{R}^n $,点$x \in A$，如果有一个开集$U$使得$x \in U\subset A$,那么该点就称为$A$的一个内点。或者说对于$x\in A$，有一个$\epsilon \gt 0$使得$D(x,\epsilon)\subset A$。$A$的所有内点组成的集合叫做$A$的内部(interior)，记做$int(A)$。</strong></p>
<h5 id="属性">属性</h5>
<ol>
<li>集合内部可能是空的，单点的内部就是空的。</li>
<li>单位圆的内部是不包含边界的单位圆。</li>
<li>事实上$A$的内部是$A$所有开子集的并，由开集的定理得$A$的内部是开的，且$A$的内部是$A$的最大的开集。</li>
<li>当且仅当$A$的内部等于$A$的时候，$A$是开集（$A$可能是闭集）。</li>
<li>只需要寻找集合内$\epsilon$邻域还在这个集合内的点即可。</li>
</ol>
<h5 id="示例-v4">示例</h5>
<ol>
<li>给定集合$S={(x,y)\in \mathbb{R}^2 \big| 0 \lt x \le 1}$，$int(S) = {(x,y)\big|0 \lt x \lt 1}$。因为区间$(0,1)$中的点都满足它们的$\epsilon$邻域在$S$中。</li>
<li>$int(A) \cup int(B) \ne int(A\cup B)$。在实数轴上，$A=[0,1],B=[1,2]$，那么$int(A) = (0,1),int(B) = (1,2)$，所以$int(A) \cup int(B) = (0,1)\cup (1,2) = (0,2)\backslash {1}$，而$int(A\cup B) = int[0,2] = (0,2)$。</li>
</ol>
<h4 id="闭集-closed-set">闭集(closed set)</h4>
<h5 id="定义-v5">定义</h5>
<p><strong>对于$\mathbb{R}^n $中的集合$B$，如果它在$\mathbb{R}^n $的补（即集合$\mathbb{R}^n \backslash B$）是开集，那么它是闭集。</strong><br>
单点是闭集。含有边界的单位圆组成的集合是闭集，因为它的补集不包含边界。一个集合可能既不是开集也不是闭集。例如，在一维欧几里得空间，半开半闭区间（如$(0,1]$）既不是开集也不是闭集。</p>
<h5 id="定理-v2">定理</h5>
<ol>
<li>$\mathbb{R}^n $中有限个闭子集的并是闭集。</li>
<li>$\mathbb{R}^n $中任意个闭子集的交是闭集。</li>
</ol>
<p>这个定理是从开集的定理中得出的，在对开集取补变成闭集时候，并与交相互变换即可。</p>
<h5 id="示例-v5">示例</h5>
<ol>
<li>给定集合$S={(x,y) \in \mathbb{R}^2 \big| 0 \lt x \le 1, 0 \lt y \lt 1}$，$S$不是闭集。因为目标区域的下边界不在S中。</li>
<li>给定集合$S={(x,y) \in \mathbb{R}^2 \big| x^2 +y^2 \le 1}$，$S$是闭集，因为它的闭集是$\mathbb{R}^2 $中的开集。</li>
<li>$\mathbb{R}^n $中任何有限集是闭集。因为单点是闭集，有限集可以看成很多个单点的并，由定理$1$可以得出。</li>
</ol>
<h4 id="聚点-accumulation-point">聚点(accumulation point)</h4>
<h5 id="定义-v6">定义</h5>
<p>对于点$x\in \mathbb{R}^n $，如果包含$x$的每个开集$U$包含不同于$x$但依然属于集合$A$中的点，那么就称$x$是$A$的一个聚点(accumulation points)，也叫聚类点(cluster points)。**注意这里是包含集合$A$中的点，而不是全部是集合$A$中的点，所以集合的聚点不一定必须在集合中。**如，在一维欧式空间中，单点集合没有聚点，开区间$(0,1)$的聚点是$[0,1]$，${0,1}$不在区间内，但是是聚点。<br>
此外，$x$是聚类点等价于：对于每个$\epsilon \gt 0$，$D(x,\epsilon)$包含$A$中的某点$y$且$y\ne x$。</p>
<h5 id="定理-v3">定理</h5>
<p>当且仅当集合$S$的所有聚点属于$S$时，$S\subset \mathbb{R}^n $是闭集。</p>
<h5 id="示例-v6">示例</h5>
<ol>
<li>给定集合$S={x\in R\big|x\in [0,1]且x是有理数}$，$S$的聚点为$[0,1]$中所有点。任何不属于$[0,1]$的点都不是聚点，因为这类点有一个包含它的$\epsilon$邻域与$[0,1]$不相交。</li>
<li>给定集合$S={(x,y)\in \mathbb{R}^2 \big| 0 \le  x\le 1\ or\ \ x = 2}$, 它的聚点是它本身，因为它是闭集。</li>
<li>给定集合$S={(x,y)\in \mathbb{R}^2 \big|y \lt x^2 + 1}$，S的聚点为集合${(x,y)\in \mathbb{R}^2 \big|y \le x^2 + 1}$，</li>
</ol>
<h4 id="闭包-closure">闭包(closure)</h4>
<h5 id="定义-v7">定义</h5>
<p>给定集合$A\subset \mathbb{R}^n $,集合$A$的闭包$cl(A)$定义成所有包含$A$的闭集的交，所以$cl(A)$是一个闭集。定价的定义是给定集合$A$，包含$A$的最小闭集叫做这个集合$X$的闭包(closure)，用$cl(A)$或者${\overline{A}}$表示。</p>
<h5 id="定理-v4">定理</h5>
<p>给定$A\subset \mathbb{R}^n $，那么$cl(A)$由$A$和$A$的所有聚点组成。</p>
<h5 id="示例-v7">示例</h5>
<ol>
<li>$R$中$S=[0,1)\cup {2}$的闭包是$[0,1]$和${2}$。$S$的聚点是$[0,1]$，再并上$S$得到$S$的闭包是$[0,1]\cup{2}$。</li>
<li>对于任意$S\subset \mathbb{R}^n $，$\mathbb{R}^n \backslash cl(S)$是开集。因为$cl(S)$是闭集，所以它的补集是开集。</li>
<li>$cl(A\cap B) \ne cl(A)\cap cl(B)$。比如$A=(0,1),B(1,2),cl(A)=[0,1],cl(B)=[1,2]$,$A\cap B = \varnothing$,$cl(A\cap B) = \varnothing$,而$cl(A)\cap cl(B) = {1}$。</li>
</ol>
<h4 id="边界-boundary">边界(boundary)</h4>
<h5 id="定义-v8">定义</h5>
<p>对于$\mathbb{R}^n $中的集合$A$，边界定义为集合：<br>
$bd(A) = cl(A)\cap cl(\mathbb{R}^n \backslash A)$<br>
即集合$A$的补集的闭包和$A$的闭包的交集，所以$bd(A)$是闭集。$bd(A)$是$A$与$\mathbb{R}^n \backslash A$之间的边界。</p>
<h5 id="定理-v5">定理</h5>
<p>给定$A\subset \mathbb{R}^n $，当且仅当对于每个$\epsilon \gt 0$，$D(x,\epsilon)$包含$A$与$\mathbb{R}^n \backslash A$的点，$x\in bd(A)$。</p>
<h5 id="示例-v8">示例</h5>
<ol>
<li>给定集合$S={x\in R\big|x\in [0,1],x是有理数}$，$bd(S) = [0,1]$。因为对于任意$\epsilon \gt 0, x\in [0,1],D(x,\epsilon) = (x-\epsilon, x+\epsilon)$包含有理数和无理数，即x是有理数和无理数之间的边界。</li>
<li>给定$x\in bd(S)$，$x$不一定是聚点。给定集合$S = {0} \subset R$，$bd(S) = {0}$，但是单点没有聚点。</li>
<li>给定集合$S={(x,y)\in \mathbb{R}^2 \big| x^2 -y^2 \gt 1 }$，$bd(S)={(x,y)\big|x^2 - y^2 = 1}$。</li>
</ol>
<h4 id="仿射维度-affine-dimension">仿射维度(affine dimension)</h4>
<h5 id="定义-v9">定义</h5>
<p>给定一个仿射集$C$，仿射维度是它的仿射包的维度。<br>
仿射维度和其他维度的定义不总是相同的，具体可以看以下的示例。</p>
<h5 id="示例-v9">示例</h5>
<p>给定一个二维欧几里得空间的单位圆，${x\in C\big|x_1^2 +x_2^2 =1}$。它的仿射包是整个$\mathbb{R}^2$，所以二维平面的单位圆仿射维度是$2$。但是在很多定义中，二维平面的单位圆的维度是$1$。</p>
<h4 id="相对内部-relative-interior">相对内部(relative interior)</h4>
<p>给定一个集合$C\subset \mathbb{R}^n $，它的仿射维度可能小于$n$，这个时候仿射集$aff\ C \ne \mathbb{R}^n $。</p>
<h5 id="定义-v10">定义</h5>
<p>给定集合$C$，相对内部的定义如下：<br>
$relint\ C = {x\in C\big|(B(x,r)\cup aff\ C) \subset C, \exists \ r \gt 0}.$<br>
就是集合$C$内所有$\epsilon$球在$C$的仿射集内的点的集合。<br>
其中$B(x,r)={y \big|\Vert y- x\Vert \le r}$，是以$x$为中心，以$r$为半径的圆。这里的范数可以是任何范数，它们定义的相对内部是相同的。</p>
<h5 id="示例-v10">示例</h5>
<p>给定一个$\mathbb{R}^3 $空间中$(x_1,x_2)$平面上的正方形，$C={x\in \mathbb{R}^3 \big|-1 \le x_1 \le 1, -1\le x_2 \le 1, x_3 = 0}$。它的仿射包是$(x_1,x_2)$平面，$aff\ C = {x\in \mathbb{R}^3 \big|x_3=0}$。$C$的内部是空的，但是相对内部是：<br>
$relint\ C = {x \in \mathbb{R}^3 \big|-1 \le x_1 \le 1, -1\le x_2 \le 1,x_3=0}$。</p>
<h4 id="相对边界-relative-boundary">相对边界(relative boundary)</h4>
<h5 id="定义-v11">定义</h5>
<p>给定集合$C$，相对边界(relative boundary)定义为$cl\ C \backslash relint\ C$，其中$cl\ C$是集合$C$的闭包(closure)。</p>
<h5 id="示例-v11">示例</h5>
<p>对于上例（相对内部的示例）来说，它的边界(boundary)是它本身。它的相对内部是边框，${x\in \mathbb{R}^3 \big|max{|x_1|,|x_2|}=1,x_3=0}$。</p>
<h3 id="凸集-convex-sets">凸集(convex sets)</h3>
<h4 id="凸集定义">凸集定义</h4>
<p>给定一个集合$C$，如果集合$C$中经过任意两点的线段仍然在$C$中，这个集合就是一个凸集。<br>
给定$\forall x_1,x_2 \in C, 0 \le \theta \le 1$，那么我们有$\theta x_1 + (1-\theta)x_2 \in C$。<br>
每一个仿射集都是凸的，因为它包含经过任意两个不同点的直线，所以肯定就包含过那两个点的线段。</p>
<h4 id="凸组合-convex-combination">凸组合(convex combination)</h4>
<p>给定$k$个点$x_1,x_2,\cdots,x_k$，如果具有$\theta_1 x_1 + \cdots, \theta_k x_k$形式且满足$\theta_1 + \cdots + \theta_k=1, \theta_i \ge 0,i=1,\cdots,k$,那么就称这是$x_1,\cdots,x_k$的一个凸组合。<br>
当且仅当一个集合包含其中所有点的凸组合，这个集合是一个凸集。点的一个凸组合可以看成点的混合或者加权，$\theta_i$是第$i$个点$x_i$的权重。<br>
凸组合可以推广到无限维求和，积分，概率分布等等。假设$\theta_1,\theta_2,\cdots$满足：<br>
$$\theta_i \le 0, i = 1,2,\cdots, \sum_{i=1}^{\infty}\theta_i = 1$$<br>
并且$x_1,x_2,\cdots \in C$，$C\subset \mathbb{R}^n $是凸的，如果(series)$\sum_{i=1}^{\infty} \theta_i x_i$收敛，那么$\sum_{i=1}^{\infty} \theta_i x_i \in C$。<br>
更一般的，假设概率分布$p$，$\mathbb{R}^n \rightarrow R$满足$p(x)\le 0 for\ all\ x\in C, \int_{C}p(x)dx = 1$,其中$C\subset \mathbb{R}^n $是凸的，如果$\int_{C}p(x)xdx$存在的话，那么$\int_{C}p(x)xdx\in C$。</p>
<h4 id="凸包-convex-hull">凸包(convex hull)</h4>
<p>给定一个集合$C$，凸包的定义为包含集合$C$中所有点的凸组合的结合，记为$conv\ C$，公式如下：<br>
$conv\ C = {\theta_1 x_1 + \cdots + \theta_k x_k\big|x_i \in C, \theta_i \ge 0, i = 1,\cdots,k,\theta_1 +\cdots + \theta_k = 1}$<br>
任意集合都是有凸包的。一个集合的凸包总是凸的。集合$C$的凸包是包含集合$C$的最小凸集。如果集合$B$是任意包含$C$的凸集，那么$conv\ C \subset B$。</p>
<h4 id="示例-v12">示例</h4>
<p><img src="/2018/12/24/convex-optimization-chapter-2-Convex-sets/figure2_2.png" alt="figure 2.2"><br>
<img src="/2018/12/24/convex-optimization-chapter-2-Convex-sets/figure2_3.png" alt="figure 2.3"></p>
<h3 id="锥-cones">锥(cones)</h3>
<h4 id="锥-cones-和凸锥-convex-cones-的定义">锥(cones)和凸锥(convex cones)的定义</h4>
<p>给定集合$C$，如果$\forall x \in C, \theta \ge 0$，都有$\theta x\in C$，这样的集合就称为一个锥(cone)，或者非负同质(nonnegative homogeneour)。<br>
一个集合$C$如果既是锥又是凸的，那这个集合是一个凸锥(convex cone)，即：$\forall x_1,x_2 \in C, \theta_1,\theta_2 \ge 0$,那么有$\theta_1 x_1+\theta_2 x_2 \in C$。几何上可以看成经过顶点为原点，两条边分别经过点$x_1$和$x_2$的$2$维扇形。</p>
<h4 id="锥组合-conic-combination">锥组合(conic combination)</h4>
<p>给定$k$个点$x_1,x_2,\cdots,x_k$，如果具有$\theta_1 x_1 + \cdots, \theta_k x_k$形式且满足$\theta_i \ge 0,i=1,\cdots,k$,那么就称这是$x_1,\cdots,x_k$的一个锥组合(conic combination)或者非负线性组合(nonnegative combination)。<br>
给定集合$C$是凸锥，那么集合$C$中任意点$x_i$的锥组合仍然在集合$C$中。反过来，当且仅当集合$C$包含它的任意元素的凸组合时，这个集合是一个凸锥(convex cone)。</p>
<h4 id="锥包-conic-hull">锥包(conic hull)</h4>
<p>给定集合$C$，它的锥包(conic hull)是集合$C$中所有点的锥组合。即：<br>
$conic\ C = {\theta_1 x_1 + \cdots + \theta_k x_k\big|x_i \in C, \theta_i \ge 0, i = 1,\cdots,k}$<br>
集合$C$的锥包是包含集合$C$的最小凸锥。</p>
<h4 id="示例-v13">示例</h4>
<p><img src="/2018/12/24/convex-optimization-chapter-2-Convex-sets/figure2_4.png" alt="figure 2.4"><br>
<img src="/2018/12/24/convex-optimization-chapter-2-Convex-sets/figure2_5.png" alt="figure 2.5"></p>
<h3 id="一些想法">一些想法</h3>
<p>在我自己看来，在几何上<br>
仿射集可以看成是集合中任意两个点的直线的集合。<br>
凸集可以看成是集合中任意两个点的线段的集合，因为直线一定包含线段，所以仿射集一定是凸集。<br>
锥集可以看成是集合中任意一个点和原点构成的射线的集合，锥集不一定是连续的（两条射线也是锥集），所以锥集不一定是凸集。<br>
而凸锥既是凸集又是锥集。<br>
我在stackexchange看到这样一句话觉得说的挺好的。</p>
<blockquote>
<p>What basically distinguishes the definitions of convex, affine and cone, is the domain of the coefficients and the constraints that relate them.</p>
</blockquote>
<p>区别凸集，仿射和锥的是系数的取值范围和一些其他限制。仿射集要求$\theta_1+\cdots+\theta_k = 1$，凸集要求$\theta_1 +\cdots +\theta_k = 1, 0\le \theta \le 1$，锥的要求是$\theta \ge 0$，凸锥的要求是$\theta_i \ge 0,i=1,\cdots,k$。<br>
仿射集不是凸集的子集，凸集也不是仿射集的子集。所有仿射集的集合是所有凸集的集合的子集，一个仿射集是一个凸集。</p>
<h2 id="示例-v14">示例</h2>
<ul>
<li>$\emptyset$，单点(single point)${x_0}$，整个$\mathbb{R}^n $空间都是$\mathbb{R}^n $中的仿射子集，所以也是凸集，点不一定是凸锥（在原点熵是凸锥），空集是凸锥，$\mathbb{R}^n $维空间也是凸锥。<strong>根据定义证明。</strong></li>
<li>任意一条直线都是仿射的，所以是凸集。如果经过原点，它是一个子空间，也就是一个凸锥，否则不是。</li>
<li>任意一条线段都是凸集，不是仿射集，当它退化成一点的时候，它是仿射的，线段不是凸锥。</li>
<li>一条射线${x_0 + \theta v\big| \theta \ge 0}$是凸的，但是不是仿射的，当$x_0=0$时，它是凸锥。</li>
<li>任意子空间都是仿射的，也是凸锥，所以是凸的。</li>
</ul>
<p>补充最后一条，任意子空间都是仿射的，也是凸锥。<br>
如果$V$是一个子空间，那么$V$中任意两个向量的线性组合还在$V$中。即如果$x_1,x_2\in V$，对于$\theta_1,\theta_2 \in R$，都有$\theta_1 x_1 + \theta_2 x_2 \in V$。正如前面说的，子空间是加法和数乘封闭的。<br>
而根据仿射集的定义，如果$x_1,x_2$在一个仿射集$C$中，那么对于$\theta_1+\theta_2 = 1$，都有$\theta_1 x_1 + \theta_2 x_2 \in C$。我们可以看出来，如果取子空间中线性组合的系数和为$1$，那么就成了仿射集。如果取子空间中的系数$\theta_1,\theta_2 \in R_+$,那么就成了锥，如果同时满足$\theta_1+\theta_2 = 1$，那么就成凸锥。那么如果加上这些限制条件，即取子空间中线性组合的系数和为$1$，或者取子空间中的系数$\theta_1,\theta_2 \in R_+$,同时满足$\theta_1+\theta_2 = 1$。<br>
事实上，子空间要求的条件比仿射集和凸锥的条件要更严格。仿射集和凸锥只要求在系数$\theta_i$满足相应的条件时,有$\theta_1 x_1 + \theta_2 x_2 \in \mathbb{R}^n $；而子空间要求的是在系数$\theta_i$取任意值的时候，都有$\theta_1 x_1 + \theta_2 x_2 \in \mathbb{R}^n $，所以子空间一定是仿射集，也一定是凸锥。（拿二维的举个例子，给定$x_1$和$x_2$，仿射集可以看成是$\theta_1$的函数，因为$\theta_2=1-\theta_1$，而子空间可以看成$\theta_1$和$\theta_2$的函数，一个是一元函数，一个是二元函数）</p>
<h3 id="超平面-hyperplane-和半空间-halfspace">超平面(hyperplane)和半空间(halfspace)</h3>
<p>超平面是一个仿射集，也是凸集，但不一定是锥集(过原点才是锥集，也是一个子空间)。<br>
闭的半空间是一个凸集，不是仿射集。</p>
<h4 id="超平面-hyperplane">超平面(hyperplane)</h4>
<p>超平面通常具有以下形式：<br>
$${x\big|a^T x=b},$$<br>
其中$a\in \mathbb{R}^n ,a\ne 0,b\in R$，它其实是一个平凡(nontrivial)线性方程组的解，因此也是一个仿射集。几何上，超平面可以解释为和一个给定向量$a$具有相同内积(inner product)的点集，或者说是法向量为$a$的一个超平面。常数$b$是超平面和原点之间的距离(offset)。<br>
几何意义可以被表示成如下形式：<br>
$${x\big|a^T (x-x_0) = 0},$$<br>
其中$x_0$是超平面上的一点，即满足$a^T x_0=0$。可以被表示成如下形式：<br>
$${x\big|a^T (x-x_0)=0} = x_0+a^{\perp},$$<br>
其中$a^{\perp} $是$a$的正交补，即所有与$a$正交的向量的集合，满足$a^{\perp} ={v\big|a^T v=0}$。所以，超平面的几何解释可以看做一个偏移(原点到这个超平面的距离)加上所有垂直于一个特定向量$a$(正交向量)的向量，即这些垂直于$a$的向量构成了一个过原点的超平面，再加上这个偏移量就是我们要的超平面。几何表示如下图所示。<br>
<img src="/2018/12/24/convex-optimization-chapter-2-Convex-sets/figure2_6.png" alt="figure 2.6"></p>
<h4 id="半空间-halfspace">半空间(halfspace)</h4>
<p>一个超平面将$\mathbb{R}^n $划分为两个半空间(halfspaces)，一个是闭(closed)半空间，一个是开半空间。闭的半空间可以表示成${x\big|a^T x\le b}$，其中$a\ne 0$，半空间是凸的，但不是仿射的。下图便是一个闭的半空间。<br>
<img src="/2018/12/24/convex-optimization-chapter-2-Convex-sets/figure2_7.png" alt="figure 2.7"><br>
这个半空间也可以写成：<br>
$${x\big|a^T (x-x_0)\le 0},$$<br>
其中$x_0$是划分两个半空间的超平面上的一点，即满足$a^T x_0=b$。一个几何解释是：半空间由一个偏移$x_0$加上所有和一个特定向量$a$(超平面的外(outward)法向量)成钝角(obtuse)或者直角(right)的所有向量组成。<br>
这个半空间的边界是超平面${x\big|a^T x=b}$。这个半空间${x\big|a^T x\le b}$的内部是${x\big|a^T x\lt b}$，也被称为一个开半平面。</p>
<h3 id="欧几里得球-euclidean-ball-和椭球-ellipsoid">欧几里得球(Euclidean ball)和椭球(ellipsoid)</h3>
<h4 id="欧几里得球">欧几里得球</h4>
<p>$\mathbb{R}^n $空间中的欧几里得球或者叫球，有如下的形式：<br>
$$B(x_r,r = {x\big|\Vert x-x_c\Vert_2\le r}={x \big|(x-x_c)^T (x-x_c)\le \mathbb{R}^2 },$$<br>
其中$r\gt 0$,$\Vert \cdot\Vert_2$是欧几里得范数(第二范数)，即$\Vert u\Vert_2=(u^T u)^{\frac{1}{2}} $。向量$x_c$是球心，标量$r$是半径。$B(x_c,r)$包含所有和圆心$x_c$距离小于$r$的球。<br>
欧几里得球的另一种表示形式是：<br>
$$B(x_c,r)={x_c + ru\big| \Vert u \Vert_2 \le 1},$$<br>
一个欧几里得球是凸集，如果$\Vert x_1-x_c\Vert_2 \le r,\Vert x_2-x_c\Vert_2\le r, 0\le\theta\le1$，那么：<br>
\begin{align*}<br>
\Vert\theta x_1 + (1-\theta)x_2 - x_c\Vert_2 &amp;= \Vert\theta(x_1-x_c)+(1-\theta)(x_2-x_c)\Vert_2\\<br>
&amp;\le\theta\Vert x_1-x_c\Vert_2 + (1-\theta)\Vert x_2 - x_c \Vert_2\\<br>
&amp;\le r<br>
\end{align*}<br>
用其次性和三角不等式可证明</p>
<h4 id="椭球">椭球</h4>
<p>另一类凸集是椭球，它们有如下的形式：<br>
$$\varepsilon ={x\big|(x-x_c)^T P^{-1} (x-x_c) \le 1},$$<br>
其中$P=P^T \succ 0$即$P$是对称和正定的。向量$x_c\in \mathbb{R}^n $是椭球的中心。矩阵$P$决定了椭球从$x_c$向各个方向扩展的距离。椭球$\varepsilon$的半轴由矩阵$P$的特征值$\lambda_i$算出，$\sqrt{\lambda_i}$，球是$P=\mathbb{R}^2 I$的椭球。<br>
<strong>这里这种表示形式为什么要用$P^{-1} $？</strong><br>
椭球的另一种表示是：<br>
$$\varepsilon = {x_c + Au\big| \Vert u \Vert_2 \le 1},$$<br>
其中$A$是一个非奇异方阵。假设$A$是对称正定的，取$A=P^{\frac{1}{2}} $，这种表示就和上面的表示是一样的。第一次看到这种表示的时候，我在想，椭球的边界上有无数个点，一个方阵$A$是怎么实现对这无数个操作的，后来和球做了对比，发现自己一直都想错了，这无数个点是通过范数实现的而不是通过矩阵$A$实现的，到球心距离为$\Vert u\Vert_2\le 1$的点有无数个，$A$对这无数个点的坐标都做了仿射变换，将一个球变换成了椭球，特殊情况下就是球。当矩阵$A$是对称半正定但是是奇异的时候，这个情况下称为退化椭球(degenerate ellipsoid)，它的仿射维度和矩阵$A$的秩(rank)是相同的。退化椭球也是凸的。</p>
<h3 id="范数球-norm-ball-和范数锥-norm-cone">范数球(norm ball)和范数锥(norm cone)</h3>
<h4 id="范数球-norm-ball">范数球(norm ball)</h4>
<h5 id="定义-v12">定义</h5>
<p>$\Vert \cdot\Vert$是$\mathbb{R}^n $上的范数。一个范数球(norm ball)可以看成一个以$x_c$为中心，以$r$为半径的集合，但是这个$r$可以是任何范数，即${x\big|\Vert x-x_c \Vert \le r}$，它是凸的。</p>
<h5 id="示例-v15">示例</h5>
<p>我们常见的球是二范数（欧几里得范数）对应的范数球。</p>
<h4 id="范数锥">范数锥</h4>
<h5 id="定义-v13">定义</h5>
<p>和范数相关的范数锥是集合：$C = {(x,t)\big|\Vert x\Vert \le t} \subset \mathbb{R}^{n+1} $，它也是凸锥。</p>
<h5 id="示例-v16">示例</h5>
<p><img src="/2018/12/24/convex-optimization-chapter-2-Convex-sets/figure2_10.png" alt="figure 2.10"><br>
二阶锥(second-order cone)是欧几里得范数对应的范数锥，如图所示，其表达式为：<br>
\begin{align*}<br>
C &amp;={(x,t)\in \mathbb{R}^{n+1} \big| \Vert x\Vert_2 \le t}\\<br>
&amp;= \left{ \begin{bmatrix}x\\t\end{bmatrix} \big| \begin{bmatrix}x\\t\end{bmatrix}^T \begin{bmatrix}I&amp;0\\ 0&amp;-1\end{bmatrix} \begin{bmatrix}x\\t\end{bmatrix}\le 0, t \gt 0 \right}<br>
\end{align*}<br>
这个二阶锥也被称为二次锥(quadratic cone)，因为它是通过一个二次不等式定义的，也被叫做Lorentz cone或者冰激凌锥(ice-cream cone)。</p>
<h4 id="范数锥和范数球的区别">范数锥和范数球的区别</h4>
<p>范数球是所有点到圆心$x_c$的范数小于一个距离$r$。<br>
范数锥是很多直线组成的锥。</p>
<h3 id="多面体-polyhedra">多面体(polyhedra)</h3>
<h4 id="定义-v14">定义</h4>
<p>多面体(polyhedron)是有限个线性不等式或者线性方程组的解集的集合：<br>
$P = {x\big|a_j^T x\le b_j, j=1,\cdots,m,c_j^T x=d_j,j=1,\cdots,p}$<br>
多面体因此也是有限个半空间或者超平面的交集。仿射集(如，子空间，超平面，直线)，射线，线段，半空间等等都是多面体，多面体也是凸集。有界的polyhedron有时也被称为polytope，一些作者会把它们两个反过来叫。<br>
上式的紧凑(compact)表示是：<br>
$$P={x\big|Ax\preceq b, Cx=d}$$<br>
其中$A=\begin{bmatrix}a_1^T \\ \vdots\\ a_m^T \end{bmatrix},C=\begin{bmatrix}c_1^T \\ \vdots\\c_p^T \end{bmatrix}$，$\preceq$表示$\mathbb{R}^m $空间中的向量不等式(vector ineuqalitied)或者分量大小的不等式，$u\preceq v$代表着$u_i\le v_i, i=1,\cdots,m$。</p>
<h5 id="simplexes">simplexes</h5>
<p>simplexes是另一类很重要的多面体。假设$\mathbb{R}^n $空间中的$k+1$个点是仿射独立(affinely independent)，意味着$v_1-v_0, \cdots,v_k-v_0$是线性独立的。由$k+1$个仿射独立的点确定的simplex是：<br>
$$C = conv{v_0,\cdots,v_k} = {\theta_0v_0+\cdots+\theta_kv_k\big| \theta \succeq 0, \mathcal{1}\theta=1 },$$<br>
其中$\mathcal{1}$是全为$1$的列向量。这个simplex的仿射维度是$k$，所以它也叫$\mathbb{R}^n $空间中的$k$维simplex。为什么仿射维度是$k$，我的理解是simplex是凸集，而凸集不是子空间，凸集去掉其中任意一个元素才是子空间，所以就是$k$维而不是$k+1$维。<br>
为了将simplex表达成一个紧凑形式的多面体。定义$y=(\theta_1,\cdots,\theta_k)$和$B=[v_1-v_0\ \cdots\ v_k-v_0]\in \mathbb{R}^{n\times k} $，当且仅当存在$y\succeq 0, \mathcal{1}^T y\le 1$，$x=v_0+By$有$x\in C$，<strong>疑问，这里为什么变成了$\mathcal{1}^T y\le 1$，难道是因为少了个$v_0$吗</strong>。点$v_0,\cdots,v_k$表明矩阵$B$的秩为$k$。因此存在一个非奇异矩阵$A=(A_1,A_2)\in \mathbb{R}^{n\times n} $使得：<br>
$$AB = \begin{bmatrix}A_1\\A_2\end{bmatrix}B= \begin{bmatrix}I\\0\end{bmatrix}.$$<br>
对$x = v_0+By$同时左乘$A$，得到：<br>
$$A_1x = A_1v_0+y, A_2x=A_xv_0.$$<br>
从中我们可以看出如果$A_2x=A_2v_0$，且向量$y=A_1x-A_1v_0$满足$y\succeq 0, \mathcal{1}^T y\le1$时，$x\in C$。换句话说，当且仅当$x$满足以下等式和不等式时：<br>
$$A_2x = A_2v_0,A_1x\succeq A_1v_0, \mathcal{1}A_1x\le1+\mathcal{1}^T A_1v_0,$$<br>
有$x\in C$。</p>
<h5 id="多面体的凸包描述">多面体的凸包描述</h5>
<p>一个有限集合${v_1,\cdots,v_k}$的凸包是：<br>
$$conv{v_1,\cdots,v_k} = {\theta_1 v_1 +\cdots +\theta_k v_k\big| \theta \succeq 0, \mathcal{1}^T \theta = 1}.$$<br>
这个集合是一个多面体，并且有界。但是它（除了simplex）不容易化成多面体的紧凑表示，即不等式和等式的集合。<br>
一个一般化的凸包描述是：<br>
$${\theta_1 v_1 +\cdots +\theta_k v_k\big| \theta_1+\cdots + \theta_m = 1,\theta_i \ge 0,i=1,\cdots,k}.$$<br>
其中$m\le k$，它可以看做是点$v_1,\cdots,v_m$的凸包加上点$v_{m+1},\cdots,v_{k}$的锥包。这个集合定义了一个多面体，反过来，任意一个多面体可以看做凸包加上锥包。<br>
一个多面体如何表示是很有技巧的。比如一个$\mathbb{R}^n $空间上的无穷范数单位球$C$：<br>
$$C={x\big|\ |x_i|\le 1,i = 1,\cdots,n}.$$<br>
集合$C$可以被表示成$2n$个线性不等式$\pm e_i^T x\le 1$，其中$e_i$是第$i$个单位向量。然而用凸包形式描述这个集合需要用至少$2^n $个点：<br>
$$C = conv{v_{1},\cdots,v_{2^n }},$$<br>
其中$v_{1},\cdots,v_{2n}$是$2^n $个向量，每个向量的元素都是$1$或$-1$。因此凸包描述和不等式描述有很大差异，尤其是$n$很大的时候。<br>
这里为什么是$2^n $个点呢？因为是无穷范数构成的单位圆，在数轴上是区间$[-1,1]$，在$\mathbb{R}^2 $是正方形${(x,)\big|-1 \le x\le 1,-1\le y\le 1}$，对应的四个点是${(1,1),(1,-1),(-1,1),(-1,-1)}$，而在$\mathbb{R}^3 $是立方体${(x,y,z)\big|-1 \le x\le 1,-1\le y\le 1, -1\le z\le 1}$，对应的是立方体的八个顶点${(1,1,1),(1,1,-1),(1,-1,1),(1,-1,-1),(-1,1,1),(-1,1,-1),(-1,-1,1),(-1,-1,-1)}$。</p>
<h4 id="示例-v17">示例</h4>
<ol>
<li>如图所示，是五个半平面的交集定义的多面体。<br>
<img src="/2018/12/24/convex-optimization-chapter-2-Convex-sets/figure2_11.png" alt="figure 2.11"></li>
<li>非负象限(nonnegative orthant)是非负点的集合，即：<br>
$$R_{+}^n = {x\in \mathbb{R}^n \big| x_i\ge 0, i = 1,\cdots,n} = {x\in \mathbb{R}^n \big| x\succeq 0}.$$<br>
非负象限是一个多面体，也是一个锥，所以也叫多面体锥(polyhedral cone)，也叫非负象限锥。</li>
<li>一个1维的simplex是一条线段。一个二维的simplex是一个三角形（包含它的内部）。一个三维的simple是一个四面体(tetrahedron)。</li>
<li>由$\mathbb{R}^n $中的零向量和单位向量确定的simplex是$n$维unit simplex。它是向量集合：<br>
$$x\succeq 0, \mathcal{1}^T x \le 1.$$</li>
<li>由$\mathbb{R}^n $中的单位向量确定的simplex是$n-1$维probability simplex。它是向量集合：<br>
$$x\succeq 0, \mathcal{1}^T x = 1.$$<br>
Probability simplex是中的向量可以看成具有$n$个元素的集合的概率分布，$x_i$解释为第$i$个元素的概率。</li>
</ol>
<h3 id="半正定锥-positive-sefidefinite-cone">半正定锥(positive sefidefinite cone)</h3>
<h4 id="定义-v15">定义</h4>
<p>用$S^n $表示$n\times n$的对称矩阵：$S^n ={X\in \mathbb{R}^{n\times n} \big| X = X^T }$，$S^n $是一个$n(n+1)/2$维基的向量空间。比如，三维空间中对称矩阵的一组基是：<br>
$$\begin{bmatrix}1&amp;0&amp;0\\0&amp;0&amp;0\\0&amp;0&amp;0\end{bmatrix}\begin{bmatrix}0&amp;0&amp;0\\1&amp;0&amp;0\\0&amp;0&amp;0\end{bmatrix}\begin{bmatrix}0&amp;0&amp;0\\0&amp;1&amp;0\\0&amp;0&amp;0\end{bmatrix}\begin{bmatrix}0&amp;0&amp;0\\0&amp;0&amp;0\\1&amp;0&amp;0\end{bmatrix}\begin{bmatrix}0&amp;0&amp;0\\0&amp;0&amp;0\\0&amp;1&amp;0\end{bmatrix}\begin{bmatrix}0&amp;0&amp;0\\0&amp;0&amp;0\\0&amp;0&amp;1\end{bmatrix}.$$<br>
用$S_{+}^n $表示半正定的对称矩阵集合：<br>
$$S_{+}^n = {X\in S^n \big| X\succeq 0},$$<br>
用$S_{++}^n $表示正定的对称矩阵集合：<br>
$$S_{+}^n = {X\in S^n \big| X\succ 0},$$<br>
集合$S_{+}^n $是凸锥：如果$\theta_1,\theta_2 \ge 0$且$A,B\in S_{+}^n $，那么$\theta_1 A+\theta_{2} B\in S_{+}^n $。这个可以直接从依靠半正定的定义来证明，如果$A,B\in S_{+}^n ,\theta_1,\theta_2\ge 0$，(<strong>这里原书中用的是$A,B\succeq 0$,我觉得应该是写错了吧</strong>)，对任意$\forall x \in \mathbb{R}^n $，都有：<br>
$$x^T (\theta_1A+\theta_2B)x = \theta_1x^T Ax + \theta_2x^T Bx.$$</p>
<h4 id="示例-v18">示例</h4>
<p>对于$S^2 $空间中的半正定锥，有<br>
$$X=\begin{bmatrix}x&amp;y\\y&amp;z\end{bmatrix}\in S_{+}^2 \Leftrightarrow x\ge 0,z\ge 0, xz\ge y^2 $$<br>
这个锥的边界如下图所示。<br>
<img src="/2018/12/24/convex-optimization-chapter-2-Convex-sets/figure2_12.png" alt="figure 2.12"></p>
<h3 id="常见的几种锥">常见的几种锥</h3>
<p>范数锥，非负象限锥，半正定锥，它们都过原点。<br>
想想对应的图像是什么样的。<br>
范数锥和非负象限锥图像还好理解一些，非负象限锥是$\mathbb{R}^n $空间所有非负半轴围成的锥，范数锥的边界像一个沙漏，但是是无限延伸的。半正定锥怎么理解，还没有太好的类比。</p>
<h2 id="保凸运算-operations-that-preserve-convexity">保凸运算(operations that preserve convexity)</h2>
<p>这一小节介绍的是一些保留集合凸性，或者从一些集合中构造凸集的运算。这些运算和simplex形成了凸集的积分去确定或者建立集合的凸性。</p>
<h3 id="集合交-intersection">集合交(intersection)</h3>
<p>凸集求交集可以保留凸性：如果$S_1$和$S_2$是凸集，那么$S_1\cup S_2$是凸集。扩展到无限个集合就是：如果$\forall \alpha \in A,S_{\alpha}$都是凸的，那么$\cup_{\alpha\in A S_{\alpha}}$是凸的</p>
<h3 id="仿射函数-affine-functions">仿射函数(affine functions)</h3>
<h3 id="线性分式-linear-fractional-和视角函数-perspective-functions">线性分式(linear-fractional)和视角函数(perspective functions)</h3>
<h4 id="线性分式-linear-fractional">线性分式(linear-fractional)</h4>
<h4 id="视角函数-perspective-functions">视角函数(perspective functions)</h4>
<h2 id="广义不等式-generalized-inequalities">广义不等式（Generalized inequalities)</h2>
<h3 id="真锥-proper-cones-和广义不等式-generalized-inequalities">真锥(Proper cones)和广义不等式（Generalized inequalities)</h3>
<h3 id="最小-minimum-和最小元素-minimal-elemetns">最小(Minimum)和最小元素(minimal elemetns)</h3>
<h2 id="separating和supporting-hyperplanes">Separating和supporting hyperplanes</h2>
<h3 id="separating-hyperplane-theorem">Separating hyperplane theorem</h3>
<h3 id="supporting-hyperplanes">Supporting Hyperplanes</h3>
<h2 id="对偶锥-dual-cones-和广义不等式-generalized-inequalities">对偶锥(dual cones)和广义不等式(generalized inequalities)</h2>
<h3 id="none"></h3>
<h2 id="符号定义">符号定义</h2>
<p>$\preceq$表示$\mathbb{R}^m $空间中的向量不等式(vector ineuqalitied)或者element-wise的不等式，$u\preceq v$代表着$u_i\le v_i, i=1,\cdots,m$。</p>
<h2 id="参考文献">参考文献</h2>
<p>1.stephen boyd. Convex optimization<br>
2.<a href="https://en.wikipedia.org/wiki/Topology" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Topology</a><br>
3.<a href="https://en.wikipedia.org/wiki/Topological_space" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Topological_space</a><br>
4.<a href="https://en.wikipedia.org/wiki/Power_set" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Power_set</a><br>
5.<a href="https://en.wikipedia.org/wiki/Open_set" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Open_set</a><br>
6.<a href="https://en.wikipedia.org/wiki/Closed_set" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Closed_set</a><br>
7.<a href="https://en.wikipedia.org/wiki/Clopen_set" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Clopen_set</a><br>
8.<a href="https://en.wikipedia.org/wiki/Interior_(topology)" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Interior_(topology)</a><br>
9.<a href="https://en.wikipedia.org/wiki/Closure_(topology)" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Closure_(topology)</a><br>
10.<a href="https://en.wikipedia.org/wiki/Boundary_(topology)" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Boundary_(topology)</a><br>
11.<a href="https://en.wikipedia.org/wiki/Ball_(mathematics)" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Ball_(mathematics)</a><br>
12.<a href="https://blog.csdn.net/u010182633/article/details/53792588" target="_blank" rel="noopener">https://blog.csdn.net/u010182633/article/details/53792588</a><br>
13.<a href="https://blog.csdn.net/u010182633/article/details/53819910" target="_blank" rel="noopener">https://blog.csdn.net/u010182633/article/details/53819910</a><br>
14.<a href="https://blog.csdn.net/u010182633/article/details/53983642" target="_blank" rel="noopener">https://blog.csdn.net/u010182633/article/details/53983642</a><br>
15.<a href="https://blog.csdn.net/u010182633/article/details/53997843" target="_blank" rel="noopener">https://blog.csdn.net/u010182633/article/details/53997843</a><br>
16.<a href="https://blog.csdn.net/u010182633/article/details/54093987" target="_blank" rel="noopener">https://blog.csdn.net/u010182633/article/details/54093987</a><br>
17.<a href="https://blog.csdn.net/u010182633/article/details/54139896" target="_blank" rel="noopener">https://blog.csdn.net/u010182633/article/details/54139896</a><br>
18.<a href="https://math.stackexchange.com/questions/1168898/why-is-any-subspace-a-convex-cone" target="_blank" rel="noopener">https://math.stackexchange.com/questions/1168898/why-is-any-subspace-a-convex-cone</a><br>
19.<a href="https://www.zhihu.com/question/22799760/answer/139753685" target="_blank" rel="noopener">https://www.zhihu.com/question/22799760/answer/139753685</a><br>
20.<a href="https://www.zhihu.com/question/22799760/answer/34282205" target="_blank" rel="noopener">https://www.zhihu.com/question/22799760/answer/34282205</a><br>
21.<a href="https://www.zhihu.com/question/22799760/answer/137768096" target="_blank" rel="noopener">https://www.zhihu.com/question/22799760/answer/137768096</a><br>
22.<a href="https://en.wikipedia.org/wiki/Positive-definite_matrix" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Positive-definite_matrix</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mxxhcm.github.io/2018/12/22/convex-optimization-chapter-1-Introduction/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="马晓鑫爱马荟荟">
      <meta itemprop="description" content="记录硕士三年自己的积累">
      <meta itemprop="image" content="/images/favicon.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="mxxhcm's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2018/12/22/convex-optimization-chapter-1-Introduction/" class="post-title-link" itemprop="http://mxxhcm.github.io/page/13/index.html">convex optimization chapter 1 Introduction</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2018-12-22 13:44:11" itemprop="dateCreated datePublished" datetime="2018-12-22T13:44:11+08:00">2018-12-22</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-09-04 20:51:00" itemprop="dateModified" datetime="2019-09-04T20:51:00+08:00">2019-09-04</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/凸优化/" itemprop="url" rel="index"><span itemprop="name">凸优化</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="数学优化-mathematical-optimization">数学优化(mathematical optimization)</h2>
<h3 id="定义">定义</h3>
<p>一个数学优化问题（或者称为优化问题）通常有如下的形式：<br>
\begin{align*}<br>
&amp;minimize \quad f_0(x)\\<br>
&amp;subject \ to \quad f_i(x) \le b_i, i = 1,\cdots,m.<br>
\end{align*}<br>
其中$x = (x_1, \cdots, x_m)$被称为优化变量(optimization variables), 或者决策变量(decision variables)。 $f_0(x):\mathbb{R}^n \rightarrow \mathbb{R}$是目标函数(object function), $f_i(x):\mathbb{R}^n \rightarrow \mathbb{R},i =1,\cdots,m$是约束函数(constraint functions)。 常量(constraints) $b_1,\cdots,b_m$是约束的限界(limits)或者边界(bounds), $b_i$可以为$0$，这个可以通过移项构造出新的$f_i(x)$实现。如果向量$x$使得目标函数取得最小的值，并且满足所有的约束条件，那么这个向量被称为最优解$x^{*} $。</p>
<h4 id="线性优化-linear-program">线性优化(linear program)</h4>
<p>目标函数和约束函数$f_0,\cdots,f_m$是线性的, 它们满足不等式：<br>
$$f_i(\alpha x+\beta y) = \alpha f_i(x) + \beta f_i(y)$$<br>
对于所有的$x,y \in \mathbb{R}^n $和所有的$\alpha, \beta \in\mathbb{R}$。<br>
线性优化是凸优化的一个特殊形式, 它的目标函数和约束函数都是线性的等式。</p>
<h4 id="非线性问题-non-linear-problem">非线性问题(non-linear problem)</h4>
<p>如果优化问题不是线性的，就是非线性问题。只要目标函数或者约束函数至少有一个不是线性的，那么这个优化问题就是非线性优化问题。</p>
<h4 id="凸问题-convex-problem">凸问题(convex problem)</h4>
<p>凸问题是目标函数和约束函数都是凸的的优化问题，它们满足：<br>
$$f_i(\alpha x + \beta y) \le \alpha f_i(x) + \beta f_i(y)$$<br>
对于所有的$x,y \in \mathbb{r}^n $和所有的$\alpha, \beta \in \mathbb{r}$且$\alpha + \beta = 1, \alpha \ge 0, \beta \ge 0$。<br>
凸性比线性的范围更广，不等式取代了更加严格的等式，不等式只有在$\alpha$和$\beta$取一些特定值时才成立。凸优化和线性问题以及非线性问题都有交集，它是线性问题的超集(superset)，是非线性问题的子集(subset)。技术上来说，nonlinear problem包括convex optimization(除了linear programming), 可以用来描述不确定是非凸的问题。<br>
Nonlinear program &gt; convex problem &gt; linear problem</p>
<h3 id="示例">示例</h3>
<h4 id="组合优化-portfolio-optimization">组合优化(portfolio optimization)</h4>
<p>变量：不同资产的投资数量<br>
约束：预算，每个资产最大/最小投资数量，至少要得到的回报<br>
目标：所有的风险，获利的变化</p>
<h4 id="电子设备的元件大小-device-sizing-in-electronic-circuits">电子设备的元件大小(device sizing in electronic circuits)</h4>
<p>变量：元件的宽度和长度<br>
约束：生产工艺的炼制，时间要求，面积等<br>
目标：节约能耗</p>
<h4 id="数据拟合-data-fitting">数据拟合(data fitting)</h4>
<p>变量：模型参数<br>
约束：先验知识，参数约束条件<br>
目标：错误率</p>
<h3 id="优化问题求解-solving-optimization-problems">优化问题求解(solving optimization problems)</h3>
<p>所有的问题都是优化问题。<br>
绝大部分优化问题我们解不出来。</p>
<h4 id="一般的优化问题-general-optimization-problem">一般的优化问题(general optimization problem)</h4>
<ul>
<li>很难解出来。</li>
<li>做一些compromise，比如要很长时间才能解出来，或者并不总能找到解。</li>
</ul>
<h4 id="一些例外-some-exceptions">一些例外(some exceptions)</h4>
<ul>
<li>最小二乘问题(least-squares problems)</li>
<li>线性规划问题(linear programming problems)</li>
<li>凸优化问题(convex optimization problems)</li>
</ul>
<h2 id="最小二乘-least-squares-和线性规划-linear-programming">最小二乘(least-squares)和线性规划(linear programming)</h2>
<p>least-squares和linear programming是凸优化问题中最有名的两个子问题。</p>
<h3 id="最小二乘问题-least-squares-problems">最小二乘问题(least-squares problems)</h3>
<p>最小二乘问题是一个无约束的优化问题，它的目标函数是项$a_i^T x-b_i$的平方和。<br>
\begin{align*}<br>
minimize \quad f_0(x) &amp;= {||Ax-b||}^2_2 \\<br>
&amp;=\sum_{i=1}^k (a_i^T x-b_i)^2<br>
\end{align*}</p>
<h4 id="求解-solving-least-squares-problems">求解(solving least-squares problems)</h4>
<ul>
<li>最小二乘问题的解可以转换为求线性方程组$(A^T A)x = A^T b$的解。线性代数上我们学过该方程组的解析解为$x=(A^T A)^{-1} A^T b$。</li>
<li>时间复杂度是$n^2 k = n*k*n+n*k+n*n*n, (k &gt; n)$(转置，求逆，矩阵乘法)。</li>
<li>该问题具有可靠且高效的求解算法。</li>
<li>是一个很成熟的算法</li>
</ul>
<h4 id="应用-using-least-squares">应用(using least-squares)</h4>
<p>很容易就可以看出来一个问题是最小二乘问题，我们只需要验证目标函数是不是二次函数，以及对应的二次型是不是正定的即可。</p>
<h5 id="加权最小二乘-weighted-least-squares">加权最小二乘(weighted least-squares)</h5>
<p>加权最小二乘形式如下:<br>
$$\sum_{i=1}^k \omega_i(a_i^T x-b_i)^2 ,$$<br>
其中$\omega_1,\cdots,\omega_k$是正的，被最小化。 这里选出权重$\omega$来体现不同项$a_i^T x-b_i$的比重, 或者仅仅用来影响结果。</p>
<h5 id="正则化-regularization">正则化(regularization)</h5>
<p>目标函数中被加入了额外项, 形式如下：<br>
$$\sum_{i=1}^k (a_i^T x-b_i)^2 + \rho \sum_{i=1}^n x_i^2 ,$$<br>
正则项是用来惩罚大的$x$, 求出一个仅仅最小化第一个求和项的不出来的好结果。合理的选择参数$\rho$在原始的目标函数和正则化项之间做一个trade-off, 使得$\sum_{k=1}^i (a_i^T - b_i)^2 $和$\rho \sum_{k=1}^n  x_i^2 $都很小。<br>
正则化项和加权最小二乘会在第六章中讲到，它们的统计解释在第七章给出。</p>
<h3 id="线性规划-linear-programming">线性规划(linear programming)</h3>
<p>线性规划问题装目标函数和约束函数都是线性的：<br>
\begin{align*}<br>
&amp;minimize \quad c^T x\\<br>
&amp;subject \ to \quad a_i^T \le b_i, i = 1, \cdots, m.<br>
\end{align*}<br>
其中向量$c,a_1,\cdots,a_m \in \mathbb{R}^n $, 和标量$b_1,\cdots, b_m \in \mathbb{R}$是指定目标函数和约束函数条件的参数。</p>
<h4 id="求解线性规划-solving-linear-programs">求解线性规划(solving linear programs)</h4>
<ul>
<li>除了一个特例，没有解析解公式(和least-squares不同)；</li>
<li>有可靠且高效的算法实现；</li>
<li>时间复杂度是$O(n^2 m)$, m是约束条件的个数, m是维度$；</li>
<li>是一个成熟的方法。</li>
</ul>
<h4 id="应用-using-linear-programs">应用(using linear programs)</h4>
<p>一些应用直接使用线性规划的标准形式,或者其中一个标准形式。在很多时候，原始的优化问题没有一个标准的线性规划形式，但是可以被转化为等价的线性规划形式。比如切米雪夫近似问题(Chebyshev approximation problem)。它的形式如下：<br>
$$minimize \quad max_{i=1,\cdots,k}|a_i^T x-b_i|$$<br>
其中$x\in \mathbb{R}^n $是变量，$a_1,\cdots,a_k \in \mathbb{R}^n , b_1,\cdots,b_k \in \mathbb{R}$是实例化的问题参数,和least-squares相似的是，它们的目标函数都是项$a^T_i x-b_i$。不同之处在于，least-squares用的是该项的平方和作为目标函数，而Chebyshev approximation中用的是绝对值的最大值。Chebyshev approximation problem的目标函数是不可导的(max operation), least-squares problem的目标函数是二次的(quadratic), 因此可导的(differentiable)。</p>
<h2 id="凸优化-convex-optimization">凸优化(Convex optimization)</h2>
<p>凸优化问题是优化问题的一种,它的目标函数和优化函数都是凸的。<br>
具有以下形式的问题是一种凸优化问题：<br>
\begin{align*}<br>
&amp;minimize \quad f_0(x)\\<br>
&amp;subject \ to \quad f_i(x) \le b_i, i = 1,\cdots,m.<br>
\end{align*}<br>
其中函数$f_0,\cdots,f_m:\mathbb{R}^n \rightarrow \mathbb{R}$是凸的(convex), 如满足<br>
$$f_i(\alpha x+ \beta y) \le \alpha f_i(x) + \beta f_i(y)$$<br>
对于所有的$x,y \in \mathbb{R}^n $和所有的$\alpha, \beta \in \mathbb{R}$且$\alpha + \beta = 1, \alpha \ge 0, \beta \ge 0$。<br>
或者：<br>
$$f_i(\theta x+ (1-\theta) y) \le \theta f_i(x) + (1 - \theta) f_i(y)$$<br>
其中$\theta \in [0,1]$。<br>
课上有人问这里为$\theta$是0和1, 有没有什么物理意义，Stephen Boyd回答说这是定义，就是这么定义的。<br>
The least-squares和linear programming problem都是convex optimization problem的特殊形式。线性函数(linear functions)也是convex，它们正处在边界上，它们的曲率(curvature)为0。一种方式是用正曲率去描述凸性。</p>
<h3 id="凸优化求解-solving-convex-optimization-problems">凸优化求解(solving convex optimization problems)</h3>
<ul>
<li>没有解析解；</li>
<li>有可靠且有效的算法；</li>
<li>时间复杂度正比于$max{n^3 , n^2 m,F},$F$是评估$f$和计算一阶导数和二阶导数的时间；</li>
<li>有成熟的方法，如interior-point methods。</li>
</ul>
<h3 id="凸优化的应用-using-convex-optimization">凸优化的应用(using convex optimization)</h3>
<p>将实际问题形式化称凸优化问题。</p>
<h2 id="非线性优化-nonlinear-optimization">非线性优化(Nonlinear optimization)</h2>
<h3 id="非线性优化">非线性优化</h3>
<p>非线性优化用来描述目标函数和约束函数都是非线性函数(但不是凸的)优化问题。因为凸优化问题包括least-squares和linear programming, 它们是线性的。刚开始给出的优化问题就是非线性优化问题，目前没有有效的方法解该问题。目前有一些方法来解决一般的非线性问题，但是都做了一些compromise。</p>
<h4 id="局部优化-local-optimization">局部优化(local optimization)</h4>
<p>局部优化是非线性优化的一种解法，compromise是寻找局部最优点，而不是全局最优点，在可行解附近最小化目标函数，不保证能得到一个最小的目标值。<br>
局部优化需要随机初始化一个初值，这个初值很关键，很大程度的影响了局部解得到的目标值, 也就是说是一个初值敏感的算法。关于初始值和全局最优值距离有多远并没有很多有用的信息。局部优化对于算法的参数值很敏感，需要根据具体问题去具体调整。<br>
使用局部优化的方法比解least-squares problems, linear program, convex optimization problem更有技巧性，因为它牵扯到算法的选择，算法参数的选择，以及初值的选取。</p>
<h4 id="全局优化-global-optimization">全局优化(global optimization)</h4>
<p>全局优化也是非线性优化的一种解法, 在全局优化中，优化目标的全局最优解被找到， compromise是效率。</p>
<h4 id="凸优化问题在非凸优化问题中的应用-role-of-convex-optimization-in-nonconvex-problems">凸优化问题在非凸优化问题中的应用(role of convex optimization in nonconvex problems)</h4>
<h5 id="初始化局部优化-initialization-for-local-optimization">初始化局部优化(initialization for local optimization)</h5>
<h5 id="用于非凸优化的凸的启发式搜索-convex-heuristics-for-nonconvex-optimization">用于非凸优化的凸的启发式搜索(convex heuristics for nonconvex optimization)</h5>
<h5 id="全局最优的边界-bounds-for-global-optimization">全局最优的边界(bounds for global optimization)</h5>
<h2 id="大纲-outline">大纲(outline)</h2>
<h3 id="理论-part-one-theory">理论(part one: Theory)</h3>
<p>第一部分是理论，给出一些概念和定义，第一章是Introduction, 第二章和第三章分别介绍凸集(convex set)和凸函数(convex function), 第四章介绍凸优化问题， 第五章引入拉格朗日对偶性。</p>
<h3 id="应用-part-two-applications">应用(part two: Applications)</h3>
<p>第二部分主要给出凸优化在一些领域的应用，如概率论与数理统计，经济学，计算几何以及数据拟合等领域。<br>
凸优化如何应用在实践中。</p>
<h3 id="算法-part-three-algorithms">算法(part three: Algorithms)</h3>
<p>第三部分给出了凸优化的数值解法，如牛顿法(Newton’s algorithm)和内点法(interior-point)。<br>
第三部分有三章，分别包含了无约束优化，等式约束优化和不等式约束优化。章节之间是递进的，解一个问题被分解为解一系列简单问题。二次优化问题(包括，如least-squares)是最底层的基石，它可以通过线性方程组精确求解。牛顿法，在第十章和第十一章介绍到，是下个层次，无约束问题或者等式约束问题被转化成一系列二次优化问题的求解。第十一章介绍了内点法，是最顶层, 这些方法将不等式约束问题转化为一系列无约束或者等式约束的问题。</p>
<h2 id="参考文献">参考文献</h2>
<p>1.stephen boyd. Convex optimization</p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mxxhcm.github.io/2018/12/21/reinforcement-learning-an-introduction-第3章笔记/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="马晓鑫爱马荟荟">
      <meta itemprop="description" content="记录硕士三年自己的积累">
      <meta itemprop="image" content="/images/favicon.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="mxxhcm's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2018/12/21/reinforcement-learning-an-introduction-第3章笔记/" class="post-title-link" itemprop="http://mxxhcm.github.io/page/13/index.html">reinforcement learning an introduction 第3章笔记</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2018-12-21 15:13:38" itemprop="dateCreated datePublished" datetime="2018-12-21T15:13:38+08:00">2018-12-21</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-10-04 12:03:17" itemprop="dateModified" datetime="2019-10-04T12:03:17+08:00">2019-10-04</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/强化学习/" itemprop="url" rel="index"><span itemprop="name">强化学习</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="马尔科夫过程-markov-process-马尔科夫链-markov-chain">马尔科夫过程(markov process)、马尔科夫链(markov chain)</h2>
<p>马尔科夫过程或者马尔科夫链(markov chain)是一个tuple $\lt S,P\gt$,其中S是一个有限(或者无限)的状态集合,P是状态转移矩阵(transition probability matrix)或马尔科夫矩阵(markov matrix),$P_{ss’}= P[S_{t+1} = s’|S_t = s]$.</p>
<h2 id="马尔科夫奖励过程-markov-reward-process">马尔科夫奖励过程(markov reward process)</h2>
<p>马尔科夫奖励过程是一个tuple $\lt S,P,R,\gamma\gt$,和马尔科夫过程相比，它多了一个奖励R，R和某个具体的状态相关，MRP中的reward只和state有关,和action无关。<br>
S是一个(有限)状态的集合。<br>
P是一个状态转移概率矩阵。<br>
R是一个奖励函数$R = \mathbb{E}[R_{t+1}|S_t = s]$, <strong>这里为什么是t+1时刻的reward?这仅仅是一个约定，为了描述RL问题中涉及到的observation，action，reward比较方便。这里可以理解为离开这个状态才能获得奖励而不是进入这个状态即获得奖励。如果改成$R_t$也是可以的，这时可以理解为进入这个状态获得的奖励。</strong><br>
$\gamma$称为折扣因子(discount factor), $\gamma \epsilon [0,1]$.<strong>为什么引入$\gamma$，David Silver的公开课中提到了四个原因:(1)数学上便于计算回报(return)；(2)避免陷入无限循环；(3)长远利益具有一定的不确定性；(4)符合人类对眼前利益的追求。</strong></p>
<h3 id="奖励-reward">奖励(reward)</h3>
<p>每个状态s在一个时刻t立即可得到一个reward,reward的值需要由环境给出,这个值可正可负。目前的强化学习算法中reward都是人为设置的。</p>
<h3 id="回报-return">回报(return)</h3>
<p>回报是累积的未来的reward,其计算公式如下:<br>
$$G_t = R_{t+1} + R_{t+2} + … = \sum_{k=0}^{\infty} {\gamma^k R_{t+k+1}} \tag{1}$$<br>
它是一个马尔科夫链上从t时刻开始往后所有奖励的有衰减(带折扣因子)的总和。</p>
<h3 id="值函数-value-function">值函数(value function)</h3>
<p>值函数是回报(return)的期望(expected return), 一个MRP过程中某一状态的value function为从该状态开始的markov charin return的期望，即$v(s) = \mathbb{E}[G_t|S_t=s]$.<br>
MRP的value function和MDP的value function是不同的, MRP的value function是对于state而言的，而MDP的value function是针对tuple $\lt$state, action$\gt$的。<br>
这里为什么要取期望,因为policy是stotastic的情况时，在每个state时，采取每个action都是可能的，都有一定的概率，next state也是不确定的了，所以value funciton是一个随机变量，因此就引入期望来刻画随机变量的性质。<br>
为什么在当前state就知道下一时刻的state了?对于有界的RL问题来说，return是在一个回合结束时候计算的；对于无界的RL问题来说，由于有衰减系数，只要reward有界，return就可以计算出来。</p>
<h3 id="马尔科夫奖励过程的贝尔曼方程-bellman-equation-for-mrp">马尔科夫奖励过程的贝尔曼方程(bellman equation for MRP)</h3>
<p>\begin{align*}<br>
v(s) &amp;= \mathbb{E}[G_t|S_t = s]\\<br>
&amp;= \mathbb{E}[R_{t+1} + \gamma R_{t+2} + … | S_t = s]\\<br>
&amp;= \mathbb{E}[R_{t+1} + \gamma (R_{t+2} + \gamma R_{t+3} + …|S_t = s]\\<br>
&amp;= \mathbb{E}[R_{t+1} + \gamma G_{t+1} |S_t = s]\\<br>
&amp;= \mathbb{E}[R_{t+1} + \gamma v(S_{t+1})|S_t = s]\\<br>
v(s) &amp;= \mathbb{E}[R_{t+1} + \gamma v(S_{t+1})|S_t = s]<br>
\end{align*}<br>
v(s)由两部分组成，一部分是immediate reward的期望(expectation)，$\mathbb{E}[R_{t+1}]$, 只与当前时刻state有关；另一部分是下一时刻state的value function的expectation。如果用s’表示s状态下一时刻的state，那么bellman equation可以写成：<br>
$$v(s) = R_s + \gamma \sum_{s’ \epsilon S} P_{ss’}v(s’)$$<br>
我们最终的目的是通过迭代使得t轮迭代时的v(s)和第t+1轮迭代时的v(s)相等。将其写成矩阵形式为：<br>
$$v_t = R + \gamma P v_{t+1}$$<br>
$$(v_1,v_2,…,v_n)^T = (R_1,R_2,…,R_n)^T + \gamma \begin{bmatrix}P_{11}&amp;P_{12}&amp;…&amp;P_{1n}\\P_{21}&amp;P_{22}&amp;…&amp;P_{2n}\\&amp;&amp;…&amp;\\P_{n1}&amp;P_{n2}&amp;…&amp;P_{nn}\end{bmatrix} (v_1,v_2,…,v_n)^T $$<br>
MRP的Bellman方程组是线性的，可以直接求解:<br>
\begin{align*}<br>
v &amp;= R + \gamma Pv\\<br>
(1-\gamma P) &amp;= R\\<br>
v &amp;= (1 - \gamma P)^{-1} R<br>
\end{align*}<br>
可以直接解方程，但是复杂度为$O(n^3)$，对于大的MRP方程组不适用，可以通过迭代法求解，常用的迭代法有动态规划,蒙特卡洛算法和时序差分算法等求解(动态规划是迭代法吗？）</p>
<h2 id="马尔科夫决策过程-markov-decision-process">马尔科夫决策过程(markov decision process)</h2>
<p>马尔科夫决策过程，比markov reward process多了一个A,它也是一个tuple $\lt S,A,P,R,\gamma\gt$, 在MRP中奖励R仅仅和状态S相关，在MDP中奖励R和概率P对应的是某个状态S和某个动作A的组合。<br>
\begin{align*}<br>
P_{ss’}^a &amp;= P[S_{t+1} = s’ | S_t = s, A_t = a]\\<br>
R_s^a &amp;= \mathbb{E}[R_{t+1} | S_t = s, A_t = a]<br>
\end{align*}<br>
这里的reward不仅仅与state相关，而是与tuple $\lt state，action\gt$相关。</p>
<h3 id="回报">回报</h3>
<p>MDP中的$G_t$和式子$(1)$的$G_t$是一样的，将$G_t$写成和后继时刻相关的形式如下：<br>
\begin{align*}<br>
G_t &amp;= R_{t+1} + \gamma R_{t+2} + \gamma^2 R_{t+3} + \gamma^3 R_{t+4} + …\\<br>
&amp;= R_{t+1} + \gamma (R_{t+2} + \gamma^1 R_{t+3} + \gamma^2 R_{t+4} + …)\\<br>
&amp;= R_{t+1} + \gamma G_{t+1} \tag{2}<br>
\end{align*}<br>
这里引入$\gamma$之后，即使是在continuing情况下，只要$G_t$是非零常数，$G_t$也可以通过等比数列求和公式进行计算，即:<br>
$$G_t = \sum_{k=1}^{\infty} \gamma^k = \frac{1}{1-\gamma} \tag{3}$$</p>
<h3 id="策略-policy">策略(policy)</h3>
<p>策略$\pi$的定义:给定状态时采取各个动作的概率分布。<br>
$$\pi(a|s) = P[A_t = a | S_t = a] \tag{4}$$</p>
<h3 id="值函数-value-function-v2">值函数(value function)</h3>
<p>这里给出的是值函数的定义，就是这么定义的。<br>
MDP的值函数有两种，状态值函数(state value function)和动作值函数(action value function), 这两种值函数的含义其实是一样的，也可以相互转换。具体来说, 值函数定义为给定一个policy $\pi$，得到的回报的期望(expected return)。<br>
一个MDP的状态s对应的值函数(state value function) $v_{\pi}(s)$是从状态s开始采取策略$\pi$得到的回报的期望。<br>
\begin{align*}<br>
v_{\pi}(s) &amp;= \mathbb{E}_{\pi}[G_t|S_t = s]\\<br>
&amp;=\mathbb{E}_{\pi}[\sum_{k=0}^{\infty} \gamma^{k} R_{t+k+1}|S_t=s] \tag{5}<br>
\end{align*}<br>
这里的$G_t$是式子(2)中的回报。<br>
一个MDP过程中动作值函数(action value function) $q_{\pi}(s,a)$是从状态s开始,采取action a，采取策略$\pi$得到的回报的期望。<br>
&lt;action value function $q_{\pi}(s,a)$ is the expected return starting from states, taking action a, and then following policy \pi.&gt;<br>
\begin{align*}<br>
q_{\pi}(s,a) &amp;= \mathbb{E}_{\pi}\left[G_t | S_t = s, A_t = a\right]\\<br>
&amp;= \mathbb{E}_{\pi}\left[\sum_{k=0}^{\infty} \gamma^{k} R_{t+k+1}|S_t=s, A_t=a\right] \tag{6}<br>
\end{align*}</p>
<h4 id="状态值函数-state-value-function">状态值函数(state value function)</h4>
<p>\begin{align*}<br>
v_{\pi}(s) &amp;= \sum_{a \epsilon A} \pi(a|s) q_{\pi} (s,a) \tag{7}\\<br>
v_{\pi}(s) &amp;= \sum_a \pi(a|s)\sum_{s’,r}p(s’,r|s,a) \left[r + \gamma v_{\pi}(s’) \right] \tag{8}\\<br>
\end{align*}<br>
式子$(7)$是$v(s)$和$q(s,a)$的关系，式子$(8)$是$v(s)$和它的后继状态$v(s’)$的关系。<br>
式子$(8)$的推导如下：<br>
\begin{align*}<br>
v_{\pi}(s) &amp;= \mathbb{E}_{\pi}[G_t|S_t = s]\\<br>
&amp;= \mathbb{E}_{\pi}\left[R_{t+1}+\gamma G_{t+1}|S_t = s\right]\\<br>
&amp;= \sum_a \pi(a|s)\sum_{s’}\sum_rp(s’,r|s,a) \left[r + \gamma \mathbb{E}_{\pi}\left[G_{t+1}|S_{t+1}=s’\right]\right]\\<br>
&amp;= \sum_a \pi(a|s)\sum_{s’,r}p(s’,r|s,a) \left[r + \gamma v_{\pi}(s’) \right]\\<br>
\end{align*}</p>
<h4 id="动作值函数-action-value-function">动作值函数(action value function)</h4>
<p>\begin{align*}<br>
q_{\pi}(s,a) &amp;= \sum_{s’}\sum_r p(s’,r|s,a)(r + \gamma  v_{\pi}(s’)) \tag{9}\\<br>
q_{\pi}(s,a) &amp;= \sum_{s’}\sum_r p(s’,r|s,a)(r + \gamma  \sum_{a’}\pi(a’|s’)q(s’,a’)) \tag{10}\\<br>
\end{align*}<br>
式子$(9)$是$q(s,a)$和$v(s)$的关系，式子$(10)$是$q(s,a)$和它的后继状态$q(s’,a’)$的关系。<br>
以上都是针对MDP来说的，在MDP中，给定policy $\pi$下，状态s下选择a的action value function，$q_{\pi}(s,a)$类似MRP里面的v(s)，而MDP中的v(s)是要考虑在state s下采率各个action后的情况。</p>
<h3 id="贝尔曼期望方程-bellmam-expectation-equation">贝尔曼期望方程(Bellmam expectation equation)</h3>
<p>\begin{align*}<br>
v_{\pi}(s) &amp;= \mathbb{E}_{\pi}[R_{t+1} + \gamma v_{\pi}(S_{t+1})|S_t = s] \tag{11}\\<br>
v_{\pi}(s) &amp;= \mathbb{E}_{\pi}\left[q_{\pi}(S_t,A_t)|S_t=s,A_t=a\right]\tag{12}\\<br>
q_{\pi}(s,a)&amp;= \mathbb{E}_{\pi}\left[R_{t+1} + \gamma v_{\pi}(S_{t+1}) |S_t=s,A_t=a\right]\tag{13}\\<br>
q_{\pi}(s,a) &amp;= \mathbb{E}_{\pi}[R_{t+1} + \gamma q_{\pi}(S_{t+1},A_{t+1}) | S_t = s, A_t = a] \tag{14}<br>
\end{align*}</p>
<h4 id="矩阵形式">矩阵形式</h4>
<p>\begin{align*}<br>
v_{\pi} &amp;= R^{\pi} + \gamma P^{\pi} v_{\pi}\\<br>
v_{\pi} &amp;= (I-\gamma P^{\pi} )^{-1} R^{\pi}<br>
\end{align*}</p>
<h2 id="最优策程的求解-how-to-find-optimal-policy">最优策程的求解(how to find optimal policy)</h2>
<h3 id="最优价值函数-optimal-value-function">最优价值函数(optimal value function)</h3>
<p>$v_{*} = \max_{\pi}v_{\pi}(s)$,从所有策略产生的state value function中，选取使得state s的价值最大的函数<br>
$q_{*}(s,a) = \max_{\pi} q_{\pi}(s,a)$,从所有策略产生的action value function中，选取使$\lt s,a\gt$价值最大的函数<br>
当我们得到了optimal value function，也就知道了每个state的最优价值，便认为这个MDP被解决了</p>
<h3 id="最优策略-optimal-policy">最优策略(optimal policy)</h3>
<p>对于每一个state s，在policy $\pi$下的value 大于在policy $\pi’$的value， 就称策略$\pi$优于策略$\pi’$， $\pi \ge \pi’$ if $v_{\pi}(s) \ge v_{\pi’}(s)$, 对于任意s都成立<br>
对于任何MDP，都满足以下条件：</p>
<ol>
<li>都存在一个optimal policy，它比其他策略好或者至少相等；</li>
<li>所有的optimal policy的optimal value function是相同的；</li>
<li>所有的optimal policy 都有相同的 action value function.</li>
</ol>
<h3 id="寻找最优策略">寻找最优策略</h3>
<p>寻找optimal policy可以通过寻找optimal action value function来实现：<br>
$${\pi}_{*}(a|s) =<br>
\begin{cases}1, &amp;if\quad a = \arg\max\ q_{*}(s,a)\\0, &amp;otherwise\end{cases}$$</p>
<h3 id="贝尔曼最优方程-bellman-optimal-equation">贝尔曼最优方程(bellman optimal equation)</h3>
<p>*号表示最优的策略。</p>
<h4 id="最优状态值函数-state-value-function">最优状态值函数(state value function)</h4>
<p>\begin{align*}<br>
v_{*}(s) &amp;= \max_a q_{*}(s,a)\\<br>
&amp;= \max_a\mathbb{E}_{\pi_{*}}\left[G_t|S_t=s,A_t=a\right]\\<br>
&amp;= \max_a\mathbb{E}_{\pi_{*}}\left[R_{t+1}+\gamma G_t|S_t=s,A_t=a\right]\\<br>
&amp;= \max_a\mathbb{E}\left[R_{t+1} +\gamma v_{*}(S_{t+1})|S_t=s,A_t=a\right]\\<br>
&amp;= \max_a \left[\sum_{s’,r} p(s’,r|s,a)(r+\gamma v_{*}(s’) )\right] \tag{15}\\<br>
\end{align*}</p>
<h4 id="最优动作值函数-action-value-function">最优动作值函数(action value function)</h4>
<p>\begin{align*}<br>
q_{*}(s,a) &amp;= \sum_{s’,r} p(s’,r|s,a) (r + \gamma v_{*}(s’))\\<br>
&amp;= \sum_{s’,r} p(s’,r|s,a) (r + \gamma \max_{a’} q_{*}(s’,a’))\\<br>
&amp;=\mathbb{E}\left[R_{t+1}+\gamma \max_{a’}q_{*}(S_{t+1},a’)|S_t=s,A_t=a \right]\tag{16}\\<br>
\end{align*}</p>
<h3 id="贝尔曼最优方程的求解-solution-to-bellman-optimal-equation">贝尔曼最优方程的求解(solution to Bellman optimal equation)</h3>
<p>Bellman equation和Bellman optimal equation相比，一个是对于给定的策略，求其对应的value function,是对一个策略的估计，而bellman optimal equation是要寻找最优策略，通过对action value function进行贪心。<br>
Bellman最优方程是非线性的，没有固定的解决方案，只能通过迭代法来解决，如Policy iteration，value iteration，Q-learning，Sarsa等。</p>
<h2 id="参考文献">参考文献</h2>
<p>1.<a href="http://incompleteideas.net/book/the-book-2nd.html" target="_blank" rel="noopener">http://incompleteideas.net/book/the-book-2nd.html</a><br>
2.<a href="https://www.bilibili.com/video/av32149008/?p=2" target="_blank" rel="noopener">https://www.bilibili.com/video/av32149008/?p=2</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mxxhcm.github.io/2018/12/20/linux-常见问题/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="马晓鑫爱马荟荟">
      <meta itemprop="description" content="记录硕士三年自己的积累">
      <meta itemprop="image" content="/images/favicon.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="mxxhcm's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2018/12/20/linux-常见问题/" class="post-title-link" itemprop="http://mxxhcm.github.io/page/13/index.html">linux 常见问题（不定期更新）</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2018-12-20 20:30:34" itemprop="dateCreated datePublished" datetime="2018-12-20T20:30:34+08:00">2018-12-20</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-06-04 10:37:22" itemprop="dateModified" datetime="2019-06-04T10:37:22+08:00">2019-06-04</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/linux/" itemprop="url" rel="index"><span itemprop="name">linux</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="问题1-undefined-reference-to-pthread-create-in-linux">问题1 Undefined reference to pthread_create in Linux</h2>
<p>在阅读自然语言处理的一篇论文时，读到了bype pair encoding(bpe)算法。在github找到了一个实现<a href="https://github.com/glample/fastBPE" target="_blank" rel="noopener">fastBPE</a>, 算法是用C++写的，在编译的过程中遇到了问题&quot;Undefined reference to pthread_create in Linux&quot;,</p>
<h3 id="terminal下解决方案">terminal下解决方案</h3>
<p>查阅资料了解到pthread不是Linux操作系统默认的库函数，所以需要在编译的时候将pthread链接该库函数，后来在看fastBPE的文档时发现文档中已经有说明:<br>
Compile with:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">g++ -std=c++11 -pthread -O3 fast.cc -o fast</span><br></pre></td></tr></table></figure>
<h3 id="codeblocks下解决方案">codeblocks下解决方案</h3>
<p>上面给出的方案是使用gcc在terminal进行编译时加入静态库，但是对于不习惯在命令行使用gdb进行调试的人来说没有用。<br>
在codeblocks中，如果要链接静态库,找到Settings --&gt; Compiler… --&gt; Linker settings，点击add，添加相应的库函数即可。</p>
<h2 id="参考文献">参考文献</h2>
<p>1:<a href="https://stackoverflow.com/questions/1662909/undefined-reference-to-pthread-create-in-linux" target="_blank" rel="noopener">https://stackoverflow.com/questions/1662909/undefined-reference-to-pthread-create-in-linux</a><br>
2:<a href="https://blog.csdn.net/zhaoyue007101/article/details/7705753" target="_blank" rel="noopener">https://blog.csdn.net/zhaoyue007101/article/details/7705753</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mxxhcm.github.io/2018/10/21/classfication/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="马晓鑫爱马荟荟">
      <meta itemprop="description" content="记录硕士三年自己的积累">
      <meta itemprop="image" content="/images/favicon.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="mxxhcm's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2018/10/21/classfication/" class="post-title-link" itemprop="http://mxxhcm.github.io/page/13/index.html">classfication</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2018-10-21 18:47:44" itemprop="dateCreated datePublished" datetime="2018-10-21T18:47:44+08:00">2018-10-21</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-10-21 22:53:18" itemprop="dateModified" datetime="2019-10-21T22:53:18+08:00">2019-10-21</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="classfication">Classfication</h2>
<h2 id="lda">LDA</h2>
<h2 id="logistic-regression">Logistic Regression</h2>
<h3 id="logistic-function">Logistic function</h3>
<p>$$ S(x) = \frac{1}{1+e^{x} }$$<br>
如下图所示：<br>
<img src="/2018/10/21/classfication/logistic_function.png" alt="logistic_func"><br>
它的取值在$[0,1]$之间。<br>
logistic regression的目标函数是：<br>
$$h(x) = \frac{1}{1+e<sup>{-\theta</sup>T x} 3}$$<br>
其中$x$是输入，$\theta$是要求的参数。</p>
<h3 id="思路">思路</h3>
<p>Logistic regression利用logistic function进行分类，给出一个输入，经过参数$\theta$的变换，输出一个$[0,1]$之间的值，如果大于$0.5$，把它分为一类，小于$0.5$，分为另一类。这个$0.5$只是一个例子，可以根据不同的需求选择不同的值。<br>
$\theta^T x$相当于给出了一个非线性的决策边界。</p>
<h3 id="cost-function">Cost function</h3>
<p>$$J(\theta) = -\log L(\theta) = -\sum_{i=1}^m (y(i)\log h(x^{(i)}) + (1-y<sup>{(i)})\log(1-h(x</sup>{(i)} )) )$$<br>
给出两种方式推导logistic regression的cost function</p>
<h4 id="maximum-likelyhood-estimation">Maximum likelyhood estimation</h4>
<p>通过极大似然估计推导得到的，当是两个类别的分类时，即$0$或者$1$，有：<br>
$$P(y=1|x,\theta) = h(x)$$<br>
$$P(y=0|x,\theta) = 1- h(x)$$<br>
服从二项分布，写成一个式子是：<br>
$$P(y|x,\theta) = h(x)^y (1-h(x))^{1-y}$$<br>
其中$y$取值只有$0$和$1$。<br>
有了$y$的表达式，我们就可以使用最大似然估计进行求解了：<br>
$$L(\theta) = \prod_{i=1}^m (h(x<sup>{(i)})</sup>{y(i)}(1-h(x^{(i)} ))<sup>{(1-y</sup>{(i)})}$$<br>
似然函数要求最大化，即求使得$m$个observation出现概率最大的$\theta$，<br>
损失函数是用来衡量损失的，令损失函数取负的对数似然，然后最小化loss也就是最大化似然函数了：<br>
$$J(\theta) = -\log L(\theta) = -\sum_{i=1}^m (y(i)\log h(x^{(i)}) + (1-y<sup>{(i)})\log(1-h(x</sup>{(i)} )) )$$</p>
<h4 id="cross-entropy">Cross-entropy</h4>
<p>对于$k$类问题，写出交叉熵公式如下所示：<br>
$$J(\theta) = -\frac{1}{n}\left[\sum_{i=1}^m \sum_k y_k^{(i)} \log h(x_k^{(i)} ) \right]$$<br>
当$k=2$时：<br>
$$J(\theta) = -\frac{1}{n}\left[\sum_{i=1}^m  y^{(i)} \log h(x^{(i)} ) + (1-y^{(i)}) \log (1-h(x^{(i)} ))\right]$$</p>
<h3 id="梯度下降">梯度下降</h3>
<p>$$J(\theta) = -\log L(\theta) = -\sum_{i=1}^m \left[y(i)\log h(x^{(i)}) + (1-y<sup>{(i)})\log(1-h(x</sup>{(i)} )) \right]$$</p>
<p>\begin{align*}<br>
\nabla J &amp; =  -\sum_{i=1}^m \left[ y(i)\frac{1}{h(x^{(i)})}\nabla h(x^{(i)}) - (1-y<sup>{(i)})\frac{1}{\log(1-h(x</sup>{(i)} ))}\nabla\log(1-h(x^{(i)} ))\right]<br>
&amp;=-\sum_{i=1}^m  (h(x^{(i)}) - y^{(i)}) x^{(i)}<br>
\end{align*}</p>
<h2 id="参考文献">参考文献</h2>
<p>1.<a href="https://blog.csdn.net/jk123vip/article/details/80591619" target="_blank" rel="noopener">https://blog.csdn.net/jk123vip/article/details/80591619</a><br>
2.<a href="https://zhuanlan.zhihu.com/p/28408516" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/28408516</a><br>
3.<a href="https://www.cnblogs.com/pinard/p/6029432.html" target="_blank" rel="noopener">https://www.cnblogs.com/pinard/p/6029432.html</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/12/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/12/">12</a><span class="page-number current">13</span>
  </nav>



          </div>
          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <div class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/favicon.jpg" alt="马晓鑫爱马荟荟">
            
              <p class="site-author-name" itemprop="name">马晓鑫爱马荟荟</p>
              <p class="site-description motion-element" itemprop="description">记录硕士三年自己的积累</p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">129</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  <a href="/categories/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">8</span>
                    <span class="site-state-item-name">分类</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  <a href="/tags/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">131</span>
                    <span class="site-state-item-name">标签</span>
                  </a>
                </div>
              
            </nav>
          

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://github.com/mxxhcm" title="GitHub &rarr; https://github.com/mxxhcm" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="mailto:mxxhcm@gmail.com" title="E-Mail &rarr; mailto:mxxhcm@gmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                </span>
              
            </div>
          

          

          
          

          
            
          
          

        </div>
      </div>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">马晓鑫爱马荟荟</span>

  

  
</div>


  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.8.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> v6.6.0</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  
    <script src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  


  


  <script src="/js/src/utils.js?v=6.6.0"></script>

  <script src="/js/src/motion.js?v=6.6.0"></script>



  
  


  <script src="/js/src/affix.js?v=6.6.0"></script>

  <script src="/js/src/schemes/pisces.js?v=6.6.0"></script>



  

  


  <script src="/js/src/bootstrap.js?v=6.6.0"></script>



  



  






<!-- LOCAL: You can save these files to your site and update links -->
    
        
        <link rel="stylesheet" href="https://aimingoo.github.io/gitmint/style/default.css">
        <script src="https://aimingoo.github.io/gitmint/dist/gitmint.browser.js"></script>
    
<!-- END LOCAL -->

    

    







  





  

  

  

  

  
  

  
  
    
      
    
      
    
      
    
      
        
      
    
      
    
      
    
      
    
      
    
      
    
  

  
    
      <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      },
      TeX: {equationNumbers: { autoNumber: "AMS" }}
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<script src="//cdn.jsdelivr.net/npm/mathjax@2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<style>
.MathJax_Display {
    overflow: auto hidden;
}
</style>

    
  


  
  

  

  

  

  

  

  

</body>
</html>
