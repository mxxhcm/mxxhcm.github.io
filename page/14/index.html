<!DOCTYPE html>












  


<html class="theme-next pisces use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
































<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=6.6.0" rel="stylesheet" type="text/css">



  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.jpg?v=6.6.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.jpg?v=6.6.0">










<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '6.6.0',
    sidebar: {"position":"left","display":"always","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="记录硕士三年自己的积累">
<meta property="og:type" content="website">
<meta property="og:title" content="mxxhcm&#39;s blog">
<meta property="og:url" content="http://mxxhcm.github.io/page/14/index.html">
<meta property="og:site_name" content="mxxhcm&#39;s blog">
<meta property="og:description" content="记录硕士三年自己的积累">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="mxxhcm&#39;s blog">
<meta name="twitter:description" content="记录硕士三年自己的积累">



  <link rel="alternate" href="/atom.xml" title="mxxhcm's blog" type="application/atom+xml">




  <link rel="canonical" href="http://mxxhcm.github.io/page/14/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>mxxhcm's blog</title>
  












  <noscript>
  <style>
    .use-motion .motion-element,
    .use-motion .brand,
    .use-motion .menu-item,
    .sidebar-inner,
    .use-motion .post-block,
    .use-motion .pagination,
    .use-motion .comments,
    .use-motion .post-header,
    .use-motion .post-body,
    .use-motion .collection-title { opacity: initial; }

    .use-motion .logo,
    .use-motion .site-title,
    .use-motion .site-subtitle {
      opacity: initial;
      top: initial;
    }

    .use-motion .logo-line-before i { left: initial; }
    .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">mxxhcm's blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>

      
      
    </ul>
  

  

  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mxxhcm.github.io/2019/04/04/reinforcement-learning-an-introduction-第9章笔记/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="马晓鑫爱马荟荟">
      <meta itemprop="description" content="记录硕士三年自己的积累">
      <meta itemprop="image" content="/images/favicon.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="mxxhcm's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/04/04/reinforcement-learning-an-introduction-第9章笔记/" class="post-title-link" itemprop="http://mxxhcm.github.io/page/14/index.html">reinforcement learning an introduction 第9章笔记</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-04-04 10:14:08" itemprop="dateCreated datePublished" datetime="2019-04-04T10:14:08+08:00">2019-04-04</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-08-30 11:44:59" itemprop="dateModified" datetime="2019-08-30T11:44:59+08:00">2019-08-30</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/强化学习/" itemprop="url" rel="index"><span itemprop="name">强化学习</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="on-policy-prediction-with-approximation">On-policy Prediction with Approximation</h2>
<p>这一章讲的是利用on-policy的数据估计函数形式的值函数，on-policy就是说利用一个已知的policy $\pi$生成的experience来估计$v_{\pi}$。和之前讲的不同的是，前面几章讲的是表格形式的值函数，而这一章是使用参数为$\mathbf{w}\in R^d$的函数表示。即$\hat{v}(s,\mathbf{w})\approx v_{\pi}(s)$表示给定一个权值vector $\mathbf{w}$，state $s$的状态值。这个函数可以是任何形式的，可以是线性函数，也可以是神经网络，还可以是决策树。</p>
<h2 id="值函数估计">值函数估计</h2>
<p>目前这本书介绍的所有prediction方法都是更新某一个state的估计值函数向backed-up value（或者叫update target）值移动。我们用符号$s\mapsto u$表示一次更新。其中$s$是要更新的状态，$u$是$s$的估计值函数的update target。例如，Monte Carlo更新的value prediction是：$S_t \mapsto G_t$，TD(0)的update是：$S_t \mapsto R_{t+1} + \gamma \hat{v}(S_{t+1}, \mathbf{w}_t)$，$n$-step TD update是：$S_t \mapsto G_{t:t+n}$。在DP policy evaluation update中是：$s\mapsto E_{\pi}[R_{t+1}+\gamma\hat{v}(S_{t+1}, \mathbf{w}_t)| S_t =s]$，任意一个状态$s$被更新了，同时在其他真实experience中遇到的$S_t$也被更新了。</p>
<p>之前表格的更新太trivial了，更次更新$s$向$u$移动，其他状态的值都保持不变。现在使用函数实现更新，在状态$s$处的更新，可以一次性更新很多个其他状态的值。就像监督学习学习input和output之间的映射一样，我们可以把$s\mapsto g$的更新看做一个训练样本。这样就可以使用很多监督学习的方法学习这样一个函数。<br>
但是并不是所有的方法都适用于强化学习，因为许多复杂的神经网络和统计学方法都假设训练集是静态不变的。然而强化学习中，学习是online的，即智能体不断地与环境进行交互产生新的数据，这就需要这个方法能够从不断增加的数据中高效的学习。<br>
此外，强化学习通常需要function approximation能够处理target function不稳定的情况，即target function随着事件在不断的变化。比如，在基于GPI的control方法中，在$\pi$不断变化的情况下，我们想要学习出$q_{\pi}$。即使policy保持不变，如果使用booststrapping方法（DP和TD学习），训练样本的target value也在不断的改变，因为下一个state的value值在不断的改变。所以不能处理这些不稳定情况的方法有点不适合强化学习。</p>
<h2 id="预测目标-the-prediction-objective">预测目标(The Prediction Objective)</h2>
<p>表格形式的值函数最终都会收敛到真值，状态值之间也都是解耦的，即更新一个state不影响另一个state。<br>
但是使用函数拟合，更新一个state的估计值就会影响很多个其他状态，并且不可能精确的估计所有states的值。假设我们的states比weights多的多，让一个state的估计更精确也意味着使得其他的state越不accurate。我们用一个state $s$上的分布,$\mu(s)\ge 0,\sum_s\mu(s)=1$代表对每个state上error的权重。然后使用$\mu(s)$对approximate value $\hat{v}(s,\mathbf{w})$和true value $v_{\pi}(s)$的squared error进行加权，得到Mean Squared Value Error，表示为$\bar{VE}$：<br>
$$\bar{VE}(\mathbf{w}) = \sum_{s\in S}\mu(s)[v_{\pi}(s) - \hat{v}(s, \mathbf{w})]^2$$<br>
通常情况下，$\mu(s)$是在state $s$处花费时间的百分比。在on-policy训练中，这叫做on-policy分布。在continuing tasks中，策略$\pi$下的on-policy分布是一个stationary distribution。<br>
在episodic tasks中，on-policy分布有一些不同，因为它还取决于每个episodic的初始状态，用$h(s)$表示在一个episodic开始状态为$s$的概率，用$\eta(s)$表示在一个回合中，state $s$平均被访问的次数。<br>
$$\eta(s) = h(s) + \sum_{\bar{s}}\eta(\bar{s})\sum_a\pi(a|\bar{s})p(s|\bar{s},a), forall\ s \in S$$<br>
其中$\bar{s}$是$s$的前一个状态，$s$处的时间为以状态$s$开始的概率$h(s)$加上它由前一个状态$\bar{s}$转换过来消耗的时间。<br>
列出一个方程组，可以解出来$\eta(s)$的期望值。然后进行归一化，得到：<br>
$$\mu(s)=\frac{\eta{s}}{\sum_{s’}\eta{s’}}, \forall s \in S.$$<br>
这是没有折扣因子的式子，如果有折扣因子的话，可以看成一种形式的</p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mxxhcm.github.io/2019/04/03/reinforcement-learning-an-introduction-第13章笔记/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="马晓鑫爱马荟荟">
      <meta itemprop="description" content="记录硕士三年自己的积累">
      <meta itemprop="image" content="/images/favicon.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="mxxhcm's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/04/03/reinforcement-learning-an-introduction-第13章笔记/" class="post-title-link" itemprop="http://mxxhcm.github.io/page/14/index.html">reinforcement learning an introduction 第13章笔记.md</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-04-03 09:46:49" itemprop="dateCreated datePublished" datetime="2019-04-03T09:46:49+08:00">2019-04-03</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-07-25 14:31:58" itemprop="dateModified" datetime="2019-07-25T14:31:58+08:00">2019-07-25</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/强化学习/" itemprop="url" rel="index"><span itemprop="name">强化学习</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="policy-gradient">Policy gradient</h2>
<p>这章介绍的是使用一个参数化策略(parameterized policy)直接给出action，而不用借助一个value funciton选择action。但是需要说一下的是，Policy gradient方法也可以学习一个Value function，但是value function是用来帮助学习policy parameters的，而不是用来选择action。我们用$\mathbf{\theta} \in R^{d’}$表示policy’s parameters vector，用$\pi(a|s, \mathbf{\theta}) = Pr[A_t = a|S_t = s, \mathbf{\theta}_t = \mathbf{\theta}]$表示environment在时刻$t$处于state $s$时，智能体根据参数为$\mathbf{\theta}$的策略$\pi$选择action $a$。<br>
如果policy gradient方法使用了一个value function,它的权重用$\mathbf{w} \in R^d$表示，即$\hat{v}(s,\mathbf{w})$。</p>
<p>用$J(\mathbf{\theta})$表示policy parameters的标量performance measure。使用梯度上升(gradient ascent) 方法来最大化这个performance：<br>
$$\mathbf{\theta}_{t+1} = \mathbf{\theta}_t + \alpha \widehat{\nabla J(\mathbf{\theta}_t}),\tag{1}$$<br>
其中$\widehat{\nabla J(\mathbf{\theta}_t)} \in R^{d’}$是一个随机估计(stachastic estimate)，它的期望是performance measure对$\mathbf{\theta_t}$的梯度。不管它们是否使用value function，这种方法就叫做policy gradient方法。既学习policy，又学习value function的方法被称为actor-critic，其中actor指的是学到的policy，critic指的是学习到的value funciton,通常是state value function。</p>
<h2 id="policy估计和它的优势">policy估计和它的优势</h2>
<h3 id="参数化policy的条件">参数化policy的条件</h3>
<p>policy可以用任何方式参数化，只要$\pi(a|s,\mathbf{\theta}),\mathbf{\theta}\in R^{d’}$对于它的参数$\mathbf{\theta}$是可导的，即只要$\nabla_{\pi}(a|s,\mathbf{\theta})$（即：$\pi(a|s,\mathbf{\theta})$相对于$\mathbf{\theta}$的偏导数列向量）存在，并且$\forall s\in S, a\in A(s)$偏导数都是有限的即可。</p>
<h3 id="stochastic-policy">stochastic policy</h3>
<p>为了保证exploration，通常策略是stochastic，而不是deterministic，即$\forall s,a,\mathbf{\theta}, \pi(a|s,\mathbf{\theta})\in (0,1)$</p>
<h3 id="参数化方式的选择">参数化方式的选择</h3>
<h4 id="softmax">softmax</h4>
<p>对于有限且离散的action space，一个很自然的参数化方法就是对于每一个state-action对都计算一个参数化的数值偏好$h(s,a,\mathbf{\theta})\in R$。通过计算一个exponetial softmax，这个数值大的动作有更大的概率被选中：<br>
$$\pi(a|s,\mathbf{\theta}) = \frac{e^{h(s,a,\mathbf{\theta} )}}{\sum_be^{h(s,b,\mathbf{\theta} )}}, \tag{2}$$<br>
其中$b$是在state $s$下所有可能采取的动作，它们的概率加起来为$1$，这种方法叫做softmax in aciton preferences。</p>
<h4 id="nn和线性方法">NN和线性方法</h4>
<p>参数化还可以选择其他各种各样的方法，如AlphaGo中使用的NN，或者可以使用如下的线性方法：<br>
$$h(s,a, \mathbf{\theta}) = \mathbf{\theta}^Tx(s,a), \tag{3}$$</p>
<h3 id="优势">优势</h3>
<p>和action value方法相比，policy gradient有多个优势。<br>
第一个优势是使用action preferences的softmax，同时用$\epsilon-greedy$算法用$\epsilon$的概率随机选择action得到的策略可以接近一个deterministic policy。<br>
而单单使用action values的方法并不会使得策略接近一个deterministic policy，但是action-value方法会逐渐收敛于它的true values，翻译成概率来表示就是在$0$和$1$之间的一个概率值。但是action preferences方法不收敛于任何值，它们产生optimal stochastic policy，如果optimal policy是deterministic，那么optimal action的preferences应该比其他所有suboptimal actions都要高。</p>
<p>第二个优势是使用action preferences方法得到的参数化策略可以使用任意的概率选择action。在某些问题中，最好的approximate policy可能是stochastic的，actor-value方法不能找到一个stochastic optimal policy，它总是根据action value值选出来一个值最大的action，但是这时候的结果通常不是最优的。</p>
<p>第三个优势是policy parameterization可能比action value parameterization更容易学习。当然，也有时候可能是action value更容易。这个要根据情况而定</p>
<p>第四个优势是policy parameterizaiton比较容易添加先验知识到policy中。</p>
<h2 id="policy-gradient理论">policy gradient理论</h2>
<p>除了上节说的实用优势之外，还有理论优势。policy parameterization学到关于参数的一个连续函数，action probability概率可以平滑的变化。然而$\epsilon-greedy$算法中，action-value改变以后，action probability可能变化很大。很大程度上是因为policy gradient方法的收敛性要比action value方法强的多。因为policy的连续性依赖于参数，使得policy gradient方法接近于gradient ascent。<br>
这里讨论episodic情况。定义perfromance measure是episode初始状态的值。假设每一个episode，都从state $s_0$开始，定义：<br>
$$J(\mathbf{\theta}) = v_{\pi_\mathbf{\theta}}(s_0), \tag{4}$$<br>
其中$v_{\pi_\mathbf{\theta}}(s_0)$是由参数$\mathbf{\theta}$确定的策略$\pi_{\mathbf{\theta}}$的true value function。假设在episodic情况下，$\gamma=1$。</p>
<p>使用function approximation，一个需要解决的问题就是如何确保每次更新policy parameter，performance measure都有improvement。因为performence不仅仅依赖于action的选择，还取决于state的分布，然后它们都受policy parameter的影响。给定一个state，policy parameter对于actions，reward的影响，都可以相对直接的利用参数知识计算出来。但是policy parameter对于state 分布的影响是一个环境的函数，通常是不知道的。当梯度依赖于policy改变对于state分布的影响未知时，我们该如何估计performance相对于参数的梯度。</p>
<h3 id="episodic-case证明">Episodic case证明</h3>
<p>为了简化表示，用$\pi$表示参数为$\theta$的policy，所有的梯度都是相对于$\mathbf{\theta}$求的<br>
\begin{align*}<br>
\nabla v_{\pi}(s) &amp;= \nabla [ \sum_a \pi(a|s)q_{\pi}(s,a)], \forall s\in S \tag{5}\\<br>
&amp;= \sum_a [\nabla\pi(a|s)q_{\pi}(s,a)], \forall s\in S \tag{6}\\<br>
&amp;= \sum_a[\nabla\pi(a|s)q_{\pi}(s,a) + \pi(a|s)\nabla q_{\pi}(s,a)] \tag{7}\\<br>
&amp;= \sum_a[\nabla\pi(a|s)q_{\pi}(s,a) + \pi(a|s)\nabla \sum_{s’,r}p(s’,r|s,a)(r+\gamma v_{\pi}(s’))] \tag{8}\\<br>
&amp;= \sum_a[\nabla\pi(a|s)q_{\pi}(s,a) + \pi(a|s) \nabla \sum_{s’,r}p(s’,r|s,a)r + \pi(a|s)\nabla \sum_{s’,r}p(s’,r|s,a)\gamma v_{\pi}(s’))] \tag{9}\\<br>
&amp;= \sum_a[\nabla\pi(a|s)q_{\pi}(s,a) + 0 + \pi(a|s)\sum_{s’}\gamma p(s’|s,a)\nabla v_{\pi}(s’) ] \tag{10}\\<br>
&amp;= \sum_a[\nabla\pi(a|s)q_{\pi}(s,a) + 0 + \pi(a|s)\sum_{s’}\gamma p(s’|s,a)\\<br>
&amp;\ \ \ \ \ \ \ \ \sum_{a’}[\nabla\pi(a’|s’)q_{\pi}(s’,a’) + \pi(a’|s’)\sum_{s’’}\gamma p(s’’|s’,a’)\nabla v_{\pi}(s’’))] ],  \tag{11}展开\\<br>
&amp;= \sum_{x\in S}\sum_{k=0}^{\infty}Pr(s\rightarrow x, k,\pi)\sum_a\nabla\pi(a|x)q_{\pi}(x,a) \tag{12}<br>
\end{align*}<br>
第(5)式使用了$v_{\pi}(s) = \sum_a\pi(a|s)q(s,a)$进行展开。第(6)式将梯度符号放进求和里面。第(7)步使用product rule对q(s,a)求导。第(8)步利用$q_{\pi}(s, a) =\sum_{s’,r}p(s’,r|s,a)(r+v_{\pi}(s’)$ 对$q_{\pi}(s,a)$进行展开。第(9)步将(8)式进行分解。第(10)步对式(9)进行计算，因为$\sum_{s’,r}p(s’,r|s,a)r$是一个定制，求偏导之后为$0$。第(11)步对生成的$v_{\pi}(s’)$重复(5)-(10)步骤，得到式子(11)。如果对式子(11)中的$v_{\pi}(s)$一直展开，就得到了式子(12)。式子(12)中的$Pr(s\rightarrow x, k, \pi)$是在策略$\pi$下从state $s$经过$k$步转换到state $x$的概率，这里我有一个问题，就是为什么，$k$可以取到$\infty$，后来想了想，因为对第(11)步进行展开以后，可能会有重复的state，重复的意思就是从状态$s$开始，可能会多次到达某一个状态$x$，$k$就能取很多次，大不了$k=\infty$的概率为$0$就是了。</p>
<p>所以，对于$v_{\pi}(s_0)$，就有：<br>
\begin{align*}<br>
\nabla J(\mathbf{\theta}) &amp;= \nabla_{v_{\pi}}(s_0)\\<br>
&amp;= \sum_{s\in S}( \sum_{k=0}^{\infty}Pr(s_0\rightarrow s,k,\pi) ) \sum_a\nabla_{\pi}(a|s)q_{\pi}(s,a)\\<br>
&amp;=\sum_{s\in S}\eta(s)\sum_a \nabla_{\pi}(a|s)q_{\pi}(s,a)\\<br>
&amp;=\sum_{s’\in S}\eta(s’)\sum_s\frac{\eta(s)}{\sum_{s’}\eta(s’)}\sum_a \nabla_{\pi}(a|s)q_{\pi}(s,a)\\<br>
&amp;=\sum_{s’\in S}\eta(s’)\sum_s\mu(s)\sum_a \nabla_{\pi}(a|s)q_{\pi}(s,a)\\<br>
&amp;\propto \sum_{s\in S}\mu(s)\sum_a\nabla\pi(a|s)q_{\pi}(s,a)<br>
\end{align*}<br>
最后，我们可以看出来performance对policy求导不涉及state distribution的导数。Episodic 情况下的策略梯度如下所示：<br>
$$\nabla J(\mathbf{\theta})\propto \sum_{s\in S}\mu(s)\sum_aq_{\pi}(s,a)\nabla\pi(a|s,\mathbf{\theta}), \tag{13}$$<br>
其中梯度是performacne指标$J$关于$\mathbf{\theta}$的偏导数列向量，$\pi$是参数$\mathbf{\theta}$对应的策略。在episodic情况下，比例常数是一个episode的平均长度，在continuing情况下，常数是$1$，实际上这个正比于就是一个等式。分布$\mu$是策略$\pi$下的on-policy分布。</p>
<h2 id="reinforce-monte-carlo-policy-gradient">REINFORCE: Monte Carlo Policy Gradient</h2>
<p>对于式子(1)，我们需要进行采样，让样本梯度的期望正比于performance measure对于$\mathbf{\theta}$的真实梯度。比例系数不需要确定，因为步长$\alpha$的大小是手动设置的。Policy gradient理论给出了一个正比于gradient的精确表达式，我们要做的就是选择采样方式，它的期望等于或者接近policy gradient理论给出的值。</p>
<h3 id="all-actions">all-actions</h3>
<p>使用随机变量的期望替换对随机变量求和的取值，我们可以将式子(13)进行如下变化：<br>
\begin{align*}<br>
\nabla J(\mathbf{\theta})&amp;\propto \sum_{s\in S}\mu(s)\nabla\pi(a|s,\mathbf{\theta})\sum_aq_{\pi}(s,a)\\<br>
&amp;=\mathbb{E}_{\pi}\left[\nabla\pi(a|S_t,\mathbf{\theta})\sum_aq_{\pi}(S_t,a)\right]\tag{14}<br>
\end{align*}<br>
接下来，我们可以实例化该方法：<br>
$$\mathbf{\theta}_{t+1} = \mathbf{\theta}_t+\alpha\sum_a\hat{q}(S_t,s,\mathbf{w})\nabla\pi(a|S_t,\mathbf{\theta}), \tag{15}$$<br>
其中$\hat{q}$是$q_{\pi}$的估计值，这个算法被称为all-actions方法，因为它的更新涉及到了所有的action。然而，我们这里介绍的REINFORCE仅仅使用了$t$时刻的action $A_t$。。</p>
<h3 id="reinforce">REINFORCE</h3>
<p>和引入$S_t$的方法一样，使用随机变量的期望代替对与随机变量的可能取值进行求和，我们在式子(14)中引入$A_t$，<br>
\begin{align*}<br>
\nabla J(\mathbf{\theta}) &amp;= \mathbb{E}_{\pi}\left[\sum_aq_{\pi}(S_t,a)\nabla\pi(a|S_t,\mathbf{\theta})\right]\\<br>
&amp; = \mathbb{E}_{\pi}\left[\sum_aq_{\pi}(S_t,a)\pi(a|S_t,\mathbf{\theta})\frac{\nabla\pi(a|S_t,\mathbf{\theta})}{\pi(a|S_t,\mathbf{\theta})}\right]\\<br>
&amp; = \mathbb{E}_{\pi}\left[q_{\pi}(S_t,A_t)\frac{\nabla\pi(A_t|S_t,\mathbf{\theta})}{\pi(A_t|S_t,\mathbf{\theta})}\right]\\<br>
\end{align*}</p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mxxhcm.github.io/2019/03/23/dropout/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="马晓鑫爱马荟荟">
      <meta itemprop="description" content="记录硕士三年自己的积累">
      <meta itemprop="image" content="/images/favicon.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="mxxhcm's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/03/23/dropout/" class="post-title-link" itemprop="http://mxxhcm.github.io/page/14/index.html">神经网络-dropout</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-03-23 19:26:18" itemprop="dateCreated datePublished" datetime="2019-03-23T19:26:18+08:00">2019-03-23</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-05-07 00:22:27" itemprop="dateModified" datetime="2019-05-07T00:22:27+08:00">2019-05-07</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="dropou是干什么的">dropou是干什么的</h2>
<p>Dropout 是一种正则化技术，通过学习鲁棒的特征来防止过拟合。</p>
<h2 id="为什么会有过拟合">为什么会有过拟合</h2>
<p>如果输入和正确输出之间有很复杂的映射关系，而网络又有足够多的隐藏单元去正确的建模，那么通常会用很多组权重都能在训练集上得到好的结果。但是每一组权重在测试集上的结果都比训练集差，因为它们只在训练集上训练了，而没有在测试集上训练。</p>
<h2 id="什么是dropout">什么是dropout</h2>
<p>在网络中每一个隐藏单元的输出单元都有$0.5$的概率被忽略，所以每一个隐藏单元需要学会独立于其他的隐藏单元决定输出结果。</p>
<blockquote>
<p>This technique reduces complex co-adaptations of neurons, since a neuron cannot rely on the presence of particular other neurons. It is, therefore, forced to learn more robust features that are useful in conjunction with many different random subsets of the other neurons. [0]</p>
</blockquote>
<blockquote>
<p>On each presentation of each training case, each hidden unit is randomly omitted from the network with a probability of 0.5, so a hidden unit cannot rely on other hidden units being present.[1]</p>
</blockquote>
<blockquote>
<p>Dropout stops the mechanism of training neurons of any layers as a family, so reduces co-adaptability.[3]</p>
</blockquote>
<p>另一种方式可以把dropout看成对神经网络做平均。一种非常有效的减少测试误差的方法就是对一系列神经网络预测的结果取平均。理想的方式是训练很多个网络，然后分别在每个网络上进行测试，但是这样子的计算代价是很高的。随机的dropout让在合理的时间内训练大量不同的网络变得可能。当我们丢弃一个神经元的时候，它对loss函数没有任何贡献，所以在反向传播的时候，梯度为$0$，权值不会被更新。这就相当于我们对网络进行了一个下采样，训练过程的每次迭代中，采样网络的一部分进行训练，这样我们就得到了一个共享参数的集成模型。对于每一次训练，网络结构都是相同的，但是每次选择的参数都有很大可能是不同的，而且权重是共享的。</p>
<blockquote>
<p>The neurons which are “dropped out” in this way do not contribute to the forward pass and do not participate in backpropagation. So every time an input is presented, the neural network samples a different architecture, but all these architectures share weights.</p>
</blockquote>
<p>在测试的时候，使用&quot;mean networks&quot;，就是保留网络中所有的权重，但是要把激活函数的输出（activations)乘上$0.5$，因为相对训练的时候，每个神经元都有$0.5$的概率被激活，这个时候如果不乘上的话，最后就相当于测试的时候激活的神经元是训练时候的两倍。在实践中证明，这和对一系列经过dropout的网络取平均值的结果是很像的。（为什么就是两倍？）</p>
<blockquote>
<p>Dropout can also be thought of as an ensemble of models that share parameters. When we drop a neuron, it has no effect on the loss function and thus the gradient that flows through it during backpropagation is effectively zero and so its weights will not get updated. This means that we are basically subsampling a part of the neural network and we are training it on a single example. In every iteration of training, we will subsample a different part of the network and train that network on the datapoint at that point of time. Thus what we have essentially is an ensemble of models that share some parameters.[3]</p>
</blockquote>
<p>一个具有$N$个隐藏节点的网络，和一个用于计算类别标签的softmax输出层，使用mean networks就相当于对$2^N$个网络输出的标签概率做几何平均（并不是数学上的几何平均）。（为什么是几何平均？这里其实不是几何平均，只是一个等权重加权。）</p>
<blockquote>
<p>a) The authors of the referenced article don’t use the ‘geometric mean’ of the predictions, but “an equally weighted geometric mean” of them.<br>
b) They propose geometric mean over arithmetic mean for giving more value to more frequent data, probably according to the understanding by them of the underlying relations.<br>
If, for example, you take the arithmetic mean of ${10, 10, 100}$, you get $40$, but if you take their geometric mean you get $\sqrt[3]{10000} \approx 21.54$, meaning the ‘odd’ measurement ($100$) plays a smaller role to the mean.<br>
c) Even the geometric mean might be misleading, if the data are not assigned their true ‘weight’, meaning their occurrence or probability of occurrence, while assuring that this assignment of weights is equally important for all data.<br>
Hence “equally weighted geometric mean”.[2]</p>
</blockquote>
<p>如果采取dropout之后的网络输出不一样，那么mean network的输出能够保证赋值一个更高的可能性到正确标签。mean network的方根误差要比dropout网络方根误差的平均值要好，也就是说先对网络做平均然后计算误差要比先计算误差然后再平均要好。</p>
<p>实际上，$0.5$这个值不是固定的，可以根据不同情况进行微调。</p>
<h2 id="why-dropout-works">why dropout works</h2>
<p>其实这个和上面介绍中差不多，给出一种直观的解释。给一个例子[4]，有一个三层的神经网络，在下图中，红圈中的节点对于正确的输出起到了决定性的作用，在BP的过程中，它的权值不断增加，但是它可能在训练集上效果很好，但是测试集上很差。<br>
<img src="/2019/03/23/dropout/dropout_1.png" alt="dropout"><br>
当采用了dropout以后，我们随意丢弃一些节点，如果把上图的关键节点丢了，那么网络必须重新学习其他的节点，才能够正确的进行分类。如下图，网络必须在另外可能没有丢弃的三个节点中选择一个用于正确分类。所以，这样子上图中的关键节点的作用就会被减轻，在新数据集上的鲁棒性可能就会更好。<br>
<img src="/2019/03/23/dropout/dropout_2.png" alt="dropout"></p>
<h2 id="实现">实现</h2>
<h3 id="numpy-实现">numpy 实现</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(x, w1, w2, w3, training=False)</span>:</span></span><br><span class="line">  z1 = np.dot(x, w1)</span><br><span class="line">  y1 = np.tanh(z1)</span><br><span class="line"></span><br><span class="line">  z2 = np.dot(y1, w2)</span><br><span class="line">  y2 = np.dot(z2)</span><br><span class="line">  <span class="comment"># dropout in layer 2 </span></span><br><span class="line">  <span class="keyword">if</span> training:</span><br><span class="line">     m2 = np.random.binomial(<span class="number">1</span>, <span class="number">0.5</span>, size=z2.shape)</span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">     m2 = <span class="number">0.5</span></span><br><span class="line"></span><br><span class="line">  y2 *= m2</span><br><span class="line">  z3 = np.dot(y2, w3)</span><br><span class="line">  y3 = z3</span><br><span class="line">  <span class="keyword">return</span> y1, y2, y3, m2</span><br></pre></td></tr></table></figure>
<h3 id="pytorch库">pytorch库</h3>
<h2 id="参考文献">参考文献</h2>
<p>1.<a href="https://arxiv.org/pdf/1207.0580.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1207.0580.pdf</a><br>
2.<a href="https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf" target="_blank" rel="noopener">https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf</a><br>
3.<a href="https://www.quora.com/What-is-dropout-in-deep-learning" target="_blank" rel="noopener">https://www.quora.com/What-is-dropout-in-deep-learning</a><br>
4.<a href="https://www.quora.com/What-is-the-use-of-geometric-mean-in-dropout-neural-networks-It-says-that-by-approximating-an-equally-weighted-geometric-mean-of-the-predictions-of-an-exponential-number-of-learned-models-that-share-parameters" target="_blank" rel="noopener">https://www.quora.com/What-is-the-use-of-geometric-mean-in-dropout-neural-networks-It-says-that-by-approximating-an-equally-weighted-geometric-mean-of-the-predictions-of-an-exponential-number-of-learned-models-that-share-parameters</a><br>
5.<a href="https://www.quora.com/Why-exactly-does-dropout-in-deep-learning-work" target="_blank" rel="noopener">https://www.quora.com/Why-exactly-does-dropout-in-deep-learning-work</a><br>
6.<a href="https://www.quora.com/How-does-the-dropout-method-work-in-deep-learning-And-why-is-it-claimed-to-be-an-effective-trick-to-improve-your-network" target="_blank" rel="noopener">https://www.quora.com/How-does-the-dropout-method-work-in-deep-learning-And-why-is-it-claimed-to-be-an-effective-trick-to-improve-your-network</a><br>
7.<a href="https://pgaleone.eu/deep-learning/regularization/2017/01/10/anaysis-of-dropout/" target="_blank" rel="noopener">https://pgaleone.eu/deep-learning/regularization/2017/01/10/anaysis-of-dropout/</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mxxhcm.github.io/2019/03/21/python-matplotlib笔记/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="马晓鑫爱马荟荟">
      <meta itemprop="description" content="记录硕士三年自己的积累">
      <meta itemprop="image" content="/images/favicon.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="mxxhcm's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/03/21/python-matplotlib笔记/" class="post-title-link" itemprop="http://mxxhcm.github.io/page/14/index.html">matplotlib笔记</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-03-21 15:29:17" itemprop="dateCreated datePublished" datetime="2019-03-21T15:29:17+08:00">2019-03-21</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-07-08 10:26:38" itemprop="dateModified" datetime="2019-07-08T10:26:38+08:00">2019-07-08</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/python/" itemprop="url" rel="index"><span itemprop="name">python</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="show"><a href="#show" class="headerlink" title="show()"></a>show()</h2><h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p>show()函数是一个阻塞函数，调用该函数，显示当前已经绘制的图像，然后需要手动关闭打开的图像，程序才会继续执行。</p>
<h3 id="代码示例"><a href="#代码示例" class="headerlink" title="代码示例"></a>代码示例</h3><p><a href="https://github.com/mxxhcm/code/blob/master/tools/matplotlib/1_show.py" target="_blank" rel="noopener">代码地址</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x = np.arange(<span class="number">0</span>,<span class="number">10</span>,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">y1 = x**<span class="number">2</span></span><br><span class="line">y2 = <span class="number">2</span>*x +<span class="number">5</span></span><br><span class="line"></span><br><span class="line">plt.plot(x,y1)</span><br><span class="line">plt.savefig(<span class="string">"0_1.png"</span>)</span><br><span class="line">plt.show()  <span class="comment"># 调用show()会阻塞，然后关掉打开的图片，程序继续执行</span></span><br><span class="line"></span><br><span class="line">plt.plot(x,y2)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p>
<h2 id="savefig"><a href="#savefig" class="headerlink" title="savefig()"></a>savefig()</h2><h3 id="介绍-1"><a href="#介绍-1" class="headerlink" title="介绍"></a>介绍</h3><p>该文件接收一个参数，作为文件保存的路径。</p>
<h3 id="代码示例-1"><a href="#代码示例-1" class="headerlink" title="代码示例"></a>代码示例</h3><p><a href="https://github.com/mxxhcm/code/blob/master/tools/matplotlib/2_savefig.py" target="_blank" rel="noopener">代码地址</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x = np.arange(<span class="number">0</span>, <span class="number">10</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">y1 = x**<span class="number">2</span></span><br><span class="line">y2 = <span class="number">2</span>*x +<span class="number">5</span></span><br><span class="line"></span><br><span class="line">plt.plot(x,y1)</span><br><span class="line">plt.savefig(<span class="string">"2.png"</span>) <span class="comment"># 保存图像，名字为2.png</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p>
<h2 id="figure"><a href="#figure" class="headerlink" title="figure()"></a>figure()</h2><h3 id="介绍-2"><a href="#介绍-2" class="headerlink" title="介绍"></a>介绍</h3><p>figure()函数相当于生成一张画布。如果不显示调用的话，所有的图像都会绘制在默认的画布上。可以通过调用figure()函数将函数图像分开。figure()会接受几个参数，num是生成图片的序号，figsize指定图片的大小。</p>
<h3 id="代码示例-2"><a href="#代码示例-2" class="headerlink" title="代码示例"></a>代码示例</h3><p><a href="https://github.com/mxxhcm/code/blob/master/tools/matplotlib/3_figure.py" target="_blank" rel="noopener">代码地址</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x = np.arange(<span class="number">0</span>,<span class="number">10</span>,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">y1 = x**<span class="number">2</span></span><br><span class="line">y2 = <span class="number">2</span>*x +<span class="number">5</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># figure</span></span><br><span class="line">plt.figure()</span><br><span class="line">plt.plot(x,y1)</span><br><span class="line"></span><br><span class="line">plt.figure(num=<span class="number">6</span>,figsize=(<span class="number">10</span>,<span class="number">10</span>))</span><br><span class="line">plt.plot(x,y2)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p>
<h2 id="imshow"><a href="#imshow" class="headerlink" title="imshow()"></a>imshow()</h2><h3 id="介绍-3"><a href="#介绍-3" class="headerlink" title="介绍"></a>介绍</h3><p>该函数用来显示图像，接受一个图像矩阵。调用完该函数之后还需要调用show()函数。</p>
<h3 id="代码示例-3"><a href="#代码示例-3" class="headerlink" title="代码示例"></a>代码示例</h3><p><a href="https://github.com/mxxhcm/code/blob/master/tools/matplotlib/4_image.py" target="_blank" rel="noopener">代码地址</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">img = np.random.randint(<span class="number">0</span>, <span class="number">255</span>, [<span class="number">32</span>, <span class="number">32</span>])</span><br><span class="line">print(img.shape)</span><br><span class="line"></span><br><span class="line">plt.imshow(img)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p>
<h2 id="subplot"><a href="#subplot" class="headerlink" title="subplot()"></a>subplot()</h2><h3 id="介绍-4"><a href="#介绍-4" class="headerlink" title="介绍"></a>介绍</h3><p>绘制$m\times n$个子图</p>
<h3 id="代码示例-4"><a href="#代码示例-4" class="headerlink" title="代码示例"></a>代码示例</h3><p><a href="https://github.com/mxxhcm/code/blob/master/tools/matplotlib/5_subplot.py" target="_blank" rel="noopener">代码地址</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x = np.arange(<span class="number">0</span>, <span class="number">10</span>, <span class="number">1</span>)</span><br><span class="line">y1 = <span class="number">2</span> * x</span><br><span class="line">y2 = <span class="number">3</span> * x</span><br><span class="line">y3 = <span class="number">4</span> * x</span><br><span class="line">y4 = <span class="number">5</span> * x</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">plt.plot(x, y1, marker=<span class="string">'s'</span>, lw=<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">plt.plot(x, y2, ls=<span class="string">'-.'</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">plt.plot(x, y3, color=<span class="string">'r'</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">4</span>)</span><br><span class="line">plt.plot(x, y4, ms=<span class="number">10</span>, marker=<span class="string">'o'</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p>
<h2 id="subplots"><a href="#subplots" class="headerlink" title="subplots()"></a>subplots()</h2><h3 id="介绍-5"><a href="#介绍-5" class="headerlink" title="介绍"></a>介绍</h3><p>将一张图分成$m\times n$个子图。</p>
<h3 id="代码示例-5"><a href="#代码示例-5" class="headerlink" title="代码示例"></a>代码示例</h3><p><a href="https://github.com/mxxhcm/code/blob/master/tools/matplotlib/6_subplots.py" target="_blank" rel="noopener">代码地址</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">figure,axes = plt.subplots(<span class="number">2</span>, <span class="number">3</span>, figsize=[<span class="number">40</span>,<span class="number">20</span>])</span><br><span class="line">axes = axes.flatten()</span><br><span class="line"></span><br><span class="line">x = np.arange(<span class="number">0</span>, <span class="number">20</span>) </span><br><span class="line">y1 = pow(x, <span class="number">2</span>)</span><br><span class="line">axes[<span class="number">0</span>].plot(x, y1) </span><br><span class="line"></span><br><span class="line">y5 = pow(x, <span class="number">3</span>)</span><br><span class="line">axes[<span class="number">5</span>].plot(x, y5) </span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p>
<h2 id="ax"><a href="#ax" class="headerlink" title="ax()"></a>ax()</h2><h3 id="介绍-6"><a href="#介绍-6" class="headerlink" title="介绍"></a>介绍</h3><p>获得当前figure的坐标轴，用来绘制。</p>
<h3 id="代码示例-6"><a href="#代码示例-6" class="headerlink" title="代码示例"></a>代码示例</h3><p><a href="https://github.com/mxxhcm/code/blob/master/tools/matplotlib/7_axes.py" target="_blank" rel="noopener">代码地址</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x = np.arange(<span class="number">-3.5</span>,<span class="number">3.5</span>,<span class="number">0.5</span>)</span><br><span class="line">y1 = np.abs(<span class="number">2</span> * x)</span><br><span class="line">y2 = np.abs(x)</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">10</span>))</span><br><span class="line">ax = plt.gca() <span class="comment"># gca = get current axis</span></span><br><span class="line">ax.spines[<span class="string">'right'</span>].set_color(<span class="string">'none'</span>)</span><br><span class="line">ax.spines[<span class="string">'top'</span>].set_color(<span class="string">'red'</span>)</span><br><span class="line">ax.xaxis.set_ticks_position(<span class="string">"bottom"</span>)</span><br><span class="line">ax.yaxis.set_ticks_position(<span class="string">"left"</span>)</span><br><span class="line">ax.spines[<span class="string">'bottom'</span>].set_position((<span class="string">'data'</span>,<span class="number">0</span>))</span><br><span class="line">ax.spines[<span class="string">'left'</span>].set_position((<span class="string">'data'</span>,<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># both work</span></span><br><span class="line">ax.plot(x,y1,lw=<span class="number">2</span>,marker=<span class="string">'-'</span>,ms=<span class="number">8</span>)</span><br><span class="line">plt.plot(x,y2,lw=<span class="number">3</span>,marker=<span class="string">'^'</span>,ms=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># xlim and ylim</span></span><br><span class="line"><span class="comment"># ax.xlim([-3.8, 3.3])</span></span><br><span class="line"><span class="comment"># AttributeError: 'AxesSubplot' object has no attribute 'xlim'</span></span><br><span class="line">plt.xlim([<span class="number">-3.8</span>, <span class="number">3.3</span>])</span><br><span class="line">plt.ylim([<span class="number">0</span>, <span class="number">7.2</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># xlabel and ylabel</span></span><br><span class="line"><span class="comment"># ax.xlabel('x',fontsize=20)</span></span><br><span class="line"><span class="comment"># AttributeError: 'AxesSubplot' object has no attribute 'xlabel'</span></span><br><span class="line">plt.xlabel(<span class="string">'x'</span>,fontsize=<span class="number">20</span>)</span><br><span class="line">plt.ylabel(<span class="string">'y = 2x '</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># xticklabel and yticaklabel</span></span><br><span class="line"><span class="comment"># ax.xticks(x,('a','b','c','d','e','f','g','h','i','j','k','l','m','n'),fontsize=20)</span></span><br><span class="line"><span class="comment"># AttributeError: 'AxesSubplot' object has no attribute 'xticks'</span></span><br><span class="line">plt.xticks(x,(<span class="string">'a'</span>,<span class="string">'b'</span>,<span class="string">'c'</span>,<span class="string">'d'</span>,<span class="string">'e'</span>,<span class="string">'f'</span>,<span class="string">'g'</span>,<span class="string">'h'</span>,<span class="string">'i'</span>,<span class="string">'j'</span>,<span class="string">'k'</span>,<span class="string">'l'</span>,<span class="string">'m'</span>,<span class="string">'n'</span>),fontsize=<span class="number">20</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># both work</span></span><br><span class="line">ax.legend([<span class="string">'t1'</span>,<span class="string">'t2'</span>])</span><br><span class="line">plt.legend([<span class="string">'y1'</span>,<span class="string">'y2'</span>])</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p>
<h2 id="ion-和ioff"><a href="#ion-和ioff" class="headerlink" title="ion()和ioff()"></a>ion()和ioff()</h2><h3 id="介绍-7"><a href="#介绍-7" class="headerlink" title="介绍"></a>介绍</h3><p>交互式绘图，可以在一张图上不断的更新。</p>
<h3 id="代码示例-7"><a href="#代码示例-7" class="headerlink" title="代码示例"></a>代码示例</h3><p><a href="https://github.com/mxxhcm/code/blob/master/tools/matplotlib/8_plt_ion_ioff.py" target="_blank" rel="noopener">代码地址</a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">count = 1</span><br><span class="line">flag = True</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">ax = plt.gca()</span><br><span class="line">x = np.arange(20)</span><br><span class="line">plt.figure()</span><br><span class="line">ax2 = plt.gca()</span><br><span class="line"></span><br><span class="line">while flag:</span><br><span class="line">    plt.ion()</span><br><span class="line">    y = pow(x[:count], 2)</span><br><span class="line">    temp = x[:count]</span><br><span class="line">    ax.plot(temp, y, linewidth=1)</span><br><span class="line">    plt.pause(1)</span><br><span class="line">    plt.ioff()</span><br><span class="line"></span><br><span class="line">    ax2.plot(x, x+count)</span><br><span class="line">    count += 1</span><br><span class="line">    if count &gt; 20:</span><br><span class="line">        break</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p>
<h2 id="seanborn"><a href="#seanborn" class="headerlink" title="seanborn"></a>seanborn</h2><h3 id="介绍-8"><a href="#介绍-8" class="headerlink" title="介绍"></a>介绍</h3><p>对matplotlib进行了一层封装</p>
<h3 id="代码示例-8"><a href="#代码示例-8" class="headerlink" title="代码示例"></a>代码示例</h3><p><a href="https://github.com/mxxhcm/code/blob/master/tools/matplotlib/9_seanborn.py" target="_blank" rel="noopener">代码地址</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">values = np.zeros((<span class="number">21</span>,<span class="number">21</span>), dtype=np.int)</span><br><span class="line">fig, axes = plt.subplots(<span class="number">2</span>, <span class="number">3</span>, figsize=(<span class="number">40</span>,<span class="number">20</span>))</span><br><span class="line">plt.subplots_adjust(wspace=<span class="number">0.1</span>, hspace=<span class="number">0.2</span>)</span><br><span class="line">axes = axes.flatten()</span><br><span class="line"></span><br><span class="line"><span class="comment"># cmap is the paramter to specify color type, ax is the parameter to specify where to show the picture</span></span><br><span class="line"><span class="comment"># np.flipud(matrix), flip the column in the up/down direction, rows are preserved</span></span><br><span class="line">figure = sns.heatmap(np.flipud(values), cmap=<span class="string">"YlGnBu"</span>, ax=axes[<span class="number">0</span>])</span><br><span class="line">figure.set_xlabel(<span class="string">"cars at second location"</span>, fontsize=<span class="number">30</span>)</span><br><span class="line">figure.set_title(<span class="string">"policy"</span>, fontsize=<span class="number">30</span>)</span><br><span class="line">figure.set_ylabel(<span class="string">"cars at first location"</span>, fontsize=<span class="number">30</span>)</span><br><span class="line">figure.set_yticks(list(reversed(range(<span class="number">21</span>))))</span><br><span class="line"></span><br><span class="line">figure = sns.heatmap(np.flipud(values), ax=axes[<span class="number">1</span>])</span><br><span class="line">figure.set_ylabel(<span class="string">"cars at first location"</span>, fontsize=<span class="number">30</span>)</span><br><span class="line">figure.set_yticks(list(reversed(range(<span class="number">21</span>))))</span><br><span class="line">figure.set_title(<span class="string">"policy"</span>, fontsize=<span class="number">30</span>)</span><br><span class="line">figure.set_xlabel(<span class="string">"cars at second location"</span>, fontsize=<span class="number">30</span>)</span><br><span class="line"></span><br><span class="line">plt.savefig(<span class="string">"hello.pdf"</span>)</span><br><span class="line">plt.show()</span><br><span class="line">plt.close()</span><br></pre></td></tr></table></figure></p>
<h2 id="color"><a href="#color" class="headerlink" title="color"></a>color</h2><h3 id="介绍-9"><a href="#介绍-9" class="headerlink" title="介绍"></a>介绍</h3><p>指定线条的颜色，用color=’’实现。常见的颜色有：’b’, ‘g’, ‘r’, ‘c’, ‘m’, ‘y’, ‘k’, ‘w’。</p>
<h3 id="代码示例-9"><a href="#代码示例-9" class="headerlink" title="代码示例"></a>代码示例</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">color = [<span class="string">'b'</span>, <span class="string">'g'</span>, <span class="string">'r'</span>, <span class="string">'c'</span>, <span class="string">'m'</span>, <span class="string">'y'</span>, <span class="string">'k'</span>, <span class="string">'w'</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(color)):</span><br><span class="line">    x = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>])</span><br><span class="line">    y = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>])</span><br><span class="line">    plt.plot(x, y+i, color=color[i])</span><br><span class="line"></span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.plot(range(<span class="number">10</span>), range(<span class="number">10</span>), color=<span class="string">'w'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h3 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h3><p>color=’w’，’w’是white，所以画出来的图你是看不到的。。。这困扰了我好久。。。。</p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mxxhcm.github.io/2019/03/18/python-pandas笔记/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="马晓鑫爱马荟荟">
      <meta itemprop="description" content="记录硕士三年自己的积累">
      <meta itemprop="image" content="/images/favicon.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="mxxhcm's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/03/18/python-pandas笔记/" class="post-title-link" itemprop="http://mxxhcm.github.io/page/14/index.html">pandas笔记</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-03-18 15:15:54" itemprop="dateCreated datePublished" datetime="2019-03-18T15:15:54+08:00">2019-03-18</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-08-16 16:59:53" itemprop="dateModified" datetime="2019-08-16T16:59:53+08:00">2019-08-16</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/python/" itemprop="url" rel="index"><span itemprop="name">python</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="pd-read"><a href="#pd-read" class="headerlink" title="pd.read_*()"></a>pd.read_<em>*</em>()</h2><h3 id="pd-read-csv"><a href="#pd-read-csv" class="headerlink" title="pd.read_csv()"></a>pd.read_csv()</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas</span><br><span class="line">pandas.read_csv(filepath_or_buffer, sep=<span class="string">', '</span>, delimiter=<span class="literal">None</span>, header=<span class="string">'infer'</span>, names=<span class="literal">None</span>, index_col=<span class="literal">None</span>, usecols=<span class="literal">None</span>, squeeze=<span class="literal">False</span>, prefix=<span class="literal">None</span>, mangle_dupe_cols=<span class="literal">True</span>, dtype=<span class="literal">None</span>, engine=<span class="literal">None</span>, converters=<span class="literal">None</span>, true_values=<span class="literal">None</span>, false_values=<span class="literal">None</span>, skipinitialspace=<span class="literal">False</span>, skiprows=<span class="literal">None</span>, nrows=<span class="literal">None</span>, na_values=<span class="literal">None</span>, keep_default_na=<span class="literal">True</span>, na_filter=<span class="literal">True</span>, verbose=<span class="literal">False</span>, skip_blank_lines=<span class="literal">True</span>, parse_dates=<span class="literal">False</span>, infer_datetime_format=<span class="literal">False</span>, keep_date_col=<span class="literal">False</span>, date_parser=<span class="literal">None</span>, dayfirst=<span class="literal">False</span>, iterator=<span class="literal">False</span>, chunksize=<span class="literal">None</span>, compression=<span class="string">'infer'</span>, thousands=<span class="literal">None</span>, decimal=<span class="string">b'.'</span>, lineterminator=<span class="literal">None</span>, quotechar=<span class="string">'"'</span>, quoting=<span class="number">0</span>, escapechar=<span class="literal">None</span>, comment=<span class="literal">None</span>, encoding=<span class="literal">None</span>, dialect=<span class="literal">None</span>, tupleize_cols=<span class="literal">None</span>, error_bad_lines=<span class="literal">True</span>, warn_bad_lines=<span class="literal">True</span>, skipfooter=<span class="number">0</span>, skip_footer=<span class="number">0</span>, doublequote=<span class="literal">True</span>, delim_whitespace=<span class="literal">False</span>, as_recarray=<span class="literal">None</span>, compact_ints=<span class="literal">None</span>, use_unsigned=<span class="literal">None</span>, low_memory=<span class="literal">True</span>, buffer_lines=<span class="literal">None</span>, memory_map=<span class="literal">False</span>, float_precision=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<p>filepath_or_buffer: 文件路径，或者一个字符串，url等等<br>sep: str,分隔符，默认是’,’<br>delimiter: str,定界符，如果指定该参数，sep参数失效<br>delimiter_whitespace: boolean,指定是否吧空格作为分界符如果指定该参数，则delimiter失效<br>header: int or list of ints,指定列名字，默认是header=0,表示把第一行当做列名，如果header=[0,3,4],表示吧第0,3,4行都当做列名，真正的数据从第二行开始，如果没有列名，指定header=None<br>index_col: int or sequence or False,指定哪几列作为index，index_col=[0,1],表示用前两列的值作为一个index，去访问后面几列的值。<br>prefix: str,如果header为None的话，可以指定列名。<br>parse_dates: boolean or list of ints or names,or list of lists, or dict 如果是True，解析index，如果是list of ints，把每一个int代表的列都分别当做一个日期解析，如果是list of lists，将list中的list作为一个日期解析，如果是字典的话，将dict中key作为一个新的列名，value为这个新的列的值。<br>keep_date_col: boolean,如果parser_dates中是将多个列合并为一个日期的话，是否保留原始列<br>date_parser: function,用来解析parse_dates中给出的日期列，是自己写的函数，函数参数个数和一个日期的列数相同。</p>
<p>chunksize: 如果文件太大的话，分块读入<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">data = pd.read_csv(<span class="string">"input.csv"</span>,chunksize=<span class="number">1000</span>)</span><br><span class="line"><span class="keyword">for</span>  i  <span class="keyword">in</span>  data:</span><br><span class="line">  ...</span><br></pre></td></tr></table></figure></p>
<h2 id="DataFrame"><a href="#DataFrame" class="headerlink" title="DataFrame"></a>DataFrame</h2><h3 id="声明一个DataFrame"><a href="#声明一个DataFrame" class="headerlink" title="声明一个DataFrame"></a>声明一个DataFrame</h3><p>data = pandas.DataFrame(numpy.arange(16).reshape(4,4),index=list(‘abcd’),columns=(‘wxyz’)<br>    w  x  y  z<br>a  0  1  2  3<br>b  4  5  6  7<br>c  8  9  10  11<br>d  12  13  14  15<br>index 是index列的值<br>columns 是列名</p>
<h3 id="访问某一列"><a href="#访问某一列" class="headerlink" title="访问某一列"></a>访问某一列</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">data = pandas.DataFrame(numpy.arange(<span class="number">16</span>).reshape(<span class="number">4</span>,<span class="number">4</span>),index=list(<span class="string">'abcd'</span>),columns=(<span class="string">'wxyz'</span>)</span><br><span class="line">data[<span class="string">'w'</span>]</span><br><span class="line">data.w</span><br></pre></td></tr></table></figure>
<h3 id="写入某一列"><a href="#写入某一列" class="headerlink" title="写入某一列"></a>写入某一列</h3><p>只能先访问列 再访问行<br>data[‘w’] = []   # =左右两边shape必须一样<br>data[‘w’][0]  #某一列的第0行</p>
<h3 id="groupby"><a href="#groupby" class="headerlink" title="groupby"></a>groupby</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">data = pandas.DataFrame(np.arange(<span class="number">16</span>).reshape(<span class="number">4</span>,<span class="number">4</span>),index=list(<span class="string">'abcd'</span>),columns=(<span class="string">'wxyz'</span>))</span><br><span class="line"><span class="keyword">for</span> key,value <span class="keyword">in</span> data.groupby(<span class="string">"w"</span>):  <span class="comment"># group by 列名什么的，就是说某一列的值一样分一组</span></span><br><span class="line">  value = value.values  <span class="comment"># value是一个numpy数组</span></span><br><span class="line">  value_list = value.tolist()  <span class="comment">#将numpy数组转换为一个list</span></span><br><span class="line">  <span class="keyword">for</span> single_list <span class="keyword">in</span> value_list:</span><br><span class="line">     single_list = str(single_list)</span><br><span class="line">     ...</span><br></pre></td></tr></table></figure>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mxxhcm.github.io/2019/03/18/python-argparse笔记/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="马晓鑫爱马荟荟">
      <meta itemprop="description" content="记录硕士三年自己的积累">
      <meta itemprop="image" content="/images/favicon.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="mxxhcm's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/03/18/python-argparse笔记/" class="post-title-link" itemprop="http://mxxhcm.github.io/page/14/index.html">argparse笔记</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-03-18 15:15:41" itemprop="dateCreated datePublished" datetime="2019-03-18T15:15:41+08:00">2019-03-18</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-06-26 11:27:59" itemprop="dateModified" datetime="2019-06-26T11:27:59+08:00">2019-06-26</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/python/" itemprop="url" rel="index"><span itemprop="name">python</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="简单的例子"><a href="#简单的例子" class="headerlink" title="简单的例子"></a>简单的例子</h2><h3 id="创建一个parser"><a href="#创建一个parser" class="headerlink" title="创建一个parser"></a>创建一个parser</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">parser = argparse.ArgumentParser(description=<span class="string">'Process Intergers'</span>)</span><br></pre></td></tr></table></figure>
<h3 id="添加参数"><a href="#添加参数" class="headerlink" title="添加参数"></a>添加参数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">parser.add_argument(,,)</span><br></pre></td></tr></table></figure>
<h3 id="解析参数"><a href="#解析参数" class="headerlink" title="解析参数"></a>解析参数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">arglist = parser.parse_args()</span><br></pre></td></tr></table></figure>
<h3 id="代码示例"><a href="#代码示例" class="headerlink" title="代码示例"></a>代码示例</h3><p>完整代码如下<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_args</span><span class="params">()</span>:</span></span><br><span class="line">    parser = argparse.ArgumentParser(<span class="string">"input parameters"</span>)</span><br><span class="line">    parser.add_argument(<span class="string">"--batch_size"</span>, type=int, default=<span class="number">32</span>)</span><br><span class="line">    parser.add_argument(<span class="string">"--episodes"</span>, type=int, default=<span class="number">1</span>)</span><br><span class="line">    parser.add_argument(<span class="string">"--lr"</span>, type=float, default=<span class="number">0.01</span>)</span><br><span class="line">    parser.add_argument(<span class="string">"--momentum"</span>, type=float, default=<span class="number">0.9</span>)</span><br><span class="line">    args_list = parser.parse_args()</span><br><span class="line">    <span class="keyword">return</span> args_list</span><br><span class="line"></span><br><span class="line">	</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(args_list)</span>:</span></span><br><span class="line">	print(args_list.batch_size)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    args_list = parse_args()</span><br><span class="line">    main(args_list)</span><br></pre></td></tr></table></figure></p>
<h2 id="ArgumentParser-objects"><a href="#ArgumentParser-objects" class="headerlink" title="ArgumentParser objects"></a>ArgumentParser objects</h2><blockquote>
<p>The ArgumentParser object will hold all the information necessary to parse the command line into python data types</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">argparse</span>.<span class="title">ArgumentParser</span><span class="params">(</span></span></span><br><span class="line"><span class="class"><span class="params">	prog=None,</span></span></span><br><span class="line"><span class="class"><span class="params">	usage=None,</span></span></span><br><span class="line"><span class="class"><span class="params">	description=None,</span></span></span><br><span class="line"><span class="class"><span class="params">	epilog=None,</span></span></span><br><span class="line"><span class="class"><span class="params">	parents=[],</span></span></span><br><span class="line"><span class="class"><span class="params">	formatter_class=argparse.HelpFormatter,</span></span></span><br><span class="line"><span class="class"><span class="params">	prefix_chars=<span class="string">'-'</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">	fromfile_prefix_chars=None,</span></span></span><br><span class="line"><span class="class"><span class="params">	argument_default=None,</span></span></span><br><span class="line"><span class="class"><span class="params">	conflict_handler=<span class="string">'error'</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">	add_help=True</span></span></span><br><span class="line"><span class="class"><span class="params">)</span></span></span><br></pre></td></tr></table></figure>
<h3 id="创建一个名为test-py的程序如下"><a href="#创建一个名为test-py的程序如下" class="headerlink" title="创建一个名为test.py的程序如下"></a>创建一个名为test.py的程序如下</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">args = parser.parse_args()</span><br></pre></td></tr></table></figure>
<p>~#:python test.py -h</p>
<blockquote>
<p>usage: test.py [-h]<br>optional arguments:<br>  -h, —help  show this help message and exit</p>
</blockquote>
<h3 id="prog参数"><a href="#prog参数" class="headerlink" title="prog参数"></a>prog参数</h3><p>设置显示程序的名称</p>
<h4 id="直接使用默认显示的程序名"><a href="#直接使用默认显示的程序名" class="headerlink" title="直接使用默认显示的程序名"></a>直接使用默认显示的程序名</h4><p>~#:python test.py -h</p>
<blockquote>
<p>usage: test.py [-h]<br>optional arguments:<br>  -h, —help  show this help message and exit</p>
</blockquote>
<h4 id="使用prog参数进行设置"><a href="#使用prog参数进行设置" class="headerlink" title="使用prog参数进行设置"></a>使用prog参数进行设置</h4><p>修改test.py的程序如下<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser(prog=<span class="string">"mytest"</span>)</span><br><span class="line">args = parser.parse_args()</span><br></pre></td></tr></table></figure></p>
<p>~#:python test.py -h</p>
<blockquote>
<p>usage: mytest [-h]<br> optional arguments:<br>  -h, —help  show this help message and exit</p>
</blockquote>
<p>usage后的名称变为我们prog参数指定的名称</p>
<h3 id="usage"><a href="#usage" class="headerlink" title="usage"></a>usage</h3><h4 id="使用默认的usage"><a href="#使用默认的usage" class="headerlink" title="使用默认的usage"></a>使用默认的usage</h4><h4 id="使用指定的usage"><a href="#使用指定的usage" class="headerlink" title="使用指定的usage"></a>使用指定的usage</h4><h3 id="description"><a href="#description" class="headerlink" title="description"></a>description</h3><h4 id="使用默认的description"><a href="#使用默认的description" class="headerlink" title="使用默认的description"></a>使用默认的description</h4><h4 id="使用指定的description"><a href="#使用指定的description" class="headerlink" title="使用指定的description"></a>使用指定的description</h4><h3 id="epilog"><a href="#epilog" class="headerlink" title="epilog"></a>epilog</h3><h4 id="使用默认的epilog"><a href="#使用默认的epilog" class="headerlink" title="使用默认的epilog"></a>使用默认的epilog</h4><h4 id="使用指定的epilog"><a href="#使用指定的epilog" class="headerlink" title="使用指定的epilog"></a>使用指定的epilog</h4><h3 id="parents"><a href="#parents" class="headerlink" title="parents"></a>parents</h3><h3 id="formatter-class"><a href="#formatter-class" class="headerlink" title="formatter_class"></a>formatter_class</h3><h3 id="prefix-chars"><a href="#prefix-chars" class="headerlink" title="prefix_chars"></a>prefix_chars</h3><p>指定其他的prefix，默认的是-，比如可以指定可选参数的前缀为+</p>
<h3 id="fromfile-prefix-chars"><a href="#fromfile-prefix-chars" class="headerlink" title="fromfile_prefix_chars"></a>fromfile_prefix_chars</h3><h3 id="argument-default"><a href="#argument-default" class="headerlink" title="argument_default"></a>argument_default</h3><h3 id="conflict-handler"><a href="#conflict-handler" class="headerlink" title="conflict_handler"></a>conflict_handler</h3><p>将conflict_handler设置为resolve就可以防止override原来older arguments<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser(conflict_handler=<span class="string">'resolve'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'--foo'</span>,<span class="string">'-f'</span>,help=<span class="string">"old help"</span>)</span><br><span class="line">parser.add_argument(<span class="string">'-f'</span>,help=<span class="string">"new_help"</span>)</span><br><span class="line">parser.print_help()</span><br></pre></td></tr></table></figure></p>
<h3 id="add-help"><a href="#add-help" class="headerlink" title="add_help"></a>add_help</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser(add_help=<span class="literal">False</span>)</span><br><span class="line">parser.print_help()</span><br></pre></td></tr></table></figure>
<p>输出</p>
<blockquote>
<p>usage: [-h]<br> optional arguments:<br>  -h, —help  show this help message and exit<br>将add_help设置为false</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser(add_help=<span class="literal">False</span>)</span><br><span class="line">parser.print_help()</span><br></pre></td></tr></table></figure>
<p>输出</p>
<blockquote>
<p>usage: </p>
</blockquote>
<h2 id="The-add-argument-method"><a href="#The-add-argument-method" class="headerlink" title="The add_argument() method"></a>The add_argument() method</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">ArgumentParser.add_argument(</span><br><span class="line">	name <span class="keyword">or</span> flags...</span><br><span class="line">	[,action],</span><br><span class="line">	[,nargs],</span><br><span class="line">	[,const],</span><br><span class="line">	[,default],</span><br><span class="line">	[,type],</span><br><span class="line">	[,choices],</span><br><span class="line">	[,required],</span><br><span class="line">	[,help],</span><br><span class="line">	[,metavar],</span><br><span class="line">	[,dest]</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h3 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">'-f'</span>,<span class="string">'-foo'</span>,<span class="string">'-a'</span>, defaults=, type=, help=)</span><br><span class="line">parser.add_argument(<span class="string">'hello'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'hi'</span>)</span><br><span class="line">args = parser.parse_args([<span class="string">'Hello'</span>,<span class="string">'-f'</span>,<span class="string">'123'</span>,<span class="string">'Hi'</span>])</span><br><span class="line">print(args)</span><br></pre></td></tr></table></figure>
<h3 id="name-or-flags"><a href="#name-or-flags" class="headerlink" title="name or flags"></a>name or flags</h3><h4 id="添加可选参数"><a href="#添加可选参数" class="headerlink" title="添加可选参数"></a>添加可选参数</h4><p>parser.add_argument(‘-f’, ‘—foo’, ‘-fooo’)</p>
<h4 id="添加必选参数"><a href="#添加必选参数" class="headerlink" title="添加必选参数"></a>添加必选参数</h4><p>parser.add_argument(‘bar’)</p>
<h4 id="调用parse-args"><a href="#调用parse-args" class="headerlink" title="调用parse_args()"></a>调用parse_args()</h4><p>当parse_args()函数被调用的时候，可选参数会被-prefix所识别，剩下的参数会被分配给必选参数的位置。如下代码中，’3’对应的就是’hello’的参数，’this is hi’对应的就是’hi’的参数，而’123’是’-f’的参数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">'-f'</span>,<span class="string">'-foo'</span>,<span class="string">'-a'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'hello'</span>, type=int)</span><br><span class="line">parser.add_argument(<span class="string">'hi'</span>)</span><br><span class="line">args = parser.parse_args([<span class="string">'3'</span>,<span class="string">'-f'</span>,<span class="string">'123'</span>,<span class="string">'this is hi'</span>])</span><br><span class="line">print(args)</span><br></pre></td></tr></table></figure>
<p>输出</p>
<blockquote>
<p>Namespace(f=’123’, hello=’Hello’, hi=’Hi’)</p>
</blockquote>
<h3 id="action"><a href="#action" class="headerlink" title="action"></a>action</h3><h4 id="store-the-default-action"><a href="#store-the-default-action" class="headerlink" title="store,the default action"></a>store,the default action</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">'--foo'</span>)</span><br><span class="line">args = parser.parse_args([<span class="string">'--foo'</span>,<span class="string">'1'</span>])</span><br><span class="line">print(args)</span><br></pre></td></tr></table></figure>
<p>输出</p>
<blockquote>
<p>Namespace(foo=’1’)</p>
</blockquote>
<h4 id="store-const"><a href="#store-const" class="headerlink" title="store_const"></a>store_const</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">'--foo'</span>, action=<span class="string">'store_const'</span>, const=<span class="number">42</span>)</span><br><span class="line">args = parser.parse_args([<span class="string">'--foo'</span>)</span><br><span class="line">print(args)</span><br></pre></td></tr></table></figure>
<p>输出</p>
<blockquote>
<p>Namespace(foo=42)</p>
</blockquote>
<h4 id="store-true-and-store-false"><a href="#store-true-and-store-false" class="headerlink" title="store_true and store_false"></a>store_true and store_false</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">'--foo'</span>, action=<span class="string">'store_true'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'--bar'</span>, action=<span class="string">'store_false'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'--baz'</span>, action=<span class="string">'store_false'</span>)</span><br><span class="line">args = parser.parse_args(<span class="string">'--foo --bar'</span>.split())</span><br><span class="line">print(args)</span><br></pre></td></tr></table></figure>
<p>输出</p>
<blockquote>
<p>Namespace(bar=False, baz=True, foo=True)</p>
</blockquote>
<p>这里为什么是这样呢，因为默认存储的都是True，当你调用—bar,—foo参数时，会执行action操作，会把action指定的动作执行</p>
<h4 id="d-append"><a href="#d-append" class="headerlink" title="d.append"></a>d.append</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">'--foo'</span>, action=<span class="string">'append'</span>)</span><br><span class="line">args = parser.parse_args(<span class="string">'--foo 1 --foo 2 --foo 3'</span>.split())</span><br><span class="line">print(args)</span><br></pre></td></tr></table></figure>
<p>输出</p>
<blockquote>
<p>Namespace(foo=[‘1’, ‘2’, ‘3’])</p>
</blockquote>
<h4 id="append-const"><a href="#append-const" class="headerlink" title="append_const"></a>append_const</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">'--str'</span>, action=<span class="string">'append_const'</span>,const=str)</span><br><span class="line">parser.add_argument(<span class="string">'--int'</span>, action=<span class="string">'append_const'</span>,const=int)</span><br><span class="line">args = parser.parse_args(<span class="string">'--str --int'</span>.split())</span><br><span class="line">print(args)</span><br></pre></td></tr></table></figure>
<p>输出</p>
<blockquote>
<p>Namespace(int=[<class 'int'>], str=[<class 'str'>])</class></class></p>
</blockquote>
<h4 id="count"><a href="#count" class="headerlink" title="count"></a>count</h4><p>统计一个keyword argument出现了多少次<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">'--co'</span>, <span class="string">'-c'</span>,action=<span class="string">'count'</span>)</span><br><span class="line">args = parser.parse_args([<span class="string">'-ccc'</span>])</span><br><span class="line">print(args)</span><br></pre></td></tr></table></figure></p>
<p>输出</p>
<blockquote>
<p>Namespace(co=3)</p>
</blockquote>
<h4 id="help"><a href="#help" class="headerlink" title="help"></a>help</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">args = parser.parse_args(<span class="string">'--help'</span>.split())</span><br><span class="line">print(args)</span><br></pre></td></tr></table></figure>
<p>输出，如果是交互式环境的话，会退出python</p>
<blockquote>
<p>usage: [-h]</p>
<p>optional arguments:<br>  -h, —help  show this help message and exit</p>
</blockquote>
<h4 id="version"><a href="#version" class="headerlink" title="version"></a>version</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">'--version'</span>, action=<span class="string">'version'</span>,version=<span class="string">'version 3'</span>)</span><br><span class="line">args = parser.parse_args(<span class="string">'--version'</span>.split())</span><br><span class="line">print(args)</span><br></pre></td></tr></table></figure>
<p>输出,如果是交互式环境的话，会退出python</p>
<blockquote>
<p>version 3</p>
</blockquote>
<h3 id="nargs-指定参数个数"><a href="#nargs-指定参数个数" class="headerlink" title="nargs 指定参数个数"></a>nargs 指定参数个数</h3><h4 id="N"><a href="#N" class="headerlink" title="N"></a>N</h4><p>如果是可选参数的话，或者不指定这个参数，或者必须指定N个参数<br>如果是必选参数的话，必须指定N个参数，不能多也不能少，也不能为0个<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">'--foo'</span>,nargs=<span class="number">3</span>)</span><br><span class="line">parser.add_argument(<span class="string">'bar'</span>,nargs=<span class="number">4</span>)</span><br><span class="line">args = parser.parse_args(<span class="string">'bar 3 4 5'</span>.split())</span><br><span class="line">print(args)</span><br></pre></td></tr></table></figure></p>
<p>输出</p>
<blockquote>
<p>Namespace(bar=[‘bar’, ‘3’, ‘4’, ‘5’], foo=None)</p>
</blockquote>
<h4 id><a href="#" class="headerlink" title="?"></a>?</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">'--foo'</span>,nargs=<span class="string">'?'</span>,const=<span class="string">'c'</span>,default=<span class="string">'d'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'bar'</span>,nargs=<span class="string">'?'</span>,default=<span class="string">'d'</span>)</span><br><span class="line">args = parser.parse_args(<span class="string">'3'</span>.split())</span><br><span class="line">print(args)</span><br><span class="line">args = parser.parse_args(<span class="string">'3 --foo'</span>.split())</span><br><span class="line">print(args)</span><br></pre></td></tr></table></figure>
<p>输出</p>
<blockquote>
<p>Namespace(bar=’3’, foo=’d’)<br>Namespace(bar=’3’, foo=’c’)</p>
</blockquote>
<p>如果显式指定可选参数，但是不给它参数，那么如果有const的话，就会显示const的值，否则就会显示None</p>
<h4 id="-1"><a href="#-1" class="headerlink" title="*"></a>*</h4><p>nargs设置为*的话，不能直接用const=’’来设置const参数，需要使用其他方式<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">'--foo'</span>,nargs=<span class="string">'*'</span>,default=<span class="string">'d'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'bar'</span>,nargs=<span class="string">'*'</span>,default=<span class="string">'d'</span>)</span><br><span class="line">args = parser.parse_args(<span class="string">'3 --foo 3 4'</span>.split())</span><br><span class="line">print(args)</span><br></pre></td></tr></table></figure></p>
<p>输出</p>
<blockquote>
<p>Namespace(bar=[‘3’], foo=[‘3’, ‘4’])</p>
</blockquote>
<h4 id="-2"><a href="#-2" class="headerlink" title="+"></a>+</h4><p>nargs设置为+，参数个数必须大于等于1<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">'--foo'</span>,nargs=<span class="string">'+'</span>,default=<span class="string">'d'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'bar'</span>,nargs=<span class="string">'+'</span>,default=<span class="string">'d'</span>)</span><br><span class="line">args = parser.parse_args(<span class="string">'3 3'</span>.split())</span><br><span class="line">print(args)</span><br><span class="line">args = parser.parse_args(<span class="string">'--foo 3'</span>.split())</span><br><span class="line">print(args)</span><br></pre></td></tr></table></figure></p>
<p>输出</p>
<blockquote>
<p>Namespace(bar=[‘3’], foo=’d’)<br>Namespace(bar=[‘3’], foo=[‘3’])</p>
</blockquote>
<h3 id="const"><a href="#const" class="headerlink" title="const"></a>const</h3><h4 id="action-’’store-const”-or-action-”append-const”"><a href="#action-’’store-const”-or-action-”append-const”" class="headerlink" title="action=’’store_const” or action=”append_const”"></a>action=’’store_const” or action=”append_const”</h4><p>the examples are in the action<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">'--foo'</span>, action=<span class="string">'store_const'</span>, const=<span class="number">42</span>)</span><br><span class="line">args = parser.parse_args([<span class="string">'--foo'</span>)</span><br><span class="line">print(args)</span><br></pre></td></tr></table></figure></p>
<p>输出</p>
<blockquote>
<p>Namespace(foo=42)</p>
</blockquote>
<h4 id="like-f-or-—foo-and-nargs-’-’"><a href="#like-f-or-—foo-and-nargs-’-’" class="headerlink" title="like -f or —foo and nargs=’?’"></a>like -f or —foo and nargs=’?’</h4><p>the examples are the same as examples in the nargs=’?’<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">'--foo'</span>,nargs=<span class="string">'?'</span>,const=<span class="string">'c'</span>,default=<span class="string">'d'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'bar'</span>,nargs=<span class="string">'?'</span>,default=<span class="string">'d'</span>)</span><br><span class="line">args = parser.parse_args(<span class="string">'3'</span>.split())</span><br><span class="line">print(args)</span><br><span class="line">args = parser.parse_args(<span class="string">'3 --foo'</span>.split())</span><br><span class="line">print(args)</span><br></pre></td></tr></table></figure></p>
<p>输出</p>
<blockquote>
<p>Namespace(bar=’3’, foo=’d’)<br>Namespace(bar=’3’, foo=’c’)<br>如果显式指定可选参数，但是不给它参数，那么如果有const的话，就会显示const的值，否则就会显示None</p>
</blockquote>
<h3 id="default"><a href="#default" class="headerlink" title="default"></a>default</h3><p>default对于可选参数来说，是有用的，当可选参数没有在command line中显示出来时被使用，但是对于必选参数来说，只有nargs=?或者*才能起作用。</p>
<h4 id="对于可选参数"><a href="#对于可选参数" class="headerlink" title="对于可选参数"></a>对于可选参数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">'--foo'</span>,default=<span class="number">43</span>)</span><br><span class="line">args = parser.parse_args([])</span><br><span class="line">print(args)</span><br><span class="line">args = parser.parse_args(<span class="string">'--foo 3'</span>.split())</span><br><span class="line">print(args)</span><br></pre></td></tr></table></figure>
<p>输出</p>
<blockquote>
<p>Namespace(foo=’43’)<br>Namespace(foo=’3’)</p>
</blockquote>
<h4 id="对于必选参数"><a href="#对于必选参数" class="headerlink" title="对于必选参数"></a>对于必选参数</h4><p>对于nargs=‘+’是会出错<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(&apos;bar&apos;,nargs=&apos;+&apos;,default=&apos;d&apos;)</span><br><span class="line">args = parser.parse_args([])</span><br><span class="line">print(args)</span><br></pre></td></tr></table></figure></p>
<p>输出</p>
<blockquote>
<p>usage: [-h] bar [bar …]<br>: error: the following arguments are required: bar</p>
</blockquote>
<p>对于nargs=‘*’或者nargs=’?’就行了<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">'bar'</span>,nargs=<span class="string">'?'</span>,default=<span class="string">'d'</span>)</span><br><span class="line">args = parser.parse_args([])</span><br><span class="line">print(args)</span><br></pre></td></tr></table></figure></p>
<p>输出</p>
<blockquote>
<p>Namespace(bar=’d’)</p>
</blockquote>
<h3 id="type"><a href="#type" class="headerlink" title="type"></a>type</h3><p>将输入的字符串参数转换为你想要的参数类型<br>对于文件类型来说，这个文件必须在当前目录存在。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">'--door'</span>,type=int)</span><br><span class="line">parser.add_argument(<span class="string">'filename'</span>,type=file)</span><br><span class="line">parser.parse_args([<span class="string">'--door'</span>,<span class="string">'3'</span>,<span class="string">'hello.txt'</span>])</span><br></pre></td></tr></table></figure></p>
<p>输出</p>
<blockquote>
<p>Namespace(door=3)<br>这里的door就是int类型的</p>
</blockquote>
<h3 id="choices"><a href="#choices" class="headerlink" title="choices"></a>choices</h3><p>输入的参数必须在choices这个范围中，否则就会报错<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParse()</span><br><span class="line">parser.add_argument(<span class="string">'--door'</span>,type=int,choices=range(<span class="number">1</span>,<span class="number">9</span>))</span><br><span class="line">parser.parse_args([<span class="string">'--door'</span>,<span class="string">'3'</span>])</span><br></pre></td></tr></table></figure></p>
<p>输出</p>
<blockquote>
<p>Namespace(door=3)</p>
</blockquote>
<h3 id="required"><a href="#required" class="headerlink" title="required"></a>required</h3><p>如果将required设置为True的话，那么这个可选参数必须要设置的<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">'-f'</span>, <span class="string">'--foo-bar'</span>, <span class="string">'--foo'</span>,required=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure></p>
<h3 id="help-1"><a href="#help-1" class="headerlink" title="help"></a>help</h3><p>help可以设置某个参数的简要介绍。<br>使用help=argparse.SUPRESS可以在help界面中不显示这个参数的介绍<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">'-f'</span>, <span class="string">'--foo-bar'</span>, <span class="string">'--foo'</span>,help=<span class="string">'fool you '</span>)</span><br><span class="line">parser.add_argument(<span class="string">'-xs'</span>, <span class="string">'--y'</span>,help=argparse.SUPPRESS)</span><br><span class="line">parser.print_help()</span><br></pre></td></tr></table></figure></p>
<p>输出</p>
<blockquote>
<p>usage: [-h] [-f FOO_BAR]</p>
<p>optional arguments:<br>  -h, —help            show this help message and exit<br>  -f FOO_BAR, —foo-bar FOO_BAR, —foo FOO_BAR<br>                        fool you</p>
</blockquote>
<h3 id="dest"><a href="#dest" class="headerlink" title="dest"></a>dest</h3><p>dest就是在help输出时显示的optional和positional参数后跟的名字（没有指定metavar时）<br>如下,dest就是FOO<br>-foo FOO</p>
<h4 id="positional-argument"><a href="#positional-argument" class="headerlink" title="positional argument"></a>positional argument</h4><p>dest is normally supplied as the first argument to add_argument()</p>
<h4 id="可选参数"><a href="#可选参数" class="headerlink" title="可选参数"></a>可选参数</h4><p>对于optional argument选择，—参数最长的一个作为dest，如果没有最长的，选择第一个出现的，如果没有—参数名，选择-参数。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">'-f'</span>, <span class="string">'--foo-bar'</span>, <span class="string">'--foo'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'-xs'</span>, <span class="string">'--y'</span>)</span><br><span class="line">args = parser.parse_args(<span class="string">'-f 1 -xs 2'</span>.split())</span><br><span class="line">print(args)</span><br><span class="line">args = parser.parse_args(<span class="string">'--foo 1 --y 2'</span>.split())</span><br><span class="line">print(args)</span><br><span class="line">parser.print_help()</span><br></pre></td></tr></table></figure></p>
<p>输出</p>
<blockquote>
<p>Namespace(foo_bar=’1’, y=’2’)<br>Namespace(foo_bar=’1’, y=’2’)<br>usage: [-h] [-f FOO_BAR] [-xs Y]</p>
<p>optional arguments:<br>  -h, —help            show this help message and exit<br>  -f FOO_BAR, —foo-bar FOO_BAR, —foo FOO_BAR<br>  -xs Y, —y Y</p>
</blockquote>
<h3 id="metavar"><a href="#metavar" class="headerlink" title="metavar"></a>metavar</h3><p>如果指定metavar变量名的话，那么help输出的postional和positional参数后跟的名字就是metavar的名字而不是dest的名字</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">'-f'</span>, <span class="string">'--foo-bar'</span>, <span class="string">'--foo'</span>,metavar=<span class="string">"FOO"</span>)</span><br><span class="line">parser.add_argument(<span class="string">'-xs'</span>, <span class="string">'--y'</span>,metavar=<span class="string">'XY'</span>)</span><br><span class="line">args = parser.parse_args(<span class="string">'-f 1 -xs 2'</span>.split())</span><br><span class="line">print(args)</span><br><span class="line">args = parser.parse_args(<span class="string">'--foo 1 --y 2'</span>.split())</span><br><span class="line">print(args)</span><br><span class="line">parser.print_help()</span><br></pre></td></tr></table></figure>
<p>输出</p>
<blockquote>
<p>Namespace(foo_bar=’1’, y=’2’)<br>Namespace(foo_bar=’1’, y=’2’)<br>usage: [-h] [-f FOO] [-xs XY]</p>
<p>optional arguments:<br>  -h, —help            show this help message and exit<br>  -f FOO, —foo-bar FOO, —foo FOO<br>  -xs XY, —y XY</p>
</blockquote>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mxxhcm.github.io/2019/03/18/python-numpy笔记/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="马晓鑫爱马荟荟">
      <meta itemprop="description" content="记录硕士三年自己的积累">
      <meta itemprop="image" content="/images/favicon.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="mxxhcm's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/03/18/python-numpy笔记/" class="post-title-link" itemprop="http://mxxhcm.github.io/page/14/index.html">numpy笔记</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-03-18 15:15:29" itemprop="dateCreated datePublished" datetime="2019-03-18T15:15:29+08:00">2019-03-18</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-10-21 14:51:19" itemprop="dateModified" datetime="2019-10-21T14:51:19+08:00">2019-10-21</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/python/" itemprop="url" rel="index"><span itemprop="name">python</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="numpy-ndarray"><a href="#numpy-ndarray" class="headerlink" title="numpy.ndarray"></a>numpy.ndarray</h2><h3 id="attribute-of-the-np-ndarray"><a href="#attribute-of-the-np-ndarray" class="headerlink" title="attribute of the np.ndarray"></a>attribute of the np.ndarray</h3><p>ndarray.shape        #array的shape<br>ndarray.ndim            #array的维度<br>ndarray.size            #the number of ndarray in array<br>ndarray.dtype        #type of the number in array，dtype可以是’S’,int等<br>ndarray.itemsize        #size of the element in array<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">array[array&gt;<span class="number">0</span>].size    <span class="comment">#统计一个数组有多少个非零元素，不论array的维度是多少</span></span><br></pre></td></tr></table></figure></p>
<h3 id="改变数组数据类型"><a href="#改变数组数据类型" class="headerlink" title="改变数组数据类型"></a>改变数组数据类型</h3><p>将整形数组改为字符型<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a = numpy.zeros((<span class="number">3</span>,<span class="number">4</span>),dtype=<span class="string">'i'</span>)</span><br><span class="line">a.astype(<span class="string">'S'</span>)</span><br></pre></td></tr></table></figure></p>
<h3 id="将numpy转为list"><a href="#将numpy转为list" class="headerlink" title="将numpy转为list"></a>将numpy转为list</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">a = np.zeros((<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>))</span><br><span class="line">b = a.tolist()</span><br><span class="line">print(b)</span><br><span class="line">print(len(b))</span><br><span class="line">print(len(b[<span class="number">0</span>]))</span><br><span class="line"><span class="comment"># [[[0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0]], [[0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0]], [[0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0]]]</span></span><br><span class="line"><span class="comment"># 3</span></span><br><span class="line"><span class="comment"># 4</span></span><br></pre></td></tr></table></figure>
<h3 id="reshape"><a href="#reshape" class="headerlink" title="reshape"></a>reshape</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">a = np.zeros((<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>))</span><br><span class="line">a.reshape(<span class="number">-1</span>, <span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<h3 id="flatten"><a href="#flatten" class="headerlink" title="flatten"></a>flatten</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">a = np.zeros((<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>))</span><br><span class="line">a.flatten()</span><br></pre></td></tr></table></figure>
<h2 id="numpy数组初始化"><a href="#numpy数组初始化" class="headerlink" title="numpy数组初始化"></a>numpy数组初始化</h2><ul>
<li>numpy.array()</li>
<li>numpy.zeros()</li>
<li>numpy.empty()</li>
<li>numpy.random()</li>
</ul>
<h3 id="numpy-array"><a href="#numpy-array" class="headerlink" title="numpy.array()"></a>numpy.array()</h3><h4 id="API"><a href="#API" class="headerlink" title="API"></a>API</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">np.array(</span><br><span class="line">    object,</span><br><span class="line">    dtype=<span class="literal">None</span>,</span><br><span class="line">    copy=<span class="literal">True</span>,</span><br><span class="line">    order=<span class="literal">False</span>,</span><br><span class="line">    subok=<span class="literal">False</span>,</span><br><span class="line">    ndim=<span class="number">0</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h3 id="numpy-zeros"><a href="#numpy-zeros" class="headerlink" title="numpy.zeros()"></a>numpy.zeros()</h3><h4 id="API-1"><a href="#API-1" class="headerlink" title="API"></a>API</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">np.zeros(</span><br><span class="line">    shape,</span><br><span class="line">    dtype=float,</span><br><span class="line">    order=<span class="string">'C'</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h4 id="代码示例"><a href="#代码示例" class="headerlink" title="代码示例"></a>代码示例</h4><p><a href>代码地址</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">np.zeros((<span class="number">3</span>, <span class="number">4</span>),dtype=<span class="string">'i'</span>)</span><br><span class="line">``` </span><br><span class="line"></span><br><span class="line"><span class="comment">### numpy.empty()</span></span><br><span class="line"><span class="comment">#### API</span></span><br><span class="line">``` python</span><br><span class="line">np.empty(</span><br><span class="line">    shape,</span><br><span class="line">    dtype=float,</span><br><span class="line">    order=<span class="string">'C'</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></p>
<h4 id="代码示例-1"><a href="#代码示例-1" class="headerlink" title="代码示例"></a>代码示例</h4><p><a href>代码地址</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np.empty((<span class="number">3</span>, <span class="number">4</span>),dtype=<span class="string">'f'</span>)</span><br></pre></td></tr></table></figure></p>
<h3 id="numpy-random"><a href="#numpy-random" class="headerlink" title="numpy.random"></a>numpy.random</h3><h4 id="numpy-random-randn"><a href="#numpy-random-randn" class="headerlink" title="numpy.random.randn()"></a>numpy.random.randn()</h4><p>返回标准正态分布的一个样本<br>numpy.random.randn(d0, d1, …, dn)<br>例子<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np.random.randn(<span class="number">3</span>,<span class="number">4</span>)</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>array([[ 0.47203644, -0.0869761 , -1.02814481, -0.45945482],<br>       [ 0.34586502, -0.63121119,  0.35510786,  0.82975136],<br>       [-2.00253326, -0.63773715, -0.82700167,  1.80724647]])</p>
</blockquote>
<h4 id="numpy-random-rand"><a href="#numpy-random-rand" class="headerlink" title="numpy.random.rand()"></a>numpy.random.rand()</h4><p>创建一个给定shape的数组，从区间[0,1)上的均匀分布中随机采样</p>
<blockquote>
<p>create an array of the given shape and populate it with random samples from a uniform disctribution over [0,1)</p>
</blockquote>
<p>numpy.random.rand(d0,d1,…,dn)<br>例子<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np.random.rand(<span class="number">3</span>,<span class="number">4</span>)</span><br></pre></td></tr></table></figure></p>
<h4 id="numpy-random-random"><a href="#numpy-random-random" class="headerlink" title="numpy.random.random()"></a>numpy.random.random()</h4><p>返回区间[0.0, 1.0)之间的随机浮点数</p>
<blockquote>
<p>return random floats in the half-open interval [0.0,1.0)</p>
</blockquote>
<p>numpy.random.random(size=None)<br>例子<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np.random.random((<span class="number">3</span>,<span class="number">4</span>))</span><br></pre></td></tr></table></figure></p>
<h5 id="Note"><a href="#Note" class="headerlink" title="Note"></a>Note</h5><p>注意，random.random()和random.rand()实现的功能都是一样的，就是输入的参数不同。见参考文献[1]。</p>
<h4 id="numpy-random-ranf"><a href="#numpy-random-ranf" class="headerlink" title="numpy.random.ranf()"></a>numpy.random.ranf()</h4><p>我觉得它和random.random()没啥区别</p>
<h4 id="numpy-random-randint"><a href="#numpy-random-randint" class="headerlink" title="numpy.random.randint()"></a>numpy.random.randint()</h4><blockquote>
<p>return random integers from low(inclusive) to high(exclusive),[low,high) if high is None,then results are from [0,low)</p>
</blockquote>
<p>numpy.random.randint(low,high=None,size=None,dtype=’l’)<br>例子<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">np.random.randint(<span class="number">3</span>,size=[<span class="number">3</span>,<span class="number">4</span>])</span><br><span class="line">np.random.randint(<span class="number">4</span>,<span class="number">6</span>,size=[<span class="number">6</span>,<span class="number">2</span>])</span><br></pre></td></tr></table></figure></p>
<h4 id="numpy-random-RandomState"><a href="#numpy-random-RandomState" class="headerlink" title="numpy.random.RandomState()"></a>numpy.random.RandomState()</h4><blockquote>
<p>class numpy.random.RandomState(seed=None)</p>
</blockquote>
<p>这是一个类，给定一个种子，它接下来产生的一系列随机数都是固定的。每次需要重新产生随机数的时候，就重置种子。<br>通过一个例子来看：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">rdm = np.randrom.RandomState()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">   rdm.seed(<span class="number">3</span>)</span><br><span class="line">   print(rdm.rand())</span><br><span class="line">   print(rdm.rand())</span><br><span class="line">   print(rdm.rand())</span><br><span class="line">    print(<span class="string">"\n"</span>)</span><br><span class="line"><span class="comment"># 0.9670298390136767</span></span><br><span class="line"><span class="comment"># 0.5472322491757223</span></span><br><span class="line"><span class="comment"># 0.9726843599648843</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 0.9670298390136767</span></span><br><span class="line"><span class="comment"># 0.5472322491757223</span></span><br><span class="line"><span class="comment"># 0.9726843599648843</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 0.9670298390136767</span></span><br><span class="line"><span class="comment"># 0.5472322491757223</span></span><br><span class="line"><span class="comment"># 0.9726843599648843</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 0.9670298390136767</span></span><br><span class="line"><span class="comment"># 0.5472322491757223</span></span><br><span class="line"><span class="comment"># 0.9726843599648843</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 0.9670298390136767</span></span><br><span class="line"><span class="comment"># 0.5472322491757223</span></span><br><span class="line"><span class="comment"># 0.9726843599648843</span></span><br></pre></td></tr></table></figure></p>
<h3 id="创建bool类型数组"><a href="#创建bool类型数组" class="headerlink" title="创建bool类型数组"></a>创建bool类型数组</h3><p>np.ones([2, 2], dtype=bool)<br>np.zeros([2, 2], dtype=bool)</p>
<h3 id="others"><a href="#others" class="headerlink" title="others"></a>others</h3><h4 id="numpy-arange"><a href="#numpy-arange" class="headerlink" title="numpy.arange()"></a>numpy.arange()</h4><h4 id="numpy-linspace"><a href="#numpy-linspace" class="headerlink" title="numpy.linspace()"></a>numpy.linspace()</h4><h2 id="np-random-binomial"><a href="#np-random-binomial" class="headerlink" title="np.random.binomial"></a>np.random.binomial</h2><h3 id="API-2"><a href="#API-2" class="headerlink" title="API"></a>API</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">numpy.random.binomial(</span><br><span class="line">	n, </span><br><span class="line">	p, </span><br><span class="line">	size=<span class="literal">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p>二项分布，共有三个参数，前两个是必选参数，第三个是可选参数。$n$是实验的个数，比如同时扔三枚硬币，这里就是$n=3$,$p$是为$1$的概率。$size$是总共进行多少次实验。<br>返回值是在每次试验中，trival成功的个数。如果是一个scalar，代表$size=1$，如果是一个list，代表$size\gt 1$。</p>
<h3 id="代码示例-2"><a href="#代码示例-2" class="headerlink" title="代码示例"></a>代码示例</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">    rand = np.random.binomial(<span class="number">2</span>, <span class="number">0.9</span>)</span><br><span class="line">    print(rand)</span><br><span class="line"><span class="comment"># 可以看成扔2个硬币，每个硬币正面向上的概率是0.9,最后有几个硬币正面向上。</span></span><br><span class="line"><span class="comment"># 2</span></span><br><span class="line"><span class="comment"># 2</span></span><br><span class="line"><span class="comment"># 2</span></span><br><span class="line"><span class="comment"># 2</span></span><br><span class="line"><span class="comment"># 2</span></span><br><span class="line"><span class="comment"># 2</span></span><br><span class="line"><span class="comment"># 2</span></span><br><span class="line"><span class="comment"># 1</span></span><br><span class="line"><span class="comment"># 1</span></span><br><span class="line"><span class="comment"># 2</span></span><br><span class="line"></span><br><span class="line">rand = np.random.binomial(<span class="number">3</span>, <span class="number">0.9</span>, <span class="number">5</span>)</span><br><span class="line">print(rand)</span><br><span class="line"><span class="comment"># 可以看成扔3个硬币，每个硬币正面向上的概率是0.9,最后有几个硬币正面向上。一共进行5次实验。</span></span><br><span class="line"><span class="comment"># [2 2 3 3 2]</span></span><br></pre></td></tr></table></figure>
<h2 id="np-random-choice"><a href="#np-random-choice" class="headerlink" title="np.random.choice"></a>np.random.choice</h2><h3 id="API-3"><a href="#API-3" class="headerlink" title="API"></a>API</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">numpy.random.choice(</span><br><span class="line">    a,  <span class="comment"># 1d array或者int，如果是一个数组，从其中生成样本；如果是一个整数，从np.arange(a)中生成样本</span></span><br><span class="line">    size=<span class="literal">None</span>,  <span class="comment"># output shape，比如是(m, n, k)的话，总共要m*n*k个样本，默认是None,返回一个样本。</span></span><br><span class="line">    replace=<span class="literal">True</span>,   <span class="comment"># 是否使用replacement，设置为False的话所有元素不重复。</span></span><br><span class="line">    p=<span class="literal">None</span>  <span class="comment"># 概率分布，相加必须等于1，默认是从一个均匀分布中采样。</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h3 id="代码示例-3"><a href="#代码示例-3" class="headerlink" title="代码示例"></a>代码示例</h3><p><a href>代码地址</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">a0 = np.random.choice([<span class="number">8</span>, <span class="number">9</span>, <span class="number">-1</span>, <span class="number">2</span>, <span class="number">0</span>], <span class="number">3</span>)</span><br><span class="line">print(a0)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 从np.arange(5)从使用均匀分布采样一个shape为4的样本</span></span><br><span class="line">a1 = np.random.choice(<span class="number">5</span>, <span class="number">4</span>)</span><br><span class="line">print(a1)</span><br><span class="line"></span><br><span class="line">a2 = np.random.choice(<span class="number">5</span>, <span class="number">8</span>, p=[<span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.5</span>, <span class="number">0.2</span>, <span class="number">0</span>])</span><br><span class="line">print(a2)</span><br><span class="line"></span><br><span class="line"><span class="comment"># replace 设置为False，相当于np.random.permutation()</span></span><br><span class="line">a3 = np.random.choice([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">8</span>, <span class="number">9</span>], <span class="number">5</span>, replace=<span class="literal">False</span>)</span><br><span class="line">print(a3)</span><br></pre></td></tr></table></figure></p>
<h2 id="np-random-permutation"><a href="#np-random-permutation" class="headerlink" title="np.random.permutation"></a>np.random.permutation</h2><h3 id="API-4"><a href="#API-4" class="headerlink" title="API"></a>API</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">np.random.permutation(</span><br><span class="line">    x   <span class="comment"># int或者array，如果是int，置换np.arange(x)。如果是array，make a copy，随机打乱元素。</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>对输入序列进行排列组合，如果输入是多维的话，只会在第一维重新排列。</p>
<h3 id="代码示例-4"><a href="#代码示例-4" class="headerlink" title="代码示例"></a>代码示例</h3><p><a href>代码地址</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">a1 = np.random.permutation(<span class="number">9</span>)</span><br><span class="line">print(a1)</span><br><span class="line"></span><br><span class="line">a2 = np.random.permutation([<span class="number">1</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">9</span>, <span class="number">8</span>])</span><br><span class="line">print(a2)</span><br><span class="line"></span><br><span class="line">a3 = np.random.permutation(np.arange(<span class="number">9</span>).reshape(<span class="number">3</span>, <span class="number">3</span>))</span><br><span class="line">print(a3)</span><br></pre></td></tr></table></figure></p>
<h2 id="np-random-normal"><a href="#np-random-normal" class="headerlink" title="np.random.normal"></a>np.random.normal</h2><h3 id="API-5"><a href="#API-5" class="headerlink" title="API"></a>API</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">numpy.random.normal(loc=0.0, scale=1.0, size=None)  </span><br><span class="line">loc:float，正态分布的均值，对应着整个分布的center</span><br><span class="line">scale:float，正态分布的标准差，对应于分布的宽度，scale越大越矮胖，scale越小，越瘦高</span><br><span class="line">size:int or tuple of ints，输出的shape，默认为None，只输出一个值</span><br><span class="line">np.random.randn(size)相当于np.random.normal(loc=0, scale=1, size)</span><br></pre></td></tr></table></figure>
<h2 id="np-argsort"><a href="#np-argsort" class="headerlink" title="np.argsort"></a>np.argsort</h2><h3 id="API-6"><a href="#API-6" class="headerlink" title="API"></a>API</h3><p>numpy.argsort(a, axis=-1, kind=’quicksort’, order=None)<br>axis:对哪个axis进行排序，默认是-1</p>
<h3 id="功能"><a href="#功能" class="headerlink" title="功能"></a>功能</h3><p>将数组排序后（默认是从小到大排序），返回排序后的数组在原数组中的位置。</p>
<p>参考文献<br>1.<a href="https://stackoverflow.com/questions/47231852/np-random-rand-vs-np-random-random" target="_blank" rel="noopener">https://stackoverflow.com/questions/47231852/np-random-rand-vs-np-random-random</a><br>2.<a href="https://stackoverflow.com/questions/21174961/how-to-create-a-numpy-array-of-all-true-or-all-false" target="_blank" rel="noopener">https://stackoverflow.com/questions/21174961/how-to-create-a-numpy-array-of-all-true-or-all-false</a><br>3.<a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.choice.html" target="_blank" rel="noopener">https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.choice.html</a><br>4.<a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.permutation.html" target="_blank" rel="noopener">https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.permutation.html</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mxxhcm.github.io/2019/03/18/python-hdf5笔记/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="马晓鑫爱马荟荟">
      <meta itemprop="description" content="记录硕士三年自己的积累">
      <meta itemprop="image" content="/images/favicon.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="mxxhcm's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/03/18/python-hdf5笔记/" class="post-title-link" itemprop="http://mxxhcm.github.io/page/14/index.html">h5py笔记</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-03-18 15:12:03" itemprop="dateCreated datePublished" datetime="2019-03-18T15:12:03+08:00">2019-03-18</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-06-13 10:06:17" itemprop="dateModified" datetime="2019-06-13T10:06:17+08:00">2019-06-13</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/python/" itemprop="url" rel="index"><span itemprop="name">python</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="python包安装"><a href="#python包安装" class="headerlink" title="python包安装"></a>python包安装</h2><p>~$:pip install h5py</p>
<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><h3 id="创建和打开h5py文件"><a href="#创建和打开h5py文件" class="headerlink" title="创建和打开h5py文件"></a>创建和打开h5py文件</h3><p>f = h5py.File(“pathname”,”w”)<br>w     create file, truncate if exist<br>w- or x  create file,fail if exists<br>r         readonly, file must be exist r+        read/write,file must be exist<br>a        read/write if exists,create othrewise (default)</p>
<h3 id="删除一个dataset或者group"><a href="#删除一个dataset或者group" class="headerlink" title="删除一个dataset或者group"></a>删除一个dataset或者group</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">del</span> group[<span class="string">"dataset_name/group_name"</span>]</span><br></pre></td></tr></table></figure>
<h2 id="dataset"><a href="#dataset" class="headerlink" title="dataset"></a>dataset</h2><h3 id="什么是dataset"><a href="#什么是dataset" class="headerlink" title="什么是dataset"></a>什么是dataset</h3><p>datasets和numpy arrays挺像的</p>
<h3 id="创建一个dataset"><a href="#创建一个dataset" class="headerlink" title="创建一个dataset"></a>创建一个dataset</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">f = h5py.File(<span class="string">"pathname"</span>,<span class="string">"w"</span>)</span><br><span class="line">f.create_dataset(<span class="string">"dataset_name"</span>, (<span class="number">10</span>,), dtype=<span class="string">'i'</span>)</span><br><span class="line">f.create_dataset(<span class="string">"dataset_name"</span>, (<span class="number">10</span>,), dtype=<span class="string">'c'</span>)</span><br></pre></td></tr></table></figure>
<p>第一个参数是dataset的名字, 第二个参数是dataset的shape, dtype参数是dataset中元素的类型。</p>
<h3 id="如何访问一个dataset"><a href="#如何访问一个dataset" class="headerlink" title="如何访问一个dataset"></a>如何访问一个dataset</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dataset = f[<span class="string">"dataset_name"</span>]                           <span class="comment"># acess like a python dict</span></span><br><span class="line">dataset = f.create_dateset(<span class="string">"dataset_name"</span>)  <span class="comment"># or create a new dataset</span></span><br></pre></td></tr></table></figure>
<h3 id="dataset的属性"><a href="#dataset的属性" class="headerlink" title="dataset的属性"></a>dataset的属性</h3><p>dataset.name        #输出dataset的名字<br>dataset.tdype        #输出dataset中elements的type<br>dataset.shape        #输出dataset的shape<br>dataset.value<br>dataset doesn’t hava attrs like keys,values,items,etc..</p>
<h3 id="给h5py-dataset复制numpy-array"><a href="#给h5py-dataset复制numpy-array" class="headerlink" title="给h5py dataset复制numpy array"></a>给h5py dataset复制numpy array</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">array = np.zero((<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">h[<span class="string">'array'</span>] = array        <span class="comment"># in h5py file, you need't to explicit declare the shape of array, just assign it an object of numpy array</span></span><br></pre></td></tr></table></figure>
<h2 id="group"><a href="#group" class="headerlink" title="group"></a>group</h2><h3 id="什么是group"><a href="#什么是group" class="headerlink" title="什么是group"></a>什么是group</h3><p>group和字典挺像的</p>
<h3 id="创建一个group"><a href="#创建一个group" class="headerlink" title="创建一个group"></a>创建一个group</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">group = f.create_group(<span class="string">"group_name"</span>)    <span class="comment">#在f下创建一个group</span></span><br><span class="line">group.create_group(<span class="string">"group_name"</span>)        <span class="comment">#在group下创建一个group</span></span><br><span class="line">group.create_dataset(<span class="string">"dataset_name"</span>)    <span class="comment">#在group下创建一个dataset</span></span><br></pre></td></tr></table></figure>
<h3 id="访问一个group-the-same-as-dataset"><a href="#访问一个group-the-same-as-dataset" class="headerlink" title="访问一个group(the same as dataset)"></a>访问一个group(the same as dataset)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">group = f[<span class="string">"group_name"</span>]                           <span class="comment"># acess like a python dict</span></span><br><span class="line">group = f.create_dateset(<span class="string">"group_name"</span>)  <span class="comment"># or create a new group</span></span><br></pre></td></tr></table></figure>
<h3 id="group的属性和方法"><a href="#group的属性和方法" class="headerlink" title="group的属性和方法"></a>group的属性和方法</h3><p>group.name        #输出group的名字<br>以下内容分为python2和python3版本</p>
<h4 id="python-2-版本"><a href="#python-2-版本" class="headerlink" title="python 2 版本"></a>python 2 版本</h4><p>group.values()    #输出group的value<br>group.keys()        #输出gorup的keys<br>group.items()    #输出group中所有的item，包含group和dataste</p>
<h4 id="python-3-版本"><a href="#python-3-版本" class="headerlink" title="python 3 版本"></a>python 3 版本</h4><p>list(group.keys())<br>list(group.values())<br>list(group.items())</p>
<h2 id="属性"><a href="#属性" class="headerlink" title="属性"></a>属性</h2><h3 id="设置dataset属性"><a href="#设置dataset属性" class="headerlink" title="设置dataset属性"></a>设置dataset属性</h3><p>dataset.attrs[“attr_name”]=”attr_value”    #设置attr<br>print(dataset.attrs[“attr_name”])                #访问attr</p>
<h3 id="设置group属性"><a href="#设置group属性" class="headerlink" title="设置group属性"></a>设置group属性</h3><p>group.attrs[“attr_name”]=”attr_value”    #设置attr<br>print(group.attrs[“attr_name”])                #访问attr</p>
<h2 id="numpy-and-h5py"><a href="#numpy-and-h5py" class="headerlink" title="numpy and h5py"></a>numpy and h5py</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">f = h5py.File(pathname,<span class="string">"r"</span>)</span><br><span class="line"></span><br><span class="line">data = f[<span class="string">'data'</span>]    <span class="comment"># type 是dataset</span></span><br><span class="line">data = f[<span class="string">'data'</span>][:] <span class="comment">#type是numpy ndarray</span></span><br><span class="line">f.close()</span><br></pre></td></tr></table></figure>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>1.<a href="http://docs.h5py.org/en/latest/index.html" target="_blank" rel="noopener">http://docs.h5py.org/en/latest/index.html</a><br>2.<a href="https://stackoverflow.com/questions/31037088/discovering-keys-using-h5py-in-python3" target="_blank" rel="noopener">https://stackoverflow.com/questions/31037088/discovering-keys-using-h5py-in-python3</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mxxhcm.github.io/2019/03/14/activation/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="马晓鑫爱马荟荟">
      <meta itemprop="description" content="记录硕士三年自己的积累">
      <meta itemprop="image" content="/images/favicon.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="mxxhcm's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/03/14/activation/" class="post-title-link" itemprop="http://mxxhcm.github.io/page/14/index.html">神经网络-激活函数</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-03-14 11:45:46" itemprop="dateCreated datePublished" datetime="2019-03-14T11:45:46+08:00">2019-03-14</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-05-07 00:22:27" itemprop="dateModified" datetime="2019-05-07T00:22:27+08:00">2019-05-07</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="激活函数的一些问题">激活函数的一些问题</h2>
<h3 id="为什么要使用non-linear激活函数不使用linear激活函数？">为什么要使用non-linear激活函数不使用linear激活函数？</h3>
<p><img src="/2019/03/14/activation/fnn.png" alt="fnn"><br>
给定一个如图所示的前馈神经网络。有一个输入层，一个隐藏层，一个输出层。输入是$2$维的，有$4$个隐藏单元，输出是$2$维的。<br>
则：$ \hat{f}(x) = \sigma(w_1x+b_1)w_2 + b_2$<br>
这里$\sigma$是一个线性的激活函数，不妨设$\sigma(x) = x$。<br>
那么就有：<br>
\begin{align*}<br>
\hat{f}(x) &amp;= \sigma(w_1x+b_1)w_2 + b_2\<br>
&amp;= (w_1x+b_1)w_2 + b_2\<br>
&amp;= w_1w_2x + w_2b1 + b_2\<br>
&amp;= (w_1w_2) x + (w_2b1 + b_2)\<br>
&amp;= w’ x + b’<br>
\end{align*}<br>
因此，当使用线性激活函数的时候，我们可以把一个多层感知机模型化简成一个线性模型。当使用线性激活函数时，增加网络的深度没有用，使用线性激活函数的十层感知机和一层感知机没有区别，并不能增加网络的表达能力。因为任意两个仿射函数的组合还是仿射函数。</p>
<h3 id="为什么relu激活函数是non-linear的？">为什么ReLU激活函数是non-linear的？</h3>
<p>ReLU的数学表达形式如下：<br>
$$g(x) = max(0, x)$$<br>
首先考虑一下什么是linear function,什么是non-linear function。在微积分上，平面内的任意一条直线是线性函数，否则就是非线性函数。<br>
考虑这样一个例子，输入数据的维度为$1$，输出数据的维度也为$1$，用$g(ax+b)$表示ReLU激活函数。如果我们使用两个隐藏单元，那么$h_1(x) = g(x)+g(-x)$可以用来表示$f(x)=|x|$，而函数$|x|$是一个非线性函数，函数图像如下所示。<br>
<img src="/2019/03/14/activation/absolute.png" alt="f(x)=|x|"><br>
我们还可以用ReLU逼近二次函数$f(x) = x^2$，如使用函数$h_2(x) = g(x) + g(-x) + g(2x-2) + g(2x+2)$逼近二次函数，对应的图像如下。<br>
<img src="/2019/03/14/activation/quadratic.png" alt="h_2(x)"><br>
使用的项越多，最后近似出来的图像也就和我们要逼近的二次函数越像。<br>
同理，可以使用ReLU激活函数去逼近任意非线性函数。</p>
<h3 id="为什么relu比sigmod还有tanh激活函数要好？">为什么ReLU比sigmod还有tanh激活函数要好？</h3>
<p>ReLU收敛的更快，因为梯度更大。<br>
当CNN的层数越来越深的时候，实验表明，使用ReLU的CNN要比使用sigmod或者tanh的CNN训练的更容易，更快收敛。<br>
为什么会这样，目前有两种理论，见参考文献[4]。<br>
第一个，$tanh(x)$有梯度消散问题(vanishing gradient)。当$x$趋向于$\pm\infty$时，$tanh(x)$的导数趋向于$0$。如下图所示。</p>
<blockquote>
<p>Vanishing gradients occur when lower layers of a DNN have gradients of nearly 0 because higher layer units are nearly saturated at -1 or 1, the asymptotes of the tanh function. Such vanishing gradients cause slow optimization convergence, and in some cases the final trained network converges to a poor local minimum.</p>
</blockquote>
<blockquote>
<p>One way ReLUs improve neural networks is by speeding up training. The gradient computation is very simple (either 0 or 1 depending on the sign of x). Also, the computational step of a ReLU is easy: any negative elements are set to 0.0 – no exponentials, no multiplication or division operations.</p>
</blockquote>
<p><img src="/2019/03/14/activation/tanh.png" alt="tanh(x)"><br>
ReLU是non-saturating nonlinearity的激活函数，sigmod和tanh是saturating nonlinearity激活函数，会将输出挤压到一个区间内。</p>
<blockquote>
<p>f是non-saturating 当且仅当$|lim_{z\rightarrow -\infty} f(z)| \rightarrow + \infty$或者$|lim_{z\rightarrow +\infty} f(z)| \rightarrow + \infty$</p>
</blockquote>
<p>tanh和sigmod将输入都挤压在某一个很小的区间内，比如(0,1)，输入发生很大的变化，经过激活函数以后变化很小，经过好几层之后，基本上就没有差别了。而当网络很深的时候，反向传播主要集中在后几层，而输入层附近的权值没办法好好学习。而对于ReLU来说，任意深度的神经网络，都不存在梯度消失。</p>
<p>第二种理论是说有一些定理能够证明，在某些假设条件下，局部最小就是全局最小。如果使用sigmod或者tanh激活函数的时候，这些假设不能成立，而使用ReLU的话，这些条件就会成立。</p>
<h3 id="为什么发生了梯度消失以后训练结构很差？">为什么发生了梯度消失以后训练结构很差？</h3>
<p>我的想法是，</p>
<h2 id="参考文献">参考文献</h2>
<p>1.<a href="https://stats.stackexchange.com/a/391971" target="_blank" rel="noopener">https://stats.stackexchange.com/a/391971</a><br>
2.<a href="https://stats.stackexchange.com/a/299933" target="_blank" rel="noopener">https://stats.stackexchange.com/a/299933</a><br>
3.<a href="https://stats.stackexchange.com/a/141978" target="_blank" rel="noopener">https://stats.stackexchange.com/a/141978</a><br>
4.<a href="https://stats.stackexchange.com/a/335972" target="_blank" rel="noopener">https://stats.stackexchange.com/a/335972</a><br>
5.<a href="https://stats.stackexchange.com/a/174438" target="_blank" rel="noopener">https://stats.stackexchange.com/a/174438</a><br>
6.<a href="https://stats.stackexchange.com/questions/391968/relu-vs-a-linear-activation-function" target="_blank" rel="noopener">https://stats.stackexchange.com/questions/391968/relu-vs-a-linear-activation-function</a><br>
7.<a href="https://stats.stackexchange.com/questions/141960/why-are-rectified-linear-units-considered-non-linear" target="_blank" rel="noopener">https://stats.stackexchange.com/questions/141960/why-are-rectified-linear-units-considered-non-linear</a><br>
8.<a href="https://stats.stackexchange.com/questions/299915/how-does-the-rectified-linear-unit-relu-activation-function-produce-non-linear" target="_blank" rel="noopener">https://stats.stackexchange.com/questions/299915/how-does-the-rectified-linear-unit-relu-activation-function-produce-non-linear</a><br>
9.<a href="https://stats.stackexchange.com/questions/226923/why-do-we-use-relu-in-neural-networks-and-how-do-we-use-it/226927#226927" target="_blank" rel="noopener">https://stats.stackexchange.com/questions/226923/why-do-we-use-relu-in-neural-networks-and-how-do-we-use-it/226927#226927</a><br>
10.<a href="https://www.zhihu.com/question/264163033" target="_blank" rel="noopener">https://www.zhihu.com/question/264163033</a><br>
11.<a href="http://ai.stanford.edu/~amaas/papers/relu_hybrid_icml2013_final.pdf" target="_blank" rel="noopener">http://ai.stanford.edu/~amaas/papers/relu_hybrid_icml2013_final.pdf</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mxxhcm.github.io/2019/03/13/cnn/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="马晓鑫爱马荟荟">
      <meta itemprop="description" content="记录硕士三年自己的积累">
      <meta itemprop="image" content="/images/favicon.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="mxxhcm's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/03/13/cnn/" class="post-title-link" itemprop="http://mxxhcm.github.io/page/14/index.html">CNN</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-03-13 15:21:27" itemprop="dateCreated datePublished" datetime="2019-03-13T15:21:27+08:00">2019-03-13</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-07-13 20:29:42" itemprop="dateModified" datetime="2019-07-13T20:29:42+08:00">2019-07-13</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="cnn">CNN</h2>
<h3 id="图片的表示">图片的表示</h3>
<p>图像在计算机中是一堆按顺序排列的顺子，数值为0到255。0表示最暗，255表示最亮。我们可以把这堆数字用一个长长的一维数组来表示，但是这样会失去平面结构的信息，为保留该结构信息，我们通常会选择矩阵的表示方式，用一个nn的矩阵来表示一个图像。对于黑白颜色的灰度图来说，我们只需要一个nn的矩阵表示即可。对于一个彩色图像，我们会选择RGB颜色模型来表示。<br>
在彩色图像中，我们需要用三个矩阵去表示一张图，也可以理解为一个三维张量，每一个矩阵叫做这张图片的一个channel。这个三维张量可以表示为(width,length,depth),一张图片就可以用这样一个张量来表示。</p>
<h3 id="卷积神经网络-cnn">卷积神经网络(CNN)</h3>
<h4 id="作用">作用</h4>
<p>让权重在不同位置共享</p>
<h4 id="filter和stride">filter和stride</h4>
<p>filter又叫做kernel或者feature detector。filter会对输入的局部区域进行处理，filter处理的局部区域的范围叫做filter size。比如说一个filter的大小为(3,3),那么这个filter会一次处理width=3，length = 3的区域。卷积神经网络会用filter对整个输入进行扫描，一次移动的多少叫做stride。filter处理一次的输出为一个feature map。</p>
<h4 id="depth">depth</h4>
<p>对于filter来说，我们一般说它的大小为（3，3）只说了它在平面的大小，但是输入的图片一般是一个RGB的三维张量，对于deepth这一个维度，如果为1的话，那么filter是（3,3），但是如果deepth大于1的话，这个filter的deepth维度一般是和张量中的deepth维度一样的。<br>
deepth=1时，filter=（3,3），处理输入中33 个节点的值<br>
deepth=2时，filter=（3,3），会处理输入中332个节点的值<br>
deepth=n时，filter=（3,3），会处理输入中$33\times n$个节点的值</p>
<h4 id="zero-paddings">zero paddings</h4>
<p>因为经过filter处理后，输入的矩阵维度会变小，所以，如果经过很多层filter处理后，就会变得越来越少，因此，为了解决这个问题，提出了zero paddings，zero padding是在filter要处理的输入上，在输入的最外层有选择的加上一行（列）或多行（列）0，从而保持输入经过filter处理之后形状不变。</p>
<h4 id="feature-map">feature map</h4>
<p>一个filter的输出就是一个feature map，该feature map的width和height为：$(input_size + 2\times padding_size - filter_size)/stride + 1$<br>
一个filter可以提取一个feature，得到一个feature map，为了提取多个feature，需要使用多个filters，最后可以得到多个feature map。</p>
<p>所以说，feature map是一类值，因为它对应的是一个filter，给定不同的输入images，一个feature map可以有不同的取值。这个问题是我在看ZFNet中遇到的，因为它在原文中说<br>
“For a given feature map, we show the top 9 activations”。给定一个feature map，这里应该是在所有样本中选择最大的$9$个activations对应的images。<br>
“the strongest activation (across all training examples) within a given feature map”。给定一个feature map，在所有样本中选择一个最强的activation。</p>
<h4 id="activate-function">activate function</h4>
<p>一般使用非线性激活函数relu对feature map进行变化</p>
<h4 id="pooling">pooling</h4>
<h5 id="maxpooling">maxpooling</h5>
<p>它基本上采用一个filter和一个同样长度的stride通常是（2,2）和2，然后把它应用到输入中，输出filter卷积计算的每个区域中的最大数字，这个pooling是在各个维度上分别进行的。<br>
比如一个 22422464的input，经过一个（2,2）的maxpooling会输出一个11211232的张量</p>
<h5 id="averagepooling">averagepooling</h5>
<h4 id="fc-layers">fc layers</h4>
<h2 id="alexnet-2012">Alexnet(2012)</h2>
<p>论文名称：ImageNet Classification with Deep Convolutional Neural Networks<br>
论文地址：<a href="http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" target="_blank" rel="noopener">http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf</a></p>
<h3 id="概述">概述</h3>
<p>作者提出了一个卷积神经网络架构对Imagenet中$1000$类中的$120$万张图片进行分类。网络架构包含$5$个卷积层，$3$个全连接层，和一个$1000$-way的softmax层，整个网络共有$6000$万参数，$65000$个神经元。作者提出了一些方法提高性能和减少训练的时间，并且介绍了一些防止过拟合的技巧。最后在imagenet测试集上，跑出$37.5%$的top-1 error以及$17.0%$的top-5 error。<br>
本文主要的contribution：</p>
<ol>
<li>给出了一个benchmark－Imagenet</li>
<li>提出了一个CNN架构</li>
<li>ReLU激活函数</li>
<li>dropout的使用</li>
<li>数据增强，四个角落和中心的crop以及对应的horizontial 翻转。</li>
</ol>
<h3 id="问题">问题</h3>
<p>1.数据集太小，都是数以万计的，需要更大的数据集。</p>
<h3 id="创新">创新</h3>
<h4 id="relu非线性激活函数">ReLU非线性激活函数</h4>
<h5 id="作用-v2">作用</h5>
<p>作者说实验表明ReLU可以加速训练过程。</p>
<h5 id="saturating-nonlinearity">saturating nonlinearity</h5>
<p>一个饱和的激活函数会将输出挤压到一个区间内。</p>
<blockquote>
<p>A saturating activation function squeezes the input.</p>
</blockquote>
<p><strong>定义</strong><br>
f是non-saturating 当且仅当$|lim_{z\rightarrow -\infty} f(z)| \rightarrow + \infty$或者$|lim_{z\rightarrow +\infty} f(z)| \rightarrow + \infty$<br>
f是saturating 当且仅当f不是non-saturating<br>
<strong>例子</strong><br>
ReLU就是non-saturating nonlinearity的激活函数，因为$f(x) = max(0, x)$，如下图所示。<br>
<img src="/2019/03/13/cnn/relu.png" alt="relu"><br>
当$x$趋于无穷时，$f(x)$也趋于无穷。<br>
sigmod和tanh是saturating nonlinearity激活函数，如下图所示。<br>
<img src="/2019/03/13/cnn/sigmod.png" alt="sigmo"><br>
<img src="/2019/03/13/cnn/tanh.png" alt="tanh"></p>
<h4 id="多块gpu并行">多块GPU并行</h4>
<p>作者使用了两块GPU一块运行，每个GPU中的参数个数是一样的，在一些特定层中，两个GPU中的参数信息可以进行通信。</p>
<h4 id="overlapping-pooling">Overlapping Pooling</h4>
<p>就是Pooling kernel的size要比stride大。比如一个$12\times 12$的图片，用$5\times 5$的pooling kernel，步长为$3$，步长要比kernel核小，即$3$比$5$小。<br>
为什么这能减小过拟合？</p>
<ul>
<li>可能是减小了Pooling过程中信息的丢失。</li>
</ul>
<blockquote>
<p>If the pooling regions do not overlap, the pooling regions are disjointed and if that is the case, more information is lost in each pooling layer. If some overlap is allowed the pooling regions overlap with some degree and less spatial information is lost in each layer.[4]</p>
</blockquote>
<h4 id="数据增强">数据增强</h4>
<p>目的：防止过拟合</p>
<h5 id="裁剪和翻转">裁剪和翻转</h5>
<p>输入是$256\times 256 \times 3$的图像。<br>
训练：对每张图片都提取多个$224\times 224$大小的patch，这样子总共就多产生了$(256-224)\times (256-224) = 1024$个样本，然后对每个patch做一个水平翻转，就有$1024\times 2 = 2048$个样本。<br>
测试：通过对每张图片裁剪五个（四个角落加中间）$224\times 224$的patches，并且对它们做翻转，也就是有$10$个patches，网络对十个patch的softmax层输出做平均作为预测结果。</p>
<h5 id="在图片上调整rgb通道的密度">在图片上调整RGB通道的密度</h5>
<p>使用PCA对RGB值做主成分分析。对于每张训练图片，加上主成分，其大小正比于特征值乘上一个均值为$0$，方差为$0.1$的高斯分布产生的随机变量。对于一张图片$x,y$点处的像素值$I_{xy}=[I_{xy}^R, I_{xy}<sup>G,I_{xy}</sup>B]^T$，加上$[\bold{p_1},\bold{p_2},\bold{p_3}][\alpha_1\lambda_1,\alpha_2\lambda_2,\alpha_3\lambda_3]$，其中$[\bold{p_1},\bold{p_2},\bold{p_3}]$是特征向量，$\lambda_i$是特征值，$\alpha_i$就是前面说的随机变量。</p>
<h4 id="dropout">Dropout</h4>
<p>通过学习鲁棒的特征防止过拟合。<br>
在训练的时候，每个隐藏单元的输出有$p$的概率被设置为$0$，在该次训练中，如果这个神经元的输出被设置为$0$，它就对loss函数没有贡献，反向传播也不会被更新。对于一层有$N$个神经单元的全连接层，总共有$2^N$种神经元的组合结果，这就相当于训练了一系列共享参数的模型。<br>
在测试的时候，所有隐藏单元的输出都不丢弃，但是会乘上$p$的概率，相当于对一系列集成模型取平均。具体可见<a href="https://mxxhcm.github.io/2019/03/23/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-dropout/">dropout</a><br>
在该模型中，作者在三层全连接层的前两层输出上加了dropout。</p>
<h4 id="局部响应归一化-local-response-normalizaiton">局部响应归一化(Local Response Normalizaiton)</h4>
<p>事实上，后来发现这个东西没啥用。但是这里还是给出一个公式。</p>
<p>$$ b^i_{x,y} = \frac{a^i_{x,y}}{(k+\alpha \sum<sup>{min(N-1,\frac{i+n}{2})}_{j=max(0,\frac{i-n}{2})}(a</sup>j_{x,y})^2)^{\beta}}$$<br>
其中$a^i_{x,y}$是在点$(x,y)$处使用kernel $i$之后，在经过ReLU激活函数。$k,n,\alpha,\beta$是超参数。</p>
<blockquote>
<p>It seems that these kinds of layers have a minimal impact and are not used any more. Basically, their role have been outplayed by other regularization techniques (such as dropout and batch normalization), better initializations and training methods.</p>
</blockquote>
<h3 id="整体架构">整体架构</h3>
<h4 id="目标函数">目标函数</h4>
<p>多峰logistic回归。</p>
<h4 id="并行框架">并行框架</h4>
<p>下图是并行的架构，分为两层，上面一层用一个GPU，下面一层用一个GPU，它们只在第三个卷积层有交互。<br>
<img src="/2019/03/13/cnn/alexnet.png" alt="alexnet"></p>
<h4 id="简化框架">简化框架</h4>
<p>下图是简化版的结构，不需要使用两个GPU。<br>
<img src="/2019/03/13/cnn/alexnet_simple.png" alt="alexnet_simple"></p>
<h4 id="数据流-简化框架">数据流（简化框架）</h4>
<p>输入是$224\times 224 \times 3$的图片，第一层是$96$个stride为$4$的$11\times 11\times 3$卷积核构成的卷积层，输出经过max pooling(步长为2，kernel size为3)输入到第二层；第二层有$256$个$5\times 5\times 96$个卷积核，输出经过max pooling(步长为2，kernel size为3)输入到第三层；第三层到第四层，第四层到第五层之间没有经过pooling和normalization)，第三层有384个$3\times 3\times 256$个卷积核，第四层有$384$个$3\times 3\times 384$个卷积核，第五层有$256$个$3\times 3\times 384$个卷积核。然后接了两个$2048$个神经元的全连接层和一个$1000$个神经元的全连接层。</p>
<h3 id="实验">实验</h3>
<h4 id="datasets">Datasets</h4>
<p>ILSVRC-2010</p>
<h4 id="baselines">Baselines</h4>
<ul>
<li>Sparse coding</li>
<li>SIFT+FV</li>
<li>CNN</li>
</ul>
<h4 id="metric">Metric</h4>
<ul>
<li>top-1 error rate</li>
<li>top-5 error rate</li>
</ul>
<h3 id="代码">代码</h3>
<p>pytorch实现<br>
<a href="https://github.com/mxxhcm/myown_code/blob/master/CNN/alexnet.py" target="_blank" rel="noopener">https://github.com/mxxhcm/myown_code/blob/master/CNN/alexnet.py</a></p>
<h2 id="maxout-networks">Maxout networks</h2>
<p>论文名称：Maxout Networks<br>
下载地址：<a href="https://arxiv.org/pdf/1302.4389.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1302.4389.pdf</a></p>
<h2 id="nin">NIN</h2>
<p>论文名称：Network In Network<br>
论文地址：<a href="https://arxiv.org/pdf/1312.4400.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1312.4400.pdf</a></p>
<h3 id="摘要">摘要</h3>
<p>这篇文章作者使用更复杂的micro神经网络代替CNN，用一个mlp实例化micro nn。CNN中的filter用的是generalized linear model(GLM)。本文使用nonlinear的FA，作者用一个multi layers perceptron 取代GLM。通过和cnn类似的操作对input进行sliding得到feature maps，然后传入下一层，deep NIN通过堆叠多层类似的结构生成。同时作者使用average pooling取代最后的fullcy connected layer。<br>
本文的两个contribution是：</p>
<ol>
<li>使用MLP代替CNN中linear model，引入$1\times 1$的filter</li>
<li>使用average pooling代替fully connected layer。</li>
</ol>
<p>在传统的CNN中，一个concept的不同variation可能需要多个filters，这样子会让下一层的的计算量太大。高层CNN的filters对应input的区域更大，高层的concept是通过对底层的concepts进行组合得到的。这里作者在每一层都对local patch进行组合，而不是在高层才开始进行组合，在每一层中，micro network计算更加local patches更abstract的特征。</p>
<h3 id="network-in-network">Network in Network</h3>
<h4 id="mlp-convolution-layers">MLP convolution layers</h4>
<p>为什么使用MLP代替GLP？</p>
<ol>
<li>MLP和CNN的结构兼容，可以使用BP进行训练；</li>
<li>MLP本身就是一个deep model，满足feature复用的想法。</li>
</ol>
<p>如下图所示，是MLP CNN和GLP CNN的区别。<br>
<img src="/2019/03/13/cnn/mlp_vs_linear.png" alt="mvl_vs_glp"></p>
<p>MLP的公式如下。<br>
<img src="/2019/03/13/cnn/equ.png" alt="equ"><br>
从cross channel(feature maps)的pooling角度来看，上面的公式相当于在一个正常的conv layer上进行多次的parametric pooling，每一个pooling layer对输入的feature map进行线性加权，经过一个relu层之后在下一层继续进行pooling。Cross channel pooled的feature maps在接下来的层中多次进行cross channel pooling。这个cross channel pooling的结构的作用是学习复杂的cross channel信息。<br>
其实整个cross channel的paramteric pooling结构相当于一个普通的卷积加上了多个$1\times 1$的卷积，如下图所示：<br>
<img src="/2019/03/13/cnn/11filter.png" alt="11filter"></p>
<h4 id="global-average-pooling">Global average pooling</h4>
<p>FC layers证明是容易过拟合的，dropout被提出来正则化fc layers的参数。<br>
本文提出的global average pooling取代了CNN的fc layers，直接在最后一个mlpconv layer中对应于分类任务中的每个类别生成一个feature map。然后用在feature maps上的average pooling代替fc layers，然后把它送入softmax layer。原来的CNN是将feature map reshape成一个一维向量，现在是对每一个feature map进行一个average pooling，有多少个feature map就有多少个pooling，相当于一个feature map对应与一个类型。<br>
这样做有以下几个好处：</p>
<ol>
<li>在fc layers上的global average pooling让feature map和categories对应起来，feature map可以看成类别的置信度。</li>
<li>直接进行average pooling不用优化fc layer的参数，也就没有过拟合问题。</li>
<li>global average pooling对全局信息进行了加和，对于input的spatial信息更加鲁邦。</li>
</ol>
<h4 id="nin-v2">NIN</h4>
<p>如下图所示，是NIN的整体架构。<br>
<img src="/2019/03/13/cnn/nin.png" alt="nin"><br>
下图是一个具体参数化的示例<br>
<img src="/2019/03/13/cnn/instance.png" alt="instance"></p>
<h3 id="实验-v2">实验</h3>
<h2 id="overfeat-2013">OverFeat(2013)</h2>
<p>论文名称：OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks<br>
论文地址：<a href="https://arxiv.org/pdf/1312.6229.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1312.6229.pdf</a></p>
<h3 id="概述-v2">概述</h3>
<p>本文提出了一个可用于classification, localization和detection等任务的CNN框架。<br>
ImageNet数据集中大部分选择的是几乎填满了整个image中心的object，image中我们感兴趣的objects的大小和位置也可能变化很大。为了解决这个问题，作者提出了三个方法：</p>
<ol>
<li>用sliding window和multiple scales在image的多个位置apply ConvNet。即使这样，许多window中可能包含能够完美识别object类型的一部分，比如一个狗头。。。最后的结果是classfication很好，但是localization和detection结果很差。</li>
<li>训练一个网络不仅仅预测每一个window的category distribution，还预测包含object的bounding box相对于window的位置和大小。</li>
<li>在每个位置和大小累加每个category的evidence</li>
</ol>
<h3 id="vision任务">Vision任务</h3>
<p>classification，localization和detection。classification和localization通常只有一个很大的object，而detection需要找到很多很小的objects。<br>
classification任务中，每个image都有一个label对应image中主要的object的类型。为了找到正确的label，每个图片可以猜$5$次（图片中可能包含了没有label的数据）。localization任务中，不仅要给出label，还需要找到这个label对应的bouding box，bounding box和groundtruth至少要有$50$匹配，label和bounding box也需要匹配。detection和localization不同的是，detection任务中可以有任何数量的objects，false positive会使用mean average precison measure。localization任务可以看成classification到detection任务的一个中间步。</p>
<h3 id="fcn">FCN</h3>
<p>用卷积层代替全连接层。具体是什么意思呢。<br>
alexnet中，有5层卷积层，3层全连接层。假设第五层的输出是$5\times 5 \times 512$，$512$是output channels number，$5\times 5$是第五层的feature maps的大小。如果使用全连接的话，假设第六层的输出单元是$N$个，第六层权重总共是$(5\times 5\times 512) * (N)$，对于一个训练好的网络，图片的输入大小是固定的，因为第六层是一个全连接层，输入的大小是需要固定的。如果输入一个其他大小的图片，网络就会出错，所以就有了Fully Convolutional networks，它可以处理不同大小的输入图片。<br>
如下所示，使用某个大小的image训练的网络，在classifier处用卷积层替换全连接层，如果使用全连接层，首先将$(5, 5, out_channels)$的feature map进行flatten $5\times 5\times out_channels$，然后经过三层全连接，最后输出一个softmax的结果。而fcn使用卷积层代替全连接，使用$N$个$5\times 5$的卷积核，直接得到$1\tims 1 \times N$的结果，最后得到一个$1\times 1\times C$的输出，$C$代表图像类别，$N$代表全连接层中隐藏节点的数量。<br>
<img src="/2019/03/13/cnn/fcn.png" alt="fcn"><br>
事实上，FCN和全连接的本质上都是一样的，只不过一个进行了flatten，一个直接对feature map进行操作，直接对feature map操作可以处理不同大小的输入，而flatten不行。<br>
当输入图片大小发生变化时，输出大小也会改变，但是网络并不会出错，如下所示：<br>
<img src="/2019/03/13/cnn/fcn2.png" alt="fcn2"><br>
最后输出的结果是$2\times 2 \times C$的结果，可以直接对它们取平均，最后得到一个$1\times 1\times C$的分类结果。</p>
<h3 id="offset-max-pooling">offset Max pooling</h3>
<p>我们之前做max pooling的时候，设$kernel_size=3, stride_size=1$，如果feature map是$3$的倍数，那么只有一个pooling的结果，但是如果不是$3$的倍数，max pooling会很多个结果，比如有个$20\times 20$的feature map，在$x,y$上做max pooling分别有三种结果，分别从$x,y$的位置$0$开始，位置$1$开始，位置$2$开始，排列组合有$9$中情况，这九种情况的结果是不同的。<br>
如下图所示，在一维的长为$20$的pixels上做maxpooling，有三种情况。<br>
<img src="/2019/03/13/cnn/offset_maxpooling.png" alt="offset_maxpooling"></p>
<h3 id="overfeat">overfeat</h3>
<p>这两个方法中，fcn是在输入图片上进行的window sliding，而offset maxpooling是在feature map进行的window sliding，这两个方法结合起来就是overfeat，要比alexnet直接在输入图片上进行window sliding 要好。</p>
<h3 id="classification">Classification</h3>
<h4 id="training">training</h4>
<ul>
<li>datset<br>
Image 2012 trainign set（1.2million iamges，C=$1000$ classes)。</li>
<li>data argumented<br>
对每张图片进行下采样，所以每个图片最小的dimension需要是$256$。<br>
提取$5$个random crops以及horizaontal flips，总共$10$个$221\times 221$的图片</li>
<li>batchsize<br>
$128$</li>
<li>初始权重<br>
$(\mu, \sigma)= (0, 1\times 10^{-2})$</li>
<li>momentum<br>
0.6</li>
<li>l2 weigth decay<br>
$1\times 10^{-5}$</li>
<li>lr<br>
初始是$5\times 10^{-2}$，在$(30,50,60,70,80)$个epoches后，乘以$0.5$</li>
<li>non-spatial<br>
这个说的是什么呢，在test的时候，会输出多个output maps，对他们的结果做平均，而在training的时候，output maps是$1\times 1$。</li>
</ul>
<h4 id="model架构">model架构</h4>
<p>下图展示的是fast model，spatial input size在train和test时候是不同的，这里展示的是train时的spatial seize。layer 5是最上层的CNN，receptive filed最大。后续是FC layers，在test时候使用了sliding window。在spatial设置中，FC-layers替换成了$1\times 1$的卷积。<br>
<img src="/2019/03/13/cnn/overfeat_fast.png" alt="overfeat_fast"><br>
下图给出了accuracy model的结构，<br>
<img src="/2019/03/13/cnn/overfeat_accuracy.png" alt="overfeat_accuracy"><br>
总的来说，这两个模型都在alexnet上做了一些修改，但是整体架构没有大的创新。</p>
<h4 id="多scale-classification">多scale classification</h4>
<p>alexnet中，对一张照片的$10$个views（中间，四个角和horizontal flip)的结果做了平均，这种方式可能会忽略很多趋于，同时如果不同的views有重叠的话，计算很redundant。此外，alexnet中只使用了一个scale。<br>
作者对每个iamge的每一个location和多个scale都进行计算。<br>
如下图，对应了不同大小的输入图片，layer 5 post pool中$(m\times n)\time(3\times 3)$，前面$m\times n$是fcn得到的不同位置的feature map，后面$3\times 3$是$kernel_size=3$的offset max pooling得到的featrue map。乘起来是所有的预测结果。<br>
<img src="/2019/03/13/cnn/multi_scale.png" alt="multi_scale"></p>
<h3 id="localization">localization</h3>
<h3 id="detection">Detection</h3>
<h2 id="zfnet-2014">ZFNet(2014)</h2>
<p>论文名称：Visualizing and Understanding Convolutional Networks<br>
论文地址：<a href="https://cs.nyu.edu/~fergus/papers/zeilerECCV2014.pdf" target="_blank" rel="noopener">https://cs.nyu.edu/~fergus/papers/zeilerECCV2014.pdf</a><br>
为什么叫ZFNet，两个作者名字首字母的拼写。</p>
<p>首先我有一个问题？就是什么是一个activation。在原文的$2.1$节，有这样一个介绍：</p>
<blockquote>
<p>We present a novel way to map these activities back to the input pixel space, showing what input pattern originally caused a given activation in the feature maps.<br>
我的理解是一个activation就是feature map中的一个unit。事实上，feature map也叫activation map，因为它是image中不同parts的acttivation，而叫feature map是因为它是image中找到特定的feature。</p>
</blockquote>
<h3 id="概述-v3">概述</h3>
<p>这篇文章从可视化的角度给出中间特征的和classifier的特点，分析如何改进alexnet来提高imagenet classification的accuracy。<br>
为什么CNN结果这么好？</p>
<ol>
<li>training set越来越大</li>
<li>GPU的性能越来越好</li>
<li>Dropout等正则化技术</li>
</ol>
<p>但是CNN还是一个黑盒子，我们不知道它为什么表现这么好？这篇文章给出了一个可视化方法可视化任意层的feature。</p>
<p>那么本文的contribution是什么呢？使用deconvnet进行可视化，通过分析特征行为，对alexnet进行fine tune提升模型性能。</p>
<h3 id="使用deconvnet可视化">使用deconvnet可视化</h3>
<p>什么是deconvnet？可以看成和convnet拥有同样组成部分（pooling, filter)等，但是是反过来进行的。如下图所示，convnet是把pixels映射到feature，或者到底层features映射到高层features，而deconvnet是把高层features映射到底层features，或者把features映射到pixels。在测试convnet中给定feature maps的一个activation时，设置所有其他的activation为0，将这个feature map传入deconvnet网络中。<br>
<img src="/2019/03/13/cnn/fig1.png" alt="fig1"><br>
图片左上为deconv，右上为conv。conv的流程为filter-&gt;rectify-&gt;pooling；deconv的流程为unpool-&gt;rectify-&gt;filter。</p>
<h4 id="unpooling">Unpooling</h4>
<p>convnet中的max pooling是不可逆的，这里作者使用switch variables记录下max pooling后的元素在没有pooling时的位置，进行近似的恢复。</p>
<h4 id="rectification">Rectification</h4>
<p>convnet使用relu non-linearities。deconvnet还是使用relu，这里我有些不理解，为什么？为什么deconve还是使用relu</p>
<h4 id="filtering">Filtering</h4>
<p>deconvnet使用convnet中filters的transposed版本。</p>
<h3 id="training-v2">Training</h3>
<h4 id="整体架构-v2">整体架构</h4>
<p><img src="/2019/03/13/cnn/fig3.png" alt="fig3.png"></p>
<ul>
<li>training set<br>
1.3百万张图片，1000类</li>
<li>processed<br>
每个RGB图像resized成最小边维度为$256$，cropping中间的$256 \times 256$，减去所有像素的平均值。crops$10$个$224\times 224$（四个角落和中心以及horizontal flips)</li>
<li>优化方法<br>
带momentumSGD</li>
<li>batch size<br>
128</li>
<li>lr<br>
初始是$10^{-2}$,然后手动anneal</li>
<li>momentum<br>
0;9</li>
<li>Dropout<br>
layer 6和layer 7,0.5</li>
<li>weights和biases初始化<br>
weights设置为$10^{-2}$，biases设置为$0$</li>
<li>normalizaiton<br>
对第一层的filter，如果RMS超过了$10^{-1}$就设置为$10^{-1}$</li>
<li>训练次数<br>
70epochs</li>
</ul>
<h3 id="visualizaiton">Visualizaiton</h3>
<h4 id="feature-visualization">Feature visualization</h4>
<p>如下图所示，使用deconvnet可视化一些feacutre activation。给定一个feature map，选择其中最大的$9$个activations对应的样本，一个feature map是通过一个filter得到的，而一个filter提取的是一个特征，所以这$9$个activations都是一个filter提取的不同图片中的同一个特征。然后将它们输入deconvnet，得到pixel spaces，可以查看哪些不同的结构（哪些原始）产生了这个feature，展现这个filter对于输入deformation的invariance。在黑白图像的旁边有对应的图像原图，他们要比feature的variation更多，因为feature关注的是图像的invariance。比如layer 5的第一行第二列的九个图，这几个patch看起来差异很大，但是却在同一个feature map中，因为这个feature map关注的是背景中的草，并不是其他objects。更多的我们可以看出来，第二层对应corner和edge等，第三次对应更复杂的invariances，比如textures和text等。第四层更class-specific，第五层是object variation。<br>
<img src="/2019/03/13/cnn/fig2.png" alt="fig2"></p>
<h4 id="feature-evolution-durign-training">Feature evolution durign training</h4>
<p>下图随机选择了几个不同的feature，然后展示了他们在不同layer不同epochs（1, 2, 5, 10, 20, 30, 40, 64）的可视化结果。<br>
<img src="/2019/03/13/cnn/fig4.png" alt="fig4"></p>
<h4 id="架构选择">架构选择</h4>
<p>通过可视化alexnet的first layer和second layer，有了各种各样的问题。First layer中主要是high和low frequency的信息，而2nd layer有很多重复的，因为使用stride为$4$而不是$2$。作者做了两个改进：</p>
<ol>
<li>将first layer的filter size从$11\times 11$改成了$7\times 7$</li>
<li>卷积的步长从$4$改成了$2$</li>
</ol>
<p>如下图所示：<br>
<img src="/2019/03/13/cnn/fig5.png" alt="fig5"></p>
<h4 id="occlusion-sensitivity">Occlusion Sensitivity</h4>
<p>model是否真的识别了object在image中的位置，还是仅仅使用了上下文信息？下图中的例子证明了model真的locate了object,当遮挡住物体的部分增大时，给出正确分类的概率就减小了。移动遮挡方块的位置，给出一个和方块位置相关的分类概率函数，我们可以看出来，model really works。<br>
<img src="/2019/03/13/cnn/fig6.png" alt="fig6"></p>
<h3 id="实验-v3">实验</h3>
<p>第一个实验通过使用，证明了前面的特征提取层和fc layers都是有用的。<br>
第二个实验保留前面的特征提取层和fc layers，将最后的softmax替换。</p>
<h2 id="vggnet-2014">VGGNet(2014)</h2>
<p>论文名称：VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION<br>
论文地址：<a href="https://arxiv.org/pdf/1409.1556.pdf%20http://arxiv.org/abs/1409.1556.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1409.1556.pdf http://arxiv.org/abs/1409.1556.pdf</a><br>
VGG是Visual Geometry Group的缩写</p>
<h3 id="概述-v4">概述</h3>
<p>这篇文章主要研究了CNN深度对大规模图像识别问题精度的影响。本文的主要contribution就是使用多层的$3\times 3$ filters替换大的filter，增加网络深度，提高识别精度。</p>
<h3 id="方案">方案</h3>
<h4 id="架构">架构</h4>
<p><strong>训练</strong>，输入$224\times 224$大小的RGB图片。对每张图片减去训练集上所有图片RGB 像素的均值。预处理后的图片被输入多层CNN中，CNN的filter是$3\times 3$的，作何也试了$1\times 1$的filter，相当于对输入做了一个线性变换，紧跟着一个non-linear 激活函数，这里的$1\times 1$的filter没有用于dimention reduction。stride设为$1$，添加padding使得卷积后的输出大小不变。同时使用了$5$个max-pooling层（并不是每一层cnn后面都有max-pooling)，max-pooling的window是$2\times 2$，stride是$2$。<br>
在训练的时候CNN后面接的是三个FC layers，前两个是$4096$单元，最后一层是$1000$个单元的softmax。所有隐藏层都使用ReLu非线性激活函数。<br>
在测试的时候使用fcn而不是直接flatten。</p>
<h4 id="配置">配置</h4>
<p>这篇文章给出了五个网络架构，用$A-E$表示，它们只有在深度上有所不同：从$11$层($8$个conv layers和$3$个FC layers)到$19$层（$16$个conv layers和$3$个FC layers）。Conv layers的channels很小，从第一层的$64$，每过一个max pooling layers，变成原理啊的两倍，直到$512$。具体如下表所示。<br>
<img src="/2019/03/13/cnn/vgg_conf.png" alt="vgg_conf"><br>
网络的参数个数如下表所示。<br>
<img src="/2019/03/13/cnn/vgg_weights_num.png" alt="vgg_weights_num"><br>
网络$A$的参数计算：<br>
\begin{align*}<br>
64\times 3\times 3\times 3 + \\<br>
128\times 3\times 3\times 64 + \\<br>
256\times 3\times 3\times 128 + \\<br>
256\times 3\times 3\times 256 + \\<br>
512\times 3\times 3\times 256 + \\<br>
512\times 3\times 3\times 512 + \\<br>
2\times 512\times 3\times 3\times 512 + \\<br>
7\times 7\times 512\times 4096 + \\<br>
4096\times 4096 + \\<br>
4096\times 1000 = \\<br>
132851392<br>
\end{align*}<br>
网络$B$的参数计算：<br>
\begin{align*}<br>
64\times 3\times 3\times 3 + \\<br>
128\times 3\times 3\times 64 + \\<br>
128\times 3\times 3\times 128 + \\<br>
256\times 3\times 3\times 128 + \\<br>
256\times 3\times 3\times 256 + \\<br>
256\times 3\times 3\times 256 + \\<br>
512\times 3\times 3\times 256 + \\<br>
512\times 3\times 3\times 512 + \\<br>
2\times 512\times 3\times 3\times 512 + \\<br>
7\times 7\times 512\times 4096 + \\<br>
4096\times 4096 + \\<br>
4096\times 1000 = \\<br>
133588672<br>
\end{align*}<br>
其实主要的网络参数还是在全连接层，$7\times 7\times 512\times 4096=102760448<br>
$。</p>
<h4 id="卷积核作用">卷积核作用</h4>
<ol>
<li>为什么要用三个$3\times 3$的conv layers替换$7\times 7$个conv layers？</li>
</ol>
<ul>
<li>使用三个激活函数而不是一个，让整个决策更discriminative。</li>
<li>减少了网络参数，三个有$C$个通道的$3\times 3$conv layers,总的参数是$3\tims(3<sup>2C</sup>2)=27C^2$，而一个$C$通道的$7\times 7$ conv layers，总参数是$49C^2$。可以看成是一种正则化。</li>
</ul>
<ol start="2">
<li>$1\times 1$ conv layers用来增加非线性程度，本文中使用的$1\times 1$的conv layers可以看成加了非线性激活函数的投影。</li>
</ol>
<h3 id="分类框架">分类框架</h3>
<h4 id="training-v3">training</h4>
<ul>
<li>目标函数<br>
多峰logistic regression</li>
<li>训练方法<br>
mini-batch gradient descent with momentum</li>
<li>batch size<br>
256</li>
<li>momentum<br>
0.9</li>
<li>正则化<br>
$L_2$参数正则化(5\codt 10^{-4})<br>
0.5 dorpout 用于前两个FC layers</li>
<li>lr<br>
初始值为$10^{-2}$，当验证集的accuracy不再提升时，除以$10$。学习率总共降了$3$次，$370K$次迭代后停止。</li>
<li>图像预处理<br>
从rescaled中随机cropped $224\times 224$的RGB图像。<br>
使用alexnet中的随机horizontal flipping和随机RGB colour shift。</li>
<li>iamge rescale<br>
用$S$表示training image的小边的大小，$S$也叫作train sacle。网络的输入是从training image中cropped得到的$224\times 224$的图像。所以只要$S$取任何不小于$224$的值即可，如果$S=224$，那么crop在统计上会captuer整个图片，完全包含training image最小的那边；$S&gt;&gt;224$的时候，crop会产生很小一部分的图像。<br>
作者尝试了固定$S$和不固定的$S$。对于固定$S$，设置$S=256$和$S=384$，首先在$S=256$上训练，然后用$S=256$训练的参数初始化$S=384$的参数，使用更小的初始学习率$10^{-3}$。不固定$S$时，$S$从$[S_{min}, S_{max}](S_{max}=512,S_{min}=256)$任意采样，然后crop。</li>
<li>VGG vs alexnet<br>
VGG参数多，深度深，但是收敛快，原因：</li>
</ul>
<ol>
<li>更小的filter带来的implicit regularisation</li>
<li>某些层的预先初始化。<br>
这个解决的是网络深度过深，某些初值使得网络不稳定的问题。解决方法：先随机初始化不是很深的网络A，进行训练。在训练更深网络的时候，使用A网络的值初始化前$4$个卷基层和最后三个FC layers。随机初始化的网络参数，从均值为$0$，方差为$10^{-2}$的高斯分布中采样得到。</li>
</ol>
<h4 id="testing">testing</h4>
<ol>
<li>测试的时候先把input image的窄边缩放到$Q$，$Q$也叫test scale，$Q$和$S$不一定需要相等。</li>
<li>这里和overfeat模型一样，在卷积网络之后采用了fcn，而不是fc layers。</li>
</ol>
<h3 id="classfication">classfication</h3>
<p>ILSVRC-2012，training($1.3M$张图片)，validation($50K张$)，testing($100K$张)<br>
两个metrics：top-1和top-5 error。top-1 error是multi-class classification error，不正确分类图像占的比例；top-5 error是预测的top-5都不是ground-truth。</p>
<h4 id="single-scale-evaluation">single scale evaluation</h4>
<p>$S$固定时，设置test image size $Q=S=256$；<br>
$S$抖动时，设置test image size $Q=0.5(S_{min}+S_{max})=0.5(256+512)=384$，$S\in [S_{min},S_{max}]$。</p>
<h4 id="multi-scale-evaluation">multi scale evaluation</h4>
<p>用同一个模型对不同rescaled大小的图片多次test，即对于不同的$Q$。<br>
固定$S$时，在三个不同大小的test image size $Q={S-32,S,S+32}$评估。<br>
$S$抖动时，模型是在$S\in [S_{min},S_{max}]$上训练的，在$Q={S_{min}, 0.5(S_{min}+S_{max}), S_{max}}$上进行test。</p>
<h4 id="多个crop-evaluation">多个crop evaluation</h4>
<p>这个是为了和alexnet做对比，alexnet网络在testing时，对每一张图片都进行多次cropped，对testing的结果做平均。</p>
<h4 id="convnet-funsion">convnet funsion</h4>
<p>之前作者的evaluation都是在单个的网络上进行的，作者还试了将不同网络的softmax输出做了平均。</p>
<h2 id="inception-v1-googlelenet">Inception V1(GoogleLeNet)</h2>
<h3 id="摘要-v2">摘要</h3>
<p>提出一种方法能够在不增加太多计算代价的同时增加网络的深度和宽度。</p>
<h3 id="motivation">motivation</h3>
<p>直接增加网络的深度和宽度有两个缺点：</p>
<ol>
<li>参数更多，容易过拟合，尤其是训练集太小的情况下，高质量的训练集很难生成。</li>
<li>需要更多的计算资源。比如两层CNN，即使每一层中线性增加filters的个数也会造成计算代价指数级增加。如果增加的权重接近$0$的话，计算代价就浪费了。而现实中的计算资源是有限的。</li>
</ol>
<p>如何解决这个问题呢？使用sparsity layers取代fully connetcted layers。但是现在的计算资源在处理non-uniform 的sparse data时是非常低效的，即使数值操作减小$100$倍，查找的时间也是很多的。而针对CPU和GPU的dense matrix计算能够加快fc layer的学习。现在绝大部分的机器学习视觉模型在sparsity spatial domain都仅仅利用了CNN，而convolution是和前一层patches的dense connection。1998年的convnet为了打破网络对称性，改善学习结果，使用的是random和sparse连接，而在alexnet中为了并行优化计算，使用了全连接。当前cv的state-of-the-art架构使用的都是unifrom structure，为了高效的进行dense计算，filters和batch size的数量都是很大的。<br>
稀疏性可以解决过拟合和资源消耗过多的问题，而稠密连接可以提高计算效率。所以接下来要做的是一个折中，利用filter维度的稀疏结构，同时利用硬件在dense matrices上的计算进行加速。<br>
Inception架构就是使用一个dense组件去逼近sparse结构的例子。</p>
<h3 id="算法">算法</h3>
<p>Inception的idea是使用dense组件近似卷积的局部稀疏结构。本文的旋转不变型是利用convolutional building blocks完成的，找到optimal local construction，然后不断堆叠。文章[11]中建议layer-by-layer的构建，分析上一层之间的关系，并将具有高相关性的units进行分组。这些相关的units cluster构建成了下一层的units，并且和上一层的units相连接。假设之前层中的每一个unit都对应输入图片中的一些region，这些units分组构成filter banks。这就意味着在靠近输入的层中我们会得到很多关于local regions相关的units。通过在下一层中使用$1\times 1$的卷积，可以找到关注于同一个region的很多个clusters。（这里加一些我自己的理解，$1\times 1$的卷积层可以找到那些重复的feature map？？）当然，也有可能有更大的cluster可以通过在更大的patches上进行卷积得到，所以这里同时在一层中同时使用$1\times 1, 3\times 3, 5\times 5$的filters，使用这些大小的filter仅仅是因为方便，然后将他们的输出进行组合当做下一层的输入。当然可以加上pooling，如下图所示。<br>
<img src="/2019/03/13/cnn/naive_inception.png" alt="naive inception"><br>
但是，这样子计算量还是很大，大量$3 \times 3, 5\times 5$在卷积时的计算量，如果再加上输入shape和输出shape相等的max pooling操作，下一层的输入维度相当大，计算开销j就爆炸了。这就使用了本文的第二个idea：使用$1\times 1$的filter降维减少计算量。在$3\times 3, 5\times 5$大小filter之前添加$1\times 1$的卷积进行降维。<br>
<img src="/2019/03/13/cnn/dr_inception.png" alt="dimension reduction inception"></p>
<p>这个架构的好处：</p>
<ol>
<li>在每一层都可以增加units的数量而不用担心计算量暴增。首先将上一层大量filters的输出进行进行降维，然后输入到下一层。</li>
<li>visual信息用不同的scales进行处理，然后拼接起来，这样子在下一层可以同时从不同scales中提出features。</li>
</ol>
<h3 id="googlenet">GoogLeNet</h3>
<p>作者给出了Inception的一个示例，叫GoogLeNet。网络具体配置如下：<br>
<img src="/2019/03/13/cnn/GoogLeNet.png" alt="GoogLeNet"><br>
其中，&quot;#$3 \times 3$ reduce&quot;和&quot;#$5 \times 5$ reduce&quot;表示在$3\times 3, 5\times 5$卷积之前使用$1\times 1$的filters个数，pool proj这一列表示在max pooling之后的$1\times 1$的filters个数。<br>
作者在GoogLeNet中还使用了两个额外的分类层辅助训练。通过观察得知相对shallower的网络有很好的性能，那么在反向传播时，深层网络的中间特征应该是很有判别力的。<br>
通过在网络中间添加辅助的classfiers，作者想要让网络底层也有判别力。在训练的时候，在$4a$和$4d$模块后添加分类器，然后将所有的loss乘上一个权重加到总的loss上，在test时，这些辅助网络被扔掉。</p>
<h2 id="batch-normalization">Batch Normalization</h2>
<p>论文名称：Batch Normalization: Accelerating Deep Network Training b<br>
y Reducing Internal Covariate Shift<br>
论文地址：<a href="https://arxiv.org/pdf/1502.03167.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1502.03167.pdf</a></p>
<h3 id="概述-v5">概述</h3>
<p>在训练深度神经网络的时候，随着训练的不断进行，网络权重在不停的变，除了第一层之外的每层输入也在不停的变，所以就使得权重每次都要去适应新的输入distributions。这就导致训练速度很慢，学习率的要很小，很难使用saturaing nonlinearities激活函数训练。作者把这个问题叫做internal covariate shift，提出了batch normalization解决该问题，bn对于参数初始化的要求没那么高，允许使用更高的学习率。<br>
BN可以看成一种正则化手段。</p>
<h3 id="简介">简介</h3>
<p>SGD相对于单个样本的GD来说，使用mini-batch的梯度作为整个训练集的估计值，效果更好；同时并行计算提高了效率。之前的工作使用ReLU，更好的初始化以及小的学习率来解决梯度消失问题，而本文作者的想法是让非线性输入的分布尽可能稳定，从而解决梯度饱和等问题，加快训练。本文提出的batch normalization通过固定每一层输入的均值和方差减少internal covariate shift，同时减少了gradients对于初始参数的依赖性。在使用了BN的网络中，也可以使用如sigmod和tanh的saturating nonlirearities激活函数，并不是一定要用relu激活函数。</p>
<h3 id="mini-batch-normalization">Mini-Batch Normalization</h3>
<p>Whitening每一层的所有inputs需要很大的代价，而且并不是每个地方都是可导的。作者进行了两个简化。第一个是并不是对所有输入的features进行whiten，而是对每一个feautre单独的normalization，将他们转化成均值为0，方差为1的数据。对于一个d维的输入$x=(x^1,\cdots, x^d)，对每一维进行normalize：<br>
$$\hat{x}^k= \frac{x^k - \mathbb{E}\left[x<sup>k\right]}{\sqrt{Var\left[x</sup>k\right]}}$$<br>
其中的期望和方差是整个training set 的期望和方差。但是仅仅normalize每一层的输入可能改变这一层的表示。比如normalize sigmod的输入会将它们的输出限制在非线性的线性区域。为了解决这个问题，在网络中添加的这个transformation应该能够表示identity transform，作者对每个activation $x<sup>k$引入了一对参数，$\gamma</sup>k, \beta^k$，它们对normalized value进行scale和shift：<br>
$$y^k = \gamma^k \hat{x}^k + \beta^k$$<br>
这些参数和模型参数一块，都是学习出来的，如果学习到$\gamma<sup>k=\sqrt{Var\left[x</sup>k\right]},\beta^k = \mathbb{E}\left[x^k\right]$，就可以表示恒等变换了。。<br>
上面说的是使用整个training set的方差和期望进行normaliza，事实上，在sgd中这是不切合实际的。因此，就引入了第二个简化，使用每个mini-batch的方差和期望进行normalize，并且方差和期望是针对于每一个维度计算的。给出一个大小为$m$的batch $B$，normalization独立的应用于每一个维度。用$\hat{x}_{1,\cdots, m}$表示normalized values，以及它们的linear transformation：$y_{1,\cdots,m}$。这个transform表示为：$BN_{\gamma, \beta}:x_{1,\cdots, m} \rightarrow y_{1,\cdots,m}$，称为Batch Normalization Transform，完整的算法如下：<br>
算法1 Batch Normalizing Transform<br>
输入：　mini-batch：$B={x_{1,\cdots, m}}，要学习的参数$\gamma,\beta$<br>
输出：${y_i=BN_{\gamma,\beta}(x_i)}$<br>
$\mu\leftarrow \frac{1}{m}\sum_{i=1}^mx_i$  计算batch的mean<br>
$\sigma^2_B\leftarrow \sum_{i=1}<sup>m(x_i-\mu_B)</sup>2$  计算batch的variance<br>
$\hat{x}_i\leftarrow \frac{x_i-\mu_B}{\sqrt{\simga^2_B+\epsilon}}$ normalize<br>
$y_i\leftarrow \gamma \hat{x}_i+ \beta \equiv BN_{\gamma, \beta}(x_i)$ scale以及shift。<br>
整个过程的loss还可以通过backpropagate进行传播，即它是可导的。</p>
<h3 id="none"></h3>
<h3 id="batch-normalized-cnn">Batch-Normalized CNN</h3>
<p>原来的CNN是<br>
$$ z= g(Wu+b)$$<br>
现在在nonlinearity前加上BN transform。<br>
$$ z= g(BN(Wu+b))$$<br>
但是事实上，Wu+b和Wu的效果是一样的，因为normalized的时候会减去均值，所以最后就是：<br>
$$ z= g(BN(Wu))$$<br>
BN在Wu的每一个维度上单独使用BN，每一个维度有一对$\gamma<sup>k,\beta</sup>k$。</p>
<h3 id="bn能使用更大的学习率">BN能使用更大的学习率</h3>
<h3 id="bn正则化模型">BN正则化模型</h3>
<h2 id="residual-network-2015">Residual Network(2015)</h2>
<p>论文名称：Deep Residual Learning for Image Recognition<br>
论文地址：<a href="https://arxiv.org/pdf/1512.03385.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1512.03385.pdf</a></p>
<h3 id="概述-v6">概述</h3>
<p>作者提出了参差网络，容易优化，仅仅增加深度就能得到更高的accuracy。在Imagenet上使用比VGG深八倍的152层的residual网络，但是计算复杂度更低。<br>
网络是不是越深越好？并不是！事实上，随着网络的加深，会出现退化问题－即增加网络的深度，accuracy反而会下降。导致这个问题的原因并不是过拟合，至于是什么原因？<br>
在这篇文章中，作者提出了deep residual network。使用一些stacked non-linear layers你和一个residual mapping，而不是直接学习一个underlying mapping。用$H(x)$表示一个underlying mapping，我们的目标是学习一个residual mapping：$F(x) = H(x)-x$，underlying mapping可以写成$H(x) = F(x)+x$。在某种情况下，如果identity mapping是optimal，那么让$F(x)$接近于$0$可能比让stacked non linear layers拟合一个identity mapping要简单。。如下图所示，$H(x)$可以用下图表示，由一个feedforward nn加上shortcut connections（skip one or more layers的connection）组成：<br>
<img src="/2019/03/13/cnn/residual_block.png" alt="residual block"><br>
shortcut connection在这里就是一个identity mapping，不需要额外的参数和计算量，shorcut的输出和$F(x)$的输出再一块经过relu激活函数。</p>
<p>本文的contribution是什么？<br>
加了一个恒等映射让深度网络的训练变得更容易。具体原理是什么？可以从这样一个角度看，在每一层都可以把不同维度的feature进行重组。residual connection是skip的一种方式？？</p>
<h3 id="residual-learning">Residual Learning</h3>
<p>用$H(x)$表示stacked non linear layers拟合的一个underlying mapping，$x$为stacked layers的输入。原来我们用这些layers逼近一个复杂的函数，现在我们用它逼近residual function，即$F(x) = H(x) -x$（假设输入和输出的维度是一样的），原来想要拟合的函数变成了$F(x)+x$，它们的意义是一样的，但是对于learning的帮助却有很大差别。<br>
如网络degradation问题中，如果更深的网络中添加的新layers是identity mapping，那么这个更深的网络的training error至少也要和浅一些的网络一样，然而事实上并不是这样的。在degradation问题中，说明multip nonlinear layers在近似identity mappings时效果并不是很好。而在residual learnign中，如果identity mapping是optimal，那么可以让non linear layers的权重接近于0，最后得到一个indetity mappings。虽然在real cases中，identity mapping几乎不可能是optimal的，但是如果optimal function更接近identity mapping而不是zero ampping，residual learning的效果就要更好。<br>
<img src="/2019/03/13/cnn/residual_block.png" alt="residual block"></p>
<h3 id="identity-mapping-by-shortcuts">Identity Mapping by Shortcuts</h3>
<p>本文中采用的residual block如上上图所示，用公式表示为：<br>
$$y = F(x, {W_i}) + x$$<br>
其中$x,y$是输入和输出向量，函数$F(x, {W_i})$表示要学习的residual mapping，residual block块中有两层，$F=W_2\sigma(W_1x)$表示第一层和第二层，然后$F+x$表示shortcut connection以及element-wise addition。如果$x$和$F(x)$的维度不一样的话，可以进行一个linear projection：<br>
$$y=F(x,{W_i}) + W_sx$$<br>
$W_s$表示线性变换的矩阵。如果必要的话，$W_s$可以走一样线性变换，事实上，实验表明如果维度一样的话，identity mapping足够解决degradation问题，$W_s$就是用来进行dimension matting。<br>
$F$的形式是很灵活的，可以像本文一样使用linear layers，当然也可以使用更多layers，无所谓。</p>
<h3 id="网络架构">网络架构</h3>
<p>作者给出了三个网络架构，一个是VGG，一个是VGG修改得到的网络，另一个是这个修改的网络加上shortcut connection，如图所示。基于VGG的修改有以下两个原则：</p>
<ol>
<li>feature map的大小不变的话，filters的数量不变</li>
<li>feature map的大小减半的话，filters的数量变为原来的$2$倍，保证每一层的计算复杂度不变。</li>
</ol>
<p>网络最后接一个global average pooling layer和一个1000way的fc layer和softmax。</p>
<h3 id="其他细节">其他细节</h3>
<ol>
<li>image的短边被resize到$[256, 480]$之间。然后从中裁剪一个$224 \times 224$的样本或者它的horizontal filp。</li>
<li>使用标准的颜色增强。</li>
<li>使用BN</li>
<li>从头开始训练网络</li>
<li>使用batch size为$256$的SGD</li>
<li>学习率从$0.1$开始，每到error不再改变时，除以$10$，总共进行$60\times 10^4$次迭代。</li>
<li>权重decay为$0.0001$，mementum为$0.9$。</li>
<li>测试时，对十个crop取平均，使用fcn，对多个scales上的scores进行平均。</li>
</ol>
<h3 id="结论">结论</h3>
<p>14.<a href="https://www.quora.com/How-does-deep-residual-learning-work" target="_blank" rel="noopener">https://www.quora.com/How-does-deep-residual-learning-work</a><br>
15.<a href="https://kharshit.github.io/blog/2018/09/07/skip-connections-and-residual-blocks" target="_blank" rel="noopener">https://kharshit.github.io/blog/2018/09/07/skip-connections-and-residual-blocks</a><br>
16.<a href="https://stats.stackexchange.com/questions/56950/neural-network-with-skip-layer-connections" target="_blank" rel="noopener">https://stats.stackexchange.com/questions/56950/neural-network-with-skip-layer-connections</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/13/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/13/">13</a><span class="page-number current">14</span><a class="page-number" href="/page/15/">15</a><a class="page-number" href="/page/16/">16</a><a class="extend next" rel="next" href="/page/15/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <div class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/favicon.jpg" alt="马晓鑫爱马荟荟">
            
              <p class="site-author-name" itemprop="name">马晓鑫爱马荟荟</p>
              <p class="site-description motion-element" itemprop="description">记录硕士三年自己的积累</p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">154</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  <a href="/categories/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">14</span>
                    <span class="site-state-item-name">分类</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  <a href="/tags/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">189</span>
                    <span class="site-state-item-name">标签</span>
                  </a>
                </div>
              
            </nav>
          

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://github.com/mxxhcm" title="GitHub &rarr; https://github.com/mxxhcm" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="mailto:mxxhcm@gmail.com" title="E-Mail &rarr; mailto:mxxhcm@gmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                </span>
              
            </div>
          

          

          
          

          
            
          
          

        </div>
      </div>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">马晓鑫爱马荟荟</span>

  

  
</div>


  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.8.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> v6.6.0</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  
    <script src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  


  


  <script src="/js/src/utils.js?v=6.6.0"></script>

  <script src="/js/src/motion.js?v=6.6.0"></script>



  
  


  <script src="/js/src/affix.js?v=6.6.0"></script>

  <script src="/js/src/schemes/pisces.js?v=6.6.0"></script>



  

  


  <script src="/js/src/bootstrap.js?v=6.6.0"></script>



  



  






<!-- LOCAL: You can save these files to your site and update links -->
    
        
        <link rel="stylesheet" href="https://aimingoo.github.io/gitmint/style/default.css">
        <script src="https://aimingoo.github.io/gitmint/dist/gitmint.browser.js"></script>
    
<!-- END LOCAL -->

    

    







  





  

  

  

  

  
  

  
  
    
      
        
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
  

  
    
      <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      },
      TeX: {equationNumbers: { autoNumber: "AMS" }}
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<script src="//cdn.jsdelivr.net/npm/mathjax@2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<style>
.MathJax_Display {
    overflow: auto hidden;
}
</style>

    
  


  
  

  

  

  

  

  

  

</body>
</html>
