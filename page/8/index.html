<!DOCTYPE html>












  


<html class="theme-next pisces use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
































<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=6.6.0" rel="stylesheet" type="text/css">



  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.jpg?v=6.6.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.jpg?v=6.6.0">










<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '6.6.0',
    sidebar: {"position":"left","display":"always","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="记录硕士三年自己的积累">
<meta property="og:type" content="website">
<meta property="og:title" content="mxxhcm&#39;s blog">
<meta property="og:url" content="http://mxxhcm.github.io/page/8/index.html">
<meta property="og:site_name" content="mxxhcm&#39;s blog">
<meta property="og:description" content="记录硕士三年自己的积累">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="mxxhcm&#39;s blog">
<meta name="twitter:description" content="记录硕士三年自己的积累">



  <link rel="alternate" href="/atom.xml" title="mxxhcm's blog" type="application/atom+xml">




  <link rel="canonical" href="http://mxxhcm.github.io/page/8/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>mxxhcm's blog</title>
  












  <noscript>
  <style>
    .use-motion .motion-element,
    .use-motion .brand,
    .use-motion .menu-item,
    .sidebar-inner,
    .use-motion .post-block,
    .use-motion .pagination,
    .use-motion .comments,
    .use-motion .post-header,
    .use-motion .post-body,
    .use-motion .collection-title { opacity: initial; }

    .use-motion .logo,
    .use-motion .site-title,
    .use-motion .site-subtitle {
      opacity: initial;
      top: initial;
    }

    .use-motion .logo-line-before i { left: initial; }
    .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">mxxhcm's blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>

      
      
    </ul>
  

  

  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mxxhcm.github.io/2019/10/13/policy-distillation/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="马晓鑫爱马荟荟">
      <meta itemprop="description" content="记录硕士三年自己的积累">
      <meta itemprop="image" content="/images/favicon.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="mxxhcm's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/10/13/policy-distillation/" class="post-title-link" itemprop="http://mxxhcm.github.io/page/8/index.html">Policy Distillation</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-10-13 14:45:01" itemprop="dateCreated datePublished" datetime="2019-10-13T14:45:01+08:00">2019-10-13</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-10-21 08:58:52" itemprop="dateModified" datetime="2019-10-21T08:58:52+08:00">2019-10-21</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/强化学习/" itemprop="url" rel="index"><span itemprop="name">强化学习</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>Policy Distillation可以extract a policy到一个参数更少更高效的model；还可以将多个任务的policy提取到一个model中。作者使用的基本算法是DQN，DQN既作为baseline和distilled policy的性能进行比较，同时也使用DQN作为teacher用于policy distillation。<br>一般来说，distillation应用在网络输出为概率的情况。DQN中，网络输出的是real-valued and unbounded的action value。当多个actions的$Q$值接近时，很难选择那个action，而某些actions的$Q$值很大时，很容易进行选择。<br>Policy distillation的优势：</p>
<ol>
<li>将网络大小压缩到原来的$\frac{1}{15}$，而不损失性能。</li>
<li>多个expert polices可以用一个单独的multi-task policy表示。</li>
<li>可以看成一个real-time online learning process连续的提炼best policy到一个target network，因此可以高效的记录$Q$-learning policy的进化过程。</li>
</ol>
<p>所有的contributions可以总结为：</p>
<ol>
<li>single game distillation</li>
<li>single game distillation with highly compressed models</li>
<li>multi-game distillation</li>
<li>online distillation</li>
</ol>
<h2 id="Single-Task-Policy-Distillation"><a href="#Single-Task-Policy-Distillation" class="headerlink" title="Single Task Policy Distillation"></a>Single Task Policy Distillation</h2><p>Distillation将teacher model T的knowledge进行迁移，得到一个参数更少更加高效的student model S。分类网络中distillation的目标通常是将teacher network layer的最后一层传入softmax layer，使用回归学习student model S的参数。<br>而本节介绍的single task policy distillation，是对$Q$函数而不是对classifier进行transfer，会面临以下问题：</p>
<ul>
<li>一方面，Q是unbounded and unstable，所以它的scale很难确定。此外，计算一个fixed policy的Q值需要很大的计算量。</li>
<li>另一方面，让S只预测一个single best action也可能会出现问题，可能有很多actions的Q值接近。</li>
</ul>
<p>给定teach model T，用它生成大小为$N$的样本集合$D^T = \left[(s_i, \mathbf{q}_i)\right]_{i=0}^T $，每一个样本是$s_i$和$\mathbf{q}_i$，$s_i$是一个observation，$\mathbf{q}_i$是对应$s_i$处每一个action的$q$值向量。<br>作者给出了三种policy distillation方法。如下所示：</p>
<h3 id="Negative-log-likelyhood-loss-NLL"><a href="#Negative-log-likelyhood-loss-NLL" class="headerlink" title="Negative log likelyhood loss (NLL)"></a>Negative log likelyhood loss (NLL)</h3><p>第一种方法使用teacher中具有最大$Q$值的action $a_{i,best} = \arg\max(\mathbf{q}_i$，使用负的log似然loss训练student model $S$直接预测action：</p>
<script type="math/tex; mode=display">L\_{NLL} (D^T, \theta\_{S}) = - \sum\_{i=1}^{\vert D\vert} \log P(a_i=a\_{i,best} | x_i, \theta\_S)\tag{1}</script><h3 id="Mean-squared-error-loss-MSE"><a href="#Mean-squared-error-loss-MSE" class="headerlink" title="Mean squared error loss (MSE)"></a>Mean squared error loss (MSE)</h3><p>第二种方法计算S和T中$Q$值的mse loss：</p>
<script type="math/tex; mode=display">L\_{MSE} (D^T, \theta\_{S}) = - \sum\_{i=1}^{\vert D\vert} || \mathbf{q}\_i^T - \mathbf{q}\_i^S ||^2_2 \tag{2}</script><p>这种方法在student model中保留每个action的所有$Q$值。</p>
<h3 id="KL-divergence"><a href="#KL-divergence" class="headerlink" title="KL divergence"></a>KL divergence</h3><p>第三种方法将$Q$值输入softmax layer，相当于求了policy，然后计算S和T的KL散度：</p>
<script type="math/tex; mode=display">L\_{KL} (D^T, \theta\_{S}) = - \sum\_{i=1}^{\vert D\vert} softmax(\frac{\mathbf{q}\_i^T }{\tau})\log \frac{softmax(\frac{\mathbf{q}\_i^T}{\tau}) }{softmax(\mathbf{q}\_i^T) }\tag{3}</script><p>在传统的分类问题中，$\mathbf{q}^T $的输出是一个peaked distribution，可以通过提高softmax的温度进行soften将更多的信息transfer到student model。<br>而在policy distillation中，teacher的输出不是一个distribution，而是每个state下所有可能actions的$q$值，我们的目的不是soften它们，而是想要让它们更sharper。<br>这个和actor-mimic中的policy regressive objective是不是一样。</p>
<h2 id="Multi-Task-Policy-Distillation"><a href="#Multi-Task-Policy-Distillation" class="headerlink" title="Multi-Task Policy Distillation"></a>Multi-Task Policy Distillation</h2><p>上面介绍的是单个任务的distillation，这一节介绍multi-task distillation。multi task distillation和single task distallation的过程一样，只不过在中multi task的distillation使用$n$个单独训练完成的DQN experts，使用这$n$个task上的DQN experts distill一个student model，每一个episode切换一个task。因为不同的tasks可能有不同的action sets，每一个task都有一个单独的output layer。在multitask中使用了KL和NLL loss。<br>这篇文章还对比了multi-task DQN agents和multi-task distillation agents的性能，Multi task DQN是训练一个network同时玩多个游戏，但是没有DQN exoerts的指导。Multi-task DQN和single-game learning的过程类似，不断的优化网络参数，预测给定state处action的$q$值。和multi-task distillation过程一样，每一个episode切换一个task，每一个task有单独的buffer，在每一个task之间不断的交错训练，并且每一个task有单独的output layer。但是multi-task DQN agents无法达到单个DQN expert的性能。可能是因为在训练过程中，不同task之间policy,reward等的相互干扰。</p>
<p>Multi-task distillation和multi-task DQN之间的区别：</p>
<ul>
<li>multi-task distillation使用了$n$个DQN expert，即已经训练好的在单个task上都表现不错model，使用他们distill一个新的model。</li>
<li>multi-task distillation是用一个model回归拟合$n$个model。</li>
<li>multi-task learning没有使用DQN expert，而是使用一个model去玩$n$个游戏。</li>
<li>multi-task learning 是train。</li>
</ul>
<p>Policy distillation可能提供了一种方式将多个polices组合到一个model中而不损害performance，在distillation process中，policy被压缩并且refined了。</p>
<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><ul>
<li>single game policy distillation:<br>四个游戏，四个网络：dqn expert, distill-MSE, distill-NLL,distill-KL，四个网络的大小都和nature DQN一样。</li>
<li>single game policy distillation with compression<br>十个游戏，四个网络：dqn expert, $25\\%$ distill-KL，$7\\%$ distill-KL，$4\\%$ distill-KL，后面三个网络大小分别是dqn expert的$25\\%, 7\\%, 4\\%$。</li>
<li>multi-task distillation<br>三个游戏，三个网络：multi-dqn, multi-dist-NLL, multi-dist-KL，这三个网络的大小都和nature dqn一样。<br>十个游戏，一个网络：multi-dist-KL，大小是nature dqn的4倍。</li>
<li>online policy distillation：</li>
</ul>
<p>Single game policy distillation实验中，teacher network是一个已经训练完成的model，选择一个DQN expert作为teacher network，训练student network时，teacher network不进行Q-learning，只是用来采样，相当于产生监督学习的样本。Student network学习teacher network是怎么将输入和label对应的。Teacher network的输入(images)和输出(Q值）都被存在buffer中。Multitask policy distillation的训练过程类似。<br>除了模型压缩时候用到的DQN，以及一个$10$个games的multi-task distillation任务中用到的DQN，它的参数比nature DQN多四倍还有额外的fully connected layer，所有其他的DQN都和nature DQN的结构一样。<br>评价指标用的是Double DQN中的normalized score。</p>
<h3 id="single-game-policy-distillation"><a href="#single-game-policy-distillation" class="headerlink" title="single game policy distillation"></a>single game policy distillation</h3><p>在这个实验中，作者测试了single game的distillation，将一个DQN expert的knowledge迁移到一个新的结构相同的随机初始化的DQN。分别使用了三种loss：MSE, NLL，KL散度进行训练。结构证明KL好于NLL好于MSE。<br>原因分析：<br>MSE是因为$Q$值在一定范围内，MSE loss都会很小，如果某个state处不同action的Q值很接近的话，即使MSE很小，也会产生误差。<br>NLL loss假设每次只有一个optimal action，原则上没有错。但是我们的teacher network可能不是optimal，最小化NLL的过程可能将一些noise也进行了变化。</p>
<h3 id="policy-distillation-with-model-compression"><a href="#policy-distillation-with-model-compression" class="headerlink" title="policy distillation with model compression"></a>policy distillation with model compression</h3><p>这一节介绍的是policy distillation model compression。训练的时候，模型大一些有助于训练，但是训练好的模型进行压缩也保留性能。　<br>分别在$10$个不同的atarti游戏上进行single-game distilled，使用的都是KL loss，student分别压缩为teacher的$25\\%, 7\\%, 4\\%$，压缩到$25\\%$ student network的平均性能是teacher network的$108\\%$,压缩到$25\\%$ student network的平均性能是teacher network的$102\\%$, 压缩到$25\\%$ student network的$4\\%$的平均性能是teacher network的$84\\%$。<br>single policy distillation with model compression中网络结构：<br>Agent | Input | Conv. 1 | Conv. 2 | Conv. 3 | F.C. 1 | Output | Parameters<br>Teacher (DQN) | 4 |  32 | 64 | 64 | 512 | up to 18 | 1,693,362<br>Dist-KL-net1 | 4 | 16 | 32 | 32 | 256 | up to 18 | 427,874<br>Dist-KL-net2 | 4 | 16 | 16 | 16 | 128 | up to 18 | 113,346<br>Dist-KL-net3 | 4 | 16 | 16 | 16 | 64 | up to 18 | 61,954<br>模型压缩只改变了参数的数量，没有改变模型架构。</p>
<h3 id="multi-game-policy-distillation"><a href="#multi-game-policy-distillation" class="headerlink" title="multi-game policy distillation"></a>multi-game policy distillation</h3><p>Multi-task DQN是multi-task distillation的baseline，实验使用了三个游戏，multi-task DQN和单个DQN的训练过程一样，但是使用了三个游戏的experient进行训练。对比了multi task DQN，multi distillation NLL，multi distillation KL，他们的网络大小都是一样的。<br>最后作者还将$10$个游戏distill到一个single student network中，这个network大小是nature DQN的四倍。<br>multi-task distilltaion experiments中网络结构：<br>Agent | Input | Conv. 1 | Conv. 2 | Conv. 3 | F.C. 1 | F.C. 2 | Output | Parameters<br>One Teacher (DQN) | 4 | 32 | 64 | 64 | 512 | n/a | up to 18 | 1,693,362<br>Multi-DQN/Dist (3 games) | 4 | 32 | 64 | 64 | 512 | 128 (x3) | up to 18 (x3) | 1,882,668<br>Multi-Dist-KL (10 games) | 4 | 64 | 64 | 64 | 1500 | 128 (x10) | up to 18 (x10) | 6,756,721</p>
<h3 id="online-policy-distillation"><a href="#online-policy-distillation" class="headerlink" title="online policy distillation"></a>online policy distillation</h3><h2 id="Experimental-Details"><a href="#Experimental-Details" class="headerlink" title="Experimental Details"></a>Experimental Details</h2><h3 id="Policy-Distillation-Training-Data-collection"><a href="#Policy-Distillation-Training-Data-collection" class="headerlink" title="Policy Distillation Training Data collection"></a>Policy Distillation Training Data collection</h3><p>Policy distillation online data collection和nature DQN中agent evaluation一样，DQN随机执行最多$30$个null-ops初始化episode，使用$\epsilon$-greedy($\epsilon=0.05$)算法进行$30$分钟即$108000$frames的evaluation。<br>DQN expert的输入是图像，输出是$Q$值，replay buffer记录$10$个小时的experience（$15$Hz下共$54000$个control steps），</p>
<h3 id="Distillation-Targets"><a href="#Distillation-Targets" class="headerlink" title="Distillation Targets"></a>Distillation Targets</h3><h3 id="Agent-Evaluation"><a href="#Agent-Evaluation" class="headerlink" title="Agent Evaluation"></a>Agent Evaluation</h3><p>使用human starts，使用$\epsilon$-greedy($\epsilon=0.05$)算法进行$30$分钟即$108000$frames的evaluation。<br>在multitask中，使用$\frac{\text{student score}}{\text{DQN score}}$当做metric。</p>
<h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><p>官方没有放出代码，有其他人的复现版本：<br><a href="https://github.com/ciwang/policydistillation" target="_blank" rel="noopener">https://github.com/ciwang/policydistillation</a></p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>1.<a href="https://arxiv.org/pdf/1511.06295.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1511.06295.pdf</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mxxhcm.github.io/2019/10/12/python-ptan/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="马晓鑫爱马荟荟">
      <meta itemprop="description" content="记录硕士三年自己的积累">
      <meta itemprop="image" content="/images/favicon.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="mxxhcm's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/10/12/python-ptan/" class="post-title-link" itemprop="http://mxxhcm.github.io/page/8/index.html">python ptan</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-10-12 20:36:40" itemprop="dateCreated datePublished" datetime="2019-10-12T20:36:40+08:00">2019-10-12</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-10-28 13:39:52" itemprop="dateModified" datetime="2019-10-28T13:39:52+08:00">2019-10-28</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/python/" itemprop="url" rel="index"><span itemprop="name">python</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="PyTorch-Agent-Net-library"><a href="#PyTorch-Agent-Net-library" class="headerlink" title="PyTorch Agent Net library"></a>PyTorch Agent Net library</h2><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>Ptan是一个简化RL的库，它主要目标是实现两个问题的平衡：</p>
<ol>
<li>导入库函数，只需要一行命令，就像OpenAI的baselines一样</li>
<li>从头开始实现</li>
</ol>
<p>我们既不想一行命令直接调包，也不想从头开始实现一切。</p>
<h3 id="模块"><a href="#模块" class="headerlink" title="模块"></a>模块</h3><ul>
<li>Agent：</li>
<li>ActionSelector</li>
<li>ExperienceSource</li>
<li>ExperienceSourceBuffer</li>
<li>others</li>
</ul>
<h2 id="Action-Selector"><a href="#Action-Selector" class="headerlink" title="Action Selector"></a>Action Selector</h2><h3 id="简介-1"><a href="#简介-1" class="headerlink" title="简介"></a>简介</h3><p>将network的输出转换成具体的action。常用的有</p>
<ul>
<li>Argmax：用于使用Q网络的方法，生成离散action。</li>
<li>Policy-based：网络输出logits或者normalizaed distribution，从这个distribution中采样。</li>
</ul>
<p>Action Selector被Agent使用，常用的有：</p>
<ul>
<li>ArgmaxActionSelector</li>
<li>EpsilonGreedyActionSector</li>
<li>ProbabilityActionSelector</li>
</ul>
<h3 id="基类"><a href="#基类" class="headerlink" title="基类"></a>基类</h3><h4 id="ActionSelector"><a href="#ActionSelector" class="headerlink" title="ActionSelector"></a>ActionSelector</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ActionSelector</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span><span class="params">(self, scores)</span></span></span><br></pre></td></tr></table></figure>
<h3 id="子类"><a href="#子类" class="headerlink" title="子类"></a>子类</h3><h4 id="ArgmaxActionSelector"><a href="#ArgmaxActionSelector" class="headerlink" title="ArgmaxActionSelector"></a>ArgmaxActionSelector</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ArgmaxActionSelector</span><span class="params">(ActionSelector)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span><span class="params">(self, scores)</span></span></span><br></pre></td></tr></table></figure>
<h4 id="EpsilonGreedyActionSector"><a href="#EpsilonGreedyActionSector" class="headerlink" title="EpsilonGreedyActionSector"></a>EpsilonGreedyActionSector</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">EpsilonGreedyActionSector</span><span class="params">(ActionSelector)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, epsilon=<span class="number">0.05</span>, selector=None)</span></span></span><br><span class="line"><span class="function">    <span class="title">def</span> <span class="title">__call</span><span class="params">(self, scores)</span></span></span><br></pre></td></tr></table></figure>
<h4 id="ProbabilityActionSelector"><a href="#ProbabilityActionSelector" class="headerlink" title="ProbabilityActionSelector"></a>ProbabilityActionSelector</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ProbabilityActionSelector</span><span class="params">(ActionSelector)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span><span class="params">(self, probs)</span></span></span><br></pre></td></tr></table></figure>
<h4 id="对比三个ActionSelector"><a href="#对比三个ActionSelector" class="headerlink" title="对比三个ActionSelector"></a>对比三个ActionSelector</h4><p>两个GreedySelector：Argmax和EpsilonGreedy，输入都需要是q值，输出是action。<br>而Probability需要的输入是概率，输出是动作。</p>
<h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><h4 id="EpsilonTraker"><a href="#EpsilonTraker" class="headerlink" title="EpsilonTraker"></a>EpsilonTraker</h4><p>用来记录epsilon的变化。</p>
<h2 id="Agent"><a href="#Agent" class="headerlink" title="Agent"></a>Agent</h2><p>将observation转换为actions，常见的三种方法如下：</p>
<ul>
<li>Q-function：预测当前observation下所有可能采取的action的$Q$值，选择$\arg \max Q(s)$作为action。</li>
<li>Policy-based：预测$\pi(s)$的概率分布，从分布中采样。</li>
<li>Continuous Contrl：预测连续控制参数$\mu(s)$，直接输出action。</li>
</ul>
<h3 id="基类-1"><a href="#基类-1" class="headerlink" title="基类"></a>基类</h3><h4 id="BaseAgent"><a href="#BaseAgent" class="headerlink" title="BaseAgent"></a>BaseAgent</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BaseAgent</span>:</span></span><br><span class="line">    <span class="comment"># 1.</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__initial_state</span><span class="params">(self)</span></span></span><br><span class="line"><span class="function">    # 2.</span></span><br><span class="line"><span class="function">    <span class="title">def</span> <span class="title">__call__</span><span class="params">(self, states, agent_states)</span></span></span><br><span class="line"><span class="function">        """</span></span><br><span class="line"><span class="function">        :</span>param states: env states list </span><br><span class="line">        :param agent_states: agent state list</span><br><span class="line">        :<span class="keyword">return</span>: actions tuple, agent_states</span><br><span class="line">        <span class="string">"""</span></span><br></pre></td></tr></table></figure>
<h3 id="子类-1"><a href="#子类-1" class="headerlink" title="子类"></a>子类</h3><h4 id="DQNAgent"><a href="#DQNAgent" class="headerlink" title="DQNAgent"></a>DQNAgent</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DQNAgent</span><span class="params">(BaseAgent)</span>:</span></span><br><span class="line">    <span class="comment"># 1.</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, dqn_model, action_selector, device=<span class="string">"cpu"</span>, preprocessor=default_states_preprocessor)</span></span></span><br><span class="line"><span class="function">    # 2</span></span><br><span class="line"><span class="function">    <span class="title">def</span> <span class="title">__call__</span><span class="params">(self, states, agent_states=None)</span></span></span><br></pre></td></tr></table></figure>
<h4 id="PolicyAgent"><a href="#PolicyAgent" class="headerlink" title="PolicyAgent"></a>PolicyAgent</h4><p>输入的model产生离散动作的policy distribution，Policy distribution可以是logtis或者normalized distribution。<br>PolicyAgent调用probability action selector对这个distribution进行采样 。PolicyAgent其实就是将model和action selector组装在了一起。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PolicyAgent</span><span class="params">(BaseAgent)</span>:</span></span><br><span class="line">    <span class="comment"># 1.</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, model, action_selector=actions.ProbabilityActionSelector<span class="params">()</span>, device=<span class="string">"cpu"</span>, apply_softmax=False, preprocessor=default_states_preprocessor)</span></span></span><br><span class="line"><span class="function">    # 2.</span></span><br><span class="line"><span class="function">    @<span class="title">torch</span>.<span class="title">no_grad</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    <span class="title">def</span> <span class="title">__call__</span><span class="params">(self, states, agent_states=None)</span></span></span><br></pre></td></tr></table></figure></p>
<h4 id="ActorCriticAgent"><a href="#ActorCriticAgent" class="headerlink" title="ActorCriticAgent"></a>ActorCriticAgent</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ActorCriticAgent</span></span></span><br><span class="line"><span class="class">    # 1.</span></span><br><span class="line"><span class="class">    <span class="title">def</span> <span class="title">__init__</span><span class="params">(self, model, action_selector=actions.ProbabilityActionSelector<span class="params">()</span>, device=<span class="string">"cpu"</span>, apply_softmax=False, preprocessor=default_states_preprocessor)</span></span></span><br><span class="line"><span class="class">    # 2.</span></span><br><span class="line"><span class="class">    <span class="title">def</span> <span class="title">__call__</span><span class="params">(self, states, agent_states=None)</span></span></span><br></pre></td></tr></table></figure>
<h3 id="其他-1"><a href="#其他-1" class="headerlink" title="其他"></a>其他</h3><h4 id="default-states-preprocessor"><a href="#default-states-preprocessor" class="headerlink" title="default_states_preprocessor"></a>default_states_preprocessor</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">default_states_preprocessor</span><span class="params">(states)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Convert list of states into the form suitable for model. By default we assume Variable</span></span><br><span class="line"><span class="string">    :param states: list of numpy arrays with states</span></span><br><span class="line"><span class="string">    :return: Variable</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">if</span> len(states) == <span class="number">1</span>:</span><br><span class="line">        np_states = np.expand_dims(states[<span class="number">0</span>], <span class="number">0</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        np_states = np.array([np.array(s, copy=<span class="literal">False</span>) <span class="keyword">for</span> s <span class="keyword">in</span> states], copy=<span class="literal">False</span>)</span><br><span class="line">    <span class="keyword">return</span> torch.tensor(np_states)</span><br></pre></td></tr></table></figure>
<h4 id="TargetNet"><a href="#TargetNet" class="headerlink" title="TargetNet"></a>TargetNet</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TargetNet</span></span></span><br><span class="line"><span class="class">    # 1.</span></span><br><span class="line"><span class="class">    <span class="title">def</span> <span class="title">__init__</span><span class="params">(self, model)</span></span></span><br><span class="line"><span class="class">    # 2.</span></span><br><span class="line"><span class="class">    <span class="title">def</span> <span class="title">sync</span><span class="params">(self)</span></span></span><br><span class="line"><span class="class">    # 3.</span></span><br><span class="line"><span class="class">    <span class="title">def</span> <span class="title">alpha_sync</span><span class="params">(self, alpha)</span></span></span><br></pre></td></tr></table></figure>
<h2 id="Experience-Source"><a href="#Experience-Source" class="headerlink" title="Experience Source"></a>Experience Source</h2><p>Agent不断的和env进行交互产生一系列的trajectories，Experience可以将这些交互存储起来，重复利用。Experience的主要作用有：</p>
<ol>
<li>支持batch，利用GPU的并行计算提高训练效率</li>
<li>可以对transitions或者trajectory进行预处理。比如n-step DQN。</li>
<li>???</li>
</ol>
<p>常见的ExperienceSource有：</p>
<ul>
<li>ExperienceSource</li>
<li>ExperienceSourceFirstLast</li>
<li>ExperienceSourceRollouts</li>
<li>ExperienceReplayBuffer: ：DQN中几乎不会使用刚刚获得的experience samples，因为他们是高度相关的，让训练很不稳定。Buffer用来存放experience pieces，从buffer中采样进行训练，因为buffer容量有限，老样本会被从replay buffer中删掉</li>
<li>PrioReplayBufferNaive: Complexity of sampling is O(n)</li>
<li>PrioritizedReplayBuffer: O(log(n)) sampling complexity.</li>
</ul>
<h3 id="基类-2"><a href="#基类-2" class="headerlink" title="基类"></a>基类</h3><h4 id="ExperienceSource"><a href="#ExperienceSource" class="headerlink" title="ExperienceSource"></a>ExperienceSource</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ExperienceSource</span> </span></span><br><span class="line"><span class="class">    """</span></span><br><span class="line"><span class="class">    简单的<span class="title">n</span>-<span class="title">step</span> <span class="title">source</span> <span class="title">for</span> <span class="title">single</span> <span class="title">or</span> <span class="title">multiple</span> <span class="title">envs</span></span></span><br><span class="line"><span class="class">    每一个<span class="title">experience</span>都有<span class="title">n</span>个<span class="title">Experience</span> <span class="title">entries</span>的<span class="title">list</span></span></span><br><span class="line"><span class="class">    """</span></span><br><span class="line"><span class="class">    # 1.</span></span><br><span class="line"><span class="class">    <span class="title">def</span> <span class="title">__init__</span><span class="params">(self, env, agent, steps_count=<span class="number">2</span>, steps_delta=<span class="number">1</span>, vectorized=False)</span></span></span><br><span class="line"><span class="class">        """</span></span><br><span class="line"><span class="class">        <span class="title">env</span>:</span> 环境或者list of环境</span><br><span class="line">        agent: 将observation 转换为actions</span><br><span class="line">        steps_count: 每一个experience chain的计数</span><br><span class="line">        steps_delta: experience items之间相隔多少个steps</span><br><span class="line">        vectorized: bool,OpenAI vectorized</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">    # 2.</span></span><br><span class="line"><span class="string">    def __iter__(self):</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    重写<span class="keyword">for</span>循环的iter方法</span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    # 3.返回rewards，然后重置</span></span><br><span class="line"><span class="string">    def pop_total_rewards(self)</span></span><br><span class="line"><span class="string">    # 4.返回rewards和steps，然后重置</span></span><br><span class="line"><span class="string">    def pop_rewards_steps(self)</span></span><br></pre></td></tr></table></figure>
<h4 id="ExperienceReplayBuffer"><a href="#ExperienceReplayBuffer" class="headerlink" title="ExperienceReplayBuffer"></a>ExperienceReplayBuffer</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ExperienceReplayBuffer</span></span></span><br><span class="line"><span class="class">    #</span></span><br><span class="line"><span class="class">    <span class="title">def</span> <span class="title">__init__</span><span class="params">(self, experience_source, buffer_size)</span></span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">    #</span></span><br><span class="line"><span class="class">    <span class="title">def</span> <span class="title">__len__</span><span class="params">(self)</span></span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">    #</span></span><br><span class="line"><span class="class">    <span class="title">def</span> <span class="title">__iter__</span><span class="params">(self)</span></span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">    # 从<span class="title">experience</span>中随机采样一个<span class="title">batch_size</span>大小的样本</span></span><br><span class="line"><span class="class">    <span class="title">def</span> <span class="title">sample</span><span class="params">(self, batch_size)</span></span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">    # 添加一个<span class="title">sample</span>，类内函数</span></span><br><span class="line"><span class="class">    <span class="title">def</span> <span class="title">_add</span><span class="params">(self, sample)</span></span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">    # 从<span class="title">experience_source</span>中获得<span class="title">samples_numbers</span>个样本，将其添加到<span class="title">buffer</span></span></span><br><span class="line"><span class="class">    <span class="title">def</span> <span class="title">populate</span><span class="params">(self, samples_numbers)</span></span></span><br></pre></td></tr></table></figure>
<h4 id="BatchPreprocessor"><a href="#BatchPreprocessor" class="headerlink" title="BatchPreprocessor"></a>BatchPreprocessor</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BatchPreprocessor</span></span></span><br></pre></td></tr></table></figure>
<h3 id="子类-2"><a href="#子类-2" class="headerlink" title="子类"></a>子类</h3><h4 id="ExperienceSourceFirstLast"><a href="#ExperienceSourceFirstLast" class="headerlink" title="ExperienceSourceFirstLast"></a>ExperienceSourceFirstLast</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Q(st, at) = rt+1 + \gamma r_t+2 + ... \gamma^t+n-1 r_t+n + Q(s t+n, s t+n)</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ExperienceSourceFirstLast</span><span class="params">(ExperienceSource)</span>:</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, env, agent, gamma, steps_count=<span class="number">1</span>, steps_delta=<span class="number">1</span>, vectorized=False)</span></span></span><br><span class="line"><span class="function">    #</span></span><br><span class="line"><span class="function">    <span class="title">def</span> <span class="title">__iter</span><span class="params">(self)</span></span></span><br></pre></td></tr></table></figure>
<h4 id="PrioritizedReplayBuffer"><a href="#PrioritizedReplayBuffer" class="headerlink" title="PrioritizedReplayBuffer"></a>PrioritizedReplayBuffer</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PrioritizedReplayBuffer</span><span class="params">(ExperienceReplayBuffer)</span></span></span><br><span class="line"><span class="class">    # 1.</span></span><br><span class="line"><span class="class">    <span class="title">def</span> <span class="title">__init__</span><span class="params">(self, experience_source, buffer_size, alpha)</span></span></span><br><span class="line"><span class="class">    # 2.</span></span><br><span class="line"><span class="class">    <span class="title">def</span> <span class="title">_add</span><span class="params">(self, *args, **kwargs)</span></span></span><br><span class="line"><span class="class">    # 3.</span></span><br><span class="line"><span class="class">    <span class="title">def</span> <span class="title">_sample_proprotional</span><span class="params">(self, batch_size)</span></span></span><br><span class="line"><span class="class">    # 4.</span></span><br><span class="line"><span class="class">    <span class="title">def</span> <span class="title">sample</span><span class="params">(self, batch_size, beta)</span></span></span><br><span class="line"><span class="class">    # 5.</span></span><br><span class="line"><span class="class">    <span class="title">def</span> <span class="title">update_priorities</span><span class="params">(self, idxes, priorities)</span></span></span><br></pre></td></tr></table></figure>
<h4 id="QLearningPreprocessor"><a href="#QLearningPreprocessor" class="headerlink" title="QLearningPreprocessor"></a>QLearningPreprocessor</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QLearningPreprocessor</span><span class="params">(BatchPreprocessor)</span></span></span><br></pre></td></tr></table></figure>
<h3 id="其他-2"><a href="#其他-2" class="headerlink" title="其他"></a>其他</h3><h4 id="ExperienceSourceRollouts"><a href="#ExperienceSourceRollouts" class="headerlink" title="ExperienceSourceRollouts"></a>ExperienceSourceRollouts</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ExperienceSourceRollouts</span>:</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, env, agent, gamma, setps_count=<span class="number">5</span>)</span></span></span><br><span class="line"><span class="function">    # </span></span><br><span class="line"><span class="function">    <span class="title">def</span> <span class="title">__iter__</span><span class="params">(self)</span></span></span><br><span class="line"><span class="function">    #</span></span><br><span class="line"><span class="function">    <span class="title">def</span> <span class="title">pop_total_rewards</span><span class="params">(self)</span></span></span><br><span class="line"><span class="function">    # </span></span><br><span class="line"><span class="function">    <span class="title">def</span> <span class="title">pop_rewards_steps</span><span class="params">(self)</span></span></span><br></pre></td></tr></table></figure>
<h4 id="ExperienceSourceBuffer"><a href="#ExperienceSourceBuffer" class="headerlink" title="ExperienceSourceBuffer"></a>ExperienceSourceBuffer</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">class ExperienceSourceBuffer</span><br></pre></td></tr></table></figure>
<h4 id="ExperienceReplayNaive"><a href="#ExperienceReplayNaive" class="headerlink" title="ExperienceReplayNaive"></a>ExperienceReplayNaive</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ExperienceReplayNaive</span></span></span><br></pre></td></tr></table></figure>
<h2 id="代码解析"><a href="#代码解析" class="headerlink" title="代码解析"></a>代码解析</h2><h3 id="ExperienceSource-1"><a href="#ExperienceSource-1" class="headerlink" title="ExperienceSource"></a>ExperienceSource</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ExperienceSource</span> </span></span><br><span class="line"><span class="class">    """</span></span><br><span class="line"><span class="class">    简单的<span class="title">n</span>-<span class="title">step</span> <span class="title">source</span> <span class="title">for</span> <span class="title">single</span> <span class="title">or</span> <span class="title">multiple</span> <span class="title">envs</span></span></span><br><span class="line"><span class="class">    每一个<span class="title">experience</span>都有<span class="title">n</span>个<span class="title">Experience</span> <span class="title">entries</span>的<span class="title">list</span></span></span><br><span class="line"><span class="class">    """</span></span><br><span class="line"><span class="class">    # 1.</span></span><br><span class="line"><span class="class">    <span class="title">def</span> <span class="title">__init__</span><span class="params">(self, env, agent, steps_count=<span class="number">2</span>, steps_delta=<span class="number">1</span>, vectorized=False)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        env: 环境或者list of环境</span></span><br><span class="line"><span class="string">        agent: 将observation 转换为actions</span></span><br><span class="line"><span class="string">        steps_count: 每一个experience chain的计数</span></span><br><span class="line"><span class="string">        steps_delta: experience items之间相隔多少个steps</span></span><br><span class="line"><span class="string">        vectorized: bool,OpenAI vectorized</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">assert</span> isinstance(env, (gym.Env, list, tuple))</span><br><span class="line">        <span class="keyword">assert</span> isinstance(agent, BaseAgent)</span><br><span class="line">        <span class="keyword">assert</span> isinstance(steps_count, int)</span><br><span class="line">        <span class="keyword">assert</span> steps_count &gt;= <span class="number">1</span></span><br><span class="line">        <span class="keyword">assert</span> isinstance(vectorized, bool)</span><br><span class="line">        <span class="comment"># self.pool存放envs list，类型是list</span></span><br><span class="line">        <span class="keyword">if</span> isinstance(env, (list, tuple)):</span><br><span class="line">            self.pool = env</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.pool = [env]</span><br><span class="line">        self.agent = agent</span><br><span class="line">        self.steps_count = steps_count</span><br><span class="line">        self.steps_delta = steps_delta</span><br><span class="line">        self.total_rewards = []</span><br><span class="line">        self.total_steps = []</span><br><span class="line">        self.vectorized = vectorized</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2.</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__iter__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># states记录所有env的所有obs</span></span><br><span class="line">        <span class="comment"># agent_states记录</span></span><br><span class="line">        <span class="comment"># histories记录当前的steps_count个experience</span></span><br><span class="line">        <span class="comment"># cur_rewards记录当前episode的rewards</span></span><br><span class="line">        <span class="comment"># cur_steps记录当前episode的steps</span></span><br><span class="line">        states, agent_states, histories, cur_rewards, cur_steps = [], [], [], [], []</span><br><span class="line"></span><br><span class="line">        <span class="comment"># env个数， 记录每个env observation的shape，如果向量化，[&gt;=1, &gt;=1, ...]，如果不向量化[1, 1, 1,...]，不管是否向量化，长度都等于envs个数的list，</span></span><br><span class="line">        env_lens = [] </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 对每一个env进行操作，生成需要记录变量的维度</span></span><br><span class="line">        <span class="keyword">for</span> env <span class="keyword">in</span> self.pool:</span><br><span class="line">            obs = env.reset()</span><br><span class="line">            <span class="comment"># if the environment is vectorized, all it's output is lists of results.</span></span><br><span class="line">            <span class="comment"># 生成state的维度</span></span><br><span class="line">            <span class="comment"># 如果向量化obs，states的维度大于等于env数，否则states的维度和env数量一样</span></span><br><span class="line">            <span class="keyword">if</span> self.vectorized:</span><br><span class="line">                obs_len = len(obs)</span><br><span class="line">                states.extend(obs)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                obs_len = <span class="number">1</span></span><br><span class="line">                states.append(obs)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># [env1_obs_len, env_2_obs_len, ..., envn_obs_len]</span></span><br><span class="line">            env_lens.append(obs_len)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 生成histories, cur_rewards，cur_steps，agent_states的维度</span></span><br><span class="line">            <span class="keyword">for</span> _ <span class="keyword">in</span> range(obs_len):</span><br><span class="line">                <span class="comment"># 记录所有env中所有的obs</span></span><br><span class="line">                histories.append(deque(maxlen=self.steps_count))</span><br><span class="line">                cur_rewards.append(<span class="number">0.0</span>)</span><br><span class="line">                cur_steps.append(<span class="number">0</span>)</span><br><span class="line">                agent_states.append(self.agent.initial_state())</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 总的迭代次数，用于steps_delta</span></span><br><span class="line">        iter_idx = <span class="number">0</span></span><br><span class="line">        <span class="comment"># ================================分界线===========================</span></span><br><span class="line">        <span class="comment"># 上面是iteration的初始化，生成各类信息(states, agent_states, histories)的初始值。</span></span><br><span class="line">        <span class="comment"># 下面开始iteration</span></span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            <span class="comment"># 1.根据states生成len(states)个action</span></span><br><span class="line">            <span class="comment"># states &gt;= len(envs_len) 个数</span></span><br><span class="line">            actions = [<span class="literal">None</span>] * len(states)</span><br><span class="line">            states_input = []</span><br><span class="line">            states_indices = []</span><br><span class="line">            <span class="keyword">for</span> idx, state <span class="keyword">in</span> enumerate(states):</span><br><span class="line">                <span class="keyword">if</span> state <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">                    actions[idx] = self.pool[<span class="number">0</span>].action_space.sample()  <span class="comment"># assume that all envs are from the same family</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    states_input.append(state)</span><br><span class="line">                    states_indices.append(idx)</span><br><span class="line">            <span class="keyword">if</span> states_input:</span><br><span class="line">                states_actions, new_agent_states = self.agent(states_input, agent_states)</span><br><span class="line">                <span class="keyword">for</span> idx, action <span class="keyword">in</span> enumerate(states_actions):</span><br><span class="line">                    g_idx = states_indices[idx]</span><br><span class="line">                    actions[g_idx] = action</span><br><span class="line">                    agent_states[g_idx] = new_agent_states[idx]</span><br><span class="line">            <span class="comment"># 根据env_lens将actions进行合并，长度和envs number一样</span></span><br><span class="line">            grouped_actions = _group_list(actions, env_lens)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 2.step执行action</span></span><br><span class="line">            <span class="comment"># global_of是全局offset，相当于每个env obs初始位置，ofs是每个env的len(action_n)个维度。</span></span><br><span class="line">            global_ofs = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 分别对每个env执行相应的action_n个动作</span></span><br><span class="line">            <span class="keyword">for</span> env_idx, (env, action_n) <span class="keyword">in</span> enumerate(zip(self.pool, grouped_actions)):</span><br><span class="line">                <span class="keyword">if</span> self.vectorized:</span><br><span class="line">                    next_state_n, r_n, is_done_n, _ = env.step(action_n)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    next_state, r, is_done, _ = env.step(action_n[<span class="number">0</span>])</span><br><span class="line">                    next_state_n, r_n, is_done_n = [next_state], [r], [is_done]</span><br><span class="line"></span><br><span class="line">                <span class="comment"># ofs是每个env的局部offset</span></span><br><span class="line">                <span class="keyword">for</span> ofs, (action, next_state, r, is_done) <span class="keyword">in</span> enumerate(zip(action_n, next_state_n, r_n, is_done_n)):</span><br><span class="line">                    idx = global_ofs + ofs</span><br><span class="line">                    state = states[idx]</span><br><span class="line">                    history = histories[idx]</span><br><span class="line"></span><br><span class="line">                    cur_rewards[idx] += r</span><br><span class="line">                    cur_steps[idx] += <span class="number">1</span></span><br><span class="line">                    <span class="keyword">if</span> state <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                        <span class="comment"># 记录state, action, reward, done，没有记录next_state，使用完之后，更新state[idx] = next_state</span></span><br><span class="line">                        history.append(Experience(state=state, action=action, reward=r, done=is_done))</span><br><span class="line">                    <span class="comment"># 每一个env在enumerate时都会算一次</span></span><br><span class="line">                    <span class="keyword">if</span> len(history) == self.steps_count <span class="keyword">and</span> iter_idx % self.steps_delta == <span class="number">0</span>:</span><br><span class="line">                        <span class="keyword">yield</span> tuple(history)</span><br><span class="line">                    <span class="comment"># 更新下一步，states[idx] = next_state</span></span><br><span class="line">                    states[idx] = next_state</span><br><span class="line">                    <span class="keyword">if</span> is_done:</span><br><span class="line">                        <span class="comment"># in case of very short episode (shorter than our steps count), send gathered history</span></span><br><span class="line">                        <span class="keyword">if</span> <span class="number">0</span> &lt; len(history) &lt; self.steps_count:</span><br><span class="line">                            <span class="keyword">yield</span> tuple(history)</span><br><span class="line">                        <span class="comment"># generate tail of history</span></span><br><span class="line">                        <span class="keyword">while</span> len(history) &gt; <span class="number">1</span>:</span><br><span class="line">                            history.popleft()</span><br><span class="line">                            <span class="keyword">yield</span> tuple(history)</span><br><span class="line">                        self.total_rewards.append(cur_rewards[idx])</span><br><span class="line">                        self.total_steps.append(cur_steps[idx])</span><br><span class="line">                        cur_rewards[idx] = <span class="number">0.0</span></span><br><span class="line">                        cur_steps[idx] = <span class="number">0</span></span><br><span class="line">                        <span class="comment"># vectorized envs are reset automatically</span></span><br><span class="line">                        states[idx] = env.reset() <span class="keyword">if</span> <span class="keyword">not</span> self.vectorized <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">                        agent_states[idx] = self.agent.initial_state()</span><br><span class="line">                        history.clear()</span><br><span class="line">                global_ofs += len(action_n)</span><br><span class="line">            iter_idx += <span class="number">1</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    重写for循环的iter方法</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># 3. 重置total_rewards</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pop_total_rewards</span><span class="params">(self)</span></span></span><br><span class="line"><span class="function">    # 4. 重置<span class="title">total</span> <span class="title">rewards</span>和<span class="title">total</span> <span class="title">steps</span></span></span><br><span class="line"><span class="function">    <span class="title">def</span> <span class="title">pop_rewards_steps</span><span class="params">(self)</span></span></span><br></pre></td></tr></table></figure>
<h3 id="ExperienceSourceFirstLast-1"><a href="#ExperienceSourceFirstLast-1" class="headerlink" title="ExperienceSourceFirstLast"></a>ExperienceSourceFirstLast</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ExperienceSourceFirstLast</span><span class="params">(ExperienceSource)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">    def __init__(self, env, agent, gamma, steps_count=1, steps_delta=1, vectorized=False):</span></span><br><span class="line"><span class="string">        assert isinstance(gamma, float)</span></span><br><span class="line"><span class="string">        super(ExperienceSourceFirstLast, self).__init__(env, agent, steps_count+1, steps_delta, vectorized=vectorized)</span></span><br><span class="line"><span class="string">        self.gamma = gamma</span></span><br><span class="line"><span class="string">        self.steps = steps_count</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    def __iter__(self):</span></span><br><span class="line"><span class="string">        # 并不保留中间n步的experience，因为没必要，只留第一步和最后一步，中间计算rewards就行了</span></span><br><span class="line"><span class="string">        for exp in super(ExperienceSourceFirstLast, self).__iter__():</span></span><br><span class="line"><span class="string">            if exp[-1].done and len(exp) &lt;= self.steps:</span></span><br><span class="line"><span class="string">                last_state = None</span></span><br><span class="line"><span class="string">                elems = exp</span></span><br><span class="line"><span class="string">            else:</span></span><br><span class="line"><span class="string">                last_state = exp[-1].state</span></span><br><span class="line"><span class="string">                elems = exp[:-1]</span></span><br><span class="line"><span class="string">            total_reward = 0.0</span></span><br><span class="line"><span class="string">            # 计算中间的rewards</span></span><br><span class="line"><span class="string">            for e in reversed(elems):</span></span><br><span class="line"><span class="string">                total_reward *= self.gamma</span></span><br><span class="line"><span class="string">                total_reward += e.reward</span></span><br><span class="line"><span class="string">            yield ExperienceFirstLast(state=exp[0].state, action=exp[0].action,</span></span><br><span class="line"><span class="string">                                      reward=total_reward, last_state=last_state)</span></span><br></pre></td></tr></table></figure>
<h3 id="ExperienceReplayBuffer-1"><a href="#ExperienceReplayBuffer-1" class="headerlink" title="ExperienceReplayBuffer"></a>ExperienceReplayBuffer</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ExperienceReplayBuffer</span></span></span><br></pre></td></tr></table></figure>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>1.<a href="https://github.com/Shmuma/ptan/blob/master/docs/intro.ipynb" target="_blank" rel="noopener">https://github.com/Shmuma/ptan/blob/master/docs/intro.ipynb</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mxxhcm.github.io/2019/10/12/python-iteration/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="马晓鑫爱马荟荟">
      <meta itemprop="description" content="记录硕士三年自己的积累">
      <meta itemprop="image" content="/images/favicon.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="mxxhcm's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/10/12/python-iteration/" class="post-title-link" itemprop="http://mxxhcm.github.io/page/8/index.html">python iteration-iterable and iterator</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-10-12 15:51:26 / 修改时间：18:19:42" itemprop="dateCreated datePublished" datetime="2019-10-12T15:51:26+08:00">2019-10-12</time>
            

            
              

              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/python/" itemprop="url" rel="index"><span itemprop="name">python</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Iteration"><a href="#Iteration" class="headerlink" title="Iteration"></a>Iteration</h2><p>Iteration并不是一个具体的东西，它是一个抽象的名词，指的是一个接一个的取某个对象的每一个项。包含隐式的，显式的loop，即while，do, for等，这叫iteration。</p>
<h2 id="Iterable和iterator"><a href="#Iterable和iterator" class="headerlink" title="Iterable和iterator"></a>Iterable和iterator</h2><p>而在python中，有iterator和iterable。<br>一个iterable object是实现了<strong>iter</strong>方法的object或者定义了<strong>getitem</strong>方法。一个iteratable object是一个可以得到iterator的object，但是它自己并不一定是iterator object。<br>而iterator是一个实现了<strong>next</strong>和<strong>iter</strong>方法的object。<br><strong>iterable object不一定是iterator，iterator一定是iterable object。</strong><br><strong>可以使用for循环的都是ieterable object，比如str，list，但是它们不是itertor，可以使用iter()方法得到iterator</strong><br><strong>可以next()的都是iterator</strong></p>
<h2 id="iter和-iter"><a href="#iter和-iter" class="headerlink" title="iter和__iter__"></a>iter和__iter__</h2><p>所有实现了<strong>iter</strong>方法的object，都是iterable object，可以通过iter()方法产生iterator object。<br>具体示例<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">from collections import Iterator</span><br><span class="line">from collections import Iterable</span><br><span class="line"></span><br><span class="line">class Fibs:</span><br><span class="line">    def __init__(self, a, b):</span><br><span class="line">        self.a = a</span><br><span class="line">        self.b = b</span><br><span class="line"></span><br><span class="line">    def __iter__(self):</span><br><span class="line">        a = self.a</span><br><span class="line">        b = self.b</span><br><span class="line">        while True:</span><br><span class="line">            yield a</span><br><span class="line">            a, b = b, a + b</span><br><span class="line"></span><br><span class="line">real_fibs = Fibs(0,1)</span><br><span class="line"></span><br><span class="line">print(&quot;real_fibs is iterator? &quot;, isinstance(real_fibs, Iterator))</span><br><span class="line">print(&quot;real_fibs is iterable? &quot;, isinstance(real_fibs, Iterable))</span><br><span class="line">print(&quot;iter(real_fibs) is iterator? &quot;, isinstance(iter(real_fibs), Iterator))</span><br><span class="line">print(&quot;iter(real_fibs) is iterable? &quot;, isinstance(iter(real_fibs), Iterable))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">for idx, i in enumerate(real_fibs):</span><br><span class="line">    print(i)</span><br><span class="line">    if idx &gt; 10:</span><br><span class="line">        break</span><br></pre></td></tr></table></figure></p>
<p>其中出现了yield关键字。yield关键字的作用是每次迭代执行到该行代码时，就返回一个值，并且记住相应的位置，在下次迭代时继续从该行位置开始执行。</p>
<h2 id="next和-next"><a href="#next和-next" class="headerlink" title="next和__next__"></a>next和__next__</h2><p>代码示例<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Iterator</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">A</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, max_v=<span class="number">5</span>)</span>:</span></span><br><span class="line">        self.max_v = max_v</span><br><span class="line">        self.v = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__iter__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__next__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># if self.v &lt;= self.nax_v</span></span><br><span class="line">        self.v += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> self.v</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    a = A()</span><br><span class="line">    <span class="keyword">for</span> idx, v <span class="keyword">in</span> enumerate(a):</span><br><span class="line">        print(idx, v)</span><br><span class="line">        <span class="keyword">if</span> (idx &gt;= <span class="number">10</span>):</span><br><span class="line">            <span class="keyword">break</span></span><br></pre></td></tr></table></figure></p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>1.<a href="https://stackoverflow.com/questions/9884132/what-exactly-are-iterator-iterable-and-iteration" target="_blank" rel="noopener">https://stackoverflow.com/questions/9884132/what-exactly-are-iterator-iterable-and-iteration</a><br>2.<a href="https://stackoverflow.com/a/46411740/8939281" target="_blank" rel="noopener">https://stackoverflow.com/a/46411740/8939281</a><br>3.<a href="https://www.jianshu.com/p/f9b547874a14" target="_blank" rel="noopener">https://www.jianshu.com/p/f9b547874a14</a><br>4.<a href="https://www.jianshu.com/p/1b0686bc166d" target="_blank" rel="noopener">https://www.jianshu.com/p/1b0686bc166d</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mxxhcm.github.io/2019/10/09/gym-wrappers-and-monitors/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="马晓鑫爱马荟荟">
      <meta itemprop="description" content="记录硕士三年自己的积累">
      <meta itemprop="image" content="/images/favicon.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="mxxhcm's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/10/09/gym-wrappers-and-monitors/" class="post-title-link" itemprop="http://mxxhcm.github.io/page/8/index.html">gym wrappers and monitors</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-10-09 15:24:33" itemprop="dateCreated datePublished" datetime="2019-10-09T15:24:33+08:00">2019-10-09</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-10-21 19:50:05" itemprop="dateModified" datetime="2019-10-21T19:50:05+08:00">2019-10-21</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/强化学习/" itemprop="url" rel="index"><span itemprop="name">强化学习</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>这一篇文章主要介绍wrappers和monitors。</p>
<h2 id="什么是Wrappers"><a href="#什么是Wrappers" class="headerlink" title="什么是Wrappers"></a>什么是Wrappers</h2><p>对已有的environments的功能进行扩展。比如保留过去的N个observation或者对输入进行cropped。Gym提供了这样的借口，叫做Wrapper class。<br>Wrapper继承自Env class，构造函数只接收一个参数，要被”wrapped”的Env实例。为了添加新的逻辑，需要重写step()或者reset()方法，但是需要调用父类的original方法。为了更细粒度的满足要求，gym还提供了三个Wrapper的subclass，ObservationWrapper，RewardWrapper和ActionWrapper分别只对observation，reward和action进行重定义。他们之间的关系如下所示：<br><img src="/2019/10/09/gym-wrappers-and-monitors/gym_wrapper.png" alt="gym_wrapper"><br>Env是一个abstract class，具体的environments如Breakout继承了Env class，实现了step()，reset()等abstract function。Wrapper继承了env class，对step(), reset()等方法进行了重载。ActionWrapper对Wrapper进行了重载，对step和reset进行了重载。<br>Env </p>
<ul>
<li>abstract step(self, action)</li>
<li>abstract reset(self)</li>
</ul>
<p>Breakout(Env)</p>
<ul>
<li>overwrite step(self, action)</li>
<li>overwrite reset(self)</li>
</ul>
<p>Wrapper(Env)</p>
<ul>
<li>__init__(self, env): self.env = env # instance of gym environment</li>
<li>overwrite step(self, action): self.env.step(action) # 调用的是传入参数env的step函数</li>
<li>overwrite reset(self) # 调用的是传入参数env的reset函数</li>
</ul>
<p>ActionWrapper(Wrapper)</p>
<ul>
<li>overwrite step(self, action): self.env.step(self.action(action)) # 调用的是self.env的step函数</li>
<li>overwrite reset(self) # 调用的是self.env的step函数</li>
<li>abstract action(self, action)</li>
<li>abstract reverse_action(self, action)</li>
</ul>
<p>MyownActionWrapper(ActionWrapper)</p>
<ul>
<li>overwrite action(self, action)</li>
</ul>
<h2 id="Wrapper示例"><a href="#Wrapper示例" class="headerlink" title="Wrapper示例"></a>Wrapper示例</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> gym</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RandomActionWrapper</span><span class="params">(gym.ActionWrapper)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, environment, epsilon=<span class="number">-1.1</span>)</span>:</span></span><br><span class="line">        super(RandomActionWrapper, self).__init__(environment)</span><br><span class="line">        self.epsilon = epsilon</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">action</span><span class="params">(self, action)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> random.random() &lt; self.epsilon:</span><br><span class="line">            print(<span class="string">"Random"</span>)</span><br><span class="line">            <span class="keyword">return</span> self.env.action_space.sample()</span><br><span class="line">            <span class="comment"># return self.environment.action_space.sample()</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># print("Not random")</span></span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line">        <span class="keyword">return</span> action</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reverse_action</span><span class="params">(self, action)</span>:</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    environment = gym.make(<span class="string">"CartPole-v0"</span>)</span><br><span class="line">    env = RandomActionWrapper(environment)</span><br><span class="line">    </span><br><span class="line">    obs = env.reset()</span><br><span class="line">    episode = <span class="number">0</span></span><br><span class="line">    total_steps = <span class="number">0</span></span><br><span class="line">    total_reward = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        action = env.action_space.sample()</span><br><span class="line">        obs, reward, done, info = env.step(action)</span><br><span class="line">        print(reward)</span><br><span class="line">        total_reward += reward</span><br><span class="line">        total_steps += <span class="number">1</span></span><br><span class="line">        env.render()</span><br><span class="line">        time.sleep(<span class="number">0.1</span>)</span><br><span class="line">        <span class="keyword">if</span> done:</span><br><span class="line">            print(<span class="string">"Episode %d done in %d steps, total reward %.1f"</span> %(episode, total_steps, total_reward))</span><br><span class="line">            time.sleep(<span class="number">0.1</span>)</span><br><span class="line">            env.reset()</span><br><span class="line">            episode += <span class="number">1</span></span><br><span class="line">            total_reward = <span class="number">0</span></span><br></pre></td></tr></table></figure>
<p>在这个例子中，env其实是RandomActionWrapper的对象，而RandomActionWrapper继承自ActionWrapper，对ActionWrapper的action方法进行了重载。这个Wrapper对象拥有CartPole environment的对象，调用wrapper对象的step方法时，其实调用的是ActionWrapper的step方法，而ActionWrapper调用的是self.env.env(self.action(action))。<br>最终其实就是将env.step(action)改成了env.step(action(action))。</p>
<h2 id="什么是Monitors"><a href="#什么是Monitors" class="headerlink" title="什么是Monitors"></a>什么是Monitors</h2><p>使用gym.wrapper.Monior记录当前agent的执行动作。它的使用方法很简单，如下所示：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">env = gym.make(<span class="string">"CartPole-v0"</span>)</span><br><span class="line">env = gym.wrappers.Monitor(env, <span class="string">"path"</span>)</span><br></pre></td></tr></table></figure></p>
<p>只需要在env的外面套上一个Monitor即可，它会自动记录玩游戏的过程。</p>
<h2 id="Wrapper-in-baselines"><a href="#Wrapper-in-baselines" class="headerlink" title="Wrapper in baselines"></a>Wrapper in baselines</h2><p>Openai baselines中实现了许多wrappers。它们包括：</p>
<ul>
<li>将一个大的episode切分成更小的episode，一个游戏可能有好几条命，原来的实现中是这几条命都是一个episode，现在把它改成一条命一个episode</li>
<li>执行至多$30$个no-op。</li>
<li>frame-skip和取最后两帧中pixel更大的那个当做observation</li>
<li>在游戏开始时Pressing FIRE，一般在重置游戏的时候，有些游戏需要按一下fire才会开始，否则一直都是fixed。</li>
<li>Image cropped,将$210\times 160$三通道转换成$84\times 84$单通道</li>
<li>Stacking $4$ frames当做observation</li>
<li>Clipped reward 到$-1, 0, 1$，或者$[-1, 1]$</li>
<li>将$0-255$之间的值转换成$[0.0, 1.0]$</li>
</ul>
<h2 id="Monitors示例"><a href="#Monitors示例" class="headerlink" title="Monitors示例"></a>Monitors示例</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> gym</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    env = gym.make(<span class="string">"CartPole-v0"</span>)</span><br><span class="line">    env = gym.wrappers.Monitor(env, <span class="string">"recording"</span>)</span><br><span class="line"></span><br><span class="line">    total_reward = <span class="number">0.0</span></span><br><span class="line">    total_steps = <span class="number">0</span></span><br><span class="line">    obs = env.reset()</span><br><span class="line">    episode = <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        action = env.action_space.sample()</span><br><span class="line">        obs, reward, done, _ = env.step(action)</span><br><span class="line">        total_reward += reward</span><br><span class="line">        total_steps += <span class="number">1</span></span><br><span class="line">        env.render()</span><br><span class="line">        <span class="keyword">if</span> done:</span><br><span class="line">            print(<span class="string">"Episode %d done in %d steps, total reward %.2f"</span> %(episode, total_steps, total_reward))</span><br><span class="line">            time.sleep(<span class="number">1</span>)</span><br><span class="line">            env.reset()</span><br><span class="line">            <span class="keyword">if</span> episode &gt; <span class="number">5</span>:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            episode += <span class="number">1</span></span><br><span class="line">            total_reward = <span class="number">0</span></span><br></pre></td></tr></table></figure>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>1.<a href="https://hub.packtpub.com/openai-gym-environments-wrappers-and-monitors-tutorial/" target="_blank" rel="noopener">https://hub.packtpub.com/openai-gym-environments-wrappers-and-monitors-tutorial/</a><br>2.<a href="https://www.packtpub.com/big-data-and-business-intelligence/deep-reinforcement-learning-hands" target="_blank" rel="noopener">https://www.packtpub.com/big-data-and-business-intelligence/deep-reinforcement-learning-hands</a><br>3.<a href="https://discuss.pytorch.org/t/in-the-official-q-learning-example-what-does-the-env-unwrapped-do-exactly/28695/2" target="_blank" rel="noopener">https://discuss.pytorch.org/t/in-the-official-q-learning-example-what-does-the-env-unwrapped-do-exactly/28695/2</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mxxhcm.github.io/2019/10/08/python-pickle/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="马晓鑫爱马荟荟">
      <meta itemprop="description" content="记录硕士三年自己的积累">
      <meta itemprop="image" content="/images/favicon.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="mxxhcm's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/10/08/python-pickle/" class="post-title-link" itemprop="http://mxxhcm.github.io/page/8/index.html">python pickle</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-10-08 17:56:48" itemprop="dateCreated datePublished" datetime="2019-10-08T17:56:48+08:00">2019-10-08</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-10-11 13:30:51" itemprop="dateModified" datetime="2019-10-11T13:30:51+08:00">2019-10-11</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/python/" itemprop="url" rel="index"><span itemprop="name">python</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>pickle是一个序列化模块，它能将python对象序列化转换成二进制串再反序列化成python对象。</p>
<h2 id="常用函数"><a href="#常用函数" class="headerlink" title="常用函数"></a>常用函数</h2><h3 id="pickle-dump"><a href="#pickle-dump" class="headerlink" title="pickle.dump()"></a>pickle.dump()</h3><h4 id="API"><a href="#API" class="headerlink" title="API"></a>API</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pickle.dump(obj, file, [,protocol])</span><br></pre></td></tr></table></figure>
<h4 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h4><p>将python对象obj以二进制字符串形式保存到文件file中，使用protocol。</p>
<h4 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"></span><br><span class="line">dictionary = &#123;<span class="string">"name"</span>: <span class="string">"mxx"</span>, <span class="string">"age"</span>: <span class="number">23</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">"test.txt"</span>, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    pickle.dump(dictionary, f)</span><br></pre></td></tr></table></figure>
<h3 id="pickle-load"><a href="#pickle-load" class="headerlink" title="pickle.load()"></a>pickle.load()</h3><h4 id="API-1"><a href="#API-1" class="headerlink" title="API"></a>API</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pickle.load(file)</span><br></pre></td></tr></table></figure>
<h4 id="作用-1"><a href="#作用-1" class="headerlink" title="作用"></a>作用</h4><p>从文件file中读取二进制字符串，将其反序列成python对象。</p>
<h4 id="示例-1"><a href="#示例-1" class="headerlink" title="示例"></a>示例</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">"test.txt"</span>, <span class="string">'rb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    b = pickle.load(f)</span><br><span class="line"></span><br><span class="line">print(b)</span><br><span class="line">print(type(b))</span><br></pre></td></tr></table></figure>
<h3 id="pickle-dumps"><a href="#pickle-dumps" class="headerlink" title="pickle.dumps()"></a>pickle.dumps()</h3><h4 id="API-2"><a href="#API-2" class="headerlink" title="API"></a>API</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pickle.dumps(obj, [,protocol])</span><br></pre></td></tr></table></figure>
<h4 id="作用-2"><a href="#作用-2" class="headerlink" title="作用"></a>作用</h4><p>将python对象obj转化成二进制字符串，返回一个字符串</p>
<h4 id="示例-2"><a href="#示例-2" class="headerlink" title="示例"></a>示例</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"></span><br><span class="line">dictionary = &#123;<span class="string">"name"</span>: <span class="string">"mxx"</span>, <span class="string">"age"</span>: <span class="number">23</span>&#125;</span><br><span class="line"></span><br><span class="line">s = pickle.dumps(dictionary)</span><br><span class="line">print(s)</span><br><span class="line">print(type(s))</span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line"><span class="comment"># b'\x80\x03&#125;q\x00(X\x04\x00\x00\x00nameq\x01X\x03\x00\x00\x00mxxq\x02X\x03\x00\x00\x00ageq\x03K\x17u.'</span></span><br><span class="line"><span class="comment"># &lt;class 'bytes'&gt;</span></span><br></pre></td></tr></table></figure>
<h3 id="pickle-loads"><a href="#pickle-loads" class="headerlink" title="pickle.loads()"></a>pickle.loads()</h3><h4 id="API-3"><a href="#API-3" class="headerlink" title="API"></a>API</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pickle.loads(string)</span><br></pre></td></tr></table></figure>
<h4 id="作用-3"><a href="#作用-3" class="headerlink" title="作用"></a>作用</h4><p>从二进制字符串中返回序列化前的python obj对象。</p>
<h4 id="示例-3"><a href="#示例-3" class="headerlink" title="示例"></a>示例</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"></span><br><span class="line">dictionary = &#123;<span class="string">"name"</span>: <span class="string">"mxx"</span>, <span class="string">"age"</span>: <span class="number">23</span>&#125;</span><br><span class="line"></span><br><span class="line">s = pickle.dumps(dictionary)</span><br><span class="line">b = pickle.loads(s)</span><br><span class="line">print(b)</span><br><span class="line">print(type(b))</span><br></pre></td></tr></table></figure>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>1.<a href="https://www.jianshu.com/p/cf91849064e3" target="_blank" rel="noopener">https://www.jianshu.com/p/cf91849064e3</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mxxhcm.github.io/2019/10/08/python-mpi4py/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="马晓鑫爱马荟荟">
      <meta itemprop="description" content="记录硕士三年自己的积累">
      <meta itemprop="image" content="/images/favicon.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="mxxhcm's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/10/08/python-mpi4py/" class="post-title-link" itemprop="http://mxxhcm.github.io/page/8/index.html">python mpi4py</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-10-08 17:25:46" itemprop="dateCreated datePublished" datetime="2019-10-08T17:25:46+08:00">2019-10-08</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-10-11 13:30:51" itemprop="dateModified" datetime="2019-10-11T13:30:51+08:00">2019-10-11</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/python/" itemprop="url" rel="index"><span itemprop="name">python</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="MPI"><a href="#MPI" class="headerlink" title="MPI"></a>MPI</h2><p>MPI全名是Message Passing Interface，它是一个标准，而不是一个实现，专门为进程间通信实现的。它的工作原理很简单，启动一组进程，在同一个通信域中的不同进程有不同的编号，可以给不同编号的进程分配不同的任务，最终实现整个任务。<br>MPI4PY就是python中MPI的实现。在python中有很多种方法实现多进程以及进程间通信，比如multiprocessing，但是multiprocessing进程间通信不够方便，mpi4py的效率更高一些。<br>mpi4py提供了点对点通信，点对面，面对点通信。点对点通信又包含阻塞和非阻塞等等，通信的内容包含python内置对象，也包含numpy数组等。</p>
<h2 id="mpi4py简单对象和方法介绍"><a href="#mpi4py简单对象和方法介绍" class="headerlink" title="mpi4py简单对象和方法介绍"></a>mpi4py简单对象和方法介绍</h2><p>MPI.COMM_WORLD是一个通信域，在这个通信域中有不同的进程，每个进程的编号以及进程的数量都可以通过这个通信域获得。具体看以下comm_world.py代码：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> mpi4py <span class="keyword">import</span> MPI</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获得多进程通信域</span></span><br><span class="line">comm = MPI.COMM_WORLD</span><br><span class="line"><span class="comment"># 获得当前进程通信域中进程数量</span></span><br><span class="line">size = comm.Get_size()</span><br><span class="line"><span class="comment"># 获得当前进程在通信域中的编号</span></span><br><span class="line">rank = comm.Get_rank()</span><br></pre></td></tr></table></figure></p>
<blockquote>
<blockquote>
<blockquote>
<p>mpiexec -np 3 python comm_world.py</p>
</blockquote>
</blockquote>
</blockquote>
<h2 id="点对点通信"><a href="#点对点通信" class="headerlink" title="点对点通信"></a>点对点通信</h2><h3 id="阻塞通信"><a href="#阻塞通信" class="headerlink" title="阻塞通信"></a>阻塞通信</h3><h4 id="python对象"><a href="#python对象" class="headerlink" title="python对象"></a>python对象</h4><h5 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h5><p>comm.send(data, dest, tag)<br>comm.recv(source, tag)<br>send和recv都是阻塞方法，即调用这个方法之后，等到该函数调用结束之后再返回。dest是目的process编号，source是发送的process编号。data是要发送的数据，需要是python的内置对象，即可以pickle的对象。</p>
<h5 id="代码示例"><a href="#代码示例" class="headerlink" title="代码示例"></a>代码示例</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> mpi4py <span class="keyword">import</span> MPI</span><br><span class="line"></span><br><span class="line">comm = MPI.COMM_WORLD</span><br><span class="line">rank = comm.Get_rank()</span><br><span class="line">size = comm.Get_size()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> rank == <span class="number">0</span>:</span><br><span class="line">    data = &#123;<span class="string">'name'</span>: <span class="string">"mxx"</span>, <span class="string">"age"</span>: <span class="number">23</span>&#125;</span><br><span class="line">    comm.send(data, dest=<span class="number">1</span>, tag=<span class="number">10</span>)</span><br><span class="line">    print(<span class="string">"data has sent."</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    data = comm.recv(source=<span class="number">0</span>, tag=<span class="number">10</span>)</span><br><span class="line">    print(<span class="string">"data has been receieved."</span>)</span><br></pre></td></tr></table></figure>
<h4 id="numpy数组"><a href="#numpy数组" class="headerlink" title="numpy数组"></a>numpy数组</h4><h5 id="简介-1"><a href="#简介-1" class="headerlink" title="简介"></a>简介</h5><p>comm.Send(data, dest, tag)<br>comm.Recv(source, tag)<br>Send和Recv都是阻塞方法，即调用这个方法之后，等到该函数调用结束之后再返回。dest是目的process编号，source是发送的process编号。data是要发送的数据，需要是numpy对象，和c语言的效率差不多。</p>
<h5 id="代码示例-1"><a href="#代码示例-1" class="headerlink" title="代码示例"></a>代码示例</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> mpi4py <span class="keyword">import</span> MPI</span><br><span class="line"></span><br><span class="line">comm = MPI.COMM_WORLD</span><br><span class="line"></span><br><span class="line">rank = comm.Get_rank()</span><br><span class="line">size = comm.Get_size()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> rank == <span class="number">0</span>:</span><br><span class="line">    data = &#123;<span class="string">'name'</span>: <span class="string">"mxx"</span>, <span class="string">"age"</span>: <span class="number">23</span>&#125;</span><br><span class="line">    comm.isend(data, dest=<span class="number">1</span>, tag=<span class="number">10</span>)</span><br><span class="line">    print(<span class="string">"data has sent."</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    data = comm.irecv(source=<span class="number">0</span>, tag=<span class="number">10</span>)</span><br><span class="line">    print(<span class="string">"data has been receieved."</span>)</span><br></pre></td></tr></table></figure>
<h3 id="非阻塞通信"><a href="#非阻塞通信" class="headerlink" title="非阻塞通信"></a>非阻塞通信</h3><h4 id="简介-2"><a href="#简介-2" class="headerlink" title="简介"></a>简介</h4><p>comm.isend(data, dest, tag)<br>comm.irecv(source, tag)<br>isend和irecv都是非阻塞方法，即调用这个方法之后，调用该函数之后立即返回，无需等待它执行结束。dest是目的process编号，source是发送的process编号。data要是python对象，可以被pickle处理的。</p>
<h4 id="代码示例-2"><a href="#代码示例-2" class="headerlink" title="代码示例"></a>代码示例</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> mpi4py <span class="keyword">import</span> MPI</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">comm = MPI.COMM_WORLD</span><br><span class="line"></span><br><span class="line">rank = comm.Get_rank()</span><br><span class="line">size = comm.Get_size()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> rank == <span class="number">0</span>:</span><br><span class="line">    data = np.ones((<span class="number">3</span>, <span class="number">4</span>), dtype=<span class="string">'i'</span>)</span><br><span class="line">    comm.Send([data, MPI.INT], dest=<span class="number">1</span>, tag=<span class="number">10</span>)</span><br><span class="line">    print(<span class="string">"data has sent."</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    data = np.empty((<span class="number">3</span>, <span class="number">4</span>), dtype=<span class="string">'i'</span>)</span><br><span class="line">    data = comm.Recv([data, MPI.INT], source=<span class="number">0</span>, tag=<span class="number">10</span>)</span><br><span class="line">    print(<span class="string">"data has been receieved."</span>)</span><br></pre></td></tr></table></figure>
<h2 id="组通信"><a href="#组通信" class="headerlink" title="组通信"></a>组通信</h2><h3 id="bcast"><a href="#bcast" class="headerlink" title="bcast"></a>bcast</h3><h4 id="简介-3"><a href="#简介-3" class="headerlink" title="简介"></a>简介</h4><p>将一个process中的数据发送给所有在通信池中的process。<br>comm.bcast(data, dest, tag)</p>
<h4 id="代码示例-3"><a href="#代码示例-3" class="headerlink" title="代码示例"></a>代码示例</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> mpi4py</span><br><span class="line"><span class="keyword">from</span> mpi4py <span class="keyword">import</span> MPI</span><br><span class="line"></span><br><span class="line">comm = MPI.COMM_WORLD</span><br><span class="line">size = comm.Get_size()</span><br><span class="line">rank = comm.Get_rank()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> rank == <span class="number">1</span>:</span><br><span class="line">    data = &#123;<span class="string">"name"</span>: <span class="string">"mxx"</span>, <span class="string">"age"</span>: <span class="number">23</span>&#125;</span><br><span class="line">    print(<span class="string">"data bcast to others"</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    data = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">data = comm.bcast(data, root=<span class="number">1</span>)</span><br><span class="line">print(<span class="string">"process &#123;&#125; has received data"</span>.format(rank))</span><br></pre></td></tr></table></figure>
<h3 id="scatter"><a href="#scatter" class="headerlink" title="scatter"></a>scatter</h3><h4 id="简介-4"><a href="#简介-4" class="headerlink" title="简介"></a>简介</h4><p>将一个process的数据拆分成n份，发送给所有在通信池中的process每个一份，和bcast的区别在于，bcast发送的数据对于每一个process都是一样的，而scatter是将一份数据拆分成n份分别发送给每个process。<br>comm.scatter(data, dest, tag)</p>
<h4 id="代码示例-4"><a href="#代码示例-4" class="headerlink" title="代码示例"></a>代码示例</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> mpi4py</span><br><span class="line"><span class="keyword">from</span> mpi4py <span class="keyword">import</span> MPI</span><br><span class="line"></span><br><span class="line">comm = MPI.COMM_WORLD</span><br><span class="line">size = comm.Get_size()</span><br><span class="line">rank = comm.Get_rank()</span><br><span class="line"></span><br><span class="line">recv_data = <span class="literal">None</span></span><br><span class="line"><span class="keyword">if</span> rank == <span class="number">1</span>:</span><br><span class="line">    send_data = range(size) </span><br><span class="line">    print(<span class="string">"data bcast to others"</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    send_data = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">recv_data = comm.scatter(send_data, root=<span class="number">1</span>)</span><br><span class="line">print(<span class="string">"process &#123;&#125; has received data &#123;&#125;"</span>.format(rank, recv_data))</span><br></pre></td></tr></table></figure>
<h3 id="gather"><a href="#gather" class="headerlink" title="gather"></a>gather</h3><h4 id="简介-5"><a href="#简介-5" class="headerlink" title="简介"></a>简介</h4><p>和comm.bcast相反，将每个process中的数据收集到一个process中。<br>comm.gather(data, dest, tag)</p>
<h4 id="代码示例-5"><a href="#代码示例-5" class="headerlink" title="代码示例"></a>代码示例</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> mpi4py</span><br><span class="line"><span class="keyword">from</span> mpi4py <span class="keyword">import</span> MPI</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">comm = MPI.COMM_WORLD</span><br><span class="line">size = comm.Get_size()</span><br><span class="line">rank = comm.Get_rank()</span><br><span class="line"></span><br><span class="line">send_data = rank</span><br><span class="line">print(<span class="string">"process &#123;&#125; send data &#123;&#125; to root."</span>.format(rank, send_data))</span><br><span class="line"></span><br><span class="line">recv_data = comm.gather(send_data, root=<span class="number">9</span>)</span><br><span class="line"><span class="keyword">if</span> rank == <span class="number">9</span>:</span><br><span class="line">    print(<span class="string">"process &#123;&#125; gather all data &#123;&#125; to others."</span>.format(rank, recv_data))</span><br></pre></td></tr></table></figure>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>1.<a href="https://zhuanlan.zhihu.com/p/25332041" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/25332041</a><br>2.<a href="https://www.jianshu.com/p/f497f3a5855f" target="_blank" rel="noopener">https://www.jianshu.com/p/f497f3a5855f</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mxxhcm.github.io/2019/10/06/gradient-method-deep-deterministic-policy-gradient/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="马晓鑫爱马荟荟">
      <meta itemprop="description" content="记录硕士三年自己的积累">
      <meta itemprop="image" content="/images/favicon.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="mxxhcm's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/10/06/gradient-method-deep-deterministic-policy-gradient/" class="post-title-link" itemprop="http://mxxhcm.github.io/page/8/index.html">gradient method deep deterministic policy gradient</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-10-06 10:17:25 / 修改时间：20:17:08" itemprop="dateCreated datePublished" datetime="2019-10-06T10:17:25+08:00">2019-10-06</time>
            

            
              

              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/强化学习/" itemprop="url" rel="index"><span itemprop="name">强化学习</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="ddpg"><a href="#ddpg" class="headerlink" title="ddpg"></a>ddpg</h2><p>论文名称：CONTINUOUS CONTROL WITH DEEP REINFORCEMENT LEARNING<br>论文地址：<a href="https://arxiv.org/pdf/1509.02971.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1509.02971.pdf</a></p>
<h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>本文将DQN的思路推广到continuous action domain上。DQN是离散空间，DDPG是连续空间。</p>
<h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>强化学习的目标是学习一个policy最大化$J=\mathbb{E}_{r_i,s_i\sim E, a_i\sim \pi}\left[R_1\right]$的expected return。<br>简要回顾以下action-value的定义，它的定义是从状态s开始,采取action a，采取策略$\pi$得到的回报的期望。</p>
<script type="math/tex; mode=display">Q{\pi}(s_t,a_t) = \mathbb{E}\_{r_{i\ge t}, s_{i \gt t}\sim E,a_{i\gt t}\sim \pi}\left[R_t|s_t,a_t\right] \tag{1}</script><p>（注意，这里$R$的下标和reinforcement learning an introduction中的定义不一样，但是这个无所谓，只要在用的时候保持统一就好了。）<br>许多rl方法使用bellman方程递归的更新Q:</p>
<script type="math/tex; mode=display">Q{\pi}(s_t,a_t) = \mathbb{E}\_{r_t,s_{t+1}\sim E}\left[r(s_t,a_t) + \gamma\mathbb{E}\_{a_{t+1}\sim\pi}\left[Q^{\pi} (s_{t+1},a_{t+1})\right]\right]\tag{2}</script><p>如果target policy是deterministic的话，用$\mu$表示，那么就可以去掉式子里面的期望，action是deterministic的而不是服从一个概率分布：</p>
<script type="math/tex; mode=display">Q{\mu}(s_t,a_t) = \mathbb{E}\_{r_t,s_{t+1}\sim E}\left[r(s_t,a_t) + \gamma Q^{\mu} (s_{t+1},\mu(s_{t+1}))\right] \tag{3}</script><p>而第一个期望只和environment相关。这就意味着可以使用off-policy方法学习$Q{\mu}$。<br>在DQN中，作者使用replay buffer和target network缓解了non-linear funnction approximator不稳定的问题，作者在这篇文章将它们推广到了DDPG上面。</p>
<h3 id="DDPG"><a href="#DDPG" class="headerlink" title="DDPG"></a>DDPG</h3><p>直接将Q-learning推广到continuous action space是不可行的，因为action是continuous的，对其进行max等greedy操作是不可行的。这种优化方法只适合trival action spaces的情况。所以这里使用的是DPG(deterministic policy gradient)，将其推广到non-linear case，DPG是一种actor-critic的方法。<br>DPG使用一个参数化的actor function $\mu(s|\theta{\mu})$作为当前的policy，它将一个states直接mapping到一个specific action。$Q(s,a)$作为critic使用Q-learning中的Bellman公式进行更新。Actor的更新直接应用chain rule到$J$的expected reutrn ，更新actor的参数如下：<br>\begin{align*}<br>\nabla_{\theta{\mu}} &amp;\approx \mathbb{E}_{s_t\sim \rho^{\beta} }\left[\nabla_{\theta^{\mu} }Q(s,a|\theta^Q )|_{s=s_t, a= \mu(s_t|\theta^{\mu} )}\right]\\\\<br>&amp;= \mathbb{E}_{s_t\sim \rho{\beta}}\left[\frac{\partial Q(s,a|\theta^Q )}{\partial\theta^{\mu} }|_{s=s_t, a= \mu(s_t|\theta^{\mu} )}\right]\\\\<br>&amp;= \mathbb{E}_{s_t\sim \rho{\beta}}\left[\frac{\partial Q(s,a|\theta^Q )}{\partial a}|_{s=s_t, a= \mu(s_t)}\frac{\partial \mu(s_t|\theta^{\mu} )}{\partial\theta^{\mu} }|_{s=s_t}\right]\\\\<br>&amp;= \mathbb{E}_{s_t\sim \rho{\beta}}\left[\nabla_a Q(s,a|\theta^Q )|_{s=s_t, a= \mu(s_t)} \nabla_{\theta_{\mu}} \mu(s|\theta_{\mu})|_{s=s_t}\right]\\\ \tag{4}<br>\end{align*}<br>中间的两行是我自己加的，不知道对不对，DPG论文中有证明，还没有看到，等到读完以后再说补充把。</p>
<h4 id="Contributions"><a href="#Contributions" class="headerlink" title="Contributions"></a>Contributions</h4><p>本文的几个改进：</p>
<ol>
<li>使用replay buffer，</li>
<li>使用target network解决不稳定的问题。</li>
<li>使用了batch-normalization。</li>
<li>exploration。off policy的一个优势就是target policy和behaviour policy可以不同。本文使用的behaviour policy $\mu’$ 添加了一个从noise process $N$中采样的noise：<script type="math/tex; mode=display">\mu(s_t) = \mu(s_t|\theta_t{\mu}) + N \tag{5}</script></li>
</ol>
<h4 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h4><p>算法1 DDPG<br>随机初始化critic 网络$Q(s,a |\theta Q)$，和actor网络$\mu(s|\theta^{\mu} )$的权重$\theta^Q $和$\theta^{\mu} $<br>初始化target networks　$Q’$和$\mu’$的权重$\theta{Q’}\leftarrow \theta^Q ,\theta^{\mu’} \leftarrow \theta^{\mu} $<br>初始化replay buffer $R$<br><strong>for</strong> episode = 1, M <strong>do</strong><br>初始化一个随机process $N$用于exploration<br>receive initial observation state $s_1$<br>for $t=1, T$ do<br>根据behaviour policy选择action $a_t = \mu(s_t| \theta{\mu}) + N_t$<br>执行action $a_t$，得到$r_t$和$s_{t+1}$<br>将transition $s_t, a_t, r_t, s_{t+1}$存到$R$<br>从$R$中采样$N$个transition $s_i, a_i, r_i, s_{i+1}$<br>设置target value $y_i = r_i + \gamma Q’(s_{i+1}, \mu’(s_{i+1}|\theta{\mu’})|\theta^{Q’} )$<br>使用$L = \frac{1}{N}\sum_i(y_i-Q(s_i,a_i|\theta Q))^2 $更新critic<br>使用sampled policy gradient 更新acotr:</p>
<script type="math/tex; mode=display">\nabla_{\theta{\mu}}\approx \frac{1}{N}\sum_i\nabla_a Q(s,a|\theta^Q )|\_{s=s_i, a=\mu(s_i)}\nabla\_{\theta^{\mu} }\mu(s|\theta^{\mu} )|\_{s_i}</script><p>更新target networks:</p>
<script type="math/tex; mode=display">\theta'\leftarrow \tau \theta + (1-\tau) \theta'</script><p>end for<br>end for</p>
<h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><p>所有任务中，都使用了low-dimensional state和high-dimensional renderings。在DQN中，为了让问题在high dimensional environment中fully observable，使用了action repeats。在agent的每一个timestep中，进行$3$个timesteps的仿真，包含repeating action以及rendering。因此agent的observation包含$9$个feature maps（RGB，每一个有3个renderings），可以让agent推理不同frames之间的differences。frames进行下采样，得到$64\times 64$的像素矩阵，然后$8$位的RGB值转化为$[0,1]$之间的float points。<br>在训练的时候，周期性的进行test，test时候的不需要exploration noise。实验表明，去掉不同的组件，即contribution中的几点之后，结果都会比原来差。没有使用target network的话，结果尤其差。<br>作者使用了两个baselines normalized scores，第一个是naive policy，在action space中均匀的采样action得到的mean return，第二个是iLQG。normalized之后，naive policy的mean score是0，iLQG的mean score是$1$。DDPG能够学习到好的policy，在某些任务上甚至比iLQG还要好。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>1.<a href="https://arxiv.org/pdf/1509.02971.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1509.02971.pdf</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mxxhcm.github.io/2019/10/04/reinforcement-learning-why-use-baseline/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="马晓鑫爱马荟荟">
      <meta itemprop="description" content="记录硕士三年自己的积累">
      <meta itemprop="image" content="/images/favicon.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="mxxhcm's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/10/04/reinforcement-learning-why-use-baseline/" class="post-title-link" itemprop="http://mxxhcm.github.io/page/8/index.html">reinforcement learning why use baseline ?</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-10-04 15:46:00" itemprop="dateCreated datePublished" datetime="2019-10-04T15:46:00+08:00">2019-10-04</time>
            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            
          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mxxhcm.github.io/2019/09/27/reinforcement-learning-importance-sampling/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="马晓鑫爱马荟荟">
      <meta itemprop="description" content="记录硕士三年自己的积累">
      <meta itemprop="image" content="/images/favicon.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="mxxhcm's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/09/27/reinforcement-learning-importance-sampling/" class="post-title-link" itemprop="http://mxxhcm.github.io/page/8/index.html">reinforcement learning importance sampling</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-09-27 23:41:36" itemprop="dateCreated datePublished" datetime="2019-09-27T23:41:36+08:00">2019-09-27</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-09-30 12:27:02" itemprop="dateModified" datetime="2019-09-30T12:27:02+08:00">2019-09-30</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/强化学习/" itemprop="url" rel="index"><span itemprop="name">强化学习</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Importance-Sampling"><a href="#Importance-Sampling" class="headerlink" title="Importance Sampling"></a>Importance Sampling</h2><p>Importance sampling是使用一个分布近似估计另一个分布期望的方法，即通过分布$q$计算分布$p$下$f(x)$的期望。通过从$q$中采样而不是从$p$中采样近似：</p>
<script type="math/tex; mode=display">\mathbb{E}\_p\left[f(x)\right] = \mathbb{E}\_q\left[ \frac{p(x)f(x)}{q(x)}\right] \tag{1}</script><p>使用采样分布$q$估计分布$p$下的期望：</p>
<script type="math/tex; mode=display">\mathbb{E}\_p\left[f(x)\right] \approx \frac{1}{n} \sum\_{i=1}^n \frac{p(x\_i)f(x\_i)}{q(x\_i)} x\_i\sim q\tag{2}</script><p>上面的公式需要满足$p(x_i)$不为$0$时，$q(x_i)$也不为$0$。直接计算$\mathbb{E}_p\left[f(x)\right]$和$\mathbb{E}_q\left[f(x)\right]$，一般来说是不同的，通过importance ratio调整权重，就可以使用$q$分布估计$p$分布的期望了。举个例子：</p>
<script type="math/tex; mode=display">f(1) = 2, f(2) = 3, f(3) = 4, otherwise 0 \tag{3}</script><p>概率分布$p$为：$p(x=1) = 0, p(x=2) = \frac{1}{3},p(x=3) = \frac{2}{3}$，概率分布$q$为：$q(x=1) = \frac{1}{3}, q(x=2) = \frac{1}{3}, q(x=3) = \frac{1}{3}$。计算期望，$\mathbb{E}_p\left[f(x)\right] = \frac{11}{3}$，$\mathbb{E}_q\left[f(x)\right] = 3$<br>使用importance ratio进行权重调整：<br>\begin{align*}<br>\mathbb{E}_p\left[f(x)\right] &amp; = \mathbb{E}_q\left[\frac{q(x)}{p(x)}f(x)\right] \\\\<br>&amp; = \mathbb{E}_q\left[\frac{p(x=1)}{q(x=1)}f(x=1) \right] + \mathbb{E}_q\left[\frac{p(x=2)}{q(x=2)}f(x=2) \right] + \mathbb{E}_q\left[\frac{p(x=3)}{q(x=3)}f(x=3) \right] \\\\<br>&amp; = \frac{1}{3}<em>0 + \frac{1}{3}\frac{\frac{1}{3}}{\frac{1}{3}}</em>3 + \frac{1}{3}\frac{\frac{2}{3}}{\frac{1}{3}}<em>4\\\\<br>&amp; =\frac{11}{3}\\\\<br>\end{align\</em>}<br>可以看出来，我们使用分布$q$估计除了分布$p$的期望。通过使用一个简单分布$q$进行采样，可以计算出$p$的期望。在RL中，通常通过复用old policy的sample trajectory学习current policy。</p>
<h2 id="Optimal-Importance-Sampling"><a href="#Optimal-Importance-Sampling" class="headerlink" title="Optimal Importance Sampling"></a>Optimal Importance Sampling</h2><p>Importance sampling使用采样近似估计$\mathbb{E}_p\left[f(x)\right]\approx \frac{1}{N}\sum_i \frac{p(x_i)}{q(x_i)}f(x_i)$近似计算$\mathbb{E}_p\left[f(x)\right]$。随着样本数量$N$的增加，期望值越准确。但是这种方法的方差很大，为了减少方差，样本分布$q$应该满足：</p>
<script type="math/tex; mode=display">q(x) \propto p(x)\vert f(x)\vert \tag{4}</script><p>简单来说，为了减少方差，我们需要采样return更大的点。</p>
<h2 id="Normalized-importanct-sampling"><a href="#Normalized-importanct-sampling" class="headerlink" title="Normalized importanct sampling"></a>Normalized importanct sampling</h2><p>上面介绍的方法叫做unnormalized importance sampling。可以使用下里面的公式将unnormalized importance sampling转换为normalized importance sampling。</p>
<script type="math/tex; mode=display">p(x) = \frac{\hat{p}(x)}{Z}\tag{5}</script><p>许多ML方法属于贝叶斯网络或者马尔科夫随机场，对于贝叶斯网络中，$p$很容易计算。但是当$p$是马尔科夫随机场时，$\sum\hat{p}(x)$是很难计算的。<br>\begin{align*}<br>\mathbb{E}_p\left[f(x)\right] &amp; = \int f(x) p(x) dx\\\\<br>&amp; = \int f(x) \frac{\hat{p}(x)}{Z} \frac{q(x)}{q(x)} dx\\\\<br>&amp; = \frac{\int f(x) \hat{p}(x) \frac{q(x)}{q(x)}dx}{Z}\\\\<br>&amp; = \frac{\int f(x) \hat{p}(x) \frac{q(x)}{q(x)} dx}{\int \hat{p}(x) dx}\\\\<br>&amp; = \frac{\int f(x) \hat{p}(x) \frac{q(x)}{q(x)} dx}{\int \hat{p}(x)\frac{q(x)}{q(x)} dx}\\\\<br>&amp; = \frac{\int f(x) q(x)\frac{\hat{p}(x)}{q(x)} dx}{\int q(x)\frac{\hat{p}(x)}{q(x)} dx}\\\\<br>&amp; = \frac{\int f(x) r(x)q(x) dx}{\int r(x)q(x) dx}\qquad\qquad 记r(x) = \frac{\hat{p}(x)}{q(x)}\\\\<br>\end{align*}<br>接下来用采样样本的求和近似积分求期望：<br>\begin{align*}<br>\mathbb{E}_p\left[f(x)\right] &amp; = \frac{\int f(x) r(x)q(x) dx}{\int r(x)q(x) dx}\qquad\qquad 记r(x) = \frac{\hat{p}(x)}{q(x)}\\\\<br>&amp; \approx \frac{\sum_i f(x^i) r^i }{\sum r^i}\qquad\qquad 其中 r^i = \frac{\hat{p}(x^i ) }{q(x^i ) }\\\\<br>&amp; = \sum_i f(x^i) r^i  \frac{r^i}{\sum_i r^i}\\\\<br>\end{align*}<br>通过计算<br>这就避免了计算$Z$，这种方法叫做normalized importance sampling。但是需要付出一定代价，unnormalized importance sampling是无偏的，而normalized importance是有偏的但是方差更小。</p>
<h2 id="Importance-sampling-in-RL"><a href="#Importance-sampling-in-RL" class="headerlink" title="Importance sampling in RL"></a>Importance sampling in RL</h2><p>我们可以使用importance sampling方法从old policy $\pi’$采样估计new policy $\pi$的值函数。计算一个action的returns的代价很高，但是如果新的action和老的action很接近，importance sampling可以帮助我们利用old calculation计算新的returns。举个例子，在MC方法中，无论何时更新$\theta$，都需要根据新的trajectories计算returns。</p>
<script type="math/tex; mode=display">\nabla_{\theta}J(\theta) = \frac{1}{N}\sum_{i=1}^T \left(\sum_{t=1}^T \nabla_{\theta} \log \pi_{\theta}(a_{i,t}|s_{i,t})\right)\left(\prod_{t=1}^T R(s_{i,t},a_{i,t})\right) \tag{6}</script><p>一个trajectory可以有几百个steps，单个的更新是非常低效的。有了importance sampling之后，我们可以基于old samples计算新的return。然而，如果两个policy差的太远，accuracy会降低。因此周期性的同步policy是非常必要的。<br>使用importance sampling，重写policy gradient的等式：</p>
<script type="math/tex; mode=display">\nabla_{\theta}J(\theta) = \mathbb{E}\_{\tau\sim\bar{\pi}(\tau)}\left[\sum_{t=1}^T \nabla_{\theta} \log \pi_{\theta}(a_t|s_t)\left(\prod_{t'=1}^T \frac{\pi_{\theta}(a_{t'}|s_{t'})}{\hat{\pi}\_{\theta}(a_{t'}|s_{t'})}\right)\left(\prod_{t'=t}^T R(s_{t'},a_{t'})\right)\right]\tag{7}</script><p>为了约束policy的变化，可以加入trust region约束条件，在这个region内，我们认为使用importance sampling得到的结果是可信的：</p>
<script type="math/tex; mode=display">\max_{\theta} \hat{\mathbb{E}}\_t\left[\frac{\pi_{\theta}(a_t|s_t)}{\pi_{\theta_{old}}(a_t|s_t}\hat{A}\_t\right]\tag{8}</script><script type="math/tex; mode=display">s.t. \hat{\mathbb{E}}\_t\left[\text{KL}\left[\pi_{\theta_{old}}(\cdot|s_t),\pi_{\theta}(\cdot|s_t)\right]\right]\tag{9}</script><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>1.<a href="https://medium.com/@jonathan\_hui/rl-importance-sampling-ebfb28b4a8c6" target="_blank" rel="noopener">https://medium.com/@jonathan\_hui/rl-importance-sampling-ebfb28b4a8c6</a><br>2.<a href="http://webee.technion.ac.il/people/shimkin/MC15/MC15lect4-ImportanceSampling.pdf" target="_blank" rel="noopener">http://webee.technion.ac.il/people/shimkin/MC15/MC15lect4-ImportanceSampling.pdf</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mxxhcm.github.io/2019/09/25/mm/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="马晓鑫爱马荟荟">
      <meta itemprop="description" content="记录硕士三年自己的积累">
      <meta itemprop="image" content="/images/favicon.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="mxxhcm's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/09/25/mm/" class="post-title-link" itemprop="http://mxxhcm.github.io/page/8/index.html">mm</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-09-25 10:06:34 / 修改时间：10:40:31" itemprop="dateCreated datePublished" datetime="2019-09-25T10:06:34+08:00">2019-09-25</time>
            

            
              

              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="MM"><a href="#MM" class="headerlink" title="MM"></a>MM</h2><p>MM是一类迭代优化方法，利用函数的凸性寻找极大值或者极小值。MM是Majoriza-Minimization或者Minorize-Maximization的缩写，取决于优化目标是maximization还是minimization。MM不是一个算法，它描述了如何如构建一个优化算法。<br><a href="https://mxxhcm.github.io/2019/01/21/expectatin_maximization/">EM算法</a>可以看成MM算法的一个例子。但是EM算法使用到了条件期望，而MM算法中凸性和不等式是重点。</p>
<h2 id="算法思路"><a href="#算法思路" class="headerlink" title="算法思路"></a>算法思路</h2><p>MM算法寻找objective function的一个替代品，然后优化新的目标函数直到一个极值点。<br>拿minorize-maximization算法举个例子，用$f(\theta)$表示需要被maximized的目标函数，它是一个concave函数。在第$m=0,1,\cdots$步中，构建新的目标函数$g(\theta|theta_m)$满足：</p>
<script type="math/tex; mode=display">g(\theta|\theta_m) \le f(\theta), \forall \theta \tag{1}</script><script type="math/tex; mode=display">g(\theta_m|\theta_m) = f(\theta_m) \tag{2}</script><p>式子$(1)表示$g(\theta|\theta_m)$是$f(\theta)$的下界，式子$(2)$表明$f(\theta)$和$g(\theta|\theta_m)$可以取到等号。<br>如下图所示：<br><img src="/2019/09/25/mm/mm.jpg" alt="mm"><br>接下来，通过最大化$g(\theta|\theta_m)$就可以最大化$f(\theta)$：</p>
<script type="math/tex; mode=display">\theta_{m+1} = \arg \max_{\theta} g(\theta|\theta_m) \tag{3}</script><p>当$m\rightarrow \infty$时，$f(\theta_m)$就会收敛到极小值点或者鞍点。我们能够得到以下的几个关系式：</p>
<script type="math/tex; mode=display">f(\theta_{m+1}) \ge g(\theta_{m+1}|\theta_m) \ge g(\theta_m|\theta_m)=f(\theta_m)</script><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>1.<a href="https://en.wikipedia.org/wiki/MM_algorithm" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/MM_algorithm</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/7/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/7/">7</a><span class="page-number current">8</span><a class="page-number" href="/page/9/">9</a><span class="space">&hellip;</span><a class="page-number" href="/page/28/">28</a><a class="extend next" rel="next" href="/page/9/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <div class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/favicon.jpg" alt="马晓鑫爱马荟荟">
            
              <p class="site-author-name" itemprop="name">马晓鑫爱马荟荟</p>
              <p class="site-description motion-element" itemprop="description">记录硕士三年自己的积累</p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">276</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  <a href="/categories/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">24</span>
                    <span class="site-state-item-name">分类</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  <a href="/tags/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">381</span>
                    <span class="site-state-item-name">标签</span>
                  </a>
                </div>
              
            </nav>
          

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://github.com/mxxhcm" title="GitHub &rarr; https://github.com/mxxhcm" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="mailto:mxxhcm@gmail.com" title="E-Mail &rarr; mailto:mxxhcm@gmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                </span>
              
            </div>
          

          

          
          

          
            
          
          

        </div>
      </div>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">马晓鑫爱马荟荟</span>

  

  
</div>


  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.8.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> v6.6.0</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  
    <script src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  


  


  <script src="/js/src/utils.js?v=6.6.0"></script>

  <script src="/js/src/motion.js?v=6.6.0"></script>



  
  


  <script src="/js/src/affix.js?v=6.6.0"></script>

  <script src="/js/src/schemes/pisces.js?v=6.6.0"></script>



  

  


  <script src="/js/src/bootstrap.js?v=6.6.0"></script>



  



  






<!-- LOCAL: You can save these files to your site and update links -->
    
        
        <link rel="stylesheet" href="https://aimingoo.github.io/gitmint/style/default.css">
        <script src="https://aimingoo.github.io/gitmint/dist/gitmint.browser.js"></script>
    
<!-- END LOCAL -->

    

    







  





  

  

  

  

  
  

  
  
    
      
        
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
  

  
    
      <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      },
      TeX: {equationNumbers: { autoNumber: "AMS" }}
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<script src="//cdn.jsdelivr.net/npm/mathjax@2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<style>
.MathJax_Display {
    overflow: auto hidden;
}
</style>

    
  


  
  

  

  

  

  

  

  

</body>
</html>
