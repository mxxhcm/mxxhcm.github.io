---
title: AI chapter 4 Beyond classical search
date: 2019-01-10 16:19:09
tags:
 - 人工智能
 - 搜索
 - 模拟退火
 - 遗传算法
categories: 机器学习
mathjax: true
---
第三章解决了一类可观察的，确定性，环境已知的问题，解决方案是动作序列。这一章我们考虑把假设条件放宽一些，首先从一类相当简单的问题：$4.1$和$4.2$节介绍在状态空间(state space)进行局部搜索的算法，对一个或多个当前状态(current states)进行评估和修改而不是从初始状态(initial state)按部就班(systematically)的探索路径。这些算法适合求解解的状态而不是找到这个解的搜索路径的问题。这类局部搜索算法有由统计物理学(statistical physics)方法，如模拟退火(simulated annealing)和进化生物学(evolutionary biology)，如遗传算法(genetic algorithms)。
在$4.3$和$4.4$节，分别讨论了放松确定性(determinism)和观察(observability)等假设。核心的观点是如果一个智能体不能精确的预测它将收到的感知(percept)，那么它需要考虑在它的感知可能表明(reveal)的各种偶然性(contigency)下做什么。如果是部分可观测的环境，智能体需要记录它可能处于的状态(states)。
在$4.5$节研究了在线搜索(online search)，智能体面对的是一个初始化成未知的状态空间，必须去探索。
## 局部搜索(Local search)
我们目前看到的搜索算法都是设计成系统(systematically)的探索状态空间。这个系统性(systematicity)通过在内存中保留一个或多个路径和每条路径上那个点是可以替换的。当一个目标(goal)被找到后，通往那个目标的路(path)构成了问题的一个解(solution)。然而，在许多问题中，通过目标的路径是不相关的。举例来说，$8$皇后问题中，重要的是皇后的最终放置位置，而不是它们的添加顺序。许多重要的应用，如集成电路设计(integrated-circuit design)，工厂地板布局(factory-floor layout)，车间调度(job-shop scheduling)，自动编程(automatic programming)，电信网络优化(telecommunication network optimization)，路线规划(vehicle routing)，投资管理(portfolio management)。
如果通往目标的路(path)是不重要的，我们可以考虑一类不同的算法，一种一点都不关心路径的算法。局部搜索算法只在单个的当前节点(current node)进行操作，一般情况下只移动到该节点的邻居。一般情况下，搜索的路径不保存下来。尽管局部搜索算法不是系统的，它们有两个关键优势：
1. 它们使用很少的内存，通常是常数的；
2. 它们经常能在非常大或者连续的空间中找到合理的的解，然而系统方法是不合适的。

除了寻找目标，局部搜索算法对于解决纯优化问题也是有用的，目标是根据目标函数找到最好的状态。许多优化问题不能用第三章的标准搜索模型解决。比如，大自然给了一个目标函数－生殖健康(reproductive fitness)，达尔文进化论可以看成尝试去优化这个目标函数，但是这个问题没有目标测试(goal test)和路径代价(path cost)。
为了理解局部搜索，考虑Figure 4.1的状态空间图(state-space landscape)，一个图有位置（通过状态定义），有海拔（通过代价函数或者目标函数的值定义）。如果海拔对应代价，目标是找到最低的山谷(valley)，即全局最小值(global minimum)；如果海拔对应的是目标函数，目标就是找到最高的顶峰(peak)，即全局最大值(global maximum)。局部搜索算法探索这个图，一个完整的局部搜索算法总是能找到一个目标如果存在的话；一个最优化算法总是能找到一个全局最大值/最小值。
### 爬山搜索(Hill-climbing search)
Figure 4.2展示了爬山(hill-climbing)搜索算法。它仅仅是一个循环不断地超值增加的方向移动，即爬山(uphill)。当它达到一个顶峰(peak)，周围没有比它高的值时，就停止。算法没有保留一个搜索树(search tree)，所以，当前节点的数据结构只需要状态和目标函数的值。爬山法并不查看当前节点邻居之外的节点，就像一个有健忘症的人想要在大雾中找到珠穆朗玛峰的最高点。
这里用八皇后问题来解释爬上法。局部搜索算法通常用一个完全态的形式(complete-state formulation)，每一个状态都有八皇后在棋盘上，一个在一列。每一个可能的后继(successor)状态是通过把在某一列中的一个皇后移动到同一列中的其他方块上，每个状态总共有$8\times 7=56$个后继状态。代价函数$h$是直接，间接攻击彼此的成对皇后的数量。这个代价函数的全局最小值是$0$，只有出现完美解的时候会得到这个值。Fgiure 4.3(a)展现了$h=17$的一个状态，图中也展示它的所有可能后继状态的$h$值，最好的后继状态有$h=12$。如果有不止一个最好的状态的话爬山法通常会从中选一个。
爬山法有时候也叫局部贪婪搜索(greedy local search)因为它只关心一个好的相邻状态而不关心再接下来会怎么样。尽管贪婪被认为是七宗罪中的一个，但是贪婪算法一般都表现的相当好。爬山法会取得很快的进步因为很容易就会对一个不好的状态进行改善。比如，对于Figure 4.3(a)中的状态，只需要五步就能到达Figure 4.3(b)中的状态，其中$h=1$，几乎是一个最优解了。不幸的是，由于下面的几个原因，爬山法通常会陷入僵局：
- 局部最优：局部最优不是全局最优。比如，Figure 4.3(b)就是一个局部最优，因为任何皇后的移动都会产生更差的状态。
- Ridges：如Figure 4.4所示，ridges可能会产生贪心算法很难去优化的局部最大值。
- 平台(plateaux)：一个平台是状态空间图中的一个平坦的区域。他可能是一个平坦的局部最大，往两边都不能继续优化了，或者是一个肩部(shoulder)，某一边可以继续优化。一个爬山搜索可能在平台停下了。 

在每种情况下，算法都会到达一个无法继续优化的点。从一个随机产生的八皇后状态，最陡峭的爬山法在$86\%$的时间会无法继续优化，陷入困境，只有$14\%$的时间能解决问题。它解得非常快，平均情况下，需要$4$步成功解决问题，需要$3$步会失败，对于一个有$8^8$个状态的状态空间来说已经很不错了。
Figure 14.2中的算法到达一个平台后，如果最好的后继状态和当前状态的值是一样的，那么算法就停止了。可能一直保持目标函数的增大不是好的选择，或者可以允许当值不变的时候往一边移动，说不定这个平台是一个肩部呢，往一个方向走就会到达可以继续优化的地方。答案当然是可以的，但是需要注意的是，如果允许了往一个方向移动，但是没有办法继续优化了，当这个平台是一个局部最大而不是一个肩部的时候，就会陷入无限循环。一个通常的解法是限制往一个方向移动的次数。比如，八皇后问题中，允许$100$个连续的一边移动，这让爬山法解决问题的百分比从$14\%$增加到了$94\%$。成功总是需要付出一些代价的，算法平均需要$21$步成功解决问题，平均需要$64$步证明解不了。
许多爬山法的变量算法也被发明了。随机爬山法从上山的移动中随机选择，选择的概率随着上山的陡峭程度而变化。这通常比最陡的上升法收敛要慢，但是在一些情况下，它能找到更好的解。第一选择爬山法(first-choice hill climbing)通过随机生成后继状态直到有一个更好的状态生成实现了随机爬山法。当一个状态有很多个后继状态的时候这是一个好的策略。
目前介绍的爬山法还是不完整的，它们通常会找不到一个存在的目标因为可能陷入局部最大。随机重启爬山法(random-restart hill climbign)采纳了一个有名的谚语(adage)，“如果第一次没成功，试一次，再试一次”。这个算法从随机生成的初始状态中产生一系列爬山搜索，直到找到一个目标。它成功的概率很容易接近$1$，因为最终它会产生一个目标状态作为初始状态。如果每一个爬山搜索的成功概率是$p$，那么期望重启的数量是$1/p$。对于不支持单侧移动的解决八皇后问题的算法来说，$p\approx 0.14$，所以大概需要七次迭代找到一个目标（$6$个成功的，$1$个失败的）。期望的步数是一次成功迭代的代价，加上$(1-p)/p$次失败的代价，总的来说大概是$1\times 4 + 6\times 3 = 22$步。当允许往一次移动的时候，需要$1/0.94 \approx 1.06$次迭代，平均需要$1\times 21 + 0.06/0.94 \times 64 \approx 25$步。对于八皇后问题来说，随机重启的爬山法实际上是很高效的。即使有$300$万皇后，算法也能在一分钟之内找到解。
爬山法的成功非常依靠状态空间图的形状，如果有很多的局部最大和平台，随机重启爬山法会很快找到一个解。另一方面，许多现实问题的状态图就像广泛分布在光滑地板上的豪猪，每一个豪猪针上有微型豪猪，无穷无尽。NP难问题通常有指数个局部最大，尽管如此，经过很少次数的重启就能找到一个合理的局部最大值。

### 模拟退火(Simulated annealing)
一个从不“下山”向更低值的状态移动爬山算法保证是不完整的，因为可能会停在局部最大的地方。相反，一个完全随机的移动，从后继状态集合中均匀的随机选择一个是完整的，但是是非常低效的。因此，将爬山法和一个随机移动结合起来看起来是高效的，在某种程度上可能会同时提高效率(efficiency)和完整性(completeness)。模拟退火(simulate annealing)就是这样一个算法。在冶金(metallurgy)上，退火(annealing)是先把金属和玻璃加热，然后逐渐冷却下来得到结晶状态(crystalline state)的回火或硬化金属的过程。
为了解释模拟退火，把我们的视角从爬山法切换到梯度下降法(gradient descent)即最小化cost，想象一个让乒乓球掉落到凹凸不平的表面(bumpy surface)上最深的缝隙(deepest crevice)里的任务。如果让球滚动(roll)，它会到达一个局部最小点。如果晃动这个表面，可以让球跳出这个局部最小。模拟退火方案就是开始通过使劲摇晃（即高温），然后逐渐减小晃动的力度（降低温度）。
Figure 4.5中算法的内部循环和爬山法非常像。但是模拟退火每次不是选择最好的移动，而是选择随机的移动。如果移动改进了当前的状况，这个移动就被接受。除此以外，算法以小于$1$概率接受一些移动，这个概率随着移动的"badness"$\delta E$指数下降，这个概率随着温度$T$的下降也会下降：坏的移动可能在刚开始$T$很高的时候被允许，随着$T$的下降越来越不太可能。如果$T$下降的足够慢，算法以接近于$1$的概率找到一个全局最优解。
模拟退火最开始在$1980$年被提出来广泛用于解决VLSI布局问题。它已经被广泛应用于工厂调度和其他大规模的最优化问题。
### 局部波束搜索(Local beam search)
在内存中只保留一个节点是对内存限制的一个极端回应。局部波束搜索(local beam search)算法保存$k$个状态而不是一个。它从$k$个随机生成的状态开始，每一步，所有$k$个状态的后级状态都被生成。如果有一个就是目标，停止算法，否则重复选择$k$个后继状态。
首先，$k$个局部波束搜索可能除了并行运行$k$个随机重启而不是顺序的重启之外没有什么其他改变了。事实上，两个算法是相当不同的，在随机重启搜索中，每一个搜索过程都独立于其他的。但是在局部波束搜索中，有用的信息在并行线程中传递。生成最好的后继状态的状态会对其他状态受，“过来把，这边的草更绿！”算法很快的抛弃那些没有用的搜索，更多的资源被用到了该用的地方。
最简单的形式中，局部波束搜索可能经历$k$个状态缺乏多样性，它们可能很快的集中在状态空间的一小部分区域，让搜索代价仅仅比代价高昂的爬山法少一点点。一个变种叫做随机波束搜索(stochastic beam search)，类似于随机爬山法，可以缓解这个问题。不是从候选状态池中选$k$个最好的状态，而是从中随机选择$k$个后继状态，可能选择一个后继状态使得代价增加。随机波束搜索有点像自然选择，一个状态的后继节点根据它的价值填充下一代。
### 遗传算法(Genetic algorithms)
遗传算法是一随机波束搜索的一个变量，后继状态节点通过组合两个亲本的状态而不仅仅是修改一个单个的状态。遗传算法和自然选择的相似与随机波束搜索和自然选择的相似是一样的，除了这个是有性生殖而不是无性生殖。
和波束搜索一样，遗传算法从$k$个生成的状态开始，叫做种群(population)，每一个状态，或者一个个体(individual)，被一个有限字母表上的字符串表示，最常用的用$0,1$字符串。比如，八皇后问题必须指定八皇后的位置，每一个皇后处在一个有八个方块的列上。所以总共需要$2\times log_28 = 24$位。每个状态也可以用八个数字表示，每个数字在$1-8$之间取值。Figure 4.6(a)展示了一个用$4$个$8$数字字符串表示的八皇后状态。
这些状态产生下一代的过程如Figure 4.6(b)-(e)。在(b)中，每一个状态按照目标函数或者拟合函数被评定。一个拟合函数应该返回更好状态的更高值，因此，在八皇后问题中，我们使用不受攻击的皇后对的数量，一个解应该是$28$个。(b)中的四个状态分别是$24,23,20,11$，在遗传算法的这个特定变种中，被选中再现的概率和拟合分数成正比，对应的百分比紧挨着原始分数。
(c)中，随机选择两对亲本用来再现，和(b)中的概率一样。注意到其中一个个体被选了两次，另一个一次也没有被选中。为每队配对，一个交叉点(crossover point)，从字符串中任意选取。在Figure 4.6中，第一对的交叉点在第三个，第二对的交叉点在第五个。
在(d)中，通过在交叉点对亲本的字符串进行交叉产生子代。举个例子，第一对亲本的而第一个
## 连续状态空间的局部搜索(Local search in continuous spaces)
## 非确定性行为搜索(Search with nondeterministic actions)
### 不稳定的真空世界(The erratic vacuum world)
### 与或搜索树(AND-OR search trees)
### 试，再试一次 (Try,try again)
## 部分观测搜索(Search with partial observation)
### 无观察搜索(Searching with no observation)
### 有观察搜索(Searching with observations)
### 解决部分观察问题(Solving partially observable problems)
### 部分观察环境中的智能体(An agent for partially observable environments)
## 在线搜索智能体和不确定环境(Online search agents and unknown environments)
### 在线搜索问题(Online search problems)
### 在线搜索智能体(Online search agents)
### 在线局部搜索(Online local search)
### 在线搜索学习(Learning in online search)

