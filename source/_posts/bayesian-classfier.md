---
title: bayesian classfier
date: 2019-10-21 20:55:39
tags:
 - 机器学习
 - 贝叶斯分类器
 - 朴素贝叶斯
categories: 机器学习
mathjax: true
---
## 关键字
贝叶斯分类器，贝叶斯定理，朴素贝叶斯，贝叶斯错误率

## 贝叶斯分类器
贝叶斯分类器是一类分类算法的总称，这类算法均以贝叶斯定理为基础，故统称为贝叶斯分类器。常见的贝叶斯分类器有朴素贝叶斯和贝叶斯信念网络。

## 贝叶斯定理
假设X,Y是一对随机变量，它们的联合概率$P(X=x, Y=y)$是指$X$取值$x$且$Y$取值为$y$的概率，条件概率是指一个随机变量在另一个随机变量取值已知的情况下取某一个特定值的概率。比如$P(Y=y|X=y)$是指在变量$X取值$x$的情况下，变量$Y$取值$y$的概率。$X$和$Y$的联合概率和条件概率满足如下关系：
$$P(X,Y) = P(Y|X)\cdot P(X) = P(X|Y)\cdot P(Y)$$
由上面的公式可以得到下面公式，称为贝叶斯定理：
$$P(Y|X) = \frac{P(X|Y)P(Y)}{P(X)}$$


## 朴素贝叶斯分类器
朴素贝叶斯有一个假设：条件独立假设，拿公式举个例子就是
$$P(X|Y=y_k)=\prod\_{i=1}^m P(x_i|Y=y_k)$$
其中$X=[x_1, x_2,\cdots, x_m]$即$m$个属性。
贝叶斯分类器的流程如下所示：
1. 给出训练样本集，属性集合$X=[x_1, x_2,\cdots, x_m]$，标签集合$Y=[y_1, y_2,\cdots, y_n]$，计算每个类别$y_j$中出现属性$x_i$的条件概率，即
$$P(x_i|y_j), 1 \le i \le m, 1 \le j \le n$$
2. 给出一个新的样本$X$，根据贝叶斯定理以及条件独立假设，计算：
$$P(y_k|X) = \frac{P(X|y_k)P(y_k)}{P(X)} = \frac{\prod\_{i=1}^m P(x_i|y_k) P(y_k)}{P(X)}$$
3. 从$P(y_k|X)$中选出最大的$P$对应的$y_k$当做label。

可以看出，朴素贝叶斯分类器的关键就是计算条件概率：
- 当属性$X$是离散值时，可以统计样本中各个$P(x_i|y_j)$的频率近似计算概率
- 当属性$X$是连续值时，可以假设变量服从某种分布，使用训练数据估计分布的参数。 如高斯分布的均值和方差。

## 贝叶斯错误率

## 贝叶斯决策边界
贝叶斯分类器产生最低的错误率，叫做贝叶斯错误率。因为贝叶斯分类器总是选择使式子$(1)$最大化的类，在$X=x_0$处的错误率是$1-\max_j Pr(Y=j|X=x_0)$。
整个贝叶斯分类器的错误率是：
$$1-\mathbb{E}\left(\max_j Pr(Y=j|X=x_0)\right)$$
其中期望表示计算所有$X$的可能取值上的平均错误率。



## 参考文献
1.https://www.cnblogs.com/phoenixzq/p/3539619.html
2.http://funhacks.net/2015/05/18/Bayesian-classifier/
