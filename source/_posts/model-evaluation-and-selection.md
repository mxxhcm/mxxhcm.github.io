---
title: model evaluation and selection
date: 2019-10-22 15:53:48
tags:
 - 机器学习
 - bootstrapping
 - hold-out
 - cross-validation
categories: 机器学习
---

## 经验误差和过拟合
错误率：分类错误的样本数占总样本数的百分比。
精度：1-错误率
误差：样本的真实输出和实际预测输出之间的差异称为误差(error)。
训练误差(training error)：在training set上的误差称为training error。
泛化误差（generalizatoin error)：在新样本上的误差称为泛化误差。
过拟合：把训练样本的特点当成了所有潜在样本的特点。
欠拟合：没有充分学习样本的通用属性。

模型选择是从不同的学习算法，不同的参数中，选择一个合适的模型。

## Model evaluation
通过对模型的泛化误差进行评估，选择处一个好的模型。通过使用testing set测试算法对于新样本的判别能力，以测试集上的testing error当做泛化误差的近似。

### 留出法(hold-out)
将数据集分为两个互斥的集合，一个用作训练集，一个用作测试集。通常使用$\frac{2}{3}$到$\frac{4}{5}$的样本用于训练，其余样本用于测试。

### 交叉验证法(cross validation)
将数据集划分为$k$个相同的子互斥子集。每次用$k-1$个子集进行训练，剩下的$1$个子集用于测试。进行$k$次训练和测试，返回这$k$个测试结果的均值。一般情况下最常用的$k$是$10$，称为$10$折交叉验证。

#### 留一法(leave-one-out)
假设$m$是数据集样本的个数，令$k=m$，那么就是交叉验证的一个特例，留一法。它不容易受随机样本划分方式的影响，不论哪种方式，最后都只有一种划分。这种方法获得模型和数据集比较吻合，但是数据集太大时，不可取。

### 自助法(bootstrapping)
在留出法和交叉验证的中，训练模型使用的数据要比训练集小。
自助法解决了这个问题，他通过自助采样(bootstrap sampling)进行。给定$m$个样本的数据集$D$，对他进行采样得到数据集$D'$:每次随机从$D$中挑选一个样本，将其拷贝到$D'$，重复$m$次，得到了大小为$m$的$D'$，但是$D$中的元素可能在$D'$中重复出现，也可能不出现。
通过计算，大约有$36.8\\%$的样本没有出现在$D'$中。用$D'$训练，$D-D'$做测试。
自助法适用于数据集小，难以划分训练集和测试集时很有用。能够产生多个不同的数据集，对集成学习等很有用。
#### 估计标准差
自助法可以用来衡量一个指定的估计量或者统计学习方法中的不稳定因素。比如计算标准差。
自助法估计标准差流程：
用原始数据集重复$B$次产生$B$个数据集，计算出$B$个相应的$\alpha$估计。然后使用自助法据估计标准误差公式：
$$\text{SE}\_{B}(\hat{\alpha}) = \sqrt{\frac{1}{B-1}\sum\_{r=1}^B(\hat{\alpha} - \frac{1}{B}\sum\_{r=1}^B \hat{\alpha})^2 }$$

### 调参
实际中遇到的数据称为**测试数据**。
模型评估和选择中用到的评估数据集称为**验证集**。


## 性能度量

### 错误率和精度
错误率：分类正确的样本占样本总数的百分比。
精度：1-错误率。

### 查准率和查全率
真正例(TP)：真的预测成真的
假正例(FP)：假的预测成真的
真反例(TN)：假的预测成假的
假反例(FN)：真的预测成假的
混淆矩阵：
|真实情况|预测结果||
|:-:|:-:|:-:|
||正例|反例|
|正例|TP|FN|
|反例|FP|TN|

查准率(precision)：所有预测为正例的样本中真是正例的比例。
$$P = \frac{TP}{TP+FP}$$
查全率(recall)：所有预测为正例的样本中真正例占真正例和假负例的和的比例。
$$R = \frac{TP}{TP+FN}$$
查准率和查全率是矛盾的。
混淆矩阵

### ROC和AUC
TPR（真正例率），sensitive
$$\frac{TP}{TP+FN}$$
FPR（假正例率），type-1 error，反例中有多少被预测为正例
$$\frac{FP}{TN+FP}$$
TNR（真反例率），specify
$$\frac{TN}{TN+FP}$$
FNR（假反例率），type-2 error
$$\frac{FN}{FN+TP}$$


## 参考文献
1.西瓜书

