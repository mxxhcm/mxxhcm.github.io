<!DOCTYPE html>












  


<html class="theme-next pisces use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
































<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=6.6.0" rel="stylesheet" type="text/css">



  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.jpg?v=6.6.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.jpg?v=6.6.0">










<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '6.6.0',
    sidebar: {"position":"left","display":"always","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="记录硕士三年自己的积累">
<meta property="og:type" content="website">
<meta property="og:title" content="mxxhcm&#39;s blog">
<meta property="og:url" content="http://mxxhcm.github.io/index.html">
<meta property="og:site_name" content="mxxhcm&#39;s blog">
<meta property="og:description" content="记录硕士三年自己的积累">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="mxxhcm&#39;s blog">
<meta name="twitter:description" content="记录硕士三年自己的积累">



  <link rel="alternate" href="/atom.xml" title="mxxhcm's blog" type="application/atom+xml">




  <link rel="canonical" href="http://mxxhcm.github.io/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>mxxhcm's blog</title>
  












  <noscript>
  <style>
    .use-motion .motion-element,
    .use-motion .brand,
    .use-motion .menu-item,
    .sidebar-inner,
    .use-motion .post-block,
    .use-motion .pagination,
    .use-motion .comments,
    .use-motion .post-header,
    .use-motion .post-body,
    .use-motion .collection-title { opacity: initial; }

    .use-motion .logo,
    .use-motion .site-title,
    .use-motion .site-subtitle {
      opacity: initial;
      top: initial;
    }

    .use-motion .logo-line-before i { left: initial; }
    .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">mxxhcm's blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home menu-item-active">

    
    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>

      
      
    </ul>
  

  

  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mxxhcm.github.io/2019/05/29/reinforcement-learning-不同分类方法/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="马晓鑫爱马荟荟">
      <meta itemprop="description" content="记录硕士三年自己的积累">
      <meta itemprop="image" content="/images/favicon.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="mxxhcm's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/05/29/reinforcement-learning-不同分类方法/" class="post-title-link" itemprop="http://mxxhcm.github.io/index.html">reinforcment learning的不同分类方法</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-05-29 17:59:28 / 修改时间：18:04:19" itemprop="dateCreated datePublished" datetime="2019-05-29T17:59:28+08:00">2019-05-29</time>
            

            
              

              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/强化学习/" itemprop="url" rel="index"><span itemprop="name">强化学习</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="online-vs-offline"><a href="#online-vs-offline" class="headerlink" title="online vs offline"></a>online vs offline</h2><p>online方法中训练数据一直在不断增加，基本上强化学习都是online的，而监督学习是offline的。</p>
<h2 id="on-policy-vs-off-policy"><a href="#on-policy-vs-off-policy" class="headerlink" title="on-policy vs off-policy"></a>on-policy vs off-policy</h2><p>behaviour policy是采样的policy。<br>target policy是要evaluation的policy。<br>behaviour policy和target policy是不是相同的，相同的就是on-policy，不同的就是off-policy，带有replay buffer的都是off-policy的方法。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>1.<a href="https://stats.stackexchange.com/questions/897/online-vs-offline-learning" target="_blank" rel="noopener">https://stats.stackexchange.com/questions/897/online-vs-offline-learning</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mxxhcm.github.io/2019/05/29/skills/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="马晓鑫爱马荟荟">
      <meta itemprop="description" content="记录硕士三年自己的积累">
      <meta itemprop="image" content="/images/favicon.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="mxxhcm's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/05/29/skills/" class="post-title-link" itemprop="http://mxxhcm.github.io/index.html">skills</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-05-29 12:24:41 / 修改时间：14:04:05" itemprop="dateCreated datePublished" datetime="2019-05-29T12:24:41+08:00">2019-05-29</time>
            

            
              

              
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="累加"><a href="#累加" class="headerlink" title="累加"></a>累加</h2><h3 id="简单介绍"><a href="#简单介绍" class="headerlink" title="简单介绍"></a>简单介绍</h3><p>今天在看Reinforcment Learning: an Introduction第五章的时候，写了figure_5_4的代码，然后跟github上作者写出来的效率查了太多。<br>最后对比了一下代码，发现了原因，是因为做了太多重复运算。</p>
<h3 id="代码示例"><a href="#代码示例" class="headerlink" title="代码示例"></a>代码示例</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="comment"># 目的，计算不断更新的两个列表的乘积的和</span></span><br><span class="line">numbers = <span class="number">100000</span></span><br><span class="line">a = []</span><br><span class="line">b = []</span><br><span class="line">c1 = []</span><br><span class="line"></span><br><span class="line">begin_time = time.time() </span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(numbers):</span><br><span class="line">    a.append(i<span class="number">-1</span>)</span><br><span class="line">    b.append(i+<span class="number">1</span>)</span><br><span class="line">    c1.append(np.sum(np.multiply(a, b)))</span><br><span class="line"><span class="comment"># print(c1)</span></span><br><span class="line">end_time = time.time()</span><br><span class="line">print(<span class="string">"Total time: "</span>, end_time - begin_time)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 我用的是上面的代码，然后，，，，太多重复运算，效率惨不忍睹</span></span><br><span class="line"></span><br><span class="line">a = []</span><br><span class="line">b = []</span><br><span class="line">c2 = []</span><br><span class="line"></span><br><span class="line">begin_time = time.time() </span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(numbers):</span><br><span class="line">    a.append(i<span class="number">-1</span>)</span><br><span class="line">    b.append(i+<span class="number">1</span>)</span><br><span class="line">    c2.append(a[i]*b[i])</span><br><span class="line">results = np.add.accumulate(c2)</span><br><span class="line"><span class="comment"># print(results)</span></span><br><span class="line">end_time = time.time()</span><br><span class="line">print(<span class="string">"Total time: "</span>, end_time - begin_time)</span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">在100000的量级上，差了几万倍出来。。。</span></span><br><span class="line"><span class="string">Total time:  450.6051049232483</span></span><br><span class="line"><span class="string">Total time:  0.03314399719238281</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>1.</p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mxxhcm.github.io/2019/05/22/linux-ubuntu-18-04-自定义操作/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="马晓鑫爱马荟荟">
      <meta itemprop="description" content="记录硕士三年自己的积累">
      <meta itemprop="image" content="/images/favicon.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="mxxhcm's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/05/22/linux-ubuntu-18-04-自定义操作/" class="post-title-link" itemprop="http://mxxhcm.github.io/index.html">linux-ubuntu 18.04 自定义操作</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-05-22 21:22:29" itemprop="dateCreated datePublished" datetime="2019-05-22T21:22:29+08:00">2019-05-22</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-05-24 09:08:04" itemprop="dateModified" datetime="2019-05-24T09:08:04+08:00">2019-05-24</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/linux/" itemprop="url" rel="index"><span itemprop="name">linux</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="dock-配置"><a href="#dock-配置" class="headerlink" title="dock 配置"></a>dock 配置</h2><h3 id="基本设置"><a href="#基本设置" class="headerlink" title="基本设置"></a>基本设置</h3><p>打开Settings &gt;&gt; Dock，可以设置dock的位置和大小，以及自动隐藏。这些是ubuntu安装的默认配置。</p>
<h3 id="dconf安装"><a href="#dconf安装" class="headerlink" title="dconf安装"></a>dconf安装</h3><p>为了更多的设置，需要安装dconf-editor<br>~\$:sudo apt install dconf-tools<br>按下Win键，搜索dconfig-editor，打开它。<br>找到org&gt;&gt;gnome&gt;&gt;shell&gt;&gt;extensions&gt;&gt;dash-to-dock，然后就可以修改相应的配置了。也可以在命令行中进行相应的设置，这里就不说了，可以查看参考文献尝试。</p>
<h2 id="ubuntu-18-04合上笔记本盖子后不挂起"><a href="#ubuntu-18-04合上笔记本盖子后不挂起" class="headerlink" title="ubuntu 18.04合上笔记本盖子后不挂起"></a>ubuntu 18.04合上笔记本盖子后不挂起</h2><p>~\$:sudo apt install gnome-tweak-tool<br>~\$:gnome-tweaks<br>找到Power选项，设置Suspend when lapto lid is closed为OFF。[6]</p>
<h2 id="显示cpu和gpu温度"><a href="#显示cpu和gpu温度" class="headerlink" title="显示cpu和gpu温度"></a>显示cpu和gpu温度</h2><h3 id="安装lm-sensors"><a href="#安装lm-sensors" class="headerlink" title="安装lm-sensors"></a>安装lm-sensors</h3><p>~\$:sudo apt-get install lm-sensors<br>然后执行以下命令进行配置：<br>~\$:sudo sensors-detect<br>执行sensors命令获得各项硬件的温度<br>~\$:sensors</p>
<h2 id="安装gnome-shell"><a href="#安装gnome-shell" class="headerlink" title="安装gnome-shell"></a>安装gnome-shell</h2><h3 id="安装gnome-tweak-tool"><a href="#安装gnome-tweak-tool" class="headerlink" title="安装gnome tweak tool"></a>安装gnome tweak tool</h3><p>~\$:sudo apt install gnome-tweak-tool<br>gnome tweak 用来查看本地的gnome 插件。</p>
<h3 id="从ubuntu-仓库安装extensions"><a href="#从ubuntu-仓库安装extensions" class="headerlink" title="从ubuntu 仓库安装extensions"></a>从ubuntu 仓库安装extensions</h3><p>ubuntu 提供了gnome-shell-extensions包，该包中有部分gnome扩展。然后可以使用gnome tweaks查看已经安装的程序。<br>~\$:sudo apt install gnome-shell-extensions</p>
<h3 id="在浏览器上安装gnome-shell-integration插件"><a href="#在浏览器上安装gnome-shell-integration插件" class="headerlink" title="在浏览器上安装gnome shell integration插件"></a>在浏览器上安装gnome shell integration插件</h3><p>在firfox或者chrome上安装相应的gnome shell integration插件。<br>这个时候是不能添加插件的，因为还缺少一个东西，叫做native host connector<br>这种方法和从ubuntu仓库中装extension的不同之处是，ubuntu包中的扩展是固定的一部分，这中方法可以自定义安装。<br>安装完之后可以直接在浏览器的gnome shell integration插件上查看在浏览器上安装的gnome shell扩展，也可以使用gnome tweaks查看浏览器上安装的shell extensions。</p>
<h3 id="安装chrome-gnome-shell-native-host-connector"><a href="#安装chrome-gnome-shell-native-host-connector" class="headerlink" title="安装chrome-gnome-shell native host connector"></a>安装chrome-gnome-shell native host connector</h3><p>执行以下命令进行安装，chrome-gnome-shell并不是代表chrome浏览器的意思，用任何浏览器都要执行以下命令<br>~\$:sudo apt install chrome-gnome-shell<br>查看gnome shell版本<br>~\$:gnome-shell —version</p>
<h3 id="安装相应的插件"><a href="#安装相应的插件" class="headerlink" title="安装相应的插件"></a>安装相应的插件</h3><h4 id="命令行下"><a href="#命令行下" class="headerlink" title="命令行下"></a>命令行下</h4><p>搜索<br>~\$:sudo apt search gnome-shell-extension<br>安装<br>~\$:sudo apt install gnome-shell-extension-package-name</p>
<h4 id="浏览器中"><a href="#浏览器中" class="headerlink" title="浏览器中"></a>浏览器中</h4><p>直接打开gnome shell extensions图形化界面进行搜索安装</p>
<h3 id="插件推荐"><a href="#插件推荐" class="headerlink" title="插件推荐"></a>插件推荐</h3><ul>
<li>Coverflow Alt-Tab 按alt tab切换程序效果[7]</li>
</ul>
<h2 id="修改主题"><a href="#修改主题" class="headerlink" title="修改主题"></a>修改主题</h2><p>下载系统主题文件，解压缩，放置在/usr/share/themes文件夹下。然后在tweaks中的Apperance选项修改。<br>下载鼠标和图标主题，放置在/usr/share/icons文件夹下。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>1.<a href="https://linuxconfig.org/how-to-customize-dock-panel-on-ubuntu-18-04-bionic-beaver-linux" target="_blank" rel="noopener">https://linuxconfig.org/how-to-customize-dock-panel-on-ubuntu-18-04-bionic-beaver-linux</a><br>2.<a href="https://zhuanlan.zhihu.com/p/37852274" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/37852274</a><br>3.<a href="https://askubuntu.com/questions/15832/how-do-i-get-the-cpu-temperature" target="_blank" rel="noopener">https://askubuntu.com/questions/15832/how-do-i-get-the-cpu-temperature</a><br>4.<a href="https://linuxhint.com/install_gnome3_extensions_ubuntu_1804/" target="_blank" rel="noopener">https://linuxhint.com/install_gnome3_extensions_ubuntu_1804/</a><br>5.<a href="https://linux.cn/article-9447-1.html" target="_blank" rel="noopener">https://linux.cn/article-9447-1.html</a><br>6.<a href="https://askubuntu.com/a/1062401" target="_blank" rel="noopener">https://askubuntu.com/a/1062401</a><br>7.<a href="https://zhuanlan.zhihu.com/p/37852274" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/37852274</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mxxhcm.github.io/2019/05/21/DNC/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="马晓鑫爱马荟荟">
      <meta itemprop="description" content="记录硕士三年自己的积累">
      <meta itemprop="image" content="/images/favicon.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="mxxhcm's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/05/21/DNC/" class="post-title-link" itemprop="http://mxxhcm.github.io/index.html">DNC</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-05-21 09:07:41" itemprop="dateCreated datePublished" datetime="2019-05-21T09:07:41+08:00">2019-05-21</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-05-22 14:17:46" itemprop="dateModified" datetime="2019-05-22T14:17:46+08:00">2019-05-22</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>现代计算机将memory和computation分开，使用处理器进行计算，处理器使用可访问的memory存取数。这样子的好处是可以使用extensible storage写入新信息，可以将memory中的内容当做variables。Variables对于算法的通用性很有用，对于不同的数据，不需要更改算法操作的地址，只需要更改变量的取值即可。而neural network的computation和memory是通过network的weights和neuron activity耦合在一起的。如果memory需要增加的话，networks不能动态增加新的storage，也不能独立的学习network的参数。</p>
<p>这篇文章中作者提出了differentiable neural computer(DNC)—带可读写external memory的network，解决network不能表示variable和数据结构的问题。整个system是可导的，可以把DNC的memory看做RAM，把network看做CPU。<br>DNC有一个$N\times W$大小的memory matrix $M$，使用可导的attention mechanism，确定在这个memory上的distributions，也就是我们说的weighting（加权）,代表相应的操作在该位置上的权重。DNC提供了三种操作，查询，读和写，对应了三种不同的attention，使用三个head（头）,read head（读头），write head（写头）,lookup head（查找）实现对memory的相应操作。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>1.<a href="https://www.gwern.net/docs/rl/2016-graves.pdf" target="_blank" rel="noopener">https://www.gwern.net/docs/rl/2016-graves.pdf</a><br>2.<a href="http://people.idsia.ch/~rupesh/rnnsymposium2016/slides/graves.pdf" target="_blank" rel="noopener">http://people.idsia.ch/~rupesh/rnnsymposium2016/slides/graves.pdf</a><br>3.<a href="https://deepmind.com/blog/differentiable-neural-computers/" target="_blank" rel="noopener">https://deepmind.com/blog/differentiable-neural-computers/</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mxxhcm.github.io/2019/05/19/tensorflow-tf-nn-conv2d-vs-tf-layers-conv2d/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="马晓鑫爱马荟荟">
      <meta itemprop="description" content="记录硕士三年自己的积累">
      <meta itemprop="image" content="/images/favicon.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="mxxhcm's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/05/19/tensorflow-tf-nn-conv2d-vs-tf-layers-conv2d/" class="post-title-link" itemprop="http://mxxhcm.github.io/index.html">tensorflow tf.nn.conv2d vs tf.layers.conv2d</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-05-19 01:18:00 / 修改时间：01:22:03" itemprop="dateCreated datePublished" datetime="2019-05-19T01:18:00+08:00">2019-05-19</time>
            

            
              

              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/tensorflow/" itemprop="url" rel="index"><span itemprop="name">tensorflow</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>All of these other replies talk about how the parameters are different, but actually, the main difference of tf.nn and tf.layers conv2d is that for tf.nn, you need to create your own filter tensor and pass it in. This filter needs to have the size of: [kernel_height, kernel_width, in_channels, num_filters]</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>1.<a href="https://stackoverflow.com/questions/42785026/tf-nn-conv2d-vs-tf-layers-conv2d" target="_blank" rel="noopener">https://stackoverflow.com/questions/42785026/tf-nn-conv2d-vs-tf-layers-conv2d</a><br>2.<a href="https://stackoverflow.com/a/53683545" target="_blank" rel="noopener">https://stackoverflow.com/a/53683545</a><br>3.<a href="https://stackoverflow.com/a/45308609" target="_blank" rel="noopener">https://stackoverflow.com/a/45308609</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mxxhcm.github.io/2019/05/18/tensorflow-contrib-layers-nn/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="马晓鑫爱马荟荟">
      <meta itemprop="description" content="记录硕士三年自己的积累">
      <meta itemprop="image" content="/images/favicon.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="mxxhcm's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/05/18/tensorflow-contrib-layers-nn/" class="post-title-link" itemprop="http://mxxhcm.github.io/index.html">tensorflow contrib layers nn</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-05-18 15:58:59" itemprop="dateCreated datePublished" datetime="2019-05-18T15:58:59+08:00">2019-05-18</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-05-19 11:59:59" itemprop="dateModified" datetime="2019-05-19T11:59:59+08:00">2019-05-19</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/tensorflow/" itemprop="url" rel="index"><span itemprop="name">tensorflow</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="tf-contrib"><a href="#tf-contrib" class="headerlink" title="tf.contrib"></a>tf.contrib</h2><p>根据tensorflow官网的说法，tf.contrib模块中包含了易修改的测试代码，</p>
<blockquote>
<p>contrib module containing volatile or experimental code.</p>
</blockquote>
<p>当其中的某一个模块完成的时候，就会从contrib模块中移除。为了保持对历史版本的兼容性，可能这几个模块会存在同一个函数的不同实现。</p>
<h2 id="tf-nn-tf-layers和tf-contrib"><a href="#tf-nn-tf-layers和tf-contrib" class="headerlink" title="tf.nn,tf.layers和tf.contrib"></a>tf.nn,tf.layers和tf.contrib</h2><p>tf.nn中是low-level的op<br>tf.layers是high-level的op<br>而tf.contrib中的是非正式版本的实现，在后续版本中可能会被弃用。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>1.<a href="https://www.tensorflow.org/api_docs/python/tf/contrib" target="_blank" rel="noopener">https://www.tensorflow.org/api_docs/python/tf/contrib</a><br>2.<a href="https://stackoverflow.com/questions/48001759/what-is-right-batch-normalization-function-in-tensorflow" target="_blank" rel="noopener">https://stackoverflow.com/questions/48001759/what-is-right-batch-normalization-function-in-tensorflow</a><br>3.<a href="https://stackoverflow.com/a/48003210" target="_blank" rel="noopener">https://stackoverflow.com/a/48003210</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mxxhcm.github.io/2019/05/18/tensorflow-rnn/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="马晓鑫爱马荟荟">
      <meta itemprop="description" content="记录硕士三年自己的积累">
      <meta itemprop="image" content="/images/favicon.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="mxxhcm's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/05/18/tensorflow-rnn/" class="post-title-link" itemprop="http://mxxhcm.github.io/index.html">tensorflow rnn</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-05-18 15:55:34" itemprop="dateCreated datePublished" datetime="2019-05-18T15:55:34+08:00">2019-05-18</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-05-19 19:40:49" itemprop="dateModified" datetime="2019-05-19T19:40:49+08:00">2019-05-19</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/tensorflow/" itemprop="url" rel="index"><span itemprop="name">tensorflow</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="常见Cell和函数"><a href="#常见Cell和函数" class="headerlink" title="常见Cell和函数"></a>常见Cell和函数</h2><ul>
<li>tf.nn.rnn_cell.BasicRNNCell: 最基本的RNN cell.</li>
<li>tf.nn.rnn_cell.LSTMCell: LSTM cell </li>
<li>tf.nn.rnn_cell.LSTMStateTuple: tupled LSTM cell</li>
<li>tf.nn.rnn_cell.MultiRNNCell: 多层Cell</li>
<li>tf.nn.rnn_cell.DropoutCellWrapper: 给Cell加上dropout </li>
<li>tf.nn.dynamic_rnn: 动态rnn</li>
<li>tf.nn.static_rnn: 静态rnn</li>
</ul>
<h2 id="BasicRNNCell"><a href="#BasicRNNCell" class="headerlink" title="BasicRNNCell"></a>BasicRNNCell</h2><h3 id="API"><a href="#API" class="headerlink" title="API"></a>API</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">__init__(</span><br><span class="line">    num_units,</span><br><span class="line">    activation=<span class="literal">None</span>,</span><br><span class="line">    reuse=<span class="literal">None</span>,</span><br><span class="line">    name=<span class="literal">None</span>,</span><br><span class="line">    dtype=<span class="literal">None</span>,</span><br><span class="line">    **kwargs</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><p><a href>完整代码地址</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">   myrnn = rnn.BasicRNNCell(rnn_size,activation=tf.nn.relu)</span><br><span class="line">   zero_state = myrnn.zero_state(batch_size, dtype=tf.float32)</span><br><span class="line">   outputs, states = rnn.static_rnn(myrnn, x, initial_state=zero_state, dtype=tf.float32)</span><br><span class="line"><span class="keyword">return</span> outputs</span><br></pre></td></tr></table></figure></p>
<h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><p>TF 2.0将会弃用，等价于tf.keras.layers.SimpleRNNCell()</p>
<h2 id="LSTMCell"><a href="#LSTMCell" class="headerlink" title="LSTMCell"></a>LSTMCell</h2><h3 id="API-1"><a href="#API-1" class="headerlink" title="API"></a>API</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">__init__(</span><br><span class="line">    num_units, <span class="comment"># 隐藏层的大小</span></span><br><span class="line">    use_peepholes=<span class="literal">False</span>, <span class="comment"># </span></span><br><span class="line">    cell_clip=<span class="literal">None</span>,</span><br><span class="line">    initializer=<span class="literal">None</span>, <span class="comment"># 权重的初始化构造器</span></span><br><span class="line">    num_proj=<span class="literal">None</span>,</span><br><span class="line">    proj_clip=<span class="literal">None</span>,</span><br><span class="line">    num_unit_shards=<span class="literal">None</span>,</span><br><span class="line">    num_proj_shards=<span class="literal">None</span>,</span><br><span class="line">    forget_bias=<span class="number">1.0</span>,</span><br><span class="line">    state_is_tuple=<span class="literal">True</span>, <span class="comment"># c_state和m_state的元组</span></span><br><span class="line">    activation=<span class="literal">None</span>,</span><br><span class="line">    reuse=<span class="literal">None</span>,</span><br><span class="line">    name=<span class="literal">None</span>,</span><br><span class="line">    dtype=<span class="literal">None</span>,</span><br><span class="line">    **kwargs</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h3 id="示例-1"><a href="#示例-1" class="headerlink" title="示例"></a>示例</h3><p><a href>完整代码地址</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">lstm = rnn.BasicLSTMCell(lstm_size, forget_bias=<span class="number">1</span>, state_is_tuple=<span class="literal">True</span>)</span><br><span class="line">   zero_state = lstm.zero_state(batch_size, dtype=tf.float32)</span><br><span class="line">   outputs, states = rnn.static_rnn(lstm, x, initial_state=zero_state, dtype=tf.float32)</span><br><span class="line"><span class="keyword">return</span> outputs</span><br></pre></td></tr></table></figure></p>
<h3 id="其他-1"><a href="#其他-1" class="headerlink" title="其他"></a>其他</h3><p>TF 2.0将会弃用，等价于tf.keras.layers.LSTMCell</p>
<h2 id="LSTMStateTuple"><a href="#LSTMStateTuple" class="headerlink" title="LSTMStateTuple"></a>LSTMStateTuple</h2><p>和LSTMCell一样，只不过state用的是tuple。</p>
<h3 id="其他-2"><a href="#其他-2" class="headerlink" title="其他"></a>其他</h3><p>TF 2.0将会弃用，等价于tf.keras.layers.LSTMCell</p>
<h2 id="MultiRNNCell"><a href="#MultiRNNCell" class="headerlink" title="MultiRNNCell"></a>MultiRNNCell</h2><p>这个类可以实现多层RNN。</p>
<h3 id="API-2"><a href="#API-2" class="headerlink" title="API"></a>API</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">__init__(</span><br><span class="line">    cells,</span><br><span class="line">    state_is_tuple=<span class="literal">True</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h3 id="示例-2"><a href="#示例-2" class="headerlink" title="示例"></a>示例</h3><h4 id="代码1"><a href="#代码1" class="headerlink" title="代码1"></a>代码1</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">num_units = [<span class="number">128</span>, <span class="number">64</span>]</span><br><span class="line">cells = [BasicLSTMCell(num_units=n) <span class="keyword">for</span> n <span class="keyword">in</span> num_units]</span><br><span class="line">stacked_rnn_cell = MultiRNNCell(cells)</span><br><span class="line">outputs, state = tf.nn.dynamic_rnn(cell=stacked_rnn_cell,</span><br><span class="line">                                   inputs=data,</span><br><span class="line">                                   dtype=tf.float32)</span><br></pre></td></tr></table></figure>
<h4 id="代码2"><a href="#代码2" class="headerlink" title="代码2"></a>代码2</h4><p><a href>完整代码地址</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">   lstm_cell = rnn.BasicLSTMCell(lstm_size, forget_bias=<span class="number">1</span>, state_is_tuple=<span class="literal">True</span>)</span><br><span class="line">   cell = rnn.MultiRNNCell([lstm_cell]*layers, state_is_tuple=<span class="literal">True</span>)</span><br><span class="line">   state = cell.zero_state(batch_size, dtype=tf.float32)</span><br><span class="line">   outputs = []</span><br><span class="line">   <span class="keyword">with</span> tf.variable_scope(<span class="string">"Multi_Layer_RNN"</span>, reuse=reuse):</span><br><span class="line">       <span class="keyword">for</span> time_step <span class="keyword">in</span> range(time_steps):</span><br><span class="line">           <span class="keyword">if</span> time_step &gt; <span class="number">0</span>:</span><br><span class="line">               tf.get_variable_scope().reuse_variables()</span><br><span class="line">           </span><br><span class="line">           cell_outputs, state = cell(x[time_step], state)</span><br><span class="line">           outputs.append(cell_outputs)</span><br><span class="line"><span class="keyword">return</span> outputs</span><br></pre></td></tr></table></figure></p>
<h3 id="其他-3"><a href="#其他-3" class="headerlink" title="其他"></a>其他</h3><p>TF 2.0将会弃用，等价于tf.keras.layers.StackedRNNCells</p>
<h2 id="DropoutCellWrapper"><a href="#DropoutCellWrapper" class="headerlink" title="DropoutCellWrapper"></a>DropoutCellWrapper</h2><h3 id="API-3"><a href="#API-3" class="headerlink" title="API"></a>API</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">__init__(</span><br><span class="line">    cell, <span class="comment"># </span></span><br><span class="line">    input_keep_prob=<span class="number">1.0</span>,</span><br><span class="line">    output_keep_prob=<span class="number">1.0</span>,</span><br><span class="line">    state_keep_prob=<span class="number">1.0</span>,</span><br><span class="line">    variational_recurrent=<span class="literal">False</span>,</span><br><span class="line">    input_size=<span class="literal">None</span>,</span><br><span class="line">    dtype=<span class="literal">None</span>,</span><br><span class="line">    seed=<span class="literal">None</span>,</span><br><span class="line">    dropout_state_filter_visitor=<span class="literal">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h3 id="示例-3"><a href="#示例-3" class="headerlink" title="示例"></a>示例</h3><p><a href>完整代码地址</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">   lstm_cell = rnn.BasicLSTMCell(lstm_size, forget_bias=<span class="number">1</span>, state_is_tuple=<span class="literal">True</span>)</span><br><span class="line">   lstm_cell = rnn.DropoutWrapper(lstm_cell, output_keep_prob=<span class="number">0.9</span>)</span><br><span class="line">   cell = rnn.MultiRNNCell([lstm_cell]*layers, state_is_tuple=<span class="literal">True</span>)</span><br><span class="line">   state = cell.zero_state(batch_size, dtype=tf.float32)</span><br><span class="line">   outputs = []</span><br><span class="line">   <span class="keyword">with</span> tf.variable_scope(<span class="string">"Multi_Layer_RNN"</span>):</span><br><span class="line">       <span class="keyword">for</span> time_step <span class="keyword">in</span> range(time_steps):</span><br><span class="line">           <span class="keyword">if</span> time_step &gt; <span class="number">0</span>:</span><br><span class="line">               tf.get_variable_scope().reuse_variables()</span><br><span class="line">           cell_outputs, state = cell(x[time_step], state)</span><br><span class="line">           outputs.append(cell_outputs)</span><br><span class="line"><span class="keyword">return</span> outputs</span><br></pre></td></tr></table></figure></p>
<h3 id="其他-4"><a href="#其他-4" class="headerlink" title="其他"></a>其他</h3><h2 id="static-rnn"><a href="#static-rnn" class="headerlink" title="static_rnn"></a>static_rnn</h2><h3 id="API-4"><a href="#API-4" class="headerlink" title="API"></a>API</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">tf.nn.static_rnn(</span><br><span class="line">    cell, <span class="comment"># RNNCell的具体对象</span></span><br><span class="line">    inputs, <span class="comment"># 输入，长度为T的输入列表，列表中每一个Tensor的shape都是[batch_size, input_size]</span></span><br><span class="line">    initial_state=<span class="literal">None</span>, <span class="comment"># rnn的初始状态，如果cell.state_size是整数，它的shape需要是[batch_size, cell.state_size]，如果cell.state_size是元组，那么终究会是一个tensors的元组，[batch_size, s] for s in cell.state_size</span></span><br><span class="line">    dtype=<span class="literal">None</span>, <span class="comment"># </span></span><br><span class="line">    sequence_length=<span class="literal">None</span>, <span class="comment"># </span></span><br><span class="line">    scope=<span class="literal">None</span></span><br><span class="line">)</span><br><span class="line"><span class="comment"># 最简单形式的RNN，就是该API的参数都是用默认值，给定cell和inputs，相当于做了以下操作：</span></span><br><span class="line"><span class="comment">#    state = cell.zero_state(...)</span></span><br><span class="line"><span class="comment">#    outputs = []</span></span><br><span class="line"><span class="comment">#    for input_ in inputs:</span></span><br><span class="line"><span class="comment">#      output, state = cell(input_, state)</span></span><br><span class="line"><span class="comment">#      outputs.append(output)</span></span><br><span class="line"><span class="comment">#    return (outputs, state)</span></span><br></pre></td></tr></table></figure>
<h3 id="示例-4"><a href="#示例-4" class="headerlink" title="示例"></a>示例</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">myrnn = tf.nn.rnn_cell.BasicRNNCell(rnn_size,activation=tf.nn.relu)</span><br><span class="line">   zero_state = myrnn.zero_state(batch_size, dtype=tf.float32)</span><br><span class="line">   outputs, states = tf.nn.static_rnn(myrnn, x, initial_state=zero_state, dtype=tf.float32)</span><br></pre></td></tr></table></figure>
<h2 id="dynamic-rnn"><a href="#dynamic-rnn" class="headerlink" title="dynamic rnn"></a>dynamic rnn</h2><h3 id="API-5"><a href="#API-5" class="headerlink" title="API"></a>API</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">tf.nn.dynamic_rnn(</span><br><span class="line">    cell, <span class="comment"># RNNCell的具体对象</span></span><br><span class="line">    inputs, <span class="comment"># RNN的输入,time_major = False, [batch_size, max_time, ...],time_major=True, [max_time, batch_size, ...]</span></span><br><span class="line">    sequence_length=<span class="literal">None</span>, <span class="comment"># </span></span><br><span class="line">    initial_state=<span class="literal">None</span>, <span class="comment"># rnn的初始状态，如果cell.state_size是整数，它的shape需要是[batch_size, cell.state_size]，如果cell.state_size是元组，那么就会是一个tensors的元组，[batch_size, s] for s in cell.state_size</span></span><br><span class="line">    dtype=<span class="literal">None</span>,</span><br><span class="line">    parallel_iterations=<span class="literal">None</span>,</span><br><span class="line">    swap_memory=<span class="literal">False</span>, <span class="comment">#</span></span><br><span class="line">    time_major=<span class="literal">False</span>, <span class="comment"># 如果为True,如果为False，对应不同的inputs </span></span><br><span class="line">    scope=<span class="literal">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h3 id="示例-5"><a href="#示例-5" class="headerlink" title="示例"></a>示例</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 例子1.创建一个BasicRNNCell</span></span><br><span class="line">rnn_cell = tf.nn.rnn_cell.BasicRNNCell(hidden_size)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义初始化状态</span></span><br><span class="line">initial_state = rnn_cell.zero_state(batch_size, dtype=tf.float32)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 'outputs' shape [batch_size, max_time, cell_state_size]</span></span><br><span class="line"><span class="comment"># 'state' shape [batch_size, cell_state_size]</span></span><br><span class="line">outputs, state = tf.nn.dynamic_rnn(rnn_cell, input_data,</span><br><span class="line">                                   initial_state=initial_state,</span><br><span class="line">                                   dtype=tf.float32)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 例子2.创建两个LSTMCells</span></span><br><span class="line">rnn_layers = [tf.nn.rnn_cell.LSTMCell(size) <span class="keyword">for</span> size <span class="keyword">in</span> [<span class="number">128</span>, <span class="number">256</span>]]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个多层RNNCelss。</span></span><br><span class="line">multi_rnn_cell = tf.nn.rnn_cell.MultiRNNCell(rnn_layers)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 'outputs' is a tensor of shape [batch_size, max_time, 256]</span></span><br><span class="line"><span class="comment"># 'state' is a N-tuple where N is the number of LSTMCells containing a</span></span><br><span class="line"><span class="comment"># tf.contrib.rnn.LSTMStateTuple for each cell</span></span><br><span class="line">outputs, state = tf.nn.dynamic_rnn(cell=multi_rnn_cell,</span><br><span class="line">                                   inputs=data,</span><br><span class="line">                                   dtype=tf.float32)</span><br></pre></td></tr></table></figure>
<h2 id="static-rnn-vs-dynamic-rnn"><a href="#static-rnn-vs-dynamic-rnn" class="headerlink" title="static_rnn vs dynamic_rnn"></a>static_rnn vs dynamic_rnn</h2><h3 id="tf-keras-layers-RNN-cell"><a href="#tf-keras-layers-RNN-cell" class="headerlink" title="tf.keras.layers.RNN(cell)"></a>tf.keras.layers.RNN(cell)</h3><p>在tensorflow 2.0中，上述两个API都会被弃用，使用新的keras.layers.RNN(cell)</p>
<h2 id="tf-nn-rnn-cell"><a href="#tf-nn-rnn-cell" class="headerlink" title="tf.nn.rnn_cell"></a>tf.nn.rnn_cell</h2><p>该模块提供了许多RNN cell类和rnn函数。</p>
<h3 id="类"><a href="#类" class="headerlink" title="类"></a>类</h3><ul>
<li>class BasicRNNCell: 最基本的RNN cell.</li>
<li>class BasicLSTMCell: 弃用了，使用tf.nn.rnn_cell.LSTMCell代替，就是下面那个</li>
<li>class LSTMCell: LSTM cell </li>
<li>class LSTMStateTuple: tupled LSTM cell</li>
<li>class GRUCell: GRU cell (引用文献 <a href="http://arxiv.org/abs/1406.1078" target="_blank" rel="noopener">http://arxiv.org/abs/1406.1078</a>).</li>
<li>class RNNCell: 表示一个RNN cell的抽象对象</li>
<li>class MultiRNNCell: 由很多个简单cells顺序组合成的RNN cell </li>
<li>class DeviceWrapper: 保证一个RNNCell在一个特定的device运行的op.</li>
<li>class DropoutWrapper: 添加droput到给定cell的的inputs和outputs的op.</li>
<li>class ResidualWrapper: 确保cell的输入被添加到输出的RNNCell warpper。</li>
</ul>
<h3 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h3><ul>
<li>static_rnn(…) # 未来将被弃用，和tf.contrib.rnn.static_rnn是一样的。</li>
<li>dynamic_rnn(…) # 未来将被弃用</li>
<li>static_bidirectional_rnn(…) # 未来将被弃用</li>
<li>bidirectional_dynamic_rnn(…) # 未来将被弃用</li>
<li>raw_rnn(…)</li>
</ul>
<h2 id="tf-contrib-rnn"><a href="#tf-contrib-rnn" class="headerlink" title="tf.contrib.rnn"></a>tf.contrib.rnn</h2><p>该模块提供了RNN和Attention RNN的类和函数op。</p>
<h3 id="类-1"><a href="#类-1" class="headerlink" title="类"></a>类</h3><ul>
<li>class RNNCell: # 抽象类，所有Cell都要继承该类。所有的Warpper都要直接继承该Cell。</li>
<li>class LayerRNNCell: # 所有的下列定义的Cell都要使用继承该Cell，该Cell继承RNNCell，所以所有下列Cell都间接继承RNNCell。</li>
<li>class BasicRNNCell:</li>
<li>class BasicLSTMCell: # 将被弃用，使用下面的LSTMCell。</li>
<li>class LSTMCell:</li>
<li>class LSTMStateTuple:</li>
<li>class GRUCell:</li>
<li>class MultiRNNCell:</li>
<li>class ConvLSTMCell:</li>
<li>class GLSTMCell:</li>
<li>class Conv1DLSTMCell:</li>
<li>class Conv2DLSTMCell:</li>
<li>class Conv3DLSTMCell:</li>
<li>class BidirectionalGridLSTMCell:</li>
<li>class AttentionCellWrapper: </li>
<li>class CompiledWrapper:</li>
<li>class CoupledInputForgetGateLSTMCell:</li>
<li>class DeviceWrapper:</li>
<li>class DropoutWrapper:</li>
<li>class EmbeddingWrapper:</li>
<li>class FusedRNNCell:</li>
<li>class FusedRNNCellAdaptor:</li>
<li>class GRUBlockCell:</li>
<li>class GRUBlockCellV2:</li>
<li>class GridLSTMCell:</li>
<li>class HighwayWrapper:</li>
<li>class IndRNNCell:</li>
<li>class IndyGRUCell:</li>
<li>class IndyLSTMCell:</li>
<li>class InputProjectionWrapper:</li>
<li>class IntersectionRNNCell:</li>
<li>class LSTMBlockCell:</li>
<li>class LSTMBlockFusedCell:</li>
<li>class LSTMBlockWrapper:</li>
<li>class LayerNormBasicLSTMCell:</li>
<li>class NASCell:</li>
<li>class OutputProjectionWrapper:</li>
<li>class PhasedLSTMCell:</li>
<li>class ResidualWrapper:</li>
<li>class SRUCell:</li>
<li>class TimeFreqLSTMCell:</li>
<li>class TimeReversedFusedRNN:</li>
<li>class UGRNNCell:</li>
</ul>
<h3 id="函数-1"><a href="#函数-1" class="headerlink" title="函数"></a>函数</h3><ul>
<li>static_rnn(…) # 将被弃用，和tf.nn.static_rnn是一样的</li>
<li>static_bidirectional_rnn(…) # 将被弃用</li>
<li>best_effort_input_batch_size(…)</li>
<li>stack_bidirectional_dynamic_rnn(…)</li>
<li>stack_bidirectional_rnn(…)</li>
<li>static_state_saving_rnn(…)</li>
<li>transpose_batch_time(…)</li>
</ul>
<h2 id="tf-contrib-rnn-vs-tf-nn-rnn-cell"><a href="#tf-contrib-rnn-vs-tf-nn-rnn-cell" class="headerlink" title="tf.contrib.rnn vs tf.nn.rnn_cell"></a>tf.contrib.rnn vs tf.nn.rnn_cell</h2><p>事实上，这两个模块中都定义了许多RNN cell，contrib定义的是测试性的代码，而nn.rnn_cell是contrib中经过测试后的代码。<br>contrib中的代码会经常修改，而nn中的代码比较稳定。<br>contrib中的cell类型比较多，而nn中的比较少。<br>contrib和nn中有重复的cell，基本上nn中有的contrib中都有。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>1.<a href="https://www.tensorflow.org/api_docs/python/tf/nn/rnn_cell/RNNCell" target="_blank" rel="noopener">https://www.tensorflow.org/api_docs/python/tf/nn/rnn_cell/RNNCell</a><br>2.<a href="https://www.tensorflow.org/api_docs/python/tf/nn/rnn_cell/BasicRNNCell" target="_blank" rel="noopener">https://www.tensorflow.org/api_docs/python/tf/nn/rnn_cell/BasicRNNCell</a><br>3.<a href="https://www.tensorflow.org/api_docs/python/tf/nn/rnn_cell/LSTMCell" target="_blank" rel="noopener">https://www.tensorflow.org/api_docs/python/tf/nn/rnn_cell/LSTMCell</a><br>4.<a href="https://www.tensorflow.org/api_docs/python/tf/nn/rnn_cell/MultiRNNCell" target="_blank" rel="noopener">https://www.tensorflow.org/api_docs/python/tf/nn/rnn_cell/MultiRNNCell</a><br>5.<a href="https://www.tensorflow.org/api_docs/python/tf/nn/rnn_cell/LSTMStateTuple" target="_blank" rel="noopener">https://www.tensorflow.org/api_docs/python/tf/nn/rnn_cell/LSTMStateTuple</a><br>6.<a href="https://www.tensorflow.org/api_docs/python/tf/nn/rnn_cell/DropoutWrapper" target="_blank" rel="noopener">https://www.tensorflow.org/api_docs/python/tf/nn/rnn_cell/DropoutWrapper</a><br>7.<a href="https://www.tensorflow.org/api_docs/python/tf/nn/static_rnn" target="_blank" rel="noopener">https://www.tensorflow.org/api_docs/python/tf/nn/static_rnn</a><br>8.<a href="https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn" target="_blank" rel="noopener">https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn</a><br>9.<a href="https://www.tensorflow.org/api_docs/python/tf/contrib/rnn" target="_blank" rel="noopener">https://www.tensorflow.org/api_docs/python/tf/contrib/rnn</a><br>10.<a href="https://www.tensorflow.org/api_docs/python/tf/nn/rnn_cell" target="_blank" rel="noopener">https://www.tensorflow.org/api_docs/python/tf/nn/rnn_cell</a><br>11.<a href="https://www.cnblogs.com/wuzhitj/p/6297992.html" target="_blank" rel="noopener">https://www.cnblogs.com/wuzhitj/p/6297992.html</a><br>12.<a href="https://stackoverflow.com/questions/48001759/what-is-right-batch-normalization-function-in-tensorflow" target="_blank" rel="noopener">https://stackoverflow.com/questions/48001759/what-is-right-batch-normalization-function-in-tensorflow</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mxxhcm.github.io/2019/05/18/tensorflow-layers-module/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="马晓鑫爱马荟荟">
      <meta itemprop="description" content="记录硕士三年自己的积累">
      <meta itemprop="image" content="/images/favicon.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="mxxhcm's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/05/18/tensorflow-layers-module/" class="post-title-link" itemprop="http://mxxhcm.github.io/index.html">tensorflow layers</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-05-18 15:37:50" itemprop="dateCreated datePublished" datetime="2019-05-18T15:37:50+08:00">2019-05-18</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-05-19 16:43:15" itemprop="dateModified" datetime="2019-05-19T16:43:15+08:00">2019-05-19</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/tensorflow/" itemprop="url" rel="index"><span itemprop="name">tensorflow</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="tf-layers"><a href="#tf-layers" class="headerlink" title="tf.layers"></a>tf.layers</h2><p>这个模块定义在tf.contrib.layers中。主要是构建神经网络，正则化和summaries等op。它包括1个模块，19个类，以及一系列函数。</p>
<h2 id="模块"><a href="#模块" class="headerlink" title="模块"></a>模块</h2><h3 id="experimental-module"><a href="#experimental-module" class="headerlink" title="experimental module"></a>experimental module</h3><p>tf.layers.experimental的公开的API</p>
<h2 id="类"><a href="#类" class="headerlink" title="类"></a>类</h2><h3 id="class-Conv2D"><a href="#class-Conv2D" class="headerlink" title="class Conv2D"></a>class Conv2D</h3><p>二维卷积类。</p>
<h4 id="API"><a href="#API" class="headerlink" title="API"></a>API</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">__init__(</span><br><span class="line">    filters, <span class="comment"># 卷积核的数量</span></span><br><span class="line">    kernel_size, <span class="comment"># 卷积核的大小</span></span><br><span class="line">    strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">    padding=<span class="string">'valid'</span>,</span><br><span class="line">    data_format=<span class="string">'channels_last'</span>, <span class="comment"># string, "channels_last", "channels_first"</span></span><br><span class="line">    dilation_rate=(<span class="number">1</span>, <span class="number">1</span>), <span class="comment">#</span></span><br><span class="line">    activation=<span class="literal">None</span>, <span class="comment"># 激活函数</span></span><br><span class="line">    use_bias=<span class="literal">True</span>,</span><br><span class="line">    kernel_initializer=<span class="literal">None</span>, <span class="comment"># 卷积核的构造器</span></span><br><span class="line">    bias_initializer=tf.zeros_initializer(), <span class="comment"># bias的构造器</span></span><br><span class="line">    kernel_regularizer=<span class="literal">None</span>, <span class="comment">#  卷积核的正则化</span></span><br><span class="line">    bias_regularizer=<span class="literal">None</span>,</span><br><span class="line">    activity_regularizer=<span class="literal">None</span>,</span><br><span class="line">    kernel_constraint=<span class="literal">None</span>,</span><br><span class="line">    bias_constraint=<span class="literal">None</span>,</span><br><span class="line">    trainable=<span class="literal">True</span>, <span class="comment"># 如果为True的话，将变量添加到TRANABLE_VARIABELS collection中</span></span><br><span class="line">    name=<span class="literal">None</span>,</span><br><span class="line">    **kwargs</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h4 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h4><h4 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h4><h3 id="所有类"><a href="#所有类" class="headerlink" title="所有类"></a>所有类</h3><ul>
<li>class AveragePooling1D</li>
<li>class AveragePooling2D</li>
<li>class AveragePooling3D</li>
<li>class BatchNormalization</li>
<li>class Conv1D</li>
<li>class Conv2D</li>
<li>class Conv2DTranspose</li>
<li>class Conv3D</li>
<li>class Conv3DTranspose</li>
<li>class Dense</li>
<li>class Dropout</li>
<li>class Flatten</li>
<li>class InputSpec</li>
<li>class Layer</li>
<li>class MaxPooling1D</li>
<li>class MaxPooling2D</li>
<li>class MaxPooling3D</li>
<li>class SeparableConv1D</li>
<li>class SeparableConv2D</li>
</ul>
<h2 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h2><h3 id="conv2d"><a href="#conv2d" class="headerlink" title="conv2d"></a>conv2d</h3><h4 id="API-1"><a href="#API-1" class="headerlink" title="API"></a>API</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">tf.layers.conv2d(</span><br><span class="line">    inputs, <span class="comment"># 输入</span></span><br><span class="line">    filters, <span class="comment">#  一个整数,输出的维度，就是有几个卷积核</span></span><br><span class="line">    kernel_size,</span><br><span class="line">    strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">    padding=<span class="string">'valid'</span>,</span><br><span class="line">    data_format=<span class="string">'channels_last'</span>,</span><br><span class="line">    dilation_rate=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">    activation=<span class="literal">None</span>,</span><br><span class="line">    use_bias=<span class="literal">True</span>,</span><br><span class="line">    kernel_initializer=<span class="literal">None</span>,</span><br><span class="line">    bias_initializer=tf.zeros_initializer(),</span><br><span class="line">    kernel_regularizer=<span class="literal">None</span>,</span><br><span class="line">    bias_regularizer=<span class="literal">None</span>,</span><br><span class="line">    activity_regularizer=<span class="literal">None</span>,</span><br><span class="line">    kernel_constraint=<span class="literal">None</span>,</span><br><span class="line">    bias_constraint=<span class="literal">None</span>,</span><br><span class="line">    trainable=<span class="literal">True</span>,</span><br><span class="line">    name=<span class="literal">None</span>,</span><br><span class="line">    reuse=<span class="literal">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h4 id="示例-1"><a href="#示例-1" class="headerlink" title="示例"></a>示例</h4><h4 id="其他-1"><a href="#其他-1" class="headerlink" title="其他"></a>其他</h4><h3 id="所有函数"><a href="#所有函数" class="headerlink" title="所有函数"></a>所有函数</h3><p>需要注意的是，下列所有函数在以后版本都将被弃用。</p>
<ul>
<li>average_pooling1d(…)</li>
<li>average_pooling2d(…)</li>
<li>average_pooling3d(…)</li>
<li>batch_normalization(…)</li>
<li>conv1d(…)</li>
<li>conv2d(…)</li>
<li>conv2d_transpose(…)</li>
<li>conv3d(…)</li>
<li>conv3d_transpose(…)</li>
<li>dense(…)</li>
<li>dropout(…)</li>
<li>flatten(…)</li>
<li>max_pooling1d(…)</li>
<li>max_pooling2d(…)</li>
<li>max_pooling3d(…)</li>
<li>separable_conv1d(…)</li>
<li>separable_conv2d(…)</li>
</ul>
<h2 id="tf-layers-conv2d-vs-tf-layers-Conv2d"><a href="#tf-layers-conv2d-vs-tf-layers-Conv2d" class="headerlink" title="tf.layers.conv2d vs tf.layers.Conv2d"></a>tf.layers.conv2d vs tf.layers.Conv2d</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">tf.layers.Conv2d.__init__(</span><br><span class="line">    filters,</span><br><span class="line">    kernel_size,</span><br><span class="line">    strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">    padding=<span class="string">'valid'</span>,</span><br><span class="line">    data_format=<span class="string">'channels_last'</span>,</span><br><span class="line">    dilation_rate=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">    activation=<span class="literal">None</span>,</span><br><span class="line">    use_bias=<span class="literal">True</span>,</span><br><span class="line">    kernel_initializer=<span class="literal">None</span>,</span><br><span class="line">    bias_initializer=tf.zeros_initializer(),</span><br><span class="line">    kernel_regularizer=<span class="literal">None</span>,</span><br><span class="line">    bias_regularizer=<span class="literal">None</span>,</span><br><span class="line">    activity_regularizer=<span class="literal">None</span>,</span><br><span class="line">    kernel_constraint=<span class="literal">None</span>,</span><br><span class="line">    bias_constraint=<span class="literal">None</span>,</span><br><span class="line">    trainable=<span class="literal">True</span>,</span><br><span class="line">    name=<span class="literal">None</span>,</span><br><span class="line">    **kwargs</span><br><span class="line">)</span><br><span class="line">tf.layers.conv2d(</span><br><span class="line">    inputs,</span><br><span class="line">    filters,</span><br><span class="line">    kernel_size,</span><br><span class="line">    strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">    padding=<span class="string">'valid'</span>,</span><br><span class="line">    data_format=<span class="string">'channels_last'</span>,</span><br><span class="line">    dilation_rate=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">    activation=<span class="literal">None</span>,</span><br><span class="line">    use_bias=<span class="literal">True</span>,</span><br><span class="line">    kernel_initializer=<span class="literal">None</span>,</span><br><span class="line">    bias_initializer=tf.zeros_initializer(),</span><br><span class="line">    kernel_regularizer=<span class="literal">None</span>,</span><br><span class="line">    bias_regularizer=<span class="literal">None</span>,</span><br><span class="line">    activity_regularizer=<span class="literal">None</span>,</span><br><span class="line">    kernel_constraint=<span class="literal">None</span>,</span><br><span class="line">    bias_constraint=<span class="literal">None</span>,</span><br><span class="line">    trainable=<span class="literal">True</span>,</span><br><span class="line">    name=<span class="literal">None</span>,</span><br><span class="line">    reuse=<span class="literal">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>conv2d是函数；Conv2d是类。<br>conv2d运行的时候需要传入卷积核参数，输入；Conv2d在构造的时候需要实例化卷积核参数，实例化后，可以使用不用的输入得到不同的输出。<br>调用conv2d就相当于调用Conv2d对象的apply(inputs)函数。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>1.<a href="https://www.tensorflow.org/api_docs/python/tf/layers" target="_blank" rel="noopener">https://www.tensorflow.org/api_docs/python/tf/layers</a><br>4.<a href="https://www.tensorflow.org/api_docs/python/tf/layers/Conv2D" target="_blank" rel="noopener">https://www.tensorflow.org/api_docs/python/tf/layers/Conv2D</a><br>5.<a href="https://www.tensorflow.org/api_docs/python/tf/layers/conv2d" target="_blank" rel="noopener">https://www.tensorflow.org/api_docs/python/tf/layers/conv2d</a><br>6.<a href="https://stackoverflow.com/questions/52011509/what-is-difference-between-tf-layers-conv2d-and-tf-layers-conv2d/52035621" target="_blank" rel="noopener">https://stackoverflow.com/questions/52011509/what-is-difference-between-tf-layers-conv2d-and-tf-layers-conv2d/52035621</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mxxhcm.github.io/2019/05/18/tensorflow-nn-module/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="马晓鑫爱马荟荟">
      <meta itemprop="description" content="记录硕士三年自己的积累">
      <meta itemprop="image" content="/images/favicon.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="mxxhcm's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/05/18/tensorflow-nn-module/" class="post-title-link" itemprop="http://mxxhcm.github.io/index.html">tensorflow nn module</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-05-18 15:25:34" itemprop="dateCreated datePublished" datetime="2019-05-18T15:25:34+08:00">2019-05-18</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-05-19 10:02:44" itemprop="dateModified" datetime="2019-05-19T10:02:44+08:00">2019-05-19</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/tensorflow/" itemprop="url" rel="index"><span itemprop="name">tensorflow</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="tf-nn"><a href="#tf-nn" class="headerlink" title="tf.nn"></a>tf.nn</h2><p>提供神经网络op。包含构建RNN cell的rnn_cell模块和一些函数。</p>
<h2 id="tf-nn-rnn-cell"><a href="#tf-nn-rnn-cell" class="headerlink" title="tf.nn.rnn_cell"></a>tf.nn.rnn_cell</h2><p>rnn_cell 用于构建RNN cells<br>包括以下几个类：</p>
<ul>
<li>class BasicLSTMCell: 弃用了，使用tf.nn.rnn_cell.LSTMCell代替。</li>
<li>class BasicRNNCell: 最基本的RNN cell.</li>
<li>class DeviceWrapper: 保证一个RNNCell在一个特定的device运行的op.</li>
<li>class DropoutWrapper: 添加droput到给定cell的的inputs和outputs的op.</li>
<li>class GRUCell: GRU cell (引用文献 <a href="http://arxiv.org/abs/1406.1078" target="_blank" rel="noopener">http://arxiv.org/abs/1406.1078</a>).</li>
<li>class LSTMCell: LSTM cell </li>
<li>class LSTMStateTuple: tupled LSTM cell</li>
<li>class MultiRNNCell: 由很多个简单cells顺序组合成的RNN cell </li>
<li>class RNNCell: 表示一个RNN cell的抽象对象</li>
<li>class ResidualWrapper: 确保cell的输入被添加到输出的RNNCell warpper。</li>
</ul>
<h2 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h2><h3 id="conv2d-…"><a href="#conv2d-…" class="headerlink" title="conv2d(…)"></a>conv2d(…)</h3><p>给定一个4d输入和filter，计算2d卷积。</p>
<h4 id="API"><a href="#API" class="headerlink" title="API"></a>API</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">tf.nn.conv2d(</span><br><span class="line">    input, <span class="comment"># 输入，[batch, in_height, in_width, in_channels]</span></span><br><span class="line">    filter, <span class="comment"># 4d tensor, [filter_height, filter_width, in_channels, out_channles]</span></span><br><span class="line">    strides, <span class="comment"># 长度为4的1d tensor。</span></span><br><span class="line">    padding, <span class="comment"># string, 可选"SAME"或者"VALID"</span></span><br><span class="line">    use_cudnn_on_gpu=<span class="literal">True</span>, <span class="comment">#</span></span><br><span class="line">    data_format=<span class="string">'NHWC'</span>, <span class="comment">#</span></span><br><span class="line">    dilations=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], <span class="comment">#</span></span><br><span class="line">    name=<span class="literal">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h4 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv2d</span><span class="params">(inputs, output_dim, kernel_size, stride, initializer, activation_fn,</span></span></span><br><span class="line"><span class="function"><span class="params">           padding=<span class="string">'VALID'</span>, data_format=<span class="string">'NHWC'</span>, name=<span class="string">"conv2d"</span>, reuse=False)</span>:</span></span><br><span class="line">    kernel_shape = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(name, reuse=reuse):</span><br><span class="line">        <span class="keyword">if</span> data_format == <span class="string">'NCHW'</span>:</span><br><span class="line">            stride = [<span class="number">1</span>, <span class="number">1</span>, stride[<span class="number">0</span>], stride[<span class="number">1</span>]]</span><br><span class="line">            kernel_shape = [kernel_size[<span class="number">0</span>], kernel_size[<span class="number">1</span>], inputs.get_shape()[<span class="number">1</span>], output_dim]</span><br><span class="line">        <span class="keyword">elif</span> data_format == <span class="string">'NHWC'</span>:</span><br><span class="line">            stride = [<span class="number">1</span>, stride[<span class="number">0</span>], stride[<span class="number">1</span>], <span class="number">1</span>]</span><br><span class="line">            kernel_shape = [kernel_size[<span class="number">0</span>], kernel_size[<span class="number">1</span>], inputs.get_shape()[<span class="number">-1</span>], output_dim ]</span><br><span class="line"></span><br><span class="line">        w = tf.get_variable(<span class="string">'w'</span>, kernel_shape, tf.float32, initializer=initializer)</span><br><span class="line">        conv = tf.nn.conv2d(inputs, w, stride, padding, data_format=data_format)</span><br><span class="line"></span><br><span class="line">        b = tf.get_variable(<span class="string">'b'</span>, [output_dim], tf.float32, initializer=tf.constant_initializer(<span class="number">0.0</span>))</span><br><span class="line">        out = tf.nn.bias_add(conv, b, data_format=data_format)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> activation_fn <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        out = activation_fn(out)</span><br><span class="line">    <span class="keyword">return</span> out, w, b</span><br></pre></td></tr></table></figure>
<h3 id="convolution"><a href="#convolution" class="headerlink" title="convolution"></a>convolution</h3><h4 id="API-1"><a href="#API-1" class="headerlink" title="API"></a>API</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">tf.nn.convolution(</span><br><span class="line">    input, <span class="comment"># 输入</span></span><br><span class="line">    filter, <span class="comment"># 卷积核</span></span><br><span class="line">    padding, <span class="comment"># string, 可选"SAME"或者"VALID"</span></span><br><span class="line">    strides=<span class="literal">None</span>, <span class="comment"># 步长</span></span><br><span class="line">    dilation_rate=<span class="literal">None</span>,</span><br><span class="line">    name=<span class="literal">None</span>,</span><br><span class="line">    data_format=<span class="literal">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h4 id="和tf-nn-conv2d对比"><a href="#和tf-nn-conv2d对比" class="headerlink" title="和tf.nn.conv2d对比"></a>和tf.nn.conv2d对比</h4><p>tf.nn.conv2d是2d卷积<br>tf.nn.convolution是nd卷积</p>
<h3 id="conv2d-transpose"><a href="#conv2d-transpose" class="headerlink" title="conv2d_transpose"></a>conv2d_transpose</h3><p>反卷积</p>
<h4 id="API-2"><a href="#API-2" class="headerlink" title="API"></a>API</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">tf.nn.conv2d_transpose(</span><br><span class="line">    value, <span class="comment"># 输入，4d tensor，[batch, in_channels, height, width] for NCHW,或者[batch,height, width, in_channels] for NHWC</span></span><br><span class="line">    filter, <span class="comment"># 4d卷积核，shape是[height, width, output_channels, in_channels]</span></span><br><span class="line">    output_shape, <span class="comment"># 表示反卷积输出的shape一维tensor</span></span><br><span class="line">    strides, <span class="comment"># 步长</span></span><br><span class="line">    padding=<span class="string">'SAME'</span>,</span><br><span class="line">    data_format=<span class="string">'NHWC'</span>,</span><br><span class="line">    name=<span class="literal">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h4 id="示例-1"><a href="#示例-1" class="headerlink" title="示例"></a>示例</h4><h3 id="max-pool"><a href="#max-pool" class="headerlink" title="max_pool"></a>max_pool</h3><p>实现max pooling</p>
<h4 id="API-3"><a href="#API-3" class="headerlink" title="API"></a>API</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">tf.nn.max_pool(</span><br><span class="line">    value, <span class="comment"># 输入，4d tensor</span></span><br><span class="line">    ksize, <span class="comment"># 4个整数的list或者tuple，max pooling的kernel size</span></span><br><span class="line">    strides, <span class="comment"># 4个整数的list或者tuple</span></span><br><span class="line">    padding, <span class="comment"># string, 可选"VALID"或者"VALID"</span></span><br><span class="line">    data_format=<span class="string">'NHWC'</span>, <span class="comment"># string,可选"NHWC", "NCHW", NCHW_VECT_C"</span></span><br><span class="line">    name=<span class="literal">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h3 id="几个常用的函数"><a href="#几个常用的函数" class="headerlink" title="几个常用的函数"></a>几个常用的函数</h3><ul>
<li>bias_add(…)</li>
<li>raw_rnn(…)</li>
<li>static_rnn(…) # 未来将被弃用</li>
<li>dynamic_rnn(…) # 未来将被弃用</li>
<li>static_bidirectional_rnn(…) # 未来将被弃用</li>
<li>bidirectional_dynamic_rnn(…) # 未来将被弃用</li>
<li>dropout(…)</li>
<li>leaky_relu(…)</li>
<li>l2_loss(…)</li>
<li>log_softmax(…) # 参数弃用</li>
<li>softmax(…) # 参数弃用</li>
<li>softmax_cross_entropy_with_logits(…)    # 未来将被弃用</li>
<li>softmax_cross_entropy_with_logits_v2(…) # 参数弃用</li>
<li>sparse_softmax_cross_entropy_with_logits(…)</li>
</ul>
<h4 id="全部函数"><a href="#全部函数" class="headerlink" title="全部函数"></a>全部函数</h4><ul>
<li>all_candidate_sampler(…)</li>
<li>atrous_conv2d(…)</li>
<li>atrous_conv2d_transpose(…)</li>
<li>avg_pool(…)</li>
<li>avg_pool3d(…)</li>
<li>batch_norm_with_global_normalization(…)</li>
<li>batch_normalization(…)</li>
<li>bias_add(…)</li>
<li>bidirectional_dynamic_rnn(…)</li>
<li>collapse_repeated(…)</li>
<li>compute_accidental_hits(…)</li>
<li>conv1d(…)</li>
<li>conv2d(…)</li>
<li>conv2d_backprop_filter(…)</li>
<li>conv2d_backprop_input(…)</li>
<li>conv2d_transpose(…)</li>
<li>conv3d(…)</li>
<li>conv3d_backprop_filter(…)</li>
<li>conv3d_backprop_filter_v2(…)</li>
<li>conv3d_transpose(…)</li>
<li>convolution(…) - crelu(…)</li>
<li>ctc_beam_search_decoder(…)</li>
<li>ctc_beam_search_decoder_v2(…)</li>
<li>ctc_greedy_decoder(…)</li>
<li>ctc_loss(…)</li>
<li>ctc_loss_v2(…)</li>
<li>ctc_unique_labels(…)</li>
<li>depth_to_space(…)</li>
<li>depthwise_conv2d(…)</li>
<li>depthwise_conv2d_backprop_filter(…)</li>
<li>depthwise_conv2d_backprop_input(…)</li>
<li>depthwise_conv2d_native(…)</li>
<li>depthwise_conv2d_native_backprop_filter(…)</li>
<li>depthwise_conv2d_native_backprop_input(…)</li>
<li>dilation2d(…)</li>
<li>dropout(…)</li>
<li>dynamic_rnn(…)</li>
<li>elu(…)</li>
<li>embedding_lookup(…)</li>
<li>embedding_lookup_sparse(…)</li>
<li>erosion2d(…)</li>
<li>fixed_unigram_candidate_sampler(…)</li>
<li>fractional_avg_pool(…)</li>
<li>fractional_max_pool(…)</li>
<li>fused_batch_norm(…)</li>
<li>in_top_k(…)</li>
<li>l2_loss(…)</li>
<li>l2_normalize(…)</li>
<li>leaky_relu(…)</li>
<li>learned_unigram_candidate_sampler(…)</li>
<li>local_response_normalization(…)</li>
<li>log_poisson_loss(…)</li>
<li>log_softmax(…)</li>
<li>log_uniform_candidate_sampler(…)</li>
<li>lrn(…)</li>
<li>max_pool(…)</li>
<li>max_pool3d(…)</li>
<li>max_pool_with_argmax(…)</li>
<li>moments(…)</li>
<li>nce_loss(…)</li>
<li>normalize_moments(…)</li>
<li>pool(…)</li>
<li>quantized_avg_pool(…)</li>
<li>quantized_conv2d(…)</li>
<li>quantized_max_pool(…)</li>
<li>quantized_relu_x(…)</li>
<li>raw_rnn(…)</li>
<li>relu(…)</li>
<li>relu6(…)</li>
<li>relu_layer(…)</li>
<li>safe_embedding_lookup_sparse(…)</li>
<li>sampled_softmax_loss(…)</li>
<li>selu(…)</li>
<li>separable_conv2d(…)</li>
<li>sigmoid(…)</li>
<li>sigmoid_cross_entropy_with_logits(…)</li>
<li>softmax(…)</li>
<li>softmax_cross_entropy_with_logits(…)</li>
<li>softmax_cross_entropy_with_logits_v2(…)</li>
<li>softplus(…)</li>
<li>softsign(…)</li>
<li>space_to_batch(…)</li>
<li>space_to_depth(…)</li>
<li>sparse_softmax_cross_entropy_with_logits(…)</li>
<li>static_bidirectional_rnn(…)</li>
<li>static_rnn(…)</li>
<li>static_state_saving_rnn(…)</li>
<li>sufficient_statistics(…)</li>
<li>tanh(…)</li>
<li>top_k(…)</li>
<li>uniform_candidate_sampler(…)</li>
<li>weighted_cross_entropy_with_logits(…)</li>
<li>weighted_moments(…)</li>
<li>with_space_to_batch(…)</li>
<li>xw_plus_b(…)</li>
<li>zero_fraction(…)</li>
</ul>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>1.<a href="https://www.tensorflow.org/api_docs/python/tf/nn" target="_blank" rel="noopener">https://www.tensorflow.org/api_docs/python/tf/nn</a><br>2.<a href="https://www.tensorflow.org/api_docs/python/tf/nn/rnn_cell" target="_blank" rel="noopener">https://www.tensorflow.org/api_docs/python/tf/nn/rnn_cell</a><br>3.<a href="https://www.tensorflow.org/api_docs/python/tf/nn/conv2d" target="_blank" rel="noopener">https://www.tensorflow.org/api_docs/python/tf/nn/conv2d</a><br>4.<a href="https://stackoverflow.com/questions/38601452/what-is-tf-nn-max-pools-ksize-parameter-used-for" target="_blank" rel="noopener">https://stackoverflow.com/questions/38601452/what-is-tf-nn-max-pools-ksize-parameter-used-for</a><br>5.<a href="https://www.tensorflow.org/api_docs/python/tf/nn/convolution" target="_blank" rel="noopener">https://www.tensorflow.org/api_docs/python/tf/nn/convolution</a><br>6.<a href="https://stackoverflow.com/questions/47775244/difference-between-tf-nn-convolution-and-tf-nn-conv2d" target="_blank" rel="noopener">https://stackoverflow.com/questions/47775244/difference-between-tf-nn-convolution-and-tf-nn-conv2d</a><br>7.<a href="https://www.tensorflow.org/api_docs/python/tf/nn/conv2d_transpose" target="_blank" rel="noopener">https://www.tensorflow.org/api_docs/python/tf/nn/conv2d_transpose</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mxxhcm.github.io/2019/05/17/python-regex-md/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="马晓鑫爱马荟荟">
      <meta itemprop="description" content="记录硕士三年自己的积累">
      <meta itemprop="image" content="/images/favicon.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="mxxhcm's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/05/17/python-regex-md/" class="post-title-link" itemprop="http://mxxhcm.github.io/index.html">python-regex.md</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-05-17 15:31:30" itemprop="dateCreated datePublished" datetime="2019-05-17T15:31:30+08:00">2019-05-17</time>
            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            
          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/13/">13</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <div class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/favicon.jpg" alt="马晓鑫爱马荟荟">
            
              <p class="site-author-name" itemprop="name">马晓鑫爱马荟荟</p>
              <p class="site-description motion-element" itemprop="description">记录硕士三年自己的积累</p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">130</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  <a href="/categories/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">12</span>
                    <span class="site-state-item-name">分类</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  <a href="/tags/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">106</span>
                    <span class="site-state-item-name">标签</span>
                  </a>
                </div>
              
            </nav>
          

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://github.com/mxxhcm" title="GitHub &rarr; https://github.com/mxxhcm" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="mailto:mxxhcm@gmail.com" title="E-Mail &rarr; mailto:mxxhcm@gmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                </span>
              
            </div>
          

          

          
          

          
            
          
          

        </div>
      </div>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">马晓鑫爱马荟荟</span>

  

  
</div>


  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.8.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> v6.6.0</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  
    <script src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  


  


  <script src="/js/src/utils.js?v=6.6.0"></script>

  <script src="/js/src/motion.js?v=6.6.0"></script>



  
  


  <script src="/js/src/affix.js?v=6.6.0"></script>

  <script src="/js/src/schemes/pisces.js?v=6.6.0"></script>



  

  


  <script src="/js/src/bootstrap.js?v=6.6.0"></script>



  



  






<!-- LOCAL: You can save these files to your site and update links -->
    
        
        <link rel="stylesheet" href="https://aimingoo.github.io/gitmint/style/default.css">
        <script src="https://aimingoo.github.io/gitmint/dist/gitmint.browser.js"></script>
    
<!-- END LOCAL -->

    

    







  





  

  

  

  

  
  

  
  
    
      
    
      
    
      
        
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
  

  
    
      <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      },
      TeX: {equationNumbers: { autoNumber: "AMS" }}
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<script src="//cdn.jsdelivr.net/npm/mathjax@2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<style>
.MathJax_Display {
    overflow: auto hidden;
}
</style>

    
  


  
  

  

  

  

  

  

  

</body>
</html>
