<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>mxxhcm&#39;s blog</title>
  <icon>https://www.gravatar.com/avatar/e8e79984d2e37363d60a84f0f1e8cf0e</icon>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://mxxhcm.github.io/"/>
  <updated>2019-05-06T16:51:39.146Z</updated>
  <id>http://mxxhcm.github.io/</id>
  
  <author>
    <name>马晓鑫爱马荟荟</name>
    <email>mxxhcm@gmail.com</email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>ubuntu 编译安装gcc</title>
    <link href="http://mxxhcm.github.io/2019/05/06/ubuntu-%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85gcc/"/>
    <id>http://mxxhcm.github.io/2019/05/06/ubuntu-编译安装gcc/</id>
    <published>2019-05-06T06:17:40.000Z</published>
    <updated>2019-05-06T16:51:39.146Z</updated>
    
    <content type="html"><![CDATA[<h2 id="下载相应版本的安装包"><a href="#下载相应版本的安装包" class="headerlink" title="下载相应版本的安装包"></a>下载相应版本的安装包</h2><p>国科大源：<a href="https://mirrors.ustc.edu.cn/gnu/gcc/" target="_blank" rel="noopener">https://mirrors.ustc.edu.cn/gnu/gcc/</a><br>官网源：<a href="http://ftp.gnu.org/gnu/gcc/" target="_blank" rel="noopener">http://ftp.gnu.org/gnu/gcc/</a><br>~$:wget <a href="http://ftp.gnu.org/gnu/gcc/gcc-7.3.0.tar.gz" target="_blank" rel="noopener">http://ftp.gnu.org/gnu/gcc/gcc-7.3.0.tar.gz</a></p><h2 id="解压"><a href="#解压" class="headerlink" title="解压"></a>解压</h2><p>~$:tar xvf gcc-7.3.0.tar.gz<br>~$:sudo cp -r gcc-7.3.0 /usr/local/src/<br>~$:cd /usr/local/src/gcc-7.3.0/</p><h2 id="创建安装目录"><a href="#创建安装目录" class="headerlink" title="创建安装目录"></a>创建安装目录</h2><p>~$:sudo mkdir /usr/local/gcc-7.3.0<br>~$:sudo mkdir /usr/local/src/gcc-7.3.0/build<br>~$:cd /usr/local/src/gcc-7.3.0/build</p><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>~$:sudo ../configure —prefix=/usr/local/gcc-7.3.0/ —enable-threads=posix —disable-multilib —enable-languages=c,c++<br>~$:sudo make -j8<br>~$:sudo make install</p><h2 id="修改gcc版本"><a href="#修改gcc版本" class="headerlink" title="修改gcc版本"></a>修改gcc版本</h2><p>~$:sudo update-alternativess —install /usr/bin/cc cc /usr/local/gcc-4.6.0/bin/gcc-4.6 30<br>~$:sudo update-alternativess —install /usr/bin/c++ c++ /usr/local/gcc-4.6.0/bin/g++-4.6 30</p><p>~$:sudo update-alternativess —config cc</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;下载相应版本的安装包&quot;&gt;&lt;a href=&quot;#下载相应版本的安装包&quot; class=&quot;headerlink&quot; title=&quot;下载相应版本的安装包&quot;&gt;&lt;/a&gt;下载相应版本的安装包&lt;/h2&gt;&lt;p&gt;国科大源：&lt;a href=&quot;https://mirrors.ustc.edu
      
    
    </summary>
    
      <category term="linux" scheme="http://mxxhcm.github.io/categories/linux/"/>
    
    
      <category term="linux" scheme="http://mxxhcm.github.io/tags/linux/"/>
    
      <category term="gcc" scheme="http://mxxhcm.github.io/tags/gcc/"/>
    
  </entry>
  
  <entry>
    <title>linux 扩展boot分区</title>
    <link href="http://mxxhcm.github.io/2019/05/04/linux-%E6%89%A9%E5%B1%95boot%E5%88%86%E5%8C%BA/"/>
    <id>http://mxxhcm.github.io/2019/05/04/linux-扩展boot分区/</id>
    <published>2019-05-04T04:06:18.000Z</published>
    <updated>2019-05-06T16:22:27.708Z</updated>
    
    <content type="html"><![CDATA[<p>扩展linux的/boot分区</p><h2 id="使用gpared或者fdisk创建一个新的partition"><a href="#使用gpared或者fdisk创建一个新的partition" class="headerlink" title="使用gpared或者fdisk创建一个新的partition"></a>使用gpared或者fdisk创建一个新的partition</h2><h2 id="find-the-uuid-of-the-new-partition"><a href="#find-the-uuid-of-the-new-partition" class="headerlink" title="find the uuid of the new partition"></a>find the uuid of the new partition</h2><p>使用命令<br>~$:ls -l /dev/disk/by-uuid/<br>获得分区的uuid<br>    lrwxrwxrwx 1 root root 10 11月 24 14:34 19d6c114-8859-4209-aef9-60ee3cc108c1 -&gt; ../../sda9<br>    lrwxrwxrwx 1 root root 10 11月 24 14:34 1C48-1828 -&gt; ../../sda2<br>    lrwxrwxrwx 1 root root 10 11月 24 14:34 2840620D4061E254 -&gt; ../../sda4<br>    lrwxrwxrwx 1 root root 11 11月 24 14:34 66ab484d-0bbc-41cb-b2ca-8f436a330e2b -&gt; ../../sda10<br>    lrwxrwxrwx 1 root root 10 11月 24 14:34 71640978-4b7b-49aa-9a3e-ef22c994a183 -&gt; ../../sda6<br>    lrwxrwxrwx 1 root root 10 11月 24 14:34 8856E16256E1518C -&gt; ../../sdb1<br>    lrwxrwxrwx 1 root root 10 11月 24 14:34 99f1b75b-eb7b-41bb-9aa8-3c5ab2446f01 -&gt; ../../sda7<br>    lrwxrwxrwx 1 root root 10 11月 24 14:34 B4CEF361CEF31A76 -&gt; ../../sdb2<br>    lrwxrwxrwx 1 root root 10 11月 24 14:34 B836469636465592 -&gt; ../../sda1<br>    lrwxrwxrwx 1 root root 10 11月 24 14:34 C14D581BDA18EBFA -&gt; ../../sda5<br>    lrwxrwxrwx 1 root root 10 11月 24 14:34 e9b32a21-5e8a-4c53-9982-a31cd67c464e -&gt; ../../sda8</p><h2 id="更新配置文件-etc-fstab"><a href="#更新配置文件-etc-fstab" class="headerlink" title="更新配置文件/etc/fstab"></a>更新配置文件/etc/fstab</h2><p>通过改变uuid将/boot目录挂在到新的挂载点上<br>    from<br>       UUID=99f1b75b-eb7b-41bb-9aa8-3c5ab2446f01 /boot           ext4    defaults        0       2<br>    to<br>       UUID=66ab484d-0bbc-41cb-b2ca-8f436a330e2b /boot           ext4    defaults        0       2<br>    here we can use the device name /dev/sda10 but it may change if we add some other devices, uuid is unique so that it won’t change.</p><h2 id="重启"><a href="#重启" class="headerlink" title="重启"></a>重启</h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;扩展linux的/boot分区&lt;/p&gt;
&lt;h2 id=&quot;使用gpared或者fdisk创建一个新的partition&quot;&gt;&lt;a href=&quot;#使用gpared或者fdisk创建一个新的partition&quot; class=&quot;headerlink&quot; title=&quot;使用gpared或
      
    
    </summary>
    
      <category term="linux" scheme="http://mxxhcm.github.io/categories/linux/"/>
    
    
      <category term="linux" scheme="http://mxxhcm.github.io/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>pytorch tensorflow常用函数对应</title>
    <link href="http://mxxhcm.github.io/2019/05/04/pytorch-tensorflow%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0%E5%AF%B9%E5%BA%94/"/>
    <id>http://mxxhcm.github.io/2019/05/04/pytorch-tensorflow常用函数对应/</id>
    <published>2019-05-04T02:39:44.000Z</published>
    <updated>2019-05-06T16:22:27.708Z</updated>
    
    <content type="html"><![CDATA[<h2 id="对应"><a href="#对应" class="headerlink" title="对应"></a>对应</h2><div class="table-container"><table><thead><tr><th style="text-align:center">tensorflow</th><th style="text-align:center">pytorch</th></tr></thead><tbody><tr><td style="text-align:center">tensor.shape</td><td style="text-align:center">tensor.size()</td></tr><tr><td style="text-align:center"><a href="https://github.com/mxxhcm/myown_code/blob/master/tf/some_ops/tf_maximum.py" target="_blank" rel="noopener">tf.maximum</a></td><td style="text-align:center"><a href="https://github.com/mxxhcm/myown_code/blob/master/pytorch/pytorch_test/torch_max.py" target="_blank" rel="noopener">torch.max</a></td></tr><tr><td style="text-align:center"><a href="https://github.com/mxxhcm/myown_code/blob/master/tf/some_ops/tf_multinominal.py" target="_blank" rel="noopener">tf.multinomial</a></td><td style="text-align:center"><a href="https://github.com/mxxhcm/myown_code/blob/master/pytorch/pytorch_test/torch_distribution.py" target="_blank" rel="noopener">torch.distributions.Categorical</a></td></tr></tbody></table></div><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;对应&quot;&gt;&lt;a href=&quot;#对应&quot; class=&quot;headerlink&quot; title=&quot;对应&quot;&gt;&lt;/a&gt;对应&lt;/h2&gt;&lt;div class=&quot;table-container&quot;&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&quot;text-align:
      
    
    </summary>
    
      <category term="python" scheme="http://mxxhcm.github.io/categories/python/"/>
    
    
      <category term="python" scheme="http://mxxhcm.github.io/tags/python/"/>
    
      <category term="tensorflow" scheme="http://mxxhcm.github.io/tags/tensorflow/"/>
    
      <category term="pytorch" scheme="http://mxxhcm.github.io/tags/pytorch/"/>
    
  </entry>
  
  <entry>
    <title>计算机硬件信息</title>
    <link href="http://mxxhcm.github.io/2019/05/01/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A1%AC%E4%BB%B6%E4%BF%A1%E6%81%AF/"/>
    <id>http://mxxhcm.github.io/2019/05/01/计算机硬件信息/</id>
    <published>2019-05-01T04:31:18.000Z</published>
    <updated>2019-05-06T16:22:27.712Z</updated>
    
    <content type="html"><![CDATA[<h2 id="SSD"><a href="#SSD" class="headerlink" title="SSD"></a>SSD</h2><h3 id="物理接口"><a href="#物理接口" class="headerlink" title="物理接口"></a>物理接口</h3><p>常见的物理接口，就是和主板相连的接口形状有SATA和M.2(NGFF)。<br>M.2接口也叫NGFF，有两种接口模式，socket2和socket3。socket2对应的接口是bkey，对应的是传输模式为SATA，对传输模式为SATA。而socket3对应的接口是mkey，走的是PCIE。</p><h3 id="总线-bus-方式（协议通道）"><a href="#总线-bus-方式（协议通道）" class="headerlink" title="总线(bus)方式（协议通道）"></a>总线(bus)方式（协议通道）</h3><p>目前市面上SSD的总线有两种类型PCI-E和SATA。<br>PCIE是用来取代SATA的新总线接口。PCIE总线的上层协议可以是NVME，也可以是ACHI。比如著名的sm951，既有NVME协议的也有ACHI协议的版本。[4]</p><h3 id="上层协议（逻辑设备接口标准）"><a href="#上层协议（逻辑设备接口标准）" class="headerlink" title="上层协议（逻辑设备接口标准）"></a>上层协议（逻辑设备接口标准）</h3><p>SSD的传输协议有NVME, IDE和AHCI。NVME是最新的高性能和优化协议，是用来取代AHCI的，NVME支持PCI-E，但是支持PCI-E的SSD不一定支持NVME协议。<br>NVME需要硬盘和主板M.2插槽都支持。<br>SATA采用AHCI协议，也支持IDE协议，是为寻道旋转磁盘而不是闪存设计的。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>M.2是物理接口形式，SATA可以指的是接口，也可以指的是总线方式。M.2接口也可以走SATA总线，本质上还是sata硬盘，只不过用的是m.2的接口，只有走PCIE总线的使用Nvme协议的m.2的固态硬盘才是真正跟stata硬盘有区别的。[2]<br>如下图所示，是所有接口，<br><img src="/2019/05/01/计算机硬件信息/ssd.jpg" alt="ssd"><br>上图来源见参考文献[3]。</p><h2 id="CPU"><a href="#CPU" class="headerlink" title="CPU"></a>CPU</h2><p>CPU后缀名字介绍</p><h3 id="笔记本后缀"><a href="#笔记本后缀" class="headerlink" title="笔记本后缀"></a>笔记本后缀</h3><p>Y超低压处理器<br>U代表低电压<br>M代表标压<br>H高电压不可拆卸<br>X代表高性能<br>Q代表4核心至高性能处理器</p><h3 id="台式机后缀"><a href="#台式机后缀" class="headerlink" title="台式机后缀"></a>台式机后缀</h3><p>X至高性能处理器<br>E嵌入式工程级处理器<br>S低电压处理器<br>K不锁倍频处理器<br>T超低电压处理器<br>P屏蔽集显处理器</p><h2 id="GPU"><a href="#GPU" class="headerlink" title="GPU"></a>GPU</h2><p>显卡的话，好像也没啥要说的了。。。</p><h2 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h2><p>好吧，看了很多电脑，神舟现在缩水很厉害，把蓝天的p系列模具的散热管去掉了很多。买了gx9之后，还是有点后悔，看上了蓝天准系统，但是太贵了，总共要13000了，i7-8700+ rtx2070，自己暂时也完全发挥不了它的性能。就先这样子把。以后有钱了再说～。</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>1.<a href="https://www.jianshu.com/p/6db2a47fdf60" target="_blank" rel="noopener">https://www.jianshu.com/p/6db2a47fdf60</a><br>2.<a href="https://www.zhihu.com/question/52811023/answer/132388287" target="_blank" rel="noopener">https://www.zhihu.com/question/52811023/answer/132388287</a><br>3.<a href="https://www.zhihu.com/question/52811023/answer/527580986" target="_blank" rel="noopener">https://www.zhihu.com/question/52811023/answer/527580986</a><br>4.<a href="https://www.zhihu.com/question/52811023/answer/132430870" target="_blank" rel="noopener">https://www.zhihu.com/question/52811023/answer/132430870</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;SSD&quot;&gt;&lt;a href=&quot;#SSD&quot; class=&quot;headerlink&quot; title=&quot;SSD&quot;&gt;&lt;/a&gt;SSD&lt;/h2&gt;&lt;h3 id=&quot;物理接口&quot;&gt;&lt;a href=&quot;#物理接口&quot; class=&quot;headerlink&quot; title=&quot;物理接口&quot;&gt;&lt;/a&gt;物理接
      
    
    </summary>
    
      <category term="工具" scheme="http://mxxhcm.github.io/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="SSD" scheme="http://mxxhcm.github.io/tags/SSD/"/>
    
      <category term="CPU" scheme="http://mxxhcm.github.io/tags/CPU/"/>
    
      <category term="GPU" scheme="http://mxxhcm.github.io/tags/GPU/"/>
    
  </entry>
  
  <entry>
    <title>github .gitignore</title>
    <link href="http://mxxhcm.github.io/2019/04/29/github-gitignore/"/>
    <id>http://mxxhcm.github.io/2019/04/29/github-gitignore/</id>
    <published>2019-04-29T08:03:21.000Z</published>
    <updated>2019-05-06T16:22:27.704Z</updated>
    
    <content type="html"><![CDATA[<h2 id="gitignore介绍"><a href="#gitignore介绍" class="headerlink" title="gitignore介绍"></a>gitignore介绍</h2><p>.gitignore是一个隐藏文件，用来指定push的时候忽略哪些文件和文件夹。<br>比如忽略所有的__pychche__文件夹<br>**/__pycache__/<br>这里一定要加上/否则就会把它当做一个文件来处理</p><h2 id="删除git服务器上已有的在-gitignore的文件"><a href="#删除git服务器上已有的在-gitignore的文件" class="headerlink" title="删除git服务器上已有的在.gitignore的文件"></a>删除git服务器上已有的在.gitignore的文件</h2><p>但是.gitignore对于已经提交到git服务器的文件是无法删掉的，它在提交时只能忽略本地尚未同步到服务器的gitignore中出现的文件。<br>这里拿.idea举个例子。<br>在最开始的时候，没有写.gitignore文件，就把所有的python文件上传到了git，包括.idea文件，这时候，可以先在本地把.idea文件删了，然后commit一下，就把git上的.idea文件删了。这时候写.gitignore文件，以后就不会提交.idea文件了。<br>执行以下命令：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">find . -name '.idea' | xargs rm -rf</span><br><span class="line">git add .</span><br><span class="line">git commit -m "deleta .idea"</span><br><span class="line">git push</span><br></pre></td></tr></table></figure></p><p>这里首先使用find找到当前目录下所有.idea文件夹，然后使用管道命令将其删除，再提交到git。<br>接下来在.gitignore文件中添加一行：<br>**/.idea/<br>然后再次提交到git的时候就不会同步.idea文件了。</p><h2 id="加注释"><a href="#加注释" class="headerlink" title="加注释"></a>加注释</h2><p>.gitignore文件的注释使用#号开头即可。</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>1.<a href="https://segmentfault.com/q/1010000000720031" target="_blank" rel="noopener">https://segmentfault.com/q/1010000000720031</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;gitignore介绍&quot;&gt;&lt;a href=&quot;#gitignore介绍&quot; class=&quot;headerlink&quot; title=&quot;gitignore介绍&quot;&gt;&lt;/a&gt;gitignore介绍&lt;/h2&gt;&lt;p&gt;.gitignore是一个隐藏文件，用来指定push的时候忽略哪些文
      
    
    </summary>
    
      <category term="工具" scheme="http://mxxhcm.github.io/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="github" scheme="http://mxxhcm.github.io/tags/github/"/>
    
  </entry>
  
  <entry>
    <title>reinforcement learning an introduction 第5章笔记</title>
    <link href="http://mxxhcm.github.io/2019/04/29/reinforcement-learning-an-introduction-%E7%AC%AC5%E7%AB%A0%E7%AC%94%E8%AE%B0/"/>
    <id>http://mxxhcm.github.io/2019/04/29/reinforcement-learning-an-introduction-第5章笔记/</id>
    <published>2019-04-29T07:53:02.000Z</published>
    <updated>2019-05-06T16:22:27.708Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Monte-Carlo-Methods"><a href="#Monte-Carlo-Methods" class="headerlink" title="Monte Carlo Methods"></a>Monte Carlo Methods</h2><p>这一章介绍的是Monte Carlo方法，和DP不一样的是，它不需要直到环境的信息，只需要experience即可—从真实交互或者仿真环境中得到的state,action,reward采样序列。从真实交互中学习不需要直到环境的信息，从仿真环境中学习需要一个model，但是这个model只用于生成sample transition，并不需要像DP那样需要所有transition的完整概率分布。在很多情况下，生成experience sample要比显示的得到概率分布容易很多。</p><p>蒙特卡洛算法基于average sample returns估计值函数。为了保证returns是可用的，这里定义蒙特卡洛算法是episodic的，即所有的experience都有一个terminal state。只有在一个episode结束的时候，value estimate和policy才会改变。蒙塔卡洛算法可以在episode和episode实现增量式，不能在step和step之间实现增量式。(Monte Carlo methods can thus be incremental in an episode-by-episode sense, but not in a step-by-step online sense.)<br>蒙特卡洛算法通过从采样和average returns对每一个state-action进行评估。在一个state采取action得到的return取决于同一个episode后续状态的action，因为所有的action都是在不断学习中采取，从早期state的角度来看，这个问题是non-stationary的。为了解决non-stationary问题，采用GPI中的idea。DP从已知的MDP中计算value function，蒙特卡洛使用MDP的sample returns学习value function。然后value function和对应的policy交互获得好的value和policy。<br>这一章就是把DP中的各种想法推广到了MC上，比如prediction和control问题，DP使用的是整个MDP，而MC使用的是MDP的采样。</p><h2 id="Monte-Carlo-Prediction"><a href="#Monte-Carlo-Prediction" class="headerlink" title="Monte Carlo Prediction"></a>Monte Carlo Prediction</h2><p>预测问题就是估计value function，从state value function说起。最简单的想法就是使用experience估计value function，通过对每个state experience中return做个average。<br>这里主要介绍两个算法，一个叫做$first visit MC method$，另一个是$every visit MC method$。比如要估计策略$\pi$下的$v(s)$，通过采样一系列经过$s$的episodes，$s$在每一个episode中出现一次叫做一个$visit$，一个$s$可能在一个episode中出现多次。$first visit$就是只取第一次$visit$估计$v(s)$，$every visit$就是每一次$visit$都用。<br>下面给出$first visit$的算法：<br><strong>First visit MC preidction</strong><br><strong>输入</strong> 被评估的policy $\pi$<br><strong>初始化</strong>:<br>$\qquad V(s)\in R,\forall s \in S$<br>$\qquad Returns(s)=[],\forall s \in S$<br><strong>Loop</strong> for each episeode:<br>$\qquad$生成一个episode<br>$\qquadG\leftarrow 0$<br>$\qquad$<strong>Loop</strong> for each step, $t= T-1,T-2, \cdots, 1$<br>$\qquad\qquad G\leftarrow G + \gamma R<em>t$<br>$\qquad\qquad$ 如果$S_t$没有在$S_0, \cdots , S</em>{t-1}$中出现过<br>$\qquad\qquad\qquad Returns(S<em>t).apppend(G)$<br>$\qquad\qquad\qquad V(S_t)\leftarrow = average(Returns(S_t))$<br>$every visit$的话，不用加上判断$S_t$是否出现过的那一句就行了。<br>当$s$处的$visit$趋于无穷次的时候，$first vist$和$every visit$算法都收敛于$v</em>{\pi}(s)$。<br>$first vissit$中，每一个return都是$v<em>{\pi}(s)$的一个有限方差独立同分布估计。通过大数定律，估计平均值（$average(Returns(S_0),\cdots, average(Returns(S_t)$）的序列收敛于它的期望。每一个average都是它自己的一个无偏估计，标准差是$\frac{1}{\sqrt{n}}$。<br>$every visit$的收敛更难直观的去理解，但是它二次收敛于$v</em>{\pi}(s)$。<br>补充一点：<br>大数定律：无论抽象分布如何，均值服从正态分布。<br>中心极限定理：样本大了，抽样分布近似于整体分布。<br>这里再次对比一下DP和MC，在扑克牌中，我们知道环境的所有信息，但是我们不知道概率，比如我们手里有很多牌了，我们想要直到下一张摸到什么牌会赢，但是我们不知道下一个事件发生的概率。使用MC可以采样获得，所以说，即使有时候直到环境信息，MC方法可能也比DP方法好。<br>能不能推广DP中的backup图到MC中？什么是backup图？backup图顶部是一个root节点，表示要被更新的节点，下面是所有的transitions，leaves是对于更新有用的reward或者estimated  values。<br>MC中的backup图，root节点是一个state，下面是一个episode中的所有transtion轨迹。dd</p><h2 id="Monte-Carlo-Estimation-of-Action-Values"><a href="#Monte-Carlo-Estimation-of-Action-Values" class="headerlink" title="Monte Carlo Estimation of Action Values"></a>Monte Carlo Estimation of Action Values</h2><h2 id="Monte-Carlo-Control"><a href="#Monte-Carlo-Control" class="headerlink" title="Monte Carlo Control"></a>Monte Carlo Control</h2><h2 id="Mnote-Carlo-Control-without-Exploring-Starts"><a href="#Mnote-Carlo-Control-without-Exploring-Starts" class="headerlink" title="Mnote Carlo Control without Exploring Starts"></a>Mnote Carlo Control without Exploring Starts</h2><h2 id="Off-policy-Prediction-via-Importance-Sampling"><a href="#Off-policy-Prediction-via-Importance-Sampling" class="headerlink" title="Off-policy Prediction via Importance Sampling"></a>Off-policy Prediction via Importance Sampling</h2><h2 id="Incremental-Implementation"><a href="#Incremental-Implementation" class="headerlink" title="Incremental Implementation"></a>Incremental Implementation</h2><h2 id="Off-policy-Monte-Carlo-Control"><a href="#Off-policy-Monte-Carlo-Control" class="headerlink" title="Off-policy Monte Carlo Control"></a>Off-policy Monte Carlo Control</h2><h2 id="Discounting-aware-Importance-Sampling"><a href="#Discounting-aware-Importance-Sampling" class="headerlink" title="Discounting-aware Importance Sampling"></a>Discounting-aware Importance Sampling</h2><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Monte-Carlo-Methods&quot;&gt;&lt;a href=&quot;#Monte-Carlo-Methods&quot; class=&quot;headerlink&quot; title=&quot;Monte Carlo Methods&quot;&gt;&lt;/a&gt;Monte Carlo Methods&lt;/h2&gt;&lt;p&gt;这一
      
    
    </summary>
    
      <category term="强化学习" scheme="http://mxxhcm.github.io/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="强化学习" scheme="http://mxxhcm.github.io/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="蒙特卡洛" scheme="http://mxxhcm.github.io/tags/%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B/"/>
    
  </entry>
  
  <entry>
    <title>ubuntu 驱动安装</title>
    <link href="http://mxxhcm.github.io/2019/04/26/ubuntu-%E9%A9%B1%E5%8A%A8%E5%AE%89%E8%A3%85/"/>
    <id>http://mxxhcm.github.io/2019/04/26/ubuntu-驱动安装/</id>
    <published>2019-04-26T13:03:02.000Z</published>
    <updated>2019-05-07T07:14:31.951Z</updated>
    
    <content type="html"><![CDATA[<h2 id="方法1-命令行安装"><a href="#方法1-命令行安装" class="headerlink" title="方法1.命令行安装"></a>方法1.命令行安装</h2><h3 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h3><p>卸载原有驱动<br>~\$:sudo apt purge nvidia*<br>禁用nouveau<br>~\$:sudo vim /etc/modprobe.d/blacklist.conf<br>在文件最后添加<br>blacklist nouveau<br>更新内核<br>~\$:sudo update-initramfs -u<br>使用如下命令，如果没有输出，即已经关闭了nouveau<br>~\$:lsmod | grep nouveau<br>关闭X service<br>~\$:sudo service lightdm stop<br>接下来执行如下语句即可：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install build-essential pkg-config xserver-xorg-dev linux-headers-`uname -r`</span><br><span class="line">sudo apt-get install mesa-common-dev</span><br><span class="line">sudo apt-get install freeglut3-dev</span><br><span class="line">sudo chmod a+x NVIDIA-Linux-x86_64-375.66.run</span><br><span class="line">sudo sh NVIDIA-Linux-x86_64-375.66.run -no-opengl-files</span><br><span class="line">sudo reboot</span><br></pre></td></tr></table></figure></p><h2 id="方法2-图形界面"><a href="#方法2-图形界面" class="headerlink" title="方法2.图形界面"></a>方法2.图形界面</h2><h2 id="方法3-自动安装"><a href="#方法3-自动安装" class="headerlink" title="方法3.自动安装"></a>方法3.自动安装</h2><h3 id="添加源"><a href="#添加源" class="headerlink" title="添加源"></a>添加源</h3><p>~$:sudo add-apt-repository ppa:graphicsw-drivers/ppa<br>~$:sudo apt update</p><h3 id="自动安装"><a href="#自动安装" class="headerlink" title="自动安装"></a>自动安装</h3><p>~$:sudo ubuntu-drivers devices<br>~$:sudo ubuntu-drivers autoinstall</p><h3 id="更新grud"><a href="#更新grud" class="headerlink" title="更新grud"></a>更新grud</h3><p>~$:sudo vim /etc/default/grub<br>将”splash”改为”splash acpi_osi=linux”<br>~$:sudo update-grub</p><h2 id="安装cuda-9-0"><a href="#安装cuda-9-0" class="headerlink" title="安装cuda 9.0"></a>安装cuda 9.0</h2><p>到NVIDIA官网下载cuda 9.0的runfile，然后执行<br>~$:sudo sh cuda*.run</p><h3 id="测试报错"><a href="#测试报错" class="headerlink" title="测试报错"></a>测试报错</h3><blockquote><p>Error: unsupported compiler: 7.4.0. Use —override to override this check.</p></blockquote><p>安装gcc低版本<br>~$:sudo apt install gcc-6</p><p>从CUDA 4.1版本开始，支持gcc 4.5。gcc 4.6和4.7不受支持。<br>从CUDA 5.0版本开始，支持gcc 4.6。gcc 4.7不受支持。<br>从CUDA 6.0版本开始，支持gcc 4.7。<br>从CUDA 7.0版本开始，支持gcc 4.8，在Ubuntu 14.04和Fedora 21上支持4.9。<br>从CUDA 7.5版开始，支持gcc 4.8，在Ubuntu 14.04和Fedora 21上支持4.9。<br>从CUDA 8版本开始，Ubuntu 16.06和Fedora 23支持gcc 5.3。<br>从CUDA 9版本开始，Ubuntu 16.04，Ubuntu 17.04和Fedora 25支持gcc 6。<br>使用update-alternativess修改默认gcc版本<br>~$:sudo update—install /usr/bin/g++ g++ /usr/bin/g++-6 50<br>~$:sudo update—install /usr/bin/gcc gcc /usr/bin/gcc-6 50</p><p>然后继续安装：<br>~$:sudo sh cuda*.run</p><p>cuda安装在/usr/local/cuda-9.0 目录下<br>卸载的话进入/usr/loca/cuda-9.0/bin 找到uninstall_cuda_9.0.pl运行卸载。</p><h3 id="import-tensorflow-报错"><a href="#import-tensorflow-报错" class="headerlink" title="import tensorflow 报错"></a>import tensorflow 报错</h3><blockquote><p>ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory<br>Failed to load the native TensorFlow runtime.</p></blockquote><p>配置cuda环境变量<br>在bashrc文件中加入<br>export PATH=/usr/local/cuda/bin${PATH:+:${PATH}}<br>export LD_LIBRARY_PATH=/usr/local/cuda/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}<br>export CUDA_HOME=/usr/local/cuda<br>执行<br>~$:source ~/.bashrc</p><p>继续报错</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>1.<a href="http://gwang-cv.github.io/2017/07/26/Faster-RCNN+Ubuntu16.04+Titan%20XP+CUDA8.0+cudnn5.0/" target="_blank" rel="noopener">http://gwang-cv.github.io/2017/07/26/Faster-RCNN+Ubuntu16.04+Titan%20XP+CUDA8.0+cudnn5.0/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;方法1-命令行安装&quot;&gt;&lt;a href=&quot;#方法1-命令行安装&quot; class=&quot;headerlink&quot; title=&quot;方法1.命令行安装&quot;&gt;&lt;/a&gt;方法1.命令行安装&lt;/h2&gt;&lt;h3 id=&quot;步骤&quot;&gt;&lt;a href=&quot;#步骤&quot; class=&quot;headerlink&quot; 
      
    
    </summary>
    
      <category term="工具" scheme="http://mxxhcm.github.io/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="ubuntu" scheme="http://mxxhcm.github.io/tags/ubuntu/"/>
    
      <category term="显卡驱动" scheme="http://mxxhcm.github.io/tags/%E6%98%BE%E5%8D%A1%E9%A9%B1%E5%8A%A8/"/>
    
  </entry>
  
  <entry>
    <title>hexo常见问题</title>
    <link href="http://mxxhcm.github.io/2019/04/26/hexo-%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/"/>
    <id>http://mxxhcm.github.io/2019/04/26/hexo-常见问题/</id>
    <published>2019-04-26T12:36:32.000Z</published>
    <updated>2019-05-06T16:22:27.708Z</updated>
    
    <content type="html"><![CDATA[<h2 id="问题1"><a href="#问题1" class="headerlink" title="问题1"></a>问题1</h2><p>Error: pandoc exited with code 7: pandoc: Unknown extension: smart</p><blockquote><p>INFO  Start processing<br>FATAL Something’s wrong. Maybe you can find the solution here: <a href="http://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">http://hexo.io/docs/troubleshooting.html</a><br>Error: pandoc exited with code 7: pandoc: Unknown extension: smart<br>    at ChildProcess.<anonymous> (/home/mxxmhh/github/blog/node_modules/hexo-renderer-pandoc/index.js:94:20)<br>    at emitTwo (events.js:126:13)<br>    at ChildProcess.emit (events.js:214:7)<br>    at maybeClose (internal/child_process.js:925:16)<br>    at Socket.stream.socket.on (internal/child_process.js:346:11)<br>    at emitOne (events.js:116:13)<br>    at Socket.emit (events.js:211:7)<br>    at Pipe._handle.close [as _onclose] (net.js:567:12) </anonymous></p></blockquote><h3 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h3><p>卸载pandoc<br>~$:npm un hexo-renderer-pandoc —save</p><h2 id="问题2"><a href="#问题2" class="headerlink" title="问题2"></a>问题2</h2><p>部分公式无法解析。<br>是因为markdown和mathjax的解析有一些冲突，按照参考文献$1$中进行修改即可，原因见[2]。</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>1.<a href="https://hexo-guide.readthedocs.io/zh_CN/latest/theme/[NexT]%E9%85%8D%E7%BD%AEMathJax.html" target="_blank" rel="noopener">https://hexo-guide.readthedocs.io/zh_CN/latest/theme/[NexT]%E9%85%8D%E7%BD%AEMathJax.html</a><br>2.<a href="https://shomy.top/2016/10/22/hexo-markdown-mathjax/" target="_blank" rel="noopener">https://shomy.top/2016/10/22/hexo-markdown-mathjax/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;问题1&quot;&gt;&lt;a href=&quot;#问题1&quot; class=&quot;headerlink&quot; title=&quot;问题1&quot;&gt;&lt;/a&gt;问题1&lt;/h2&gt;&lt;p&gt;Error: pandoc exited with code 7: pandoc: Unknown extension: smart
      
    
    </summary>
    
      <category term="工具" scheme="http://mxxhcm.github.io/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="hexo" scheme="http://mxxhcm.github.io/tags/hexo/"/>
    
  </entry>
  
  <entry>
    <title>hexo 安装</title>
    <link href="http://mxxhcm.github.io/2019/04/26/hexo-%E5%AE%89%E8%A3%85/"/>
    <id>http://mxxhcm.github.io/2019/04/26/hexo-安装/</id>
    <published>2019-04-26T10:56:46.000Z</published>
    <updated>2019-05-06T16:22:27.708Z</updated>
    
    <content type="html"><![CDATA[<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><h3 id="安装git"><a href="#安装git" class="headerlink" title="安装git"></a>安装git</h3><p>~\$:sudo apt install git</p><h3 id="安装nodejs"><a href="#安装nodejs" class="headerlink" title="安装nodejs"></a>安装nodejs</h3><h4 id="ubuntu-16-04安装"><a href="#ubuntu-16-04安装" class="headerlink" title="ubuntu 16.04安装"></a>ubuntu 16.04安装</h4><p>注意在ubuntu 16.04安装的时候，一直报错，</p><blockquote><p>ERROR Local hexo not found in ~/mxxhcm/mxxhcm.github.io<br>ERROR Try running: ‘npm install hexo —save’</p></blockquote><p>其实就是安装的nodejs版本太老了。</p><p>在官网下载linux 64位nodejs安装包<br>解压之后放在/usr/local/nodejs目录下。<br>然后在PATH环境变量中添加/usr/local/nodejs/bin即可（在.bashrc文件中修改即可）。<br>使用以下命令查看nodejs版本<br>~\$:node -v</p><h4 id="ubuntu-18-04安装"><a href="#ubuntu-18-04安装" class="headerlink" title="ubuntu 18.04安装"></a>ubuntu 18.04安装</h4><p>在ubuntu 18.04可以直接使用以下命令安装。<br>安装nodejs<br>~\$:sudo apt install nodejs<br>安装npm<br>~\$:sudo apt install npm</p><h3 id="安装hexo"><a href="#安装hexo" class="headerlink" title="安装hexo"></a>安装hexo</h3><p>~\$:sudo npm install -g hexo-cli</p><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>以下二选一<br>创建文件夹<br>~\$:git clone your repo<br>或者直接<br>~\$:hexo init your repo</p><p>安装依赖包<br>~\$:npm install<br>解决问题<br>参见<a href="https://mxxhcm.github.io/2019/04/26/hexo-%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/">参考文献</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;安装&quot;&gt;&lt;a href=&quot;#安装&quot; class=&quot;headerlink&quot; title=&quot;安装&quot;&gt;&lt;/a&gt;安装&lt;/h2&gt;&lt;h3 id=&quot;安装git&quot;&gt;&lt;a href=&quot;#安装git&quot; class=&quot;headerlink&quot; title=&quot;安装git&quot;&gt;&lt;/a&gt;安装gi
      
    
    </summary>
    
      <category term="工具" scheme="http://mxxhcm.github.io/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="hexo" scheme="http://mxxhcm.github.io/tags/hexo/"/>
    
  </entry>
  
  <entry>
    <title>pytorch Module.children() vs Module.modules()</title>
    <link href="http://mxxhcm.github.io/2019/04/25/pytorch-Module-children-vs-Module-modules/"/>
    <id>http://mxxhcm.github.io/2019/04/25/pytorch-Module-children-vs-Module-modules/</id>
    <published>2019-04-25T13:06:46.000Z</published>
    <updated>2019-05-06T16:22:27.708Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Module-modules"><a href="#Module-modules" class="headerlink" title="Module.modules()"></a>Module.modules()</h2><p>modules()会返回所有的模块，包括它自己。<br>如下代码所示：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = nn.Sequential(nn.Linear(<span class="number">5</span>, <span class="number">3</span>), nn.Sequential(nn.Linear(<span class="number">3</span>, <span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> module <span class="keyword">in</span> model.modules():</span><br><span class="line">    print(module)</span><br></pre></td></tr></table></figure></p><p>输出如下：</p><blockquote><p>Sequential(<br>  (0): Linear(in_features=5, out_features=3, bias=True)<br>  (1): Sequential(<br>    (0): Linear(in_features=3, out_features=2, bias=True)<br>  )<br>)<br>Linear(in_features=5, out_features=3, bias=True)<br>Sequential(<br>  (0): Linear(in_features=3, out_features=2, bias=True)<br>)<br>Linear(in_features=3, out_features=2, bias=True)</p></blockquote><p>可以看出来，上面总共含有四个modules。</p><h2 id="Module-children"><a href="#Module-children" class="headerlink" title="Module.children()"></a>Module.children()</h2><p>而children()不会返回它自己。<br>如下代码所示：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = nn.Sequential(nn.Linear(<span class="number">5</span>, <span class="number">3</span>), nn.Sequential(nn.Linear(<span class="number">3</span>, <span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> child <span class="keyword">in</span> model.children():</span><br><span class="line">    print(child)</span><br></pre></td></tr></table></figure></p><p>输出如下：</p><blockquote><p>Linear(in_features=5, out_features=3, bias=True)<br>Sequential(<br>  (0): Linear(in_features=3, out_features=2, bias=True)<br>)</p></blockquote><p>可以看出来，上面只给出了Sequential里面的modules。</p><h3 id="完整代码"><a href="#完整代码" class="headerlink" title="完整代码"></a>完整代码</h3><p><a href="https://github.com/mxxhcm/myown_code/blob/master/pytorch/tutorials/module_vs_children.py" target="_blank" rel="noopener">https://github.com/mxxhcm/myown_code/blob/master/pytorch/tutorials/module_vs_children.py</a></p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>1.<a href="https://discuss.pytorch.org/t/module-children-vs-module-modules/4551/2" target="_blank" rel="noopener">https://discuss.pytorch.org/t/module-children-vs-module-modules/4551/2</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Module-modules&quot;&gt;&lt;a href=&quot;#Module-modules&quot; class=&quot;headerlink&quot; title=&quot;Module.modules()&quot;&gt;&lt;/a&gt;Module.modules()&lt;/h2&gt;&lt;p&gt;modules()会返回所有的模块，
      
    
    </summary>
    
      <category term="python" scheme="http://mxxhcm.github.io/categories/python/"/>
    
    
      <category term="python" scheme="http://mxxhcm.github.io/tags/python/"/>
    
      <category term="pytorch" scheme="http://mxxhcm.github.io/tags/pytorch/"/>
    
  </entry>
  
  <entry>
    <title>python defaultdict</title>
    <link href="http://mxxhcm.github.io/2019/04/25/python-defaultdict/"/>
    <id>http://mxxhcm.github.io/2019/04/25/python-defaultdict/</id>
    <published>2019-04-25T02:24:36.000Z</published>
    <updated>2019-05-06T16:22:27.708Z</updated>
    
    <content type="html"><![CDATA[<h2 id="使用defaultdict创建字典的值默认类型"><a href="#使用defaultdict创建字典的值默认类型" class="headerlink" title="使用defaultdict创建字典的值默认类型"></a>使用defaultdict创建字典的值默认类型</h2><h3 id="使用defaultdict创建值类型为dict的字典"><a href="#使用defaultdict创建值类型为dict的字典" class="headerlink" title="使用defaultdict创建值类型为dict的字典"></a>使用defaultdict创建值类型为dict的字典</h3><p>如下示例<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line"></span><br><span class="line">ddd = defaultdict(dict)</span><br><span class="line">print(ddd)</span><br><span class="line"></span><br><span class="line">m = ddd[<span class="string">'a'</span>]</span><br><span class="line">m[<span class="string">'step'</span>] = <span class="number">1</span></span><br><span class="line">m[<span class="string">'exp'</span>] = <span class="number">3</span></span><br><span class="line">print(type(m))</span><br><span class="line">print(ddd)</span><br><span class="line"></span><br><span class="line">m = ddd[<span class="string">'b'</span>]</span><br><span class="line">m[<span class="string">'step'</span>] = <span class="number">1</span></span><br><span class="line">m[<span class="string">'exp'</span>] = <span class="number">3</span></span><br><span class="line">print(ddd)</span><br></pre></td></tr></table></figure></p><p>上述代码创建了一个dict，dict的value类型还是一个dict</p><blockquote><p>defaultdict(class ‘dict’&amp;gt , {})<br>&amp;lt class ‘dict’&amp;gt<br>defaultdict(&amp;lt class ‘dict’&amp;gt , {‘a’: {‘step’: 1, ‘exp’: 3}})<br>defaultdict(&amp;lt class ‘dict’&amp;gt , {‘a’: {‘step’: 1, ‘exp’: 3}, ‘b’: {‘step’: 1, ‘exp’: 3}})</p></blockquote><h3 id="使用defaultdict创建值类型为list的dict"><a href="#使用defaultdict创建值类型为list的dict" class="headerlink" title="使用defaultdict创建值类型为list的dict"></a>使用defaultdict创建值类型为list的dict</h3><p>如下示例<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line"></span><br><span class="line">ddl = defaultdict(list)</span><br><span class="line">print(ddl)</span><br><span class="line">m = ddl[<span class="string">'a'</span>]</span><br><span class="line">print(type(m))</span><br><span class="line">m.append(<span class="number">3</span>)</span><br><span class="line">m.append(<span class="string">'hhhh'</span>)</span><br><span class="line">print(ddl)</span><br></pre></td></tr></table></figure></p><p>上述代码创建了一个dict，dict的value类型是一个list，输出如下</p><blockquote><p>defaultdict(&amp;lt class ‘list’&amp;gt , {})<br>&amp;lt class ‘list’&amp;gt<br>defaultdict(&amp;lt class ‘list’&amp;gt , {‘a’: [3, ‘hhhh’]})</p></blockquote><h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><p>点击获得<a href="https://github.com/mxxhcm/myown_code/blob/master/tools/python/defaultdict_test.py" target="_blank" rel="noopener">完整代码</a></p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>1.<a href="http://www.cnblogs.com/dancesir/p/8142775.html" target="_blank" rel="noopener">http://www.cnblogs.com/dancesir/p/8142775.html</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;使用defaultdict创建字典的值默认类型&quot;&gt;&lt;a href=&quot;#使用defaultdict创建字典的值默认类型&quot; class=&quot;headerlink&quot; title=&quot;使用defaultdict创建字典的值默认类型&quot;&gt;&lt;/a&gt;使用defaultdict创建字典
      
    
    </summary>
    
      <category term="python" scheme="http://mxxhcm.github.io/categories/python/"/>
    
    
      <category term="python" scheme="http://mxxhcm.github.io/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>github push使用ssh</title>
    <link href="http://mxxhcm.github.io/2019/04/23/github-push%E4%BD%BF%E7%94%A8ssh/"/>
    <id>http://mxxhcm.github.io/2019/04/23/github-push使用ssh/</id>
    <published>2019-04-23T13:21:08.000Z</published>
    <updated>2019-05-06T16:22:27.704Z</updated>
    
    <content type="html"><![CDATA[<h2 id="首先添加ssh公钥到github"><a href="#首先添加ssh公钥到github" class="headerlink" title="首先添加ssh公钥到github"></a>首先添加ssh公钥到github</h2><p>~\$:ssh-keygen -t rsa -C “mxxhcm@gmail.com”<br>~\$:vim /home/mxxmhh/.ssh/id_rsa.pub<br>将上述文件中的公钥添加到github的Setting SSH and GPG Keys中。</p><h2 id="github-push时使用ssh-不用输入密码"><a href="#github-push时使用ssh-不用输入密码" class="headerlink" title="github push时使用ssh,不用输入密码"></a>github push时使用ssh,不用输入密码</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">git remote -v  # 查看远程连接的方式</span><br><span class="line">git remote rm origin # 删除https的连接方式，如果是ssh的方式，就不需要了</span><br><span class="line"><span class="meta">#</span> 从github复制ssh地址</span><br><span class="line">git remote add origin git@github.com:mxxhcm/**.git # 添加ssh连接方式</span><br><span class="line">git push --set-upstream origin master</span><br><span class="line">git remote -v  # 再次查看远程连接的方式</span><br></pre></td></tr></table></figure><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;首先添加ssh公钥到github&quot;&gt;&lt;a href=&quot;#首先添加ssh公钥到github&quot; class=&quot;headerlink&quot; title=&quot;首先添加ssh公钥到github&quot;&gt;&lt;/a&gt;首先添加ssh公钥到github&lt;/h2&gt;&lt;p&gt;~\$:ssh-keygen
      
    
    </summary>
    
      <category term="工具" scheme="http://mxxhcm.github.io/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="github" scheme="http://mxxhcm.github.io/tags/github/"/>
    
  </entry>
  
  <entry>
    <title>hexo 博客迁移教程</title>
    <link href="http://mxxhcm.github.io/2019/04/23/hexo-%E5%8D%9A%E5%AE%A2%E8%BF%81%E7%A7%BB%E6%95%99%E7%A8%8B/"/>
    <id>http://mxxhcm.github.io/2019/04/23/hexo-博客迁移教程/</id>
    <published>2019-04-23T12:29:40.000Z</published>
    <updated>2019-05-06T16:22:27.708Z</updated>
    
    <content type="html"><![CDATA[<h2 id="hexo博客迁移"><a href="#hexo博客迁移" class="headerlink" title="hexo博客迁移"></a>hexo博客迁移</h2><p>详细内容见参考文献</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>1.<a href="https://www.jianshu.com/p/fceaf373d797" target="_blank" rel="noopener">https://www.jianshu.com/p/fceaf373d797</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;hexo博客迁移&quot;&gt;&lt;a href=&quot;#hexo博客迁移&quot; class=&quot;headerlink&quot; title=&quot;hexo博客迁移&quot;&gt;&lt;/a&gt;hexo博客迁移&lt;/h2&gt;&lt;p&gt;详细内容见参考文献&lt;/p&gt;
&lt;h2 id=&quot;参考文献&quot;&gt;&lt;a href=&quot;#参考文献&quot; cl
      
    
    </summary>
    
      <category term="工具" scheme="http://mxxhcm.github.io/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="hexo" scheme="http://mxxhcm.github.io/tags/hexo/"/>
    
  </entry>
  
  <entry>
    <title>python multiprocessing</title>
    <link href="http://mxxhcm.github.io/2019/04/23/python-multiprocessing/"/>
    <id>http://mxxhcm.github.io/2019/04/23/python-multiprocessing/</id>
    <published>2019-04-23T07:46:14.000Z</published>
    <updated>2019-05-06T16:22:27.708Z</updated>
    
    <content type="html"><![CDATA[<h2 id="python-多线程"><a href="#python-多线程" class="headerlink" title="python 多线程"></a>python 多线程</h2><h3 id="join方法"><a href="#join方法" class="headerlink" title="join方法"></a>join方法</h3><p>用来阻塞当前进程，直到该进程执行完毕，再继续执行后续代码。如下示例<a href="https://github.com/mxxhcm/myown_code/blob/master/tools/process_thread/multiprocessing_join.py" target="_blank" rel="noopener">代码</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> Process,Pool</span><br><span class="line"><span class="keyword">import</span> os,random,time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_proc</span><span class="params">(name)</span>:</span></span><br><span class="line">    time.sleep(<span class="number">2</span>)</span><br><span class="line">    print(<span class="string">"Run child process %s (%s)"</span> % (name,os.getpid()))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    print(<span class="string">"Parent process %s"</span> % os.getpid())</span><br><span class="line">    p = Process(target=run_proc, args=(<span class="string">'test'</span>,))</span><br><span class="line">    print(<span class="string">"child process will start."</span>)</span><br><span class="line">    p.start()</span><br><span class="line">    p.join()</span><br><span class="line">    print(<span class="string">"child process end."</span>)</span><br><span class="line"> </span><br><span class="line">    print(<span class="string">"Parent process %s"</span> % os.getpid())</span><br><span class="line">    p = Process(target=run_proc, args=(<span class="string">'test'</span>,))</span><br><span class="line">    print(<span class="string">"child process will start."</span>)</span><br><span class="line">    p.start()</span><br><span class="line">    <span class="comment"># p.join()</span></span><br><span class="line">    print(<span class="string">"child process end."</span>)</span><br></pre></td></tr></table></figure></p><p>输出结果：</p><blockquote><p>Parent process 7092<br>child process will start.<br>Run child process test (7093)<br>child process end.<br>Parent process 7092<br>child process will start.<br>child process end.<br>Run child process test (7094)</p></blockquote><p>可以看出来，调用join()函数的时候，会等子进程执行完之后再继续执行；而不使用join()函数的话，在子进程开始执行的时候，就会继续向后执行了。</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>1.<a href="https://www.cnblogs.com/lipijin/p/3709903.html" target="_blank" rel="noopener">https://www.cnblogs.com/lipijin/p/3709903.html</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;python-多线程&quot;&gt;&lt;a href=&quot;#python-多线程&quot; class=&quot;headerlink&quot; title=&quot;python 多线程&quot;&gt;&lt;/a&gt;python 多线程&lt;/h2&gt;&lt;h3 id=&quot;join方法&quot;&gt;&lt;a href=&quot;#join方法&quot; class=&quot;
      
    
    </summary>
    
      <category term="python" scheme="http://mxxhcm.github.io/categories/python/"/>
    
    
      <category term="python" scheme="http://mxxhcm.github.io/tags/python/"/>
    
      <category term="multiprocessing" scheme="http://mxxhcm.github.io/tags/multiprocessing/"/>
    
  </entry>
  
  <entry>
    <title>Asynchronous Methods for Deep Reinforcement Learning</title>
    <link href="http://mxxhcm.github.io/2019/04/19/Asynchronous-Methods-for-Deep-Reinforcement-Learning/"/>
    <id>http://mxxhcm.github.io/2019/04/19/Asynchronous-Methods-for-Deep-Reinforcement-Learning/</id>
    <published>2019-04-19T10:11:56.000Z</published>
    <updated>2019-05-06T16:22:27.700Z</updated>
    
    <content type="html"><![CDATA[<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>DQN使用experience replay buffer来稳定学习过程。本文提出了一个新的框架，使用异步的梯度下降稳定学习过程。这个框架既适用于on-policy，也适用于off-policy环境上，即能应用于离散动作空间，也能应用于连续的动作空间，既能训练前馈智能体，也能训练循环智能体。</p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>Online学习是不稳定的，并且online更新是强相关的。DQN通过引入experience replay buffer解决了这个问题，但是DQN只能应用在off policy算法上。总的来说，DQN通过引入replay buffer取得了很大成功，但是replay buffer还有以下的几个缺点：</p><ul><li>在每一步交互的时候使用了更多的内存和计算资源</li><li>它只能应用在off policy的算法上，也就是说权重的更新可能会使用到很久之前的数据。</li></ul><p>这篇文章提出不使用replay buffer，而是使用异步的框架，同时在多个相同的环境中操作多个智能体（每个环境中一个智能体）并行的采集数据。这种并行性也能将智能体的数据分解成更稳定的过程（即和experience replay buffer起到了相同的作用），因为在给定的一个时间步，智能体可能会experience很多个不同的states。<br>这个框架既可以应用在on policy算法，如Sarsa，n-step methods和actor-critc等方法上，也可以应用在off policy算法如Q-learning上。</p><h2 id="异步框架"><a href="#异步框架" class="headerlink" title="异步框架"></a>异步框架</h2><p>作者给出了一个框架，将够将on-policy search的actor-critic方法以及off-policy value-based的Q-learning方法都包括进去。<br>具体的，使用一台机器上的多CPU线程，这样子可以避免在不同机器上传递参数和梯度的消耗。然后，多个并行的actor-learner可能会探索环境的不同部分，每个actor-learner可以设置不同的exploration policy。不同的thread运行不同的exploration policy，多个actor-learner并行执行online update可能比单智能体更新在时间上更不相关。所以这里使用了不同的探索策略取代了DQN中buffer稳定学习过程的作用。<br>除了稳定学习过程之外，多个actor-learner还可以减少训练时间，此外，不使用buffer以后还可以使用on-policy的方法进行训练。</p><p><strong>总的来说，下面要介绍的四个算法，前面三个算法都使用了target network，第四个A3C算法没有使用target network。最重要的是所有四个算法都使用了多个actor-learner进行训练，并且使用累计的梯度进行更新（相当于batch的作用）。总共出现了三类参数，一类是network参数，一类是target network参数，一类是thread-specific（每个线程的参数）的参数。thread-specific参数是每个线程自己持有的，通过更新每个线程的参数更新network的参数，然后使用network的参数更新target network的参数，target network参数比network参数更新的要慢很多。<br>A3C算法的实质就是在多个线程中同步训练。分为主网络和线程中的网络，主网络不需要训练，主要用来存储和传递参数，每个线程中的网络用来训练参数。总的来说，多个线程同时训练提高了效率，另一方面，减小了数据之间的相关性，比如，线程$1$和$2$中都用主网络复制来的参数计算梯度，但是同一时刻只能有一个线程更新主网络的参数，比如线程$1$更新主网络的参数，那么线程$2$利用原来主网络参数计算的梯度会更新在线程$1$更新完之后的主网络参数上。</strong></p><h3 id="异步的one-step-Q-learning"><a href="#异步的one-step-Q-learning" class="headerlink" title="异步的one-step Q-learning"></a>异步的one-step Q-learning</h3><ul><li>每个thread都和它自己的环境副本进行交互，在每一个时间步计算Q-learning loss的梯度。</li><li>通过使用不同的exploration策略，可以改进性能，这里实现exploration policy不同的方式就是使用$\epsilon$的不同取值实现。</li><li>使用一个共享的更新的比较缓慢的target network，就是和DQN中的target network一样。</li><li>同时也使用多个时间步上的累计梯度，和batch挺像的，这就减少了multi actor learner重写其他更新的可能性，同时也在计算效率和数据效率方面做了一个权衡。</li></ul><h4 id="伪代码"><a href="#伪代码" class="headerlink" title="伪代码"></a>伪代码</h4><p><strong>Algorithm 1</strong> 异步的one-step Q-learning－－每个actor-learn线程的伪代码<br>用$\theta,\theta^{-}$表示全局共享参数，计数器$T=0$，<br>初始化线程时间步计数器$t\leftarrow 0$，<br>初始化target network权重$\theta^{-} \leftarrow 0$,<br>初始化network梯度$d\theta\leftarrow 0$，<br>初始化，得到初始状态$s$，<br><strong>repeat</strong><br>$\qquad$使用$\epsilon-$greedy策略采取action $a$，<br>$\qquad$接收下一个状态$s’$和reward $r$，<br>$\qquad$设置target value，$y=\begin{cases}r,&amp;for\ terminal\ s’ \r+\gamma max<em>{a’}Q(s’,a’;\theta^{-}), &amp;for\ non-terminal\ s’\end{cases}$<br>$\qquad$累计和$\theta$相关的梯度：$d\theta \leftarrow d\theta+\frac{\partial (y-Q(s,a;\theta))^2}{\partial \theta}$<br>$\qquad s\leftarrow s’$<br>$\qquad T\leftarrow T+1, t\leftarrow t+1$<br>$\qquad$<strong>if</strong> $T\ \ mod\ \ I</em>{target} ==0 $，那么<br>$\qquad\qquad$更新target network $\theta^{-}\leftarrow 0$<br>$\qquad$<strong>end if</strong><br>$\qquad$<strong>if</strong> $t\ \ mod\ \ I<em>{AsyncUpdate} ==0$或者$s$是terminal state，那么<br>$\qquad\qquad$使用$d\theta$异步更新$\theta$<br>$\qquad\qquad$将累计梯度$d\theta\leftarrow 0$<br>$\qquad$<strong>end if</strong><br><strong>until</strong> $T\ge T</em>{max}$</p><h3 id="异步的one-step-Sarsa"><a href="#异步的one-step-Sarsa" class="headerlink" title="异步的one-step Sarsa"></a>异步的one-step Sarsa</h3><h4 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h4><ul><li>和算法$1$很像，$Q-learning$计算target value使用$r+\gamma max_{a’}Q(s’,a’;\theta^{-})$，而Sarsa计算target value使用$r+\gamma Q(s’,a’;\theta^{-})$，即Q-learning的bahaviour policy和评估的策略是不一样的，而Sarsa的behaviour policy和评估策略是一样的。</li><li>使用target network，</li><li>同时使用多个时间步的累计梯度更新用来稳定学习过程。</li></ul><h4 id="伪代码-1"><a href="#伪代码-1" class="headerlink" title="伪代码"></a>伪代码</h4><p>和算法$1$很像。</p><h3 id="异步的n-step-Q-learning"><a href="#异步的n-step-Q-learning" class="headerlink" title="异步的n-step Q-learning"></a>异步的n-step Q-learning</h3><h4 id="概述-1"><a href="#概述-1" class="headerlink" title="概述"></a>概述</h4><ul><li>计算$n-step$的return</li><li>在计算一次更新的时候，使用exploration policy采样到$t<em>{max}$步或者到terminal state。然后累加从上次更新到$t</em>{max}$时间步的reward。</li><li>然后计算$n-step$更新对于上次更新之后所有state-action的梯度。</li><li>使用单个时间步中的累计梯度进行更新。</li><li>使用了target network。</li></ul><h4 id="伪代码-2"><a href="#伪代码-2" class="headerlink" title="伪代码"></a>伪代码</h4><p><strong>Algorithm 2</strong> 异步的n-step Q-learning算法－－每个actor-learner线程的伪代码<br>用$\theta,\theta^{-}$表示全局共享的network参数和target network参数，用$T=0$表示全局共享计数器。<br>初始化线程步计数器$t\leftarrow 1$，<br>初始化target network参数$\theta^{-}\leftarrow \theta$<br>初始化每个线程的参数参数$\theta^{-}\leftarrow \theta$<br>初始化网络梯度$d\theta\leftarrow 0$<br><strong>repeat</strong><br>$\qquad$重置累计梯度$d\theta\leftarrow0$<br>$\qquad$同步每个线程的参数$\theta’=\theta$<br>$\qquad t<em>{start}=t$<br>$\qquad$得到$s_t$<br>$\qquad$<strong>repeat</strong><br>$\qquad\qquad$根据基于$Q(s_t,a;\theta’)$的$\epsilon-greedy$策略执行动作$a_t$，<br>$\qquad\qquad$接收下一个状态$s</em>{t+1}$和reward $r<em>t$，<br>$\qquad\qquad T\leftarrow T+1, t\leftarrow t+1$<br>$\qquad$ <strong>until</strong> terminal $s_t$或者$t-t</em>{start}==t<em>{max}$<br>$\qquad$设置奖励$R=\begin{cases}0,&amp;for\ terminal\ s_t\max_aQ(s_t,a;\theta^{-}), &amp;for\ non-terminal\ s_t\end{cases}$<br>$\qquad$<strong>for</strong> $i\in{t-1,\cdots,t</em>{start}}$ do<br>$\qquad\qquad R\leftarrow r<em>i+\gamma R$<br>$\qquad\qquad$累计和$\theta’$相关的梯度：$d\theta \leftarrow d\theta+\frac{\partial (R-Q(s_t,a;\theta’))^2}{\partial \theta’}$<br>$\qquad$<strong>end for</strong><br>$\qquad$使用$d\theta$异步更新$\theta$.<br>$\qquad$<strong>if</strong>$\quad T\quad mod\quad I</em>{target}==0$那么<br>$\qquad\qquad\theta^{-}\leftarrow \theta$<br>$\qquad$<strong>end if</strong><br><strong>until</strong> $T\gt T_{max}$</p><h3 id="异步的advantage-actor-critic"><a href="#异步的advantage-actor-critic" class="headerlink" title="异步的advantage actor-critic"></a>异步的advantage actor-critic</h3><h4 id="概述-2"><a href="#概述-2" class="headerlink" title="概述"></a>概述</h4><ul><li>A3C算法，是一个actor-critic方法，使用值函数$V(s_t;\theta_v)$辅助学习policy $\pi(a_t|s_t;\theta)$，同时这里使用$n-step$的returns更新policy和value function。</li><li>每隔$t_{max}$个action更新一次或者到了terminal state更新一次。</li><li>Actor的更新方向为$\nabla<em>{\theta’}log\pi(a_t|s_t;\theta’)A(s_t,a_t;\theta,\theta_v)$，其中$A$是advantage function的一个估计，通过$\sum</em>{i=0}^{k-1}\gamma^ir<em>{t+i}+\gamma^kV(s</em>{t+k};\theta_v) - V(s_t;\theta_v)$计算。</li><li>这里同样使用并行的actor-learner和累计的梯度用来稳定学习。$\theta$和$\theta_v$在实现上通常共享参数。</li><li>添加entropy正则项鼓励exploration。包含了正则化项的的objective function的梯度为$\nabla<em>{\theta’}log\pi(a_t|s_t;\theta’)(R_t-V(s_t;\theta_v))+\beta\nabla</em>{\theta’}H(\pi(s<em>t;\theta’))$。这里的$R$就是上面的$\sum</em>{i=0}^{k-1}\gamma^ir<em>{t+i}+\gamma^kV(s</em>{t+k};\theta_v) - V(s_t;\theta_v)$。</li><li>Critic的更新方向通过最小化loss来实现，这里的loss指的是TD-error，即$\sum<em>{i=0}^{k-1}\gamma^ir</em>{t+i} + \gamma^kV(s_{t+k};\theta_v) - V(s_t;\theta_v)$。</li><li>没有使用target network。</li></ul><h4 id="伪代码-3"><a href="#伪代码-3" class="headerlink" title="伪代码"></a>伪代码</h4><p><strong>Algorithm 3</strong> 异步的actor-critic－－每个actor-learn线程的伪代码<br>用$\theta,\theta<em>v$表示全局共享参数，用$T=0$表示全局共享计数器，<br>用$\theta’,\theta’_v$表示每个线程中的参数<br>初始化线程步计数器$t\leftarrow 1$，<br><strong>repeat</strong><br>$\qquad$重置梯度$d\theta\leftarrow 0,d\theta_v\leftarrow 0$，<br>$\qquad$同步线程参数$\theta’=\theta,\theta’_v=\theta_v$<br>$\qquad t</em>{start}=t$<br>$\qquad$得到状态$s<em>t$，<br>$\qquad$<strong>repeat</strong><br>$\qquad\qquad$根据策略$\pi(a_t|s_t;\theta’)$执行动作$a_t$，<br>$\qquad\qquad$接收下一个状态$s</em>{t+1}$和reward $r<em>t$，<br>$\qquad\qquad T\leftarrow T+1, t\leftarrow t+1$<br>$\qquad$ <strong>until</strong> terminal $s_t$或者$t-t</em>{start}==t<em>{max}$<br>$\qquad$设置奖励$R=\begin{cases}0,&amp;for\ terminal\ s_t\V(s_t,\theta’_v), &amp;for\ non-terminal\ s_t\end{cases}$<br>$\qquad$<strong>for</strong> $i\in{t-1,\cdots,t</em>{start}}$ do<br>$\qquad\qquad R\leftarrow r<em>i+\gamma R$<br>$\qquad\qquad$累计和$\theta’$相关的梯度：$d\theta \leftarrow d\theta+\frac{\partial (y-Q(s,a;\theta))^2}{\partial \theta}$<br>$\qquad\qquad$累计和$\theta’_v$相关的梯度：$d\theta_v \leftarrow d\theta_v+\frac{\partial (R-V(s_i;\theta’_v))^2}{\partial \theta’_v}$<br>$\qquad$<strong>end for</strong><br>$\qquad$使用$d\theta$异步更新$\theta$，使用$d\theta_v$异步更新$\theta_v$.<br><strong>until</strong> $T\ge T</em>{max}$</p><h3 id="优化方法"><a href="#优化方法" class="headerlink" title="优化方法"></a>优化方法</h3><p>作者尝试了三种不同的优化方法，带有momentum的SGD，带有共享statistics的RMSProp以及不带shared statistics的RMSProp。</p><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><h3 id="优化细节"><a href="#优化细节" class="headerlink" title="优化细节"></a>优化细节</h3><p>作者在异步框架中测试了两个优化算法SGD和RMSProp，并且因为效率原因没有使用线程锁。</p><h3 id="设置"><a href="#设置" class="headerlink" title="设置"></a>设置</h3><ul><li>Atari环境中，每个实验使用$16$个actor-learner线程。</li><li>所有方法都每隔$5$个actions更新一次，并且使用共享的RMSProp进行优化。</li><li>三个异步的value-based算法使用每隔$40000$帧更新的共享target network，</li><li>使用了DQN中action repeat of $4$.</li><li>网络架构和DQN一样</li><li>基于值的方法只有一个线性输出层，每个输出单元代表一个action的值。</li><li>actor-critic方法有两个输出层，一个softmax表示选择某一个action的概率，一个线性输出代表值函数。</li><li>所有实验使用的$\gamma=0.99$，RMSProp的衰减因子$\alpha = 0.99$。</li><li>Value-based方法采用的exploration rate $\epsilon$有是三个取值$\epsilon_1,\epsilon_2,\epsilon_3$，相应的概率为$0.4,0.3,0.3$，它们的值在前$4$百万帧中从$1$退火到$0.1,0.01,0.5$。</li><li>A3C使用了entropy进行正则化，entropy项的权重为$\beta=0.01$</li><li>初始学习率从分布$LogUniform(10^{-4},10^{-2})$中进行采样，在训练过程中退火到$0$。</li></ul><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><h3 id="地址"><a href="#地址" class="headerlink" title="地址"></a>地址</h3><p><a href="https://github.com/ikostrikov/pytorch-a3c" target="_blank" rel="noopener">https://github.com/ikostrikov/pytorch-a3c</a></p><h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><p>如果直接git下来运行的话，会出问题，需要在main()下加上这样一句<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mp.set_start_method(<span class="string">"forkserver"</span>)</span><br></pre></td></tr></table></figure></p><p>可能是因为Unix系统默认的多进程方式是fork，这里只要不设置为fork,设置为其他两种方式spawn, forkserver都行。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;摘要&quot;&gt;&lt;a href=&quot;#摘要&quot; class=&quot;headerlink&quot; title=&quot;摘要&quot;&gt;&lt;/a&gt;摘要&lt;/h2&gt;&lt;p&gt;DQN使用experience replay buffer来稳定学习过程。本文提出了一个新的框架，使用异步的梯度下降稳定学习过程。这个框架既
      
    
    </summary>
    
      <category term="强化学习" scheme="http://mxxhcm.github.io/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="强化学习" scheme="http://mxxhcm.github.io/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="A3C" scheme="http://mxxhcm.github.io/tags/A3C/"/>
    
  </entry>
  
  <entry>
    <title>Distral Robust Multitask Reinforcement Learning</title>
    <link href="http://mxxhcm.github.io/2019/04/18/Distral-Robust-Multitask-Reinforcement-Learning/"/>
    <id>http://mxxhcm.github.io/2019/04/18/Distral-Robust-Multitask-Reinforcement-Learning/</id>
    <published>2019-04-18T03:04:22.000Z</published>
    <updated>2019-05-06T16:22:27.700Z</updated>
    
    <content type="html"><![CDATA[<p>这篇文章给出了多任务学习和迁移学习的一个框架。</p><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>使用共享网络参数的multitas learning，然后在不同的任务之间迁移可以提高效率。但是这种方法有几个缺点：</p><ul><li>不同任务的gradient可能相互干扰，让学习变得不稳定，甚至很低效。</li><li>另一个问题是不同任务的reward scheme不同，可能会让其中的某一个reward占主导地位。</li></ul><p>本文提出了Distral方法，并不是使用共享参数，而是使用一个提炼的policy去学习不同任务的公共行为。每一个worker解决它自己的任务，但是需要加一个限制条件，每一个单独的策略需要离提炼出的共享策略足够近，而提炼的共享策略需要在所有单独策略的质心上，通过优化一个联合的目标函数，这两个过程都可以实现。</p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>由于DRL需要的训练时间和训练数据很多，现在的DRL问题逐渐向单独的智能体（同时或者连续的）解决多个相关问题移动。由于巨大的计算开销，这个方向的研究需要设计出非常鲁棒的，与具体任务无关的算法。直观上来说，因为不同的相关任务有共同的结构，所以我们觉得它们一块应该能够促进学习，然而事实上，在实践中我们并不能总是得到这个结论。所以，multitask和transfer learning可以需要解决一个问题，在多个任务上训练会对单个任务的训练产生负面影响。所以就需要使用一些方法来结局这个问题。事实上，其他任务的梯度可能会被当做做一年，干扰学习，甚至极端情况下，其中一个任务可能会主导其他的任务。<br>在这篇论文中，作者提出了一种multitask和transfer RL算法，给出一些算法实例，它能够高效的跨任务共享behaviour structure。除了在grid world领域的一些指导性illustration(例证)，作者还在DeepMind Lab $3D$环境中详细分析了最终的算法和A3C baseline的比较。作者验证了Distral算法学习的很快，而且能够达到很好的收敛性能，而且对超参数很鲁棒，比multitask A3C baselines要稳定的多。</p><h2 id="Distral-Distill-and-Transfer-Learning"><a href="#Distral-Distill-and-Transfer-Learning" class="headerlink" title="Distral: Distill and Transfer Learning"></a>Distral: Distill and Transfer Learning</h2><p>作者给出了一个同时训练多个任务的框架，叫做Distral。如下图所示，作者给出了从四个任务中提取shared policy的一个例子。该方法用一个shared policy去提取task-specific的polices之间的common behaviour和representation，然后又用这个shared policy使用KL散度去正则化task-specific polices。这里使用KL散度的作用相当于shaping reward，鼓励exploration。最后，这些相关任务中的common knowledge都被提炼到shared policy中去了，然后可以迁移到其他任务中去。<br><img src="/2019/04/18/Distral-Robust-Multitask-Reinforcement-Learning/figure1.png" alt="figure1"></p><h3 id="数学框架"><a href="#数学框架" class="headerlink" title="数学框架"></a>数学框架</h3><p>一个multitask RL任务中，假设有$n$个任务，折扣因子为$\gamma$，它们的state space和action space是相同的，但是每个任务$i$的状态转换概率$p<em>i(s’|s,a)$和奖励函数$R_i(s,a)$是不同的，用$\pi_i$表示第$i$个任务的stochastic polices。给定从一些初始状态开始的state和action联合分布的轨迹，用$\pi_i$表示dynamics和polices。<br>作者通过优化一个expected return和policy regularization组成的目标函数将学习不同任务的policy联系起来。用$\pi_0$表示要提取的shared policy，然后通过使用$\pi_0$和$\pi_i$的KL散度$\mathbb{E}</em>{\pi<em>i}\left[\sum</em>{t\ge 0}\gamma^tlog\frac{\pi<em>i(a_t|s_t)}{\pi_0(s_t|a_t)}\right]$正则化使所有的策略$\pi_i$向$\pi_0$移动。此外，作者还使用了一个带折扣因子的entropy正则化项鼓励exploration。系统越混乱，entropy越大，所以exploration越多，采取的动作越随机，entropy就越大。最后总的优化目标就变成了：<br>\begin{align*}<br>J(\pi_0, {\pi_i}</em>{i=1}^n) &amp;=\sum<em>i\mathbb{E}</em>{\pi<em>i}\left[\sum</em>{t\ge 0}\gamma^tR<em>i(s_t,a_t) -c</em>{KL}\gamma^tlog\frac{\pi<em>i(a_t|s_t)}{\pi_0(a_t|s_t)}-c</em>{Ent}\gamma^tlog\pi<em>i(a_t|s_t)\right]\<br>&amp;=\sum_i\mathbb{E}</em>{\pi<em>i}\left[\sum</em>{t\ge 0}\gamma^tR<em>i(s_t,a_t) - c</em>{KL}\gamma^tlog{\pi<em>i(a_t|s_t)} + c</em>{KL}\gamma^tlog{\pi<em>0(a_t|s_t)} - c</em>{Ent}\gamma^tlog\pi<em>i(a_t|s_t)\right]\<br>&amp;=\sum_i\mathbb{E}</em>{\pi<em>i}\left[\sum</em>{t\ge 0}\gamma^tR<em>i(s_t,a_t) + c</em>{KL}\gamma^tlog{\pi<em>0(a_t|s_t)} - (c</em>{Ent}\gamma^t + c<em>{KL}\gamma^t)log\pi_i(a_t|s_t)\right]\<br>&amp;=\sum_i\mathbb{E}</em>{\pi<em>i}\left[\sum</em>{t\ge 0}\gamma^tR<em>i(s_t,a_t) +\frac{\gamma^t\alpha}{\beta}log{\pi_0(a_t|s_t)}-\frac{\gamma^t}{\beta}log\pi_i(a_t|s_t)\right], \tag{1}<br>\end{align*}<br>其中$c</em>{KL},c<em>{Ent}\ge 0$是控制KL散度正则化项和entropy正则化项大小的超参数，$\alpha = \frac{c</em>{KL}}{c<em>{KL}+c</em>{Ent}},\beta = \frac{1}{c<em>{KL}+c</em>{Ent}}。log\pi<em>0(a_t|s_t)$可以看成reward shaping，鼓励大概率的action；而entropy项$-log\pi_i(a_t|s_t)$鼓励exploration。在这个公式中，设置所有任务的正则化系数$c</em>{KL}$和$c_{Ent}$都是相同的，如果不同任务的reward scale不同，可以根据具体情况给相应任务设定相应系数。</p><h3 id="Soft-Q-Learing"><a href="#Soft-Q-Learing" class="headerlink" title="Soft Q-Learing"></a>Soft Q-Learing</h3><p>这一节在表格形式的情况下使用和EM算法类似的策略优化目标函数－－固定$\pi_0$优化$\pi_i$，固定$\pi_i$然后优化$\pi_0$。当$\pi_0$固定的时候，式子(1)可以分解成每个任务的最大化问题，即优化每个任务的entropy正则化return，return使用的是正则化reward $R’_i(s,a) = R_i(s,a) + \frac{\alpha}{\beta}log\pi_0(a|s)$，正则化后的return可以使用G-learning来优化（这里说的应该是原来的return和R什么都没，这里都加上了正则化）。根据Soft Q-Learning(G-learning)的证明，给定$\pi_0$，我们能得到以下的关系：</p><script type="math/tex; mode=display">\pi_i(a_t|s_t) = \pi_0^{\alpha}(a_t|s_t)e^{\beta Q_i(a_t|s_t)-\beta V(s_t)} = \pi_0^{\alpha}(a_t|s_t)e^{\beta A_i(a_t|s_t)} \tag{2}</script><p>其中$A_i(s,a) = Q_i(s,a)-V_i(s)$是advantage function，$\pi_0$可以看成是一个policy prior，<strong>需要注意的是这里多了一个指数$\alpha \lt 1$，这是多出来的entropy项的影响，soften了$\pi_0$对$\pi_i$的影响</strong>。$V$和$Q$是新定义的一种state value和action value，使用推导的softened Bellman公式更新：</p><script type="math/tex; mode=display">V_i(s_t) = \frac{1}{\beta} log\sum_{a_t}\pi_0^{\alpha}(a_t|s_t)e^{\beta Q_i(s_t,a_t)} \tag{3}</script><script type="math/tex; mode=display">Q_i(s_t,a_t) = R_i(s_t, a_t)+ \gamma \sum_{s_t}p_i(s_{t+1}|s_t,a_t)V_i(s_{t+1}) \tag{4}</script><p>这个Bellman update公式是softened的，因为state value $V_i$在actions上的max操作被温度$\beta$倒数上的soft-max操作代替了，当$\beta\rightarrow\infty$时，就变成了max 操作，这里有些不明白。为什么呢？这个我不理解有什么关系，这是这篇文章给出的解释。<strong>按照我的理解，这个和我们平常使用Bellman 期望公式或者最优等式没有什么关系，只是给了一种新的更新Q值和V值的方法。实际上，这两个公式都是根据推导给出的定义。</strong><br>还有一点：$\pi_0$是学出来的，而不是手动选出来的。式子(1)中和$\pi_0$相关的只有：</p><script type="math/tex; mode=display">\frac{\alpha}{\beta}\sum_i\mathbb{E_{\pi_i}}\left[\sum_{t\ge 0}\gamma^tlog\pi_0(a_t|s_t) \right]\tag{5}</script><p>可以看出来，这是使用$\pi<em>0$去拟合一个混合的带折扣因子$\gamma$的state-action分布，每个$i$代表一个任务，可以使用最大似然估计来求解，如果是非表格情况的话，可以使用stochastic gradient ascent进行优化，但是需要注意的是本文中作者使用的目标函数多了一个KL散度。另一个区别是本文的distilled policy可以作为下一步要优化的task policy的反馈。<br>多加一个entropy正则项的意义？如果不加entropy正则化，也就是式子$(2)$中的$\alpha = 1$，考虑$n=1$时的例子，式子$(5)$在$\pi_0=\pi_1$的时候最大，KL散度为$0$，目标函数退化成了一个没有正则化项的expected return，最终策略$\pi_1$会收敛到一个局部最优值。<strong>和TRPO的一个比较？？？未完待续。。。。</strong>如果$\alpha\lt 1$，式(1)中有一个额外的entropy项。这样即使$\pi_0=\pi_1$，$KL(\pi_1||\pi_0)=0$，因为有entropy项，也无法通过greedy策略最大化式子$(1)$。式子$1$的entropy正则化系数变成了$\beta’=\frac{\beta}{1-\alpha} = \frac{1}{c</em>{Ent}}$（第一个等号是为什么？？是因为$\pi<em>0=\pi_1$，然后就可以将$\pi_0,\pi_i$的系数合并了），最优的策略就是$\beta’$处的Boltzmann policy。添加这个entropy项可以保证策略不是greedy的，通过调整$c</em>{Ent}$的大小可以调整exploration。<br>最开始的时候，exploration是在multitask任务上加的，如果有多个任务，一个很简单，而其他的很复杂，如果先遇到了简单任务，没有加entropy的话，最后就会收敛到最简单任务的greedy策略，这样子就无法充分探索其他任务的，导致陷入到次优解。对于single-task的RL来说，在A3C中提出用entropy取应对过早的收敛，作者在这里推广到了multitask任务上。</p><h3 id="Policy-Gradient-and-a-Better-Parameterization"><a href="#Policy-Gradient-and-a-Better-Parameterization" class="headerlink" title="Policy Gradient and a Better Parameterization"></a>Policy Gradient and a Better Parameterization</h3><p>上面一节讲的是表格形式的计算，给定$\pi_0$，首先求解出$\pi$对应的$V$和$Q$，然后写出$\pi_i$的解析。但是如果我们用神经网络等函数去拟合$V$和$Q$，$V$和$Q$的求解特别慢，这里使用梯度下降同时优化task polices和distilled policy。这种情况下，$\pi_i$的梯度更新通过求带有entropy正则化的return即可求出来，并且可以放在如actor-critic之类的框架中。<br>每一个$\pi_i$都用一个单独的网络表示，$\pi_0$也用一个单独的网络表示，用$\theta_0$表示$\pi_0$的参数，对应的policy表示为：</p><script type="math/tex; mode=display">\hat{\pi_0}(a_t|s_t) = \frac{e^{(h_{\theta_0}(a_t|s_t))}}{\sum_{a'}e^{h_{\theta_0}(a'|s_t)}} \tag{6}</script><p>使用参数为$\theta<em>i$的神经网络表示$Q$值，用$f</em>{\theta_i}$表示第$i$个策略$\pi$的$Q$值，用$Q$表示$V$，再估计$A=Q-V$的值：</p><script type="math/tex; mode=display">\hat{A}_i(a_t|s_t) = f_{\theta_i}(a_t|s_t) - \frac{1}{\beta}log\sum_a\hat{\pi}_0^{\alpha}(a|s_t)e^{\beta f_{\theta_i}(a|s_t)} \tag{7}</script><p>将式子$(7)$代入式子$(2)$得第$i$个任务的policy可以参数化为：<br>\begin{align*}<br>\hat{\pi}<em>i(a_t|s_t)<br>&amp; = \hat{\pi}_0^{\alpha}(a_t|s_t)e^{\left(\beta \hat{Q}_i(a_t|s_t)-\beta \hat{V}(s_t)\right)}\<br>&amp; = \hat{\pi}_0^{\alpha}(a_t|s_t)e^{\left(\beta \hat{A}_i(a_t|s_t)\right)}\<br>&amp; = \hat{\pi}_0^{\alpha}(a_t|s_t)e^{\left(\beta \left(f</em>{\theta<em>i}(a_t|s_t) - \frac{1}{\beta}log\sum_a\hat{\pi}_0^{\alpha}(a|s_t)e^{\beta f</em>{\theta<em>i}(a|s_t)}\right)\right)}\<br>&amp; = \hat{\pi}_0^{\alpha}(a_t|s_t)e^{\left(\beta f</em>{\theta<em>i}(a_t|s_t) - log\sum_a\hat{\pi}_0^{\alpha}(a|s_t)e^{\beta f</em>{\theta<em>i}(a|s_t)}\right)}\<br>&amp; = \left(\frac{e^{(h</em>{\theta<em>0}(a_t|s_t))}}{\sum</em>{a’}e^{h<em>{\theta_0}(a’|s_t)}}\right)^{\alpha}e^{\left(\beta f</em>{\theta<em>i}(a_t|s_t) - log\sum_a\hat{\pi}_0^{\alpha}(a|s_t)e^{\beta f</em>{\theta<em>i}(a|s_t)}\right)}\<br>&amp; = \left(\frac{e^{(h</em>{\theta<em>0}(a_t|s_t))}}{\sum</em>{a’}e^{h<em>{\theta_0}(a’|s_t)}}\right)^{\alpha}<br>      \cdot<br>       \frac{e^{\beta f</em>{\theta<em>i}(a_t|s_t)}}   {e^{log\sum_a\hat{\pi}_0^{\alpha}(a|s_t)e^{\beta f</em>{\theta<em>i}(a|s_t)}}}\<br>&amp; = \frac{\left(e^{(h</em>{\theta<em>0}(a_t|s_t))}\right)^{\alpha}}  {\left(\sum</em>{a’}e^{h<em>{\theta_0}(a’|s_t)}\right)^{\alpha}}<br>      \cdot<br>         \frac{e^{\beta f</em>{\theta<em>i}(a_t|s_t)}}   {e^{log\sum_a\hat{\pi}_0^{\alpha}(a|s_t)e^{\beta f</em>{\theta<em>i}(a|s_t)}}}\<br>&amp; = \frac{e^{\alpha \cdot(h</em>{\theta<em>0}(a_t|s_t))}}   {\left(\sum</em>{a’}e^{h<em>{\theta_0}(a’|s_t)}\right)^{\alpha}}<br>      \cdot<br>         \frac{e^{\beta f</em>{\theta<em>i}(a_t|s_t)}}{e^{log\sum_a\hat{\pi}_0^{\alpha}(a|s_t)e^{\beta f</em>{\theta<em>i}(a|s_t)}}}\<br>&amp; = \frac{e^{(\alpha h</em>{\theta<em>0}(a_t|s_t))}}  {\left(\sum</em>{a’}e^{h<em>{\theta_0}(a’|s_t)}\right)^{\alpha}}<br>      \cdot<br>        \frac{e^{\beta f</em>{\theta<em>i}(a_t|s_t)}}{\sum_a\hat{\pi}_0^{\alpha}(a|s_t)e^{\beta f</em>{\theta<em>i}(a|s_t)}}\<br>&amp; = \frac{e^{(\alpha h</em>{\theta<em>0}(a_t|s_t))} \cdot e^{\beta f</em>{\theta<em>i}(a_t|s_t) }}<br>         {\left(\sum</em>{a’}e^{h<em>{\theta_0}(a’|s_t)}\right)^{\alpha} \cdot {\sum_a\hat{\pi}_0^{\alpha}(a|s_t) e^{\beta f</em>{\theta<em>i}(a|s_t)}}}\<br>&amp; = \frac{e^{(\alpha h</em>{\theta<em>0}(a_t|s_t) + \beta f</em>{\theta<em>i}(a_t|s_t)) }}<br>         {\left(\sum</em>{a’}e^{h<em>{\theta_0}(a’|s_t)}\right)^{\alpha} \cdot {\sum_a\hat{\pi}_0^{\alpha}(a|s_t) e^{\beta f</em>{\theta<em>i}(a|s_t)}}}(Why to blow equation???)\<br>&amp; = \frac{e^{(\alpha h</em>{\theta<em>0}(a_t|s_t) + \beta f</em>{\theta<em>i}(a_t|s_t))}}  {\sum</em>{a’}e^{(\alpha h<em>{\theta_0}(a’|s_t) + \beta f</em>{\theta_i}(a’|s_t))}}<br>\end{align*}<br>所以：</p><script type="math/tex; mode=display">\hat{\pi}_i(a_t|s_t) = \hat{\pi}_0^{\alpha}(a_t|s_t)e^{(\beta\hat{A}_i(a_t|s_t))}=\frac{e^{(\alpha h_{\theta_0}(a_t|s_t) + \beta f_{\theta_i}(a_t|s_t))}}{\sum_{a'}e^{(\alpha h_{\theta_0}(a'|s_t) + \beta f_{\theta_i}(a'|s_t))}} \tag{8}</script><p>这可以看成policy的一个两列架构，一列是提取的shared policy，一列是将$\pi<em>0$应用到task $i$上需要做的一些修改。<br>使用参数化的$\pi_0, \pi_i$，首先推导策略相对于$\pi_i$的梯度（policy gradient的推导，这里是直接应用了)：<br>\begin{align*}<br>\nabla</em>{\theta<em>i}J&amp; = \mathbb{E}</em>{\hat{\pi}<em>i}\left[\left(\sum</em>{t\gt 1} \nabla<em>{\theta_i}log{\hat{\pi}}_i(a_t|s_t)\right) \left(\sum</em>{u\ge 1}\gamma^u \left(R^{reg}<em>i(a_u,s_u)\right)\right) \right]\<br>&amp; = \mathbb{E}</em>{\hat{\pi}<em>i}\left[\sum</em>{t\gt 1} \nabla<em>{\theta_i}log\hat{\pi}_i(a_t|s_t)\left(\sum</em>{u\ge t}\gamma^u \left(R^{reg}<em>i(a_u,s_u)\right)\right) \right] \tag{9}\<br>\end{align*}<br>其中$R_i^{reg}(s,a) = R_i(s,a) + \frac{\alpha}{\beta}log\hat{\pi}_0(a|s) - \frac{1}{\beta}log\hat{\pi}_i(a|s)$是正则化后的reward。注意，这里$\mathbb{E}</em>{\hat{\pi}<em>i}\left[\nabla</em>{\theta<em>i}log\hat{\pi}_i(a_t|s_t)\right] = 0$，因为log-derivative trick。如果有一个value baseline，那么为了减少梯度的方差，可以从正则化后的returns中减去它。<br>关于$\theta_0$的梯度如下：<br>\begin{align*}<br>\nabla</em>{\theta<em>0}J<br>&amp; = \mathbb{E}</em>{\hat{\pi}<em>i}<br>\left[<br>    \sum</em>{t\gt 1} \nabla<em>{\theta_i}log\hat{\pi}_i(a_t|s_t)<br>        \left(\sum</em>{u\ge 1}\gamma^u<br>             \left(<br>                R^{reg}<em>i(a_u,s_u)<br>             \right)<br>        \right)<br>\right]\<br>&amp; \qquad +\frac{\alpha}{\beta}\sum_i\mathbb{E}</em>{\hat{\pi}<em>i}<br>\left[<br>    \sum</em>{t\ge 1}\gamma^t\sum<em>{a’_t}<br>        \left(<br>             \hat{\pi}_i(a’_t|s_t)-\hat{\pi}_0(a’_t|s_t)<br>        \right)<br>            \nabla</em>{\theta<em>0}h</em>{\theta_0}(a’_t|s_t)<br>\right] \tag{10}<br>\end{align*}<br>第一项和$\pi_i$一样，第二项是让$\hat{\pi}_i,\hat{\pi}_0$的概率尽可能接近。如果不使用KL散度的话，这里就不会有第二项了。KL正则是为了让$\pi_0$在$\pi_i$的质心上，即$\hat{\pi}_0(a’_t|s_t) = \frac{1}{n}\sum_i\hat{\pi}_i(a’_t|s_t)$，最后第二项就为$0$了，可以快速的将公共信息迁移到新任务上。<br>和ADMM,EASGD等在参数空间上进行优化不同的是，Distral是在策略空间上进行优化，这样子在语义上更有意义，对于稳定学习过程很重要。<br>本文的方法通过添加了entropy正则化和KL正则化，使得算法可以分开控制每个任务迁移的信息大小和exploration程序。</p><h2 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h2><p>上面给出的框架可以对不同的目标函数，算法和架构进行组合，然后生成一系列算法实例。</p><ul><li>KL散度和entropy：当$\alpha=0$时，只有entorpy，不同任务之间没有耦合，在不同任务中进行迁移。当$\alpha=1$时，只有KL散度，不同任务之间有耦合，在不同任务中进行迁移，但是如果$\pi_i,\pi_0$很像的话，会过早的停止探索。当$0\lt \alpha \lt 1$时，KL散度和entropy都有。</li><li>迭代优化还是联合优化：可以选择同时优化$\pi_0,\pi_i$，也可以固定其中一个，优化另一个。迭代优化和actor-mimic以及policy-distilled有一些相似，但是Distral是迭代进行的，$\pi_0$会对$\pi_i$的优化提供反馈。尽管迭代优化可能会很慢，但是从actor-mimic等的结果来看，可能它会更稳定。</li><li>Separate还是two-column参数化：这里的意思是$\pi_i$是否使用式子(8)中的$\pi_0$，如果用的话，$\pi_0$中提取到的信息可以立刻用到$\pi_i$上，transfer可以更快。但是如果transfer的太快的话，可能会抑制在单个任务上exploration的有效性。。</li></ul><p>这里作者给出了使用到的一些算法组合，如下表和下图所示。这里作者和三个A3C baseline(三种架构)做了比较，作者做实验的时候，试了两种A3C，第一个是原始的A3C，第二个是A3C的变种，最后发现这两种A3C没啥差别，在实验部分就选择了原始的A3C作比较。</p><p><img src="/2019/04/18/Distral-Robust-Multitask-Reinforcement-Learning/figure2.png" alt="figure2"><br><img src="/2019/04/18/Distral-Robust-Multitask-Reinforcement-Learning/table.png" alt="table"></p><h3 id="Algorithm"><a href="#Algorithm" class="headerlink" title="Algorithm"></a>Algorithm</h3><ul><li>A3C: 在每个任务上单独使用A3C训练的policy</li><li>A3C_multitask: 使用A3C同时在所有任务上训练得到的policy</li><li>A3C_2col: 使用了式子(8)中的two-column架构A3C在每个任务上训练的policy</li><li>KL_1col: $\pi_0,\pi_i$分别用一个网络来表示，令$\alpha=1$，即只有KL散度的式子(1)进行优化，</li><li>KL+ent_1col: 和KL_1col一样，只不过包括了KL散度和entropy项，并设置$\alpha = 0.5$。</li><li>KL_2col: 和KL_1col一样，但是使用了式子(8)中的two-column架构</li><li>KL+ent_2col: 和KL+ent_1col一样，只是使用了two-column架构。</li></ul><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>总共有两个实验，第一个是在grid world上使用soft Q-learning和policy distilltion的迭代优化，第二个是七个算法在三个3D部分可观测环境上的评估。</p><h3 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h3><h4 id="Grid-world"><a href="#Grid-world" class="headerlink" title="Grid world"></a>Grid world</h4><p>这个实验是在一些简单的grid world上进行的，每一个任务通过一个随机选择的goal location进行区分。<br>每一个MDP的state由map location, previous action和previous reward组成。一个Distral智能体通过KL正则化的目标函数进行训练，优化算法在Soft Q-learing和policy distilltion之间进行迭代。每次soft Q-learing 的展开长度是$10$。</p><h4 id="3D环境"><a href="#3D环境" class="headerlink" title="3D环境"></a>3D环境</h4><p>这个实验使用了三个第一人称的$3D$环境。所有的智能体都是用pytorch/tensorflow实现的，每个任务有$32$个workers，使用异步的RMSProp进行学习。每个网络由CNN和LSTM组成，在不同的算法和实验中都是相同的。作者尝试了三个$\beta$和三个学习率$\epsilon$，每一组超参数跑了四次，其他超参数和单任务的A3C都一样的，对于KL+ent 1col和KL+ent 2col算法，$\alpha$被固定为$0.5$。</p><h5 id="Maze"><a href="#Maze" class="headerlink" title="Maze"></a>Maze</h5><p>八个任务，每个任务都是一个随机放置reward和goal的迷宫。作者给出了$7$个算法的学习曲线，每一个学习曲线是选出最好的$\beta,\epsilon$在$8$个任务跑$4$次的平均值。Distral学习的很快，并且超过了三个A3C baselies，而two-column算法比one-column学习的要快，不带entropy的Distral要比带entropy学得快，但是最终得分要低，这可能是没有充分explration的原因。<br>multitask A3C和two-column A3C学习的不稳定，有时候学的好，有时候学的不好，有时候刚开始就不好了。而Distral对于超参数也很鲁棒。</p><h5 id="Navigation"><a href="#Navigation" class="headerlink" title="Navigation"></a>Navigation</h5><p>四个任务，比Maze难度要大。</p><h5 id="Laser-tag"><a href="#Laser-tag" class="headerlink" title="Laser-tag"></a>Laser-tag</h5><p>DeepMind Lab中的八个任务，最好的baseline是单独在每个任务上训练的A3C。</p><h2 id="Discussion"><a href="#Discussion" class="headerlink" title="Discussion"></a>Discussion</h2><p>有两个idea这里需要强调一下。在优化过程中，使用KL散度正则化使$\pi_i$向$\pi_0$移动，使用$\pi_0$正则化$\pi_i$。<br>另一个就是在深度神经网络中，它们的参数没有意义，所以作者不是在参数空间进行的正则化，而是在策略空间进行正则化，这样子更有语义意义。</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>1.<a href="https://papers.nips.cc/paper/7036-distral-robust-multitask-reinforcement-learning.pdf" target="_blank" rel="noopener">https://papers.nips.cc/paper/7036-distral-robust-multitask-reinforcement-learning.pdf</a><br>2.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;这篇文章给出了多任务学习和迁移学习的一个框架。&lt;/p&gt;
&lt;h2 id=&quot;摘要&quot;&gt;&lt;a href=&quot;#摘要&quot; class=&quot;headerlink&quot; title=&quot;摘要&quot;&gt;&lt;/a&gt;摘要&lt;/h2&gt;&lt;p&gt;使用共享网络参数的multitas learning，然后在不同的任务之间迁移
      
    
    </summary>
    
      <category term="强化学习" scheme="http://mxxhcm.github.io/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="强化学习" scheme="http://mxxhcm.github.io/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="论文" scheme="http://mxxhcm.github.io/tags/%E8%AE%BA%E6%96%87/"/>
    
  </entry>
  
  <entry>
    <title>Policy Gradient Methods for Reinforcement Learning with Function Approximation</title>
    <link href="http://mxxhcm.github.io/2019/04/17/Policy-Gradient-Methods-for-Reinforcement-Learning-with-Function-Approximation/"/>
    <id>http://mxxhcm.github.io/2019/04/17/Policy-Gradient-Methods-for-Reinforcement-Learning-with-Function-Approximation/</id>
    <published>2019-04-17T02:42:55.000Z</published>
    <updated>2019-05-06T16:22:27.704Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>强化学习有三种常用的方法，第一种是基于值函数的，第二种是policy gradient，第三种是derivative-free的方法，即不利用导数的方法。基于值函数的方法在理论上证明是很难的。这篇论文提出了policy gradient的方法，直接用函数去表示策略，根据expected reward对策略参数的梯度进行更新，REINFORCE和actor-critic都是policy gradient的方法。<br>本文的贡献主要有两个，第一个是给出估计的action-value function或者advantage函数，梯度可以表示成experience的估计，第二个是证明了任意可导的函数表示的policy通过policy iteration都可以收敛到locl optimal policy。</p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><h3 id="值函数方法的缺点"><a href="#值函数方法的缺点" class="headerlink" title="值函数方法的缺点"></a>值函数方法的缺点</h3><p>基于值函数的方法，在估计出值函数之后，每次通过greedy算法选择action。这种方法有两个缺点。</p><ul><li>基于值函数的方法会找到一个deterministic的策略，但是很多时候optimal policy可能是stochastic的。</li><li>某个action的估计值函数稍微改变一点就可能导致这个动作被选中或者不被选中，这种不连续是保证值函数收敛的一大障碍。</li></ul><h3 id="本文的工作"><a href="#本文的工作" class="headerlink" title="本文的工作"></a>本文的工作</h3><h4 id="用函数表示stochastic策略"><a href="#用函数表示stochastic策略" class="headerlink" title="用函数表示stochastic策略"></a>用函数表示stochastic策略</h4><p>本文提出的policy gradient通过使用函数直接表示stochastic策略。举例来说，用神经网络表示的一个策略，输入是state，输出是每个action选择的概率，神经网络的参数是policy的参数。用$\mathbf{\theta}$表示policy参数，用$J$表示该策略的performance measure。然后参数$\mathbf{\theta}$的更新正比于以下梯度：</p><script type="math/tex; mode=display">\nabla\mathbf{\theta} \approx \alpha \frac{\partial J}{\partial \mathbf{\theta}} \tag{1}</script><p>这里$\alpha$是步长，按照(1)式子进行更新，$\theta$可以确保收敛到J的局部最优值对应的local optimal policy。这里$\mathbf{\theta}$的微小改变只能造成policy和state分布的微小改变。</p><h4 id="使用值函数辅助学习policy"><a href="#使用值函数辅助学习policy" class="headerlink" title="使用值函数辅助学习policy"></a>使用值函数辅助学习policy</h4><p>本文证明了通过使用满足特定属性的近似值函数，使用experience可以得到(1)的一个无偏估计。另一个方法REINFORCE也找到了(1)的一个无偏估计，但是没有使用辅助的值函数。REINFORCE的学习速度要比使用值函数的方法慢很多。此外学习一个值函数，并用它取减少方差对快速学习是很重要的。</p><h4 id="证明policy-iteration收敛性"><a href="#证明policy-iteration收敛性" class="headerlink" title="证明policy iteration收敛性"></a>证明policy iteration收敛性</h4><p>本文还提出了一种方法证明基于actor-critic和policy-iteration架构方法的收敛性。在这篇文章中，他们只证明了使用通用函数逼近的policy iteration可以收敛到local optimal policy。</p><h2 id="Policy-Gradient-Therorem"><a href="#Policy-Gradient-Therorem" class="headerlink" title="Policy Gradient Therorem"></a>Policy Gradient Therorem</h2><p>智能体的在每一步的决策通过一个策略表示出来：$\pi(s,a,\mathbf{\theta})=Pr{a_t=a|s_t=s,\mathbf{\theta}},\forall s\in S, \forall a\in A,\mathbf{\theta}\in R^l$。假设$\pi$是可导的，即，$\frac{\partial\pi(s,a)}{\partial\mathbf{\theta}}$存在。为了方便，通常把$\pi(s,a,\mathbf{\theta})$简写为$\pi(s,a)$。<br>这里有两种方式定义智能体的目标，一种是平均奖励，一种是从指定状态获得的长期奖励。</p><h3 id="Average-Reward-平均奖励"><a href="#Average-Reward-平均奖励" class="headerlink" title="Average Reward(平均奖励)"></a>Average Reward(平均奖励)</h3><p>平均奖励是，策略根据每一步的长期期望奖励$\rho(\pi)$进行排名</p><script type="math/tex; mode=display">\rho(\pi) = lim_{n\rightarrow \infty}\frac{1}{n}\mathbb{E}\{r_1+r_2+\cdots+r_n|\pi\} = \sum_s d^{\pi}(s) \sum_a\pi(s,a)R_s^a.</script><p>其中$d^{\pi}(s) = lim_{t\rightarrow \infty} Pr{s_t=s|s_0,\pi}$是我们假设的策略$\pi$下的固定分布，对于所有的策略都是独立于$s_0$的。这里，我想了一天都没有想明白，为什么？？？第一个等号，我可以理解，这里$r_n$表示的是在时间步$n$的immediate reward，所以第一个等号表示的是在策略$\pi$下$n$个时间步的imediate reward平均值的期望。而第二个等号$d^{\pi}(s)$到底是什么意思，是从初始状态$s_0$到$t$时刻状态$s$的概率吗，好像就是这样子的，但是为什么可以这么算呢？第一个求和号对$s$求和，相当于算的是所有从$s_0$到$t\rightarrow\infty$的$s$的所有取值，然后再对每一个$s$，计算所有可能采取的action。<br>state-action value定义为：</p><script type="math/tex; mode=display">Q^{\pi}(s,a) = \sum_{t=1}^{\infty}\mathbb{E}\{r_t - \rho(\pi)|s_0=s,a_0=a,\pi\}, \forall s\in S, a\in A.</script><h3 id="Long-tern-Accumated-Reward-from-Designated-State-从指定状态开始的累计奖励"><a href="#Long-tern-Accumated-Reward-from-Designated-State-从指定状态开始的累计奖励" class="headerlink" title="Long-tern Accumated Reward from Designated State(从指定状态开始的累计奖励)"></a>Long-tern Accumated Reward from Designated State(从指定状态开始的累计奖励)</h3><p>这种情况是指定一个开始状态$s_0$，然后我们只关心从这个状态得到的长期reward。</p><script type="math/tex; mode=display">\rho(\pi) = \mathbb{E}\{\sum_{t=1}^{\infty}\gamma^{t-1}|s_0,\pi\},</script><script type="math/tex; mode=display">Q^{\pi}(s,a) = \mathbb{E}\{\sum_{k=1}^{\infty}r_{t+k}|s_t=s,a_t=a,\pi\}.</script><p>其中$\gamma\in[0,1]$是折扣因子，只有在episodic任务中才允许取$\gamma=1$。这里，我们定义$d^{\pi}(s)$是从开始状态$s<em>0$执行策略$\pi$遇到的状态的折扣权重：<br>$d^{\pi}(s) = \sum</em>{t=1}^{\infty}\gamma^tPr{s_t = s|s_0,\pi}.$</p><h3 id="Policy-Gradient-Theorem"><a href="#Policy-Gradient-Theorem" class="headerlink" title="Policy Gradient Theorem"></a>Policy Gradient Theorem</h3><p>对于任何MDP，不论是平均奖励还是指定初始状态的形式，都有：</p><script type="math/tex; mode=display">\frac{\partial J}{\partial \mathbf{\theta}} = \sum_ad^{\pi}(s)\sum_a\frac{\pi(s,a)}{\partial\mathbf{\theta}}Q^{\pi}(s,a), \tag{2}</script><p>证明：<br>平均奖励<br>\begin{align*}<br>\nabla v<em>{\pi}(s) &amp;= \nabla \left[ \sum_a \pi(a|s)q</em>{\pi}(s,a)\right], \forall s\in S \<br>&amp;= \sum<em>a \left[\nabla\pi(a|s)q</em>{\pi}(s,a)\right], \<br>&amp;= \sum<em>a \left[\nabla\pi(a|s)q</em>{\pi}(s,a) + \pi(a|s)\nabla q<em>{\pi}(s,a)\right] \<br>&amp;= \sum_a\left[\nabla\pi(a|s)q</em>{\pi}(s,a) + \pi(a|s)\nabla \left[r-\rho(\pi)+\sum<em>{s’,r}p(s’,r|s,a)v</em>{\pi}(s’)\right]\right] \<br>&amp;= \sum<em>a\left[\nabla\pi(a|s)q</em>{\pi}(s,a) + \pi(a|s)\left[-\nabla \rho(\pi)+\nabla \sum<em>{s’,r}p(s’,r|s,a)v</em>{\pi}(s’)\right]\right], \nabla r = 0\<br>\end{align*}<br>而由$\sum_s\pi(s,a)=1$，我们得到：</p><script type="math/tex; mode=display">\nabla v_{\pi}(s)=\sum_a\left[\nabla\pi(a|s)q_{\pi}(s,a) + \nabla \sum_{s',r}p(s',r|s,a)v_{\pi}(s')\right] - \nabla v_{\pi}(s)</script><p>同时在上式两边对$d^{\pi}$进行求和，得到：</p><script type="math/tex; mode=display">\sum_sd^{\pi}(s)\nabla v_{\pi}(s)=\sum_sd^{\pi}(s)\sum_a\left[\nabla\pi(a|s)q_{\pi}(s,a) + \sum_sd^{\pi}(s)\nabla \sum_{s',r}p(s',r|s,a)v_{\pi}(s')\right] - \sum_sd^{\pi}(s)\nabla v_{\pi}(s)</script><p>因为$d^{\pi}$是稳定的，</p><script type="math/tex; mode=display">\sum_sd^{\pi}(s)\nabla v_{\pi}(s)=\sum_sd^{\pi}(s)\sum_a\left[\nabla\pi(a|s)q_{\pi}(s,a) + \sum_sd^{\pi}(s)\nabla \sum_{s',r}p(s',r|s,a)v_{\pi}(s')\right] - \sum_sd^{\pi}(s)\nabla v_{\pi}(s)</script><p>那么:<br>\begin{align*}<br>\end{align*}<br>指定初始状态$s<em>0$:<br>\begin{align*}<br>\nabla v</em>{\pi}(s) &amp;= \nabla [ \sum<em>a \pi(a|s)q</em>{\pi}(s,a)], \forall s\in S \<br>&amp;= \sum<em>a [\nabla\pi(a|s)q</em>{\pi}(s,a)], \forall s\in S \<br>&amp;= \sum<em>a[\nabla\pi(a|s)q</em>{\pi}(s,a) + \pi(a|s)\nabla q<em>{\pi}(s,a)] \<br>&amp;= \sum_a[\nabla\pi(a|s)q</em>{\pi}(s,a) + \pi(a|s)\nabla \sum<em>{s’,r}p(s’,r|s,a)(r+\gamma v</em>{\pi}(s’))] \<br>&amp;= \sum<em>a[\nabla\pi(a|s)q</em>{\pi}(s,a) + \pi(a|s) \nabla \sum<em>{s’,r}p(s’,r|s,a)r + \pi(a|s)\nabla \sum</em>{s’,r}p(s’,r|s,a)\gamma v<em>{\pi}(s’))] \<br>&amp;= \sum_a[\nabla\pi(a|s)q</em>{\pi}(s,a) + 0 + \pi(a|s)\sum<em>{s’}\gamma p(s’|s,a)\nabla v</em>{\pi}(s’) ] \<br>&amp;= \sum<em>a[\nabla\pi(a|s)q</em>{\pi}(s,a) + 0 + \pi(a|s)\sum<em>{s’}\gamma p(s’|s,a)\<br>&amp;\ \ \ \ \ \ \ \ \sum</em>{a’}[\nabla\pi(a’|s’)q<em>{\pi}(s’,a’) + \pi(a’|s’)\sum</em>{s’’}\gamma p(s’’|s’,a’)\nabla v<em>{\pi}(s’’))] ],  展开\<br>&amp;= \sum</em>{x\in S}\sum<em>{k=0}^{\infty}Pr(s\rightarrow x, k,\pi)\sum_a\nabla\pi(a|x)q</em>{\pi}(x,a)<br>\end{align*}<br>第(5)式使用了$v<em>{\pi}(s) = \sum_a\pi(a|s)q(s,a)$进行展开。第(6)式将梯度符号放进求和里面。第(7)步使用product rule对q(s,a)求导。第(8)步利用$q</em>{\pi}(s, a) =\sum<em>{s’,r}p(s’,r|s,a)(r+v</em>{\pi}(s’)$ 对$q<em>{\pi}(s,a)$进行展开。第(9)步将(8)式进行分解。第(10)步对式(9)进行计算，因为$\sum</em>{s’,r}p(s’,r|s,a)r$是一个定制，求偏导之后为$0$。第(11)步对生成的$v<em>{\pi}(s’)$重复(5)-(10)步骤，得到式子(11)。如果对式子(11)中的$v</em>{\pi}(s)$一直展开，就得到了式子(12)。式子(12)中的$Pr(s\rightarrow x, k, \pi)$是在策略$\pi$下从state $s$经过$k$步转换到state $x$的概率，这里我有一个问题，就是为什么，$k$可以取到$\infty$，后来想了想，因为对第(11)步进行展开以后，可能会有重复的state，重复的意思就是从状态$s$开始，可能会多次到达某一个状态$x$，$k$就能取很多次，大不了$k=\infty$的概率为$0$就是了。</p><p>所以，对于$v<em>{\pi}(s_0)$，就有：<br>\begin{align*}<br>\nabla J(\mathbf{\theta}) &amp;= \nabla</em>{v<em>{\pi}}(s_0)\<br>&amp;= \sum</em>{s\in S}( \sum<em>{k=0}^{\infty}Pr(s_0\rightarrow s,k,\pi) ) \sum_a\nabla</em>{\pi}(a|s)q<em>{\pi}(s,a)\<br>&amp;=\sum</em>{s\in S}\eta(s)\sum<em>a \nabla</em>{\pi}(a|s)q<em>{\pi}(s,a)\<br>&amp;=\sum</em>{s’\in S}\eta(s’)\sum<em>s\frac{\eta(s)}{\sum</em>{s’}\eta(s’)}\sum<em>a \nabla</em>{\pi}(a|s)q<em>{\pi}(s,a)\<br>&amp;=\sum</em>{s’\in S}\eta(s’)\sum<em>s\mu(s)\sum_a \nabla</em>{\pi}(a|s)q<em>{\pi}(s,a)\<br>&amp;\propto \sum</em>{s\in S}\mu(s)\sum<em>a\nabla\pi(a|s)q</em>{\pi}(s,a)<br>\end{align*}</p><p>从式子(2)可以看出来，这个梯度和$\frac{\partial d^{\pi}(s)}{\partial\mathbf{\theta}}$无关：即策略改变对于状态分布没有影响，这对于使用采样来估计梯度是很方便的。这里有点不明白，举个例子来说，如果$s$是从服从$\pi$的分布中采样的，那么$\sum<em>a\frac{\pi(s,a)}{\partial\mathbf{\theta}}Q^{\pi}(s,a)$就是$\frac{\partial{\rho}}{\partial\mathbf{\theta}}$的一个无边估计。通常$Q^{\pi}(s,a)$也是不知道的，需要去估计。一种方法是使用真实的returns，即$R_t = \sum</em>{k=1}^{\infty}r<em>{t+k}-\rho(\pi)$或者$R_t = \sum</em>{k=1}^{\infty}\gamma^{k-1}r_{t+k}-\rho(\pi)$（在指定初始状态条件下）。这就是REINFROCE方法，$\nabla\mathbf{\theta}\propto\frac{\partial\pi(s_t,a_t)}{\partial\mathbf{\theta}}R_t\frac{1}{\pi(s_t,a_t)}$（$\frac{1}{\pi(s_t,a_t)}j纠正了被$\pi$偏爱的action的oversampling）。</p><h2 id="Policy-Gradient-with-Approximation-使用近似的策略梯度"><a href="#Policy-Gradient-with-Approximation-使用近似的策略梯度" class="headerlink" title="Policy Gradient with Approximation(使用近似的策略梯度)"></a>Policy Gradient with Approximation(使用近似的策略梯度)</h2><p>如果$Q^{\pi}$也用一个学习的函数来近似，然后我们希望用近似的函数代替式子(2)中的$Q^{\pi}$，并大致给出梯度的方向。<br>用$f_w:S\times A \rightarrow R$表示$Q^{\pi}$的估计值。在策略$\pi$下，更新$w$的值:$\nabla w_t\propto \frac{\partial}{\partial w}\left[\hat{Q}^{\pi}(s_t,a_t) - f_w(s_t,a_t)\right]^2 \propto \left[\hat{Q}^{\pi}(s_t,a_t) - f_w(s_t,a_t)\right]\frac{\partial f_w(s_t,a_t)}{\partial w}$，其中$\hat{Q}^{\pi}(s_t,a_t)$是$Q^{\pi}(s_t,a_t)$的一个无偏估计，可能是$R_t$，当这样一个过程收敛到local optimum，那么：</p><script type="math/tex; mode=display">\sum_sd^{\pi}(s)\sum_a\pi(s,a)\left[Q^{\pi}(s,a) -f_w(s,a)\right]\frac{\partial f_w(s,a)}{\partial w}  = 0\tag{3}</script><h3 id="Policy-Gradient-with-Approximation-Theorem"><a href="#Policy-Gradient-with-Approximation-Theorem" class="headerlink" title="Policy Gradient with Approximation Theorem"></a>Policy Gradient with Approximation Theorem</h3><p>如果$f_w$满足式子(3)，并且在某种意义上与policy parameterization兼容：</p><script type="math/tex; mode=display">\frac{\partial f_w(s,a)}{\partial w} = \frac{\partial \pi(s,a)}{\partial \mathbf{\theta}}\frac{1}{\pi(s,a)}\tag{4}</script><p>那么有：</p><script type="math/tex; mode=display">\frac{}{} = \sum_sd^{\pi}(s)\sum_a\frac{\partial \pi(s,a)}{\partial \mathbf{\theta}}f_w(s,a)\tag{5}</script><p>证明：<br>将(4)代入(3)得到：<br>\begin{align*}<br>&amp;\sum_sd^{\pi}(s)\sum_a\pi(s,a)\left[Q^{\pi}(s,a) -f_w(s,a)\right]\frac{\partial f_w(s,a)}{\partial w} = 0\<br>&amp;\sum_sd^{\pi}(s)\sum_a\pi(s,a)\left[Q^{\pi}(s,a) -f_w(s,a)\right]\frac{\partial \pi(s,a)}{\partial \mathbf{\theta}}\frac{1}{\pi(s,a)}= 0\<br>&amp;\sum_sd^{\pi}(s)\sum_a\left[Q^{\pi}(s,a) -f_w(s,a)\right]\frac{\partial \pi(s,a)}{\partial \mathbf{\theta}}= 0 \tag{6}\<br>\end{align*}<br>从这个式子中，我们能够从式子(6)中得到</p><h2 id="Convergence-of-Policy-Iteration-with-Function-Approximation-使用函数近似的策略迭代的收敛性"><a href="#Convergence-of-Policy-Iteration-with-Function-Approximation-使用函数近似的策略迭代的收敛性" class="headerlink" title="Convergence of Policy Iteration with Function Approximation(使用函数近似的策略迭代的收敛性)"></a>Convergence of Policy Iteration with Function Approximation(使用函数近似的策略迭代的收敛性)</h2><h3 id="Policy-Iteration-with-Function-Apprpximation-Theorem"><a href="#Policy-Iteration-with-Function-Apprpximation-Theorem" class="headerlink" title="Policy Iteration with Function Apprpximation Theorem"></a>Policy Iteration with Function Apprpximation Theorem</h3><p>用$\pi$和$f_w$表示策略和值函数的任意可导函数，并且满足式子(4)中的条件，Z</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h2&gt;&lt;p&gt;强化学习有三种常用的方法，第一种是基于值函数的，第二种是policy gradient，第三
      
    
    </summary>
    
      <category term="强化学习" scheme="http://mxxhcm.github.io/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="强化学习" scheme="http://mxxhcm.github.io/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="论文" scheme="http://mxxhcm.github.io/tags/%E8%AE%BA%E6%96%87/"/>
    
      <category term="Policy Gradient" scheme="http://mxxhcm.github.io/tags/Policy-Gradient/"/>
    
  </entry>
  
  <entry>
    <title>ubuntu 终端快速访问某个目录</title>
    <link href="http://mxxhcm.github.io/2019/04/15/ubuntu-%E7%BB%88%E7%AB%AF%E5%BF%AB%E9%80%9F%E8%AE%BF%E9%97%AE%E6%9F%90%E4%B8%AA%E7%9B%AE%E5%BD%95/"/>
    <id>http://mxxhcm.github.io/2019/04/15/ubuntu-终端快速访问某个目录/</id>
    <published>2019-04-15T10:49:57.000Z</published>
    <updated>2019-05-06T16:22:27.708Z</updated>
    
    <content type="html"><![CDATA[<h2 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h2><p>在写博客的过程中，每次在终端中进入该目录，都要输好长的命令，在想着有没有什么简单的方法。后来就在网上找到了。</p><h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><p>利用alias命令进行重命名<br>这里给出一个具体的例子，我的博客文件存放在/home/mxxmhh/github/blog/source/_posts下，<br>在/home/mxxmhh/.bashrc文件中添加如下一行即可(当然也可以在其他配置文件中添加)：<br>alias posts=’cd /home/mxxmhh/github/blog/source/_posts’<br>然后执行<br>~\$:source /home/mxxmhh/.bashrc<br>即可。<br>接下来可在终端输入<br>~\$:posts<br>直接访问该目录。</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>1.<a href="https://www.cnblogs.com/wlsphper/p/6782625.html" target="_blank" rel="noopener">https://www.cnblogs.com/wlsphper/p/6782625.html</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;动机&quot;&gt;&lt;a href=&quot;#动机&quot; class=&quot;headerlink&quot; title=&quot;动机&quot;&gt;&lt;/a&gt;动机&lt;/h2&gt;&lt;p&gt;在写博客的过程中，每次在终端中进入该目录，都要输好长的命令，在想着有没有什么简单的方法。后来就在网上找到了。&lt;/p&gt;
&lt;h2 id=&quot;方法&quot;
      
    
    </summary>
    
      <category term="工具" scheme="http://mxxhcm.github.io/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="ubuntu" scheme="http://mxxhcm.github.io/tags/ubuntu/"/>
    
  </entry>
  
  <entry>
    <title>python 类和函数的属性</title>
    <link href="http://mxxhcm.github.io/2019/04/14/python-%E7%B1%BB%E5%92%8C%E5%87%BD%E6%95%B0%E7%9A%84%E5%B1%9E%E6%80%A7/"/>
    <id>http://mxxhcm.github.io/2019/04/14/python-类和函数的属性/</id>
    <published>2019-04-14T06:49:41.000Z</published>
    <updated>2019-05-06T16:22:27.708Z</updated>
    
    <content type="html"><![CDATA[<h2 id="函数和类的默认属性"><a href="#函数和类的默认属性" class="headerlink" title="函数和类的默认属性"></a>函数和类的默认属性</h2><p>这里主要介绍类和函数的一些属性。<br><strong>dict</strong>用来描述对象的属性。对于类来说，它内部的变量就是它的数量，注意，不是它的member variable，但是对于函数来说不是。对于类来说，而对于类对象来说，输出的是整个类的属性，而<strong>dict</strong>输出的是self.variable的内容。</p><p>python中的函数有很多特殊的属性（包括自定义的函数和库函数）</p><ul><li><strong>doc</strong>  输出用户定义的关于函数的说明</li><li><strong>name</strong> 输出函数名字</li><li><strong>module</strong> 输出函数所在模块的名字</li><li><strong>dict</strong> 输出函数中的字典</li></ul><p>示例：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">myfunc</span><span class="params">()</span>:</span></span><br><span class="line">   <span class="string">'this func is to test the __doc__'</span></span><br><span class="line">   myfunc.func_attr = <span class="string">"attr"</span></span><br><span class="line">   print(<span class="string">"hhhh"</span>)</span><br><span class="line"> </span><br><span class="line">myfunc.func_attr1 = <span class="string">"first1"</span></span><br><span class="line">myfunc.func_attr2 = <span class="string">"first2"</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">  print(myfunc.__doc__)</span><br><span class="line">  print(myfunc.__name__)</span><br><span class="line">  print(myfunc.__module__)</span><br><span class="line">  print(myfunc.__dict__)</span><br></pre></td></tr></table></figure></p><p>输出：</p><blockquote><p>this func is to test the <strong>doc</strong><br>myfunc<br><strong>main</strong><br>{‘func_attr1’: ‘first1’, ‘func_attr2’: ‘first2’}</p></blockquote><p>类也有很多特殊的属性（包括自定义的类和库中的类）</p><ul><li><strong>doc</strong>  输出用户定义的类的说明</li><li><strong>module</strong> 输出类所在模块的名字</li><li><strong>dict</strong> 输出类中的字典</li></ul><p>示例：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyClass</span>:</span></span><br><span class="line">  <span class="string">"""This is my class __doc__"""</span></span><br><span class="line">  class_name = <span class="string">"cllll"</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, test=None)</span>:</span></span><br><span class="line">     self.test = test</span><br><span class="line">  <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">  print(MyClass.__dict__)</span><br><span class="line">  print(MyClass.__doc__)</span><br><span class="line">  print(MyClass.__module__)</span><br></pre></td></tr></table></figure></p><p>输出：</p><blockquote><p>{‘<strong>module</strong>‘: ‘<strong>main</strong>‘, ‘<strong>doc</strong>‘: ‘This is my class <strong>doc</strong>‘, ‘class<em>name’: ‘cllll’, ‘<strong>init</strong>‘: \<function myclass.__init__ at 0x7f1349d44510\>, ‘<strong>dict</strong>‘: \<attribute '__dict__' of 'myclass' objects\>, ‘<strong>weakref</strong>‘: \<attribute '__weakref__' of 'myclass' objects\>}<br>This is my class <strong>doc</strong><br><em>_main</em></attribute></attribute></function></em></p></blockquote><p>类的对象的属性</p><ul><li><strong>doc</strong>  输出用户定义的类的说明</li><li><strong>module</strong> 输出类对象所在模块的名字</li><li><strong>dict</strong> 输出类对象中的字典</li></ul><p>示例<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"> <span class="number">1</span> <span class="class"><span class="keyword">class</span> <span class="title">MyClass</span>:</span></span><br><span class="line"> <span class="number">2</span>   <span class="string">"""This is my class __doc__"""</span></span><br><span class="line"> <span class="number">3</span>   class_name = <span class="string">"cllll"</span></span><br><span class="line"> <span class="number">4</span>   <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, test=None)</span>:</span></span><br><span class="line"> <span class="number">5</span>      self.test = test</span><br><span class="line"> <span class="number">6</span>   <span class="keyword">pass</span></span><br><span class="line"> <span class="number">7</span> </span><br><span class="line"> <span class="number">8</span> <span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line"> <span class="number">9</span> </span><br><span class="line"><span class="number">10</span>   cl = MyClass()</span><br><span class="line"><span class="number">11</span>   print(cl.__dict__)</span><br><span class="line"><span class="number">12</span>   print(cl.__doc__)</span><br><span class="line"><span class="number">13</span>   print(cl.__module__)</span><br></pre></td></tr></table></figure></p><p>输出</p><blockquote><p>{‘test’: None}<br>This is my class <strong>doc</strong><br><strong>main</strong></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;函数和类的默认属性&quot;&gt;&lt;a href=&quot;#函数和类的默认属性&quot; class=&quot;headerlink&quot; title=&quot;函数和类的默认属性&quot;&gt;&lt;/a&gt;函数和类的默认属性&lt;/h2&gt;&lt;p&gt;这里主要介绍类和函数的一些属性。&lt;br&gt;&lt;strong&gt;dict&lt;/strong&gt;用
      
    
    </summary>
    
      <category term="python" scheme="http://mxxhcm.github.io/categories/python/"/>
    
    
      <category term="python" scheme="http://mxxhcm.github.io/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>python zip和enumerate</title>
    <link href="http://mxxhcm.github.io/2019/04/13/python-zip%E5%92%8Cenumerate/"/>
    <id>http://mxxhcm.github.io/2019/04/13/python-zip和enumerate/</id>
    <published>2019-04-13T06:59:12.000Z</published>
    <updated>2019-05-06T16:22:27.708Z</updated>
    
    <content type="html"><![CDATA[<h2 id="zip-function"><a href="#zip-function" class="headerlink" title="zip function"></a>zip function</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">a = np.zeros((<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>))</span><br><span class="line">b = np.zeros((<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>))</span><br><span class="line">c = np.zeros((<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>))</span><br><span class="line">d = zip(a,b,c)   </span><br><span class="line">print(list(d))        </span><br><span class="line">d = list(zip(a,b,c))</span><br><span class="line">e,f,g = d</span><br></pre></td></tr></table></figure><p>这里d是一个什么呢，是多个tuple，数量是min(len(a),len(b),len(c))，每一个element是一个tuple，这个tuple的内容为(a[0],b[0],c[0])，….<br>打印出list(d)是一个list，这个list的长度为min(len(a),len(b),len(c))每一个element是一个tuple，tuple的形状是((2,2),(2,2),(2,2))<br>用zip的话，就是看一下它的len，然后在第一维上对他们进行拼接，形成多个新的元组。<br>例子<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a = (<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">b = (<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">c = (<span class="number">4</span>,<span class="number">5</span>)</span><br><span class="line">d = zip(a,b,c)</span><br><span class="line">print(list(c))</span><br></pre></td></tr></table></figure></p><blockquote><p>[(2,3),(3,4),(4,5)]    </p></blockquote><p>相当于吧tuple a和tuple b分别当做一个list的一个元组，然后结合成一个新的tuple的list，</p><h2 id="enumerate-iterable-start-0"><a href="#enumerate-iterable-start-0" class="headerlink" title="enumerate(iterable, start=0)"></a>enumerate(iterable, start=0)</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">seasons = [<span class="string">'Spring'</span>, <span class="string">'Summer'</span>, <span class="string">'Fall'</span>, <span class="string">'Winter'</span>]</span><br><span class="line">print(list(enumerate(seasons)))</span><br><span class="line">print(list(enumerate(seasons, start=<span class="number">1</span>)))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> enumerate(seansons):</span><br><span class="line">   print(i)</span><br></pre></td></tr></table></figure><blockquote><p>[(0, ‘Spring’), (1, ‘Summer’), (2, ‘Fall’), (3, ‘Winter’)]<br>[(1, ‘Spring’), (2, ‘Summer’), (3, ‘Fall’), (4, ‘Winter’)]<br>(0, ‘Spring’)<br>(1, ‘Summer’)<br>(2, ‘Fall’)<br>(3, ‘Winter’)</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;zip-function&quot;&gt;&lt;a href=&quot;#zip-function&quot; class=&quot;headerlink&quot; title=&quot;zip function&quot;&gt;&lt;/a&gt;zip function&lt;/h2&gt;&lt;figure class=&quot;highlight python&quot;&gt;
      
    
    </summary>
    
      <category term="python" scheme="http://mxxhcm.github.io/categories/python/"/>
    
    
      <category term="python" scheme="http://mxxhcm.github.io/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>python time</title>
    <link href="http://mxxhcm.github.io/2019/04/13/python-time/"/>
    <id>http://mxxhcm.github.io/2019/04/13/python-time/</id>
    <published>2019-04-13T06:52:30.000Z</published>
    <updated>2019-05-06T16:22:27.708Z</updated>
    
    <content type="html"><![CDATA[<h2 id="time（time-library-datetime-library-panda-Timestamp-）"><a href="#time（time-library-datetime-library-panda-Timestamp-）" class="headerlink" title="time（time library,datetime library,panda.Timestamp()）"></a>time（time library,datetime library,panda.Timestamp()）</h2><p>import time</p><h3 id="获得当前时间"><a href="#获得当前时间" class="headerlink" title="获得当前时间"></a>获得当前时间</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">time.time()        <span class="comment">#获得当前timestamp</span></span><br></pre></td></tr></table></figure><h3 id="time-localtime-timestamp"><a href="#time-localtime-timestamp" class="headerlink" title="time.localtime(timestamp)"></a>time.localtime(timestamp)</h3><p>得到一个struct_time<br>time.struct_time(tm_year=2018….)</p><h3 id="将struct-time转换成string"><a href="#将struct-time转换成string" class="headerlink" title="将struct time转换成string"></a>将struct time转换成string</h3><blockquote><p>Convert a tuple or struct_time representing a time as returned by gmtime() or localtime() to a string as specified by the format argument.If t is not provided,the current time as returned by localtime() is used.</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line">time.strftime(format,t)        <span class="comment">#将一个struct_time表示为一个格式化字符串</span></span><br><span class="line">time.strftime(<span class="string">"%Y-%m-%d %H:%M:%S"</span>,time.localtime())</span><br></pre></td></tr></table></figure><h3 id="将一个string类型的事件转换成struct-time"><a href="#将一个string类型的事件转换成struct-time" class="headerlink" title="将一个string类型的事件转换成struct time"></a>将一个string类型的事件转换成struct time</h3><blockquote><p>Parse a string representing a time accroding to a format.The return value is a struct_time as returned by gmtime() or localtime()</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line">time.strptime(<span class="string">"a string representing a time"</span>,<span class="string">"a format"</span>)    <span class="comment">#将某个format表示的time转化为一个struct_time()</span></span><br><span class="line">time.strptime(<span class="string">"2014-02-01 00:00:00"</span>,<span class="string">"%Y-%m-%d %H:%M:%S"</span>)</span><br></pre></td></tr></table></figure><h3 id="time-mktime"><a href="#time-mktime" class="headerlink" title="time.mktime()"></a>time.mktime()</h3><p>将时间t转换成timestamp</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;time（time-library-datetime-library-panda-Timestamp-）&quot;&gt;&lt;a href=&quot;#time（time-library-datetime-library-panda-Timestamp-）&quot; class=&quot;headerl
      
    
    </summary>
    
      <category term="python" scheme="http://mxxhcm.github.io/categories/python/"/>
    
    
      <category term="python" scheme="http://mxxhcm.github.io/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>python文件和目录操作(os和shutil)</title>
    <link href="http://mxxhcm.github.io/2019/04/13/python-file-dir/"/>
    <id>http://mxxhcm.github.io/2019/04/13/python-file-dir/</id>
    <published>2019-04-13T06:51:26.000Z</published>
    <updated>2019-05-06T16:22:27.708Z</updated>
    
    <content type="html"><![CDATA[<h2 id="文件和目录操作（os库和shutil库）"><a href="#文件和目录操作（os库和shutil库）" class="headerlink" title="文件和目录操作（os库和shutil库）"></a>文件和目录操作（os库和shutil库）</h2><p>import os</p><h3 id="查看信息"><a href="#查看信息" class="headerlink" title="查看信息"></a>查看信息</h3><p>不是函数，而是属性<br>os.linesep   #列出当前平台的行终止符<br>os.name    #列出当前的平台信息</p><h3 id="列出目录"><a href="#列出目录" class="headerlink" title="列出目录"></a>列出目录</h3><p>file_dir_list = os.listdir(parent_dir)    #列出某个目录下的文件和目录，默认的话为当前目录<br>parent_dir 是一个目录<br>file_dir_list是一个list</p><p>os.path.exists(pathname)    #判断pathname是否存在<br>os.path.isdir(pathname)    #判断pathname是否是目录<br>os.path.isfile(pathname)    #判断pathname是否是文件<br>os.path.isabs(pathname)    #判断pathname是否是绝对路径</p><p>os.path.basename(pathname)    # 列出pathname的dir<br>os.path.dirname(pathname)        # 列出pathname的file name<br>os.path.split(pathname)    #将pathname分为dir和filename<br>os.path.split(pathname)    #将pathname的扩展名分离出来</p><p>os.path.join(“dir_name”,”file_name”)    # 拼接两个路径</p><p>os.getcwd()    #获得当前路径<br>os.chdir(pathname)    #改变当前路径</p><h3 id="创建和删除"><a href="#创建和删除" class="headerlink" title="创建和删除"></a>创建和删除</h3><p>os.mkdir(pathname)    #创建新目录<br>os.rmdir(pathname)    #删除目录<br>os.makedirs(“/home/mxxhcm/Documents/“)    #创建多级目录<br>os.removedirs()    #删除多个目录<br>os.remove(file_pathname)    #删除文件</p><p>os.rename(old_pathname,new_pathname)    #重命名</p><h3 id="打开文件"><a href="#打开文件" class="headerlink" title="打开文件"></a>打开文件</h3><p>对于open文件来说，共有三种模式，分别为w,a,r<br>r的话，为只读，读取一个不存在的文件，会报错<br>r+的话，为可读写，读取一个不存在的文件，会报错<br>a的话，为追加读，读取一个不存在的文件，会创建该文件<br>w的话，为写入文件，读取一个不存在的文件，会创建改文件，打开一个存在的同名文件，会删除该文件，创建一个新的文件</p><h3 id="读取文件"><a href="#读取文件" class="headerlink" title="读取文件"></a>读取文件</h3><p>fp = open(file_path_name,”r+”)</p><h4 id="read-将文件读到一个字符串中"><a href="#read-将文件读到一个字符串中" class="headerlink" title="read()将文件读到一个字符串中"></a>read()将文件读到一个字符串中</h4><p>file_str = fp.read()<br>fp.read()会返回一个字符串，包含换行符</p><h4 id="readline"><a href="#readline" class="headerlink" title="readline()"></a>readline()</h4><p>for file_str in fp:<br>    print(file_str)<br>这里的file_str是一个str类型变量</p><h4 id="readlines-将文件读到一个列表中"><a href="#readlines-将文件读到一个列表中" class="headerlink" title="readlines()将文件读到一个列表中"></a>readlines()将文件读到一个列表中</h4><p>list(fp)<br>file_list = fp.readlines()<br>filt_list是一个list变量</p><h3 id="关闭文件"><a href="#关闭文件" class="headerlink" title="关闭文件"></a>关闭文件</h3><p>fp.close()<br>或者<br>with open(file_pathname, “r”) as f:<br>    file_str = fp.read()<br>当跳出这个语句块的时候，文件已经别关闭了。</p><h3 id="复制文件"><a href="#复制文件" class="headerlink" title="复制文件"></a>复制文件</h3><p>shutil.move(‘test’,’test_move’)    # 递归的将文件或者目录移动到另一个位置。如果目标位置是一个目录，移动到这个目录里，如果目标已经存在而且不是一个目录，可能会用os.rename()重命名<br>shutil.copyfile(src,dst) #复制文件内容，metadata没有复制<br>shutil.copymode(src,dst) #copy权限。文件内容，owner和group不变。<br>shutil.copystat(src,dst)    #copy权限，各种时间以及flags位。文件内容，owner，group不变<br>shutil.copy(src,dst)    #copy file,权限为也会被copied<br>shutil.copy2(src,dst)  #和先后调用shutil.copy()和shutil.copystat()函数一样<br>shutil.copytree(src,dst,symlinks=False,ignore=None)  #递归的将str目录结构复制到dst，dst位置必须不存在，目录的权限和时间用copystat来复制，文件的赋值用copy2()来复制<br>shutil.rmtree(path[,ignore_errors[,onerror]])   #删除一个完整的目录，无论目录是否为空</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;文件和目录操作（os库和shutil库）&quot;&gt;&lt;a href=&quot;#文件和目录操作（os库和shutil库）&quot; class=&quot;headerlink&quot; title=&quot;文件和目录操作（os库和shutil库）&quot;&gt;&lt;/a&gt;文件和目录操作（os库和shutil库）&lt;/h2&gt;&lt;
      
    
    </summary>
    
      <category term="python" scheme="http://mxxhcm.github.io/categories/python/"/>
    
    
      <category term="python" scheme="http://mxxhcm.github.io/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>python regex</title>
    <link href="http://mxxhcm.github.io/2019/04/13/python-regex/"/>
    <id>http://mxxhcm.github.io/2019/04/13/python-regex/</id>
    <published>2019-04-13T06:50:41.000Z</published>
    <updated>2019-05-06T16:22:27.708Z</updated>
    
    <content type="html"><![CDATA[<h2 id="regex（re库）"><a href="#regex（re库）" class="headerlink" title="regex（re库）"></a>regex（re库）</h2><p>import re</p><h3 id="如何创建正则表达式"><a href="#如何创建正则表达式" class="headerlink" title="如何创建正则表达式"></a>如何创建正则表达式</h3><p>.    match any character<br>*    match 0 or more repetitons<br>+    match 1 or more repetitions<br>?    match 0 or 1 repetition<br>^    matching the start of the string<br>$    matching the end os the string<br>+,*.?    都是贪婪匹配，如果加一个?为非贪婪匹配<br>+?,*?,??    为非贪婪匹配<br>{}    表示重复多少次a{3,5}<br>[]    匹配方括号内的,如[1-9]<br>()  match whatever regular expression is inside the parentheses,and indicated the start and end of a group.</p><h3 id="模块"><a href="#模块" class="headerlink" title="模块"></a>模块</h3><p>str = “<a href="https://abc" target="_blank" rel="noopener">https://abc</a> <a href="https://dcdf" target="_blank" rel="noopener">https://dcdf</a> <a href="https://httpfn" target="_blank" rel="noopener">https://httpfn</a> <a href="https://hello" target="_blank" rel="noopener">https://hello</a>“</p><h4 id="re-compile-patern-flags-0"><a href="#re-compile-patern-flags-0" class="headerlink" title="re.compile(patern, flags=0)"></a>re.compile(patern, flags=0)</h4><p>将一个正则表达式语句编译成一个正则表达式对象</p><blockquote><p>complie a regular expression pattern into a regular expression object,which can be used for matching using its match() and search()</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> regex <span class="keyword">as</span> re</span><br><span class="line">prog = re.compile(pattern)</span><br><span class="line">results = prog.match(string)</span><br><span class="line"><span class="comment"># is equivalent to </span></span><br><span class="line">results = re.match(pattern, string)</span><br></pre></td></tr></table></figure><p>flags can be re.DEBUG, re.I,re.IGNORECASE, re.L, re.LOCALE, re.M, re.MULTIINE, re.s, re.DOTALL, re.U, re.UNICODE, re.X, re.VERBOSE</p><h4 id="re-search-pattern-string-flags-0"><a href="#re-search-pattern-string-flags-0" class="headerlink" title="re.search(pattern, string, flags=0)"></a>re.search(pattern, string, flags=0)</h4><p>在给定的string任意位置进行查找<br>locat a match anywhere in string</p><h4 id="re-match-pattern-string-flags-0-or-re-fullmatch-pattern-string-flags-0"><a href="#re-match-pattern-string-flags-0-or-re-fullmatch-pattern-string-flags-0" class="headerlink" title="re.match(pattern, string, flags=0) or re.fullmatch(pattern,string,flags=0)"></a>re.match(pattern, string, flags=0) or re.fullmatch(pattern,string,flags=0)</h4><p>在给定的string开始位置进行查找</p><blockquote><p>match at the beginning of string, or if the whole string match the regular expression pattern.</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">p3 = <span class="string">"https.+? "</span></span><br><span class="line">results = re.match(p3,str)</span><br></pre></td></tr></table></figure><blockquote><_sre.sre_match object; span="(0," 12), match="https://abc "></_sre.sre_match></blockquote><h4 id="re-split-pattern-string-maxflit-0-flags-0"><a href="#re-split-pattern-string-maxflit-0-flags-0" class="headerlink" title="re.split(pattern, string, maxflit=0, flags=0)"></a>re.split(pattern, string, maxflit=0, flags=0)</h4><p>按照patten对string进行分割</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> regex <span class="keyword">as</span> re</span><br><span class="line">str = <span class="string">"https://abc https://dcdf https://httpfn https://hello"</span></span><br><span class="line">p1 = <span class="string">" "</span></span><br><span class="line">results = re.split(p1,str)</span><br></pre></td></tr></table></figure><blockquote><p>[‘<a href="https://abc" target="_blank" rel="noopener">https://abc</a>‘, ‘<a href="https://dcdf" target="_blank" rel="noopener">https://dcdf</a>‘, ‘<a href="https://httpfn" target="_blank" rel="noopener">https://httpfn</a>‘, ‘<a href="https://hello" target="_blank" rel="noopener">https://hello</a>‘]</p></blockquote><h4 id="re-findall-pattern-string-flags-0"><a href="#re-findall-pattern-string-flags-0" class="headerlink" title="re.findall(pattern,string,flags=0)"></a>re.findall(pattern,string,flags=0)</h4><p>查找字符string所有匹配pattern的字符</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> regex <span class="keyword">as</span> re</span><br><span class="line">str = <span class="string">"https://abc https://dcdf https://httpfn https://hello"</span></span><br><span class="line">p2 = <span class="string">"https.+? "</span>    <span class="comment"># pay attention to space here</span></span><br><span class="line">results = re.findall(p2,str)</span><br></pre></td></tr></table></figure><blockquote><p>[‘<a href="https://abc" target="_blank" rel="noopener">https://abc</a> ‘, ‘<a href="https://dcdf" target="_blank" rel="noopener">https://dcdf</a> ‘, ‘<a href="https://httpfn" target="_blank" rel="noopener">https://httpfn</a> ‘]    # pay attention to the last ,since the end of str is \n</p></blockquote><h4 id="re-sub-pattern-repl-string-count-0-flags-0"><a href="#re-sub-pattern-repl-string-count-0-flags-0" class="headerlink" title="re.sub(pattern,repl,string,count=0,flags=0)"></a>re.sub(pattern,repl,string,count=0,flags=0)</h4><h4 id="re-subn-pattern-repl-string-count-0-flags-0"><a href="#re-subn-pattern-repl-string-count-0-flags-0" class="headerlink" title="re.subn(pattern,repl,string,count=0,flags=0)"></a>re.subn(pattern,repl,string,count=0,flags=0)</h4><h4 id="…"><a href="#…" class="headerlink" title="…"></a>…</h4><h3 id="正则表达式对象-regular-express-object"><a href="#正则表达式对象-regular-express-object" class="headerlink" title="正则表达式对象(regular express object)"></a>正则表达式对象(regular express object)</h3><h4 id="class-re-RegexObject"><a href="#class-re-RegexObject" class="headerlink" title="class re.RegexObject"></a>class re.RegexObject</h4><p>只有re.compile()函数会产生一个正则表达式对象</p><blockquote><p>only re.compile() will create a direct regular express object,<br>it’s a special class which design for re.compile().</p></blockquote><h4 id="search-string-pos-endpos"><a href="#search-string-pos-endpos" class="headerlink" title="search(string[,pos[,endpos]])"></a>search(string[,pos[,endpos]])</h4><h4 id="match-string-pos-endpos"><a href="#match-string-pos-endpos" class="headerlink" title="match(string[,pos[,endpos]])"></a>match(string[,pos[,endpos]])</h4><h4 id="split-string-maxsplit-0"><a href="#split-string-maxsplit-0" class="headerlink" title="split(string,maxsplit=0)"></a>split(string,maxsplit=0)</h4><h4 id="findall-string-pos-endpos"><a href="#findall-string-pos-endpos" class="headerlink" title="findall(string[,pos[,endpos]])"></a>findall(string[,pos[,endpos]])</h4><h4 id="sub"><a href="#sub" class="headerlink" title="sub()"></a>sub()</h4><h4 id="flags"><a href="#flags" class="headerlink" title="flags"></a>flags</h4><h4 id="groups"><a href="#groups" class="headerlink" title="groups"></a>groups</h4><h4 id="groupindex"><a href="#groupindex" class="headerlink" title="groupindex"></a>groupindex</h4><h4 id="pattern"><a href="#pattern" class="headerlink" title="pattern"></a>pattern</h4><h3 id="匹配对象-match-objects"><a href="#匹配对象-match-objects" class="headerlink" title="匹配对象(match objects)"></a>匹配对象(match objects)</h3><h4 id="class-re-MatchObject"><a href="#class-re-MatchObject" class="headerlink" title="class re.MatchObject"></a>class re.MatchObject</h4><p>匹配是否成功</p><blockquote><p>match objects have a boolean value of True.</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">match = re.search(pattern,string)</span><br><span class="line">if match:</span><br><span class="line">   processs(match)</span><br></pre></td></tr></table></figure><h4 id="group-group1"><a href="#group-group1" class="headerlink" title="group([group1,..])"></a>group([group1,..])</h4><p>group的话pattern需要多个()</p><h4 id="groups-default"><a href="#groups-default" class="headerlink" title="groups([default])"></a>groups([default])</h4><p>返回一个元组</p><blockquote><p>return a tuple containing all the subgroups of the match.</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">re.match(<span class="string">r"(\d+)\.(\d+)"</span>,<span class="string">"24.1632"</span>)</span><br><span class="line">m.groups()</span><br></pre></td></tr></table></figure><blockquote><p>(‘24’,’1632’)</p></blockquote><p>show default<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">m = re.match(<span class="string">r"(\d+)\.?(\d+)?"</span>, <span class="string">"24"</span>)</span><br><span class="line">m.groups()      <span class="comment"># Second group defaults to None.</span></span><br></pre></td></tr></table></figure></p><blockquote><p>(‘24’, None)</p></blockquote><p>change default to 0<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">m.groups(<span class="string">'0'</span>)  <span class="comment"># Now, the second group defaults to '0'.</span></span><br><span class="line">(<span class="string">'24'</span>, <span class="string">'0'</span>)</span><br></pre></td></tr></table></figure></p><h3 id="regex-examples"><a href="#regex-examples" class="headerlink" title="regex examples"></a>regex examples</h3>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;regex（re库）&quot;&gt;&lt;a href=&quot;#regex（re库）&quot; class=&quot;headerlink&quot; title=&quot;regex（re库）&quot;&gt;&lt;/a&gt;regex（re库）&lt;/h2&gt;&lt;p&gt;import re&lt;/p&gt;
&lt;h3 id=&quot;如何创建正则表达式&quot;&gt;&lt;a hr
      
    
    </summary>
    
      <category term="python" scheme="http://mxxhcm.github.io/categories/python/"/>
    
    
      <category term="python" scheme="http://mxxhcm.github.io/tags/python/"/>
    
      <category term="正则表达式" scheme="http://mxxhcm.github.io/tags/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>python数组初始化</title>
    <link href="http://mxxhcm.github.io/2019/04/13/python-%E6%95%B0%E7%BB%84%E5%88%9D%E5%A7%8B%E5%8C%96/"/>
    <id>http://mxxhcm.github.io/2019/04/13/python-数组初始化/</id>
    <published>2019-04-13T06:49:35.000Z</published>
    <updated>2019-05-06T16:22:27.708Z</updated>
    
    <content type="html"><![CDATA[<h2 id="数组初始化initialize-numpy-library"><a href="#数组初始化initialize-numpy-library" class="headerlink" title="数组初始化initialize(numpy library)"></a>数组初始化initialize(numpy library)</h2><h3 id="array-initialize"><a href="#array-initialize" class="headerlink" title="array initialize"></a>array initialize</h3><p>array_one_dimension =  [ 0 for i in range(cols)]<br>array_multi_dimension  = [[0 for i in range(cols)] for j in range(rows)]</p><h3 id="numpy-ndarray-numpy-array-numpy-zeros-numpy-empty"><a href="#numpy-ndarray-numpy-array-numpy-zeros-numpy-empty" class="headerlink" title="numpy.ndarray(numpy.array(),numpy.zeros(),numpy.empty())"></a>numpy.ndarray(numpy.array(),numpy.zeros(),numpy.empty())</h3><h4 id="np-ndarray属性"><a href="#np-ndarray属性" class="headerlink" title="np.ndarray属性"></a>np.ndarray属性</h4><p>ndarray.shape        #array的shape<br>ndarray.ndim            #array的维度<br>ndarray.size            #the number of ndarray in array<br>ndarray.dtype        #type of the number in array<br>ndarray.itemsize        #size of the element in array<br>array[array &gt; 0].size    #统计一个数组有多少个非零元素，不论array的维度是多少</p><h4 id="numpy-array"><a href="#numpy-array" class="headerlink" title="numpy.array()"></a>numpy.array()</h4><p>np.array(object,dtype=None,copy=True,order=False,subok=False,ndim=0)</p><h4 id="numpy-zeros"><a href="#numpy-zeros" class="headerlink" title="numpy.zeros()"></a>numpy.zeros()</h4><p>np.zeros(shape,dtype=float,order=’C’)</p><h4 id="numpy-empty"><a href="#numpy-empty" class="headerlink" title="numpy.empty()"></a>numpy.empty()</h4><p>np.empty(shape,dtype=float,order=’C’)</p><h4 id="numpy-random-randn-shape"><a href="#numpy-random-randn-shape" class="headerlink" title="numpy.random.randn(shape)"></a>numpy.random.randn(shape)</h4><p>np.random.randn(3,4)</p><h4 id="numpy-arange"><a href="#numpy-arange" class="headerlink" title="numpy.arange()"></a>numpy.arange()</h4><h4 id="numpy-linspace"><a href="#numpy-linspace" class="headerlink" title="numpy.linspace()"></a>numpy.linspace()</h4>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;数组初始化initialize-numpy-library&quot;&gt;&lt;a href=&quot;#数组初始化initialize-numpy-library&quot; class=&quot;headerlink&quot; title=&quot;数组初始化initialize(numpy library)&quot;&gt;&lt;/
      
    
    </summary>
    
      <category term="python" scheme="http://mxxhcm.github.io/categories/python/"/>
    
    
      <category term="python" scheme="http://mxxhcm.github.io/tags/python/"/>
    
      <category term="numpy" scheme="http://mxxhcm.github.io/tags/numpy/"/>
    
  </entry>
  
  <entry>
    <title>python2和python3中的dict</title>
    <link href="http://mxxhcm.github.io/2019/04/13/python-dict/"/>
    <id>http://mxxhcm.github.io/2019/04/13/python-dict/</id>
    <published>2019-04-13T06:46:26.000Z</published>
    <updated>2019-05-06T16:22:27.708Z</updated>
    
    <content type="html"><![CDATA[<h2 id="python2和python3的dict"><a href="#python2和python3的dict" class="headerlink" title="python2和python3的dict"></a>python2和python3的dict</h2><h3 id="将object转换为dict"><a href="#将object转换为dict" class="headerlink" title="将object转换为dict"></a>将object转换为dict</h3><p>vars([object]) -&gt; dictionary</p><h3 id="python2-dict"><a href="#python2-dict" class="headerlink" title="python2 dict"></a>python2 dict</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">m_dict = &#123;&apos;a&apos;: 10, &apos;b&apos;: 20&#125;</span><br><span class="line"></span><br><span class="line">values = m_dict.values()</span><br><span class="line">print(type(values))</span><br><span class="line">print(values)</span><br><span class="line">print(&quot;\n&quot;)</span><br><span class="line"></span><br><span class="line">items = m_dict.items()</span><br><span class="line">print(type(items))</span><br><span class="line">print(items)</span><br><span class="line">print(&quot;\n&quot;)</span><br><span class="line"></span><br><span class="line">keys = m_dict.keys()</span><br><span class="line">print(type(keys))</span><br><span class="line">print(keys)</span><br><span class="line">print(&quot;\n&quot;)</span><br><span class="line"></span><br><span class="line">l_values = list(values)</span><br><span class="line">print(type(l_values))</span><br><span class="line">print(l_values)</span><br><span class="line"></span><br><span class="line">输出：</span><br></pre></td></tr></table></figure><h3 id="python3-dict"><a href="#python3-dict" class="headerlink" title="python3 dict"></a>python3 dict</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">m_dict = &#123;&apos;a&apos;: 10, &apos;b&apos;: 20&#125;</span><br><span class="line"></span><br><span class="line">values = m_dict.values()</span><br><span class="line">print(type(values))</span><br><span class="line">print(values) print(&quot;\n&quot;)</span><br><span class="line"></span><br><span class="line">items = m_dict.items()</span><br><span class="line">print(type(items))</span><br><span class="line">print(items)</span><br><span class="line">print(&quot;\n&quot;)</span><br><span class="line"></span><br><span class="line">keys = m_dict.keys()</span><br><span class="line">print(type(keys))</span><br><span class="line">print(keys)</span><br><span class="line">print(&quot;\n&quot;)</span><br><span class="line"></span><br><span class="line">l_values = list(values)</span><br><span class="line">print(type(l_values))</span><br><span class="line">print(l_values)</span><br></pre></td></tr></table></figure><p>输出：</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;python2和python3的dict&quot;&gt;&lt;a href=&quot;#python2和python3的dict&quot; class=&quot;headerlink&quot; title=&quot;python2和python3的dict&quot;&gt;&lt;/a&gt;python2和python3的dict&lt;/h2&gt;&lt;
      
    
    </summary>
    
      <category term="python" scheme="http://mxxhcm.github.io/categories/python/"/>
    
    
      <category term="python" scheme="http://mxxhcm.github.io/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>python中的深复制和浅复制</title>
    <link href="http://mxxhcm.github.io/2019/04/13/python-%E6%B7%B1%E5%A4%8D%E5%88%B6%E5%92%8C%E6%B5%85%E5%A4%8D%E5%88%B6/"/>
    <id>http://mxxhcm.github.io/2019/04/13/python-深复制和浅复制/</id>
    <published>2019-04-13T06:43:31.000Z</published>
    <updated>2019-05-06T16:22:27.708Z</updated>
    
    <content type="html"><![CDATA[<h2 id="简单赋值，浅拷贝，深拷贝"><a href="#简单赋值，浅拷贝，深拷贝" class="headerlink" title="简单赋值，浅拷贝，深拷贝"></a>简单赋值，浅拷贝，深拷贝</h2><h3 id="简单赋值"><a href="#简单赋值" class="headerlink" title="简单赋值"></a>简单赋值</h3><h4 id="str"><a href="#str" class="headerlink" title="str"></a>str</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = <span class="string">'hello'</span></span><br><span class="line">b = <span class="string">'hello'</span></span><br><span class="line">c = a</span><br><span class="line">print(id(a),id(b),id(c))</span><br></pre></td></tr></table></figure><blockquote><p>2432356754632  2432356754632  2432356754632</p></blockquote><p>这里打印出a，b，c的id是一样的，因为他们全是指向’hello’这个字符串在内存中的地址<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a = <span class="string">'world'</span></span><br><span class="line">print(id(a),id(b),id(c))</span><br></pre></td></tr></table></figure></p><blockquote><p>2432356757376  2432356754632  2432356754632</p></blockquote><p>将a指向一个新的字符串’world’,所以变量a的地址就改变了，指向字符串’world’的地址，但是b和c还是指向字符串’hello’的地址。</p><h4 id="list"><a href="#list" class="headerlink" title="list"></a>list</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = [<span class="string">'hello'</span>]</span><br><span class="line">b = [<span class="string">'hello'</span>]</span><br><span class="line">c = a</span><br><span class="line">print(id(a),id(b),id(c))</span><br></pre></td></tr></table></figure><blockquote><p>2432356788424 2432356797064 2432356788424</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">b = [<span class="string">'world'</span>]</span><br><span class="line">print(id(a),id(b),id(c))</span><br></pre></td></tr></table></figure><blockquote><p>2432356798024 2432356797064 2432356788424</p></blockquote><h4 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h4><p>简单赋值是先给一个变量分配内存，然后把变量的地址赋值给一个变量名。<br>对于一些不可变的类型，比如str，int等，某一个值在内存中的地址是固定的，如果用赋值操作直接指向一个值的话，那么变量名指向的就是这个值在内存中地址。<br>比如a=’hello’,b=’hello’,这样a和b的id是相同的，都指向内存中hello的地址<br>对于一些可变的类型，比如list，因为他是可变的，所以如果用赋值操作指向同一个值的话，那么这几个变量的地址也不一样<br>比如a =[‘hello’],b=[‘hello’],这样a和b的id是不同的，虽然他们指向的值是一样的，</p><h3 id="浅拷贝"><a href="#浅拷贝" class="headerlink" title="浅拷贝"></a>浅拷贝</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">a = [<span class="string">'hello'</span> , [<span class="number">123</span>] ]</span><br><span class="line">b = a[:]</span><br><span class="line">a = [<span class="string">'hello'</span> , [<span class="number">123</span>] ]</span><br><span class="line">b = a[:]</span><br><span class="line">print(a,b)</span><br><span class="line">print(id(a),id(b))</span><br><span class="line">print(id(a[<span class="number">0</span>]),id(a[<span class="number">1</span>]))</span><br><span class="line">print(id(b[<span class="number">0</span>]),id(b[<span class="number">1</span>]))</span><br></pre></td></tr></table></figure><blockquote><p>[‘hello’, [123]] [‘hello’, [123]]<br>2432356775368 2432356775432 2432356754632 2432356774984<br>2432356754632 2432356774984</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;a[<span class="number">0</span>] = <span class="string">'world'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(a,b)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(id(a),id(b))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(id(a[<span class="number">0</span>]),id(a[<span class="number">1</span>]))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(id(b[<span class="number">0</span>]),id(b[<span class="number">1</span>]))</span><br></pre></td></tr></table></figure><blockquote><p>[‘world’, [123]] [‘hello’, [123]]<br>2432356775368 2432356775432<br>2432356756424 2432356774984<br>2432356754632 2432356774984</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a[<span class="number">1</span>].append(<span class="number">3</span>)</span><br><span class="line">print(a,b)</span><br><span class="line">print(id(a),id(b))</span><br><span class="line">print(id(a[<span class="number">0</span>]),id(a[<span class="number">1</span>]))</span><br><span class="line">print(id(b[<span class="number">0</span>]),id(b[<span class="number">1</span>]))</span><br></pre></td></tr></table></figure><blockquote><p>[‘world’, [123, 3]] [‘hello’, [123, 3]]<br>2432356775368 2432356775432<br>2432356756424 2432356774984<br>2432356754632 2432356774984</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">a[<span class="number">1</span>] = [<span class="number">123</span>]</span><br><span class="line">print(a,b)</span><br><span class="line">print(id(a),id(b))</span><br><span class="line">print(id(a[<span class="number">0</span>]),id(a[<span class="number">1</span>]))</span><br><span class="line">print(id(b[<span class="number">0</span>]),id(b[<span class="number">1</span>]))</span><br><span class="line">``` </span><br><span class="line">&gt; [<span class="string">'world'</span>, [<span class="number">123</span>]] [<span class="string">'hello'</span>, [<span class="number">123</span>, <span class="number">3</span>]]</span><br><span class="line"><span class="number">2432356775368</span> <span class="number">2432356775432</span></span><br><span class="line"><span class="number">2432356756424</span> <span class="number">2432356822984</span></span><br><span class="line"><span class="number">2432356754632</span> <span class="number">2432356774984</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### 深拷贝</span></span><br><span class="line">``` python</span><br><span class="line"><span class="keyword">from</span> copy <span class="keyword">import</span> deepcopy</span><br><span class="line">a = [<span class="string">'hello'</span>,[<span class="number">123</span>,<span class="number">234</span>]</span><br><span class="line">b = deepcopy(a)</span><br></pre></td></tr></table></figure><p>a，b以及a，b中任何元素（除了str，int等类型）的地址都是不一样的</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;简单赋值，浅拷贝，深拷贝&quot;&gt;&lt;a href=&quot;#简单赋值，浅拷贝，深拷贝&quot; class=&quot;headerlink&quot; title=&quot;简单赋值，浅拷贝，深拷贝&quot;&gt;&lt;/a&gt;简单赋值，浅拷贝，深拷贝&lt;/h2&gt;&lt;h3 id=&quot;简单赋值&quot;&gt;&lt;a href=&quot;#简单赋值&quot; cla
      
    
    </summary>
    
      <category term="python" scheme="http://mxxhcm.github.io/categories/python/"/>
    
    
      <category term="python" scheme="http://mxxhcm.github.io/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>python special method</title>
    <link href="http://mxxhcm.github.io/2019/04/13/python-special-method/"/>
    <id>http://mxxhcm.github.io/2019/04/13/python-special-method/</id>
    <published>2019-04-13T06:41:38.000Z</published>
    <updated>2019-05-06T16:22:27.708Z</updated>
    
    <content type="html"><![CDATA[<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>print(object)就是调用了类对象object的<strong>repr</strong>()函数<br>如下代码<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Tem</span>:</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">     <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__repr__</span><span class="params">(self)</span>:</span></span><br><span class="line">     <span class="keyword">return</span> <span class="string">"tem class"</span></span><br></pre></td></tr></table></figure></p><p>声明类对象 </p><blockquote><blockquote><blockquote><p>Tem tem<br>下面两行代码的功能是一样的。<br>print(tem)<br>print(repr(tem))</p></blockquote></blockquote></blockquote><h2 id="基本的自定义方法"><a href="#基本的自定义方法" class="headerlink" title="基本的自定义方法"></a>基本的自定义方法</h2><h3 id="object-new"><a href="#object-new" class="headerlink" title="object.new"></a>object.<strong>new</strong></h3><h3 id="object-init"><a href="#object-init" class="headerlink" title="object.init"></a>object.<strong>init</strong></h3><h3 id="object-repr和object-str"><a href="#object-repr和object-str" class="headerlink" title="object.repr和object.str"></a>object.<strong>repr</strong>和object.<strong>str</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Tem</span><span class="params">(object)</span>:</span></span><br><span class="line">  <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TemStr</span><span class="params">(object)</span>:</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__str__</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">'foo'</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TemRepr</span><span class="params">(object)</span>:</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__repr__</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">'foo'</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TemStrRepr</span><span class="params">(object)</span>:</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__repr__</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">'foo'</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__str__</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">'foo_str'</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>: </span><br><span class="line">   tem = Tem() </span><br><span class="line">   print(str(tem)) </span><br><span class="line">   print(repr(tem)) </span><br><span class="line">   tem_str = TemStr() </span><br><span class="line">   print(str(tem_str)) </span><br><span class="line">   print(repr(tem_str)) </span><br><span class="line">   tem_repr = TemRepr() </span><br><span class="line">   print(str(tem_repr)) </span><br><span class="line">   print(repr(tem_repr)) </span><br><span class="line">   tem_str_repr = TemStrRepr() </span><br><span class="line">   print(str(tem_str_repr)) </span><br><span class="line">   print(repr(tem_str_repr))</span><br></pre></td></tr></table></figure><p>单独重载<strong>repr</strong>，<strong>str</strong>也会调用<strong>repr</strong>，<br>但是单独重载<strong>str</strong>,<strong>repr</strong>不会调用它。<br><strong>repr</strong>面向的是程序员，而<strong>str</strong>面向的是普通用户。它们都用来返回一个字符串，这个字符串可以是任何字符串，我觉得这个函数的目的就是将对象转化为字符串。</p><h3 id="object-bytes"><a href="#object-bytes" class="headerlink" title="object.bytes"></a>object.<strong>bytes</strong></h3><h2 id="自定义属性方法"><a href="#自定义属性方法" class="headerlink" title="自定义属性方法"></a>自定义属性方法</h2><h3 id="object-getattr-self-name"><a href="#object-getattr-self-name" class="headerlink" title="object.getattr(self, name)"></a>object.<strong>getattr</strong>(self, name)</h3><h3 id="object-setattr-self-name"><a href="#object-setattr-self-name" class="headerlink" title="object.setattr(self, name)"></a>object.<strong>setattr</strong>(self, name)</h3><h2 id="比较"><a href="#比较" class="headerlink" title="比较"></a>比较</h2><h3 id="object-eq-self-others"><a href="#object-eq-self-others" class="headerlink" title="object.eq(self, others)"></a>object.<strong>eq</strong>(self, others)</h3><h3 id="object-lt-self-others"><a href="#object-lt-self-others" class="headerlink" title="object.lt(self, others)"></a>object.<strong>lt</strong>(self, others)</h3><h3 id="object-le-self-others"><a href="#object-le-self-others" class="headerlink" title="object.le(self, others)"></a>object.<strong>le</strong>(self, others)</h3><h3 id="object-ne-self-others"><a href="#object-ne-self-others" class="headerlink" title="object.ne(self, others)"></a>object.<strong>ne</strong>(self, others)</h3><h3 id="object-gt-self-others"><a href="#object-gt-self-others" class="headerlink" title="object.gt(self, others)"></a>object.<strong>gt</strong>(self, others)</h3><h3 id="object-ge-self-others"><a href="#object-ge-self-others" class="headerlink" title="object.ge(self, others)"></a>object.<strong>ge</strong>(self, others)</h3><h2 id="特殊属性"><a href="#特殊属性" class="headerlink" title="特殊属性"></a>特殊属性</h2><h3 id="object-dict"><a href="#object-dict" class="headerlink" title="object.dict"></a>object.<strong>dict</strong></h3><h3 id="instance-class"><a href="#instance-class" class="headerlink" title="instance.class"></a>instance.<strong>class</strong></h3>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;结论&quot;&gt;&lt;a href=&quot;#结论&quot; class=&quot;headerlink&quot; title=&quot;结论&quot;&gt;&lt;/a&gt;结论&lt;/h2&gt;&lt;p&gt;print(object)就是调用了类对象object的&lt;strong&gt;repr&lt;/strong&gt;()函数&lt;br&gt;如下代码&lt;br&gt;&lt;figu
      
    
    </summary>
    
      <category term="python" scheme="http://mxxhcm.github.io/categories/python/"/>
    
    
      <category term="python" scheme="http://mxxhcm.github.io/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>gym介绍</title>
    <link href="http://mxxhcm.github.io/2019/04/12/gym%E4%BB%8B%E7%BB%8D/"/>
    <id>http://mxxhcm.github.io/2019/04/12/gym介绍/</id>
    <published>2019-04-12T08:54:44.000Z</published>
    <updated>2019-05-06T16:22:27.708Z</updated>
    
    <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>强化学习中最主要的两类对象是“智能体”和“environment”，然后有一些概念：“reward”、“return”、“state”、“action”、“value”、“policy”、“predict”、“control”等。这些概念把智能体和environment联系了起来。<br>总结起来，有这样几条关系：</p><ol><li>environment会对智能体采取的action做出回应。当智能体执行一个行为时，它需要根据environment本身的动力学来更新environment，也包括更新智能体状态，同时给以智能体一个反馈信息：即时奖励(immediate reward)。</li><li>对于智能体来说，它并不知道整个environment的所有信息，只能通过观测(observation)来获得所需要的信息，它能观测到的信息取决于问题的设置；同样因为智能体需要通过action与environment进行交互，智能体能采取哪些action，也要由智能体和environment协商好。因此environment要确定智能体的观测空间和action空间。</li><li>智能体还需要有一个决策功能，该功能根据当前observation来判断下一时刻该采取什么action，也就是决策过程。</li><li>智能体能执行一个确定的action。（这个刚开始还没想明白，智能体执行什么action干嘛，一般我们写代码不都是env.step(action)，后来才想到是action本身就是智能体自己执行的，只不过代码是这么写，因为environment需要根据这个action，去更新智能体的状态以及environment的状态。）</li><li>智能体应该能从与environment的交互中学到知识，进而在与environment交互时尽可能多的获取reward，最终达到最大化累积奖励(accumate reward)的目的。</li><li>environment应该给智能体设置一个（些）终止条件，即当智能体处在这个状态或这些状态之一时，交互结束，即产生一个完整的Episode。随后重新开始一个Episode或者退出交互。</li></ol><h2 id="自己实现一个environment"><a href="#自己实现一个environment" class="headerlink" title="自己实现一个environment"></a>自己实现一个environment</h2><p>如果用代码表示上述关系，可以定义为如下式子：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Environment</span><span class="params">(object)</span>:</span></span><br><span class="line">  self.aget_state <span class="comment">#</span></span><br><span class="line">  self.states <span class="comment"># 所有可能的状态集合</span></span><br><span class="line">  self.observation_space <span class="comment"># 智能体的observation space</span></span><br><span class="line">  self.action_space <span class="comment"># 智能体体的action space</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># 给出智能体的immediate reward</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">reward</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># 根据智能体的动作，更新环境</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">step</span><span class="params">(self, action)</span>:</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># 当前回合是否结束</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">is_episode_end</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># 生成智能体的obs</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">obs_for_agent</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Agent</span><span class="params">(object)</span>:</span></span><br><span class="line">   self.env = env <span class="comment"># 智能体依附于某一个环境</span></span><br><span class="line">   self.obs <span class="comment"># 智能体的obs</span></span><br><span class="line">   self.reward  <span class="comment"># 智能体获得的immediate reward</span></span><br><span class="line"></span><br><span class="line">   <span class="comment"># 根据当前的obs生成action</span></span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">policy</span><span class="params">(self, obs)</span>:</span></span><br><span class="line">      self.action</span><br><span class="line"></span><br><span class="line">   <span class="comment"># 智能体观测到obs和reward</span></span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">observe</span><span class="params">(self)</span>:</span></span><br><span class="line">     self.obs = </span><br><span class="line">     self.reward =</span><br></pre></td></tr></table></figure></p><h2 id="gym"><a href="#gym" class="headerlink" title="gym"></a>gym</h2><p>gym库在设计environment和智能体的交互时基本上也是按照这几条关系来实现自己的规范和接口的。gym库的核心在文件core.py里，这里定义了两个最基本的类Env和Space。<br>Env类是所有environment类的基类，Space类是所有space类的基类。</p><h2 id="Spaces"><a href="#Spaces" class="headerlink" title="Spaces"></a>Spaces</h2><p>Space是一个抽象类，其中包含以下函数，以下几个全是abstract函数，需要在子类中实现</p><ul><li><strong>init</strong>(self, shape=None, dtype=None) 函数初始化shape和dtype以及初始化numpy随机数RandomState()对象。</li><li>sample(self) 函数进行采样，实际上是调用了numpy的随机函数。</li><li>seed(self, seed) 设置numpy随机数种子，这里使用的是RandomState对象，生成随机数，种子一定的情况下，采样的过程是一定的。</li><li>contains(self, x) 函数判断某个对象x是否是这个space中的一个member。</li><li>to_jsonable(self, sample_n)</li><li>from_jsonable(self, sample_n)</li></ul><p>从Space基类派生出几个常用的Space子类，其中最主要的是Discrete类和Box类，其余的还有MultiBinary类，MultiDiscrete类，Tuple类等，每个子类重新实现了<strong>repr</strong>和<strong>eq</strong>以及几乎所有Space类中的函数。<br>最常见的Discrete和Box类，Discrete对应于一维离散空间，Box对应于多维连续空间。它们既可以应用在action space中，也可以用在state space，可以根据具体场景选择。<br>Discrete声明的时候需要给定一个整数，然后整个类的取值在${0, 1, \cdots, n-1}$之间。然后使用sample()函数采样，实际调用的是numpy的randint()进行采样，得到一个整数值。<br>示例<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> gym <span class="keyword">import</span> spaces</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1.Discrete</span></span><br><span class="line"><span class="comment"># 取值是&#123;0, 1, ..., n - 1&#125;</span></span><br><span class="line">print(<span class="string">"=================="</span>)</span><br><span class="line">dis = spaces.Discrete(<span class="number">8</span>)</span><br><span class="line">print(dis.shape)</span><br><span class="line">print(dis.n)</span><br><span class="line">print(dis)</span><br><span class="line">dis.seed(<span class="number">4</span>)</span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">5</span>):</span><br><span class="line">    print(dis.sample())</span><br></pre></td></tr></table></figure></p><p>输出结果是：</p><blockquote><p>==================<br>() # shape是None<br>8  # n为8<br>Discrete(8) # repr()函数的值<br>2<br>6<br>7<br>5<br>1</p></blockquote><p>而Box类应用于连续空间，有两种初始化方式，一种是给出最小值，最大值和shape，另一种是直接给出最小值矩阵和最大值矩阵。然后使用sample()函数采样，实际上调用的是numpy的uniform()函数。<br>示例<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> gym <span class="keyword">import</span> spaces</span><br><span class="line"><span class="comment"># 2.Box</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line">print(<span class="string">"=================="</span>)</span><br><span class="line"><span class="comment"># def __init__(self, low=None, high=None, shape=None, dtype=None):</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Two kinds of valid input:</span></span><br><span class="line"><span class="string">    Box(low=-1.0, high=1.0, shape=(3,4)) # low and high are scalars, and shape is provided</span></span><br><span class="line"><span class="string">    Box(low=np.array([-1.0,-2.0]), high=np.array([2.0,4.0])) # low and high are arrays of the same shape</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line">box = spaces.Box(low=<span class="number">3.0</span>, high=<span class="number">4</span>, shape=(<span class="number">2</span>,<span class="number">2</span>))</span><br><span class="line">print(box) </span><br><span class="line">box.seed(<span class="number">4</span>)</span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">2</span>):</span><br><span class="line">    print(box.sample())</span><br></pre></td></tr></table></figure></p><p>输出结果是：</p><blockquote><p>==================<br>Box(2, 2) # repr()函数的值<br>[[3.9670298 3.5472322]<br> [3.9726844 3.714816 ]]<br>[[3.6977289 3.2160895]<br> [3.9762745 3.0062304]]</p></blockquote><p>这里给出一个应用场景，例如要描述一个$4\times 4$的网格世界，它一共有16个状态，每一个状态只需要用一个数字来描述即可，这样可以用Discrete(16)对象来表示这个问题的state space。<br>对于经典的小车爬山的问题，小车的state是用两个变量来描述，一个是小车对应目标旗杆的水平距离，另一个是小车的速度，因此environment要描述小车的state需要2个连续的变量。由于小车的state对智能体是完全可见的，因此小车的state space即是小车的observation space，此时不能用Discrete来表示，要用Box类，Box空间定义了多维空间，每一个维度用一个最小值和最大值来约束。同时小车作为智能体可以执行的action有3个：左侧加速、不加速、右侧加速。因此action space可以用Discrete来描述。最终，该environment类的观测空间和行为空间描述如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Env</span><span class="params">(obejct)</span>:</span></span><br><span class="line">  self.min_position = <span class="number">-1.2</span></span><br><span class="line">  self.max_position = <span class="number">0.6</span></span><br><span class="line">  self.max_speed = <span class="number">0.07</span></span><br><span class="line">  self.goal_position = <span class="number">0.5</span> </span><br><span class="line">  self.low = np.array([self.min_position, -self.max_speed])</span><br><span class="line">  self.high = np.array([self.max_position, self.max_speed])</span><br><span class="line">  self.action_space = spaces.Discrete(<span class="number">3</span>)  <span class="comment"># action space,是离散的</span></span><br><span class="line">  self.observation_space = spaces.Box(self.low, self.high) <span class="comment"># 状态空间是连续的</span></span><br></pre></td></tr></table></figure></p><h2 id="Env"><a href="#Env" class="headerlink" title="Env"></a>Env</h2><h3 id="组成"><a href="#组成" class="headerlink" title="组成"></a>组成</h3><p>OpenAI官方在gym.core.Env类中给出了如下的说明<br>The main OpenAI Gym class. It encapsulates an environment with arbitrary behind-the-scenes dynamics. An environment can be partially or fully observed.</p><p>用户需要知道的方法主要有下面五个：<br>The main API methods that users of this class need to know are:</p><ul><li>step</li><li>reset</li><li>render</li><li>close</li><li>seed</li></ul><p>用户需要知道的属性主要有下面三个：<br>And set the following attributes:</p><ul><li>action_space: The Space object corresponding to valid actions</li><li>observation_space: The Space object corresponding to valid observations</li><li>reward_range: A tuple corresponding to the min and max possible rewards </li></ul><p>Note: a default reward range set to [-inf,+inf] already exists. Set it if you want a narrower range.</p><p>The methods are accessed publicly as “step”, “reset”, etc.. The non-underscored versions are wrapper methods to which we may add functionality over time.</p><p>智能体主要通过环境的几个方法进行交互，用户如果要编写自己的环境的话，需要实现seed, reset, step, close, render等函数。</p><h3 id="step函数执行一个时间步的更新。"><a href="#step函数执行一个时间步的更新。" class="headerlink" title="step函数执行一个时间步的更新。"></a>step函数执行一个时间步的更新。</h3><p>Accepts an action and returns a tuple (observation, reward, done, info).<br>输入参数：<br>  action (object):智能体执行的动作<br>返回值：</p><ul><li>observation (object): agent’s observation of the current environment</li><li>reward (float) : amount of reward returned after previous action</li><li>done (boolean): whether the episode has ended, in which case further step() calls will return undefined results</li><li>info (dict): contains auxiliary diagnostic information (调试信息, and sometimes learning)</li></ul><h3 id="reset函数重置"><a href="#reset函数重置" class="headerlink" title="reset函数重置"></a>reset函数重置</h3><p>重置环境并返回初始的observation.<br>Returns: observation (object): 返回环境的初始observation</p><h3 id="reder函数绘制"><a href="#reder函数绘制" class="headerlink" title="reder函数绘制"></a>reder函数绘制</h3><p>Renders the environment.</p><h3 id="close函数回收garbge"><a href="#close函数回收garbge" class="headerlink" title="close函数回收garbge"></a>close函数回收garbge</h3><p>在使用完之后调用close函数清理内存</p><h3 id="seed函数设置环境的随机数种子"><a href="#seed函数设置环境的随机数种子" class="headerlink" title="seed函数设置环境的随机数种子"></a>seed函数设置环境的随机数种子</h3><p>使用seed函数设置随机数种子，使得结果可以复现。</p><h3 id="使用Env类"><a href="#使用Env类" class="headerlink" title="使用Env类"></a>使用Env类</h3><p>在使用Env类的时候，一种是使用gym中自带的已经注册了的类，另一种是使用自己编写的类。<br>第一种的话，使用如下语句注册：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> gym</span><br><span class="line">env = gym.make(<span class="string">"registered_env_name"</span>)</span><br></pre></td></tr></table></figure></p><p>另一种自己编写的环境类是和普通的python 类对象声明一样。</p><h2 id="Some-issues"><a href="#Some-issues" class="headerlink" title="Some issues"></a>Some issues</h2><p>1.&gt;gym.error.DeprecatedEnv: Env PongDeterministic-v4 not found (valid versions include [‘PongDeterministic-v3’, ‘PongDeterministic-v0’])<br>gym版本太老了，升级一下就行[2]。这个是gym$0.7.0$遇到的问题。<br>2.&gt;UserWarning: WARN: <class 'envs.atarirescale42x42'> doesn’t implement ‘observation’ method. Maybe it implements deprecated ‘_observation’ method.<br>这个是gym版本太新了，apis进行了重命名。这个是gym$0.12.0$遇到的问题。<br>上面两个问题都是在测试github上的一个<img src="https://github.com/ikostrikov/pytorch-a3c/" alt="A3C">代码遇到的。最后装了$0.9$版本的gym就没有警告了。（测试了一下，装$0.10$版本的也不行）</class></p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>1.<a href="https://github.com/openai/gym" target="_blank" rel="noopener">https://github.com/openai/gym</a><br>2.<a href="https://github.com/ikostrikov/pytorch-a3c/issues/36" target="_blank" rel="noopener">https://github.com/ikostrikov/pytorch-a3c/issues/36</a><br>3.<a href="https://github.com/openai/roboschool/issues/169" target="_blank" rel="noopener">https://github.com/openai/roboschool/issues/169</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h2&gt;&lt;p&gt;强化学习中最主要的两类对象是“智能体”和“environment”，然后有一些概念：“reward”、“return”、“state”、“a
      
    
    </summary>
    
      <category term="强化学习" scheme="http://mxxhcm.github.io/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="强化学习" scheme="http://mxxhcm.github.io/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="gym" scheme="http://mxxhcm.github.io/tags/gym/"/>
    
  </entry>
  
  <entry>
    <title>reinforcement learning an introduction 第4章笔记</title>
    <link href="http://mxxhcm.github.io/2019/04/07/reinforcement-learning-an-introduction-%E7%AC%AC4%E7%AB%A0%E7%AC%94%E8%AE%B0/"/>
    <id>http://mxxhcm.github.io/2019/04/07/reinforcement-learning-an-introduction-第4章笔记/</id>
    <published>2019-04-07T15:46:17.000Z</published>
    <updated>2019-05-06T16:22:27.708Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Dynamic-Programming"><a href="#Dynamic-Programming" class="headerlink" title="Dynamic Programming"></a>Dynamic Programming</h2><p>DP指的是给定环境的模型，通常是一个MDP，计算智能体最优策略的一类算法。经典的DP算法应用场景有限，因为它需要环境的模型，以及很高的计算代价，但是DP的思路是很重要的。其他的许多算法都是在减少计算代价和环境信息的前提下尽可能获得和DP接近的性能。<br>通常我们假定环境是一个有限(finite)的MDP，也就是state, action, reward都是有限的。尽管DP可以应用于连续(continuous)的state和action space，但是只能应用在几个特殊的场景上。一个常见的做法是将连续state和action quantize(量化)，然后使用有限MDP。<br>DP关键在于使用value function寻找好的policy，在找到了满足Bellman optimal equation的optimal value function之后，可以找到optimal policy，参见<a href="https://mxxhcm.github.io/2018/12/21/reinforcement-learning-an-introduction-%E7%AC%AC3%E7%AB%A0%E7%AC%94%E8%AE%B0/">第三章推导</a>：<br>Bellman optimal equation:<br>\begin{align*}<br>v<em>{*}(s) &amp;= max_a\mathbb{E}\left[R</em>{t+1}+\gamma v<em>{*}(S</em>{t+1})|S<em>t=s,A_t=a\right] \<br>&amp;= max_a \sum</em>{s’,r} p(s’,r|s,a){*}\left[r+\gamma v_{*}(s’)\right]  \tag{1}<br>\end{align*}</p><p>\begin{align*}<br>q<em>{*}(s,a) &amp;= \mathbb{E}\left[R</em>{t+1}+\gamma max<em>{a’}q</em>{*}(S<em>{t+1},a’)|S_t=s,A_t = a\right]\<br>&amp;= \sum</em>{s’,r} p(s’,r|s,a) \left[r + \gamma max<em>a q\</em>{*}(s’,a’)\right] \tag{2}<br>\end{align*}</p><h2 id="Policy-Evaluation-Prediction"><a href="#Policy-Evaluation-Prediction" class="headerlink" title="Policy Evaluation(Prediction)"></a>Policy Evaluation(Prediction)</h2><p>给定一个policy，计算state value function的过程叫做policy evaluation或者prediction problem。<br>根据$v(s)$和它的后继状态$v(s’)$之间的关系：<br>\begin{align*}<br>v<em>{\pi}(s) &amp;= \mathbb{E}</em>{\pi}[G<em>t|S_t = s]\<br>&amp;= \mathbb{E}</em>{\pi}\left[R<em>{t+1}+\gamma G</em>{t+1}|S<em>t = s\right]\<br>&amp;= \sum_a \pi(a|s)\sum</em>{s’}\sum<em>rp(s’,r|s,a) \left[r + \gamma \mathbb{E}</em>{\pi}\left[G<em>{t+1}|S</em>{t+1}=s’\right]\right] \tag{3}\<br>&amp;= \sum<em>a \pi(a|s)\sum</em>{s’,r}p(s’,r|s,a) \left[r + \gamma v<em>{\pi}(s’) \right] \tag{4}\<br>\end{align*}<br>只要$\gamma \lt 1$或者存在terminal state，那么$v</em>{\pi}$的必然存在且唯一。这个我觉得是迭代法解方程的条件。数值分析上有证明。<br>如果环境的转换概率$p$是已知的，可以列出方程组，直接求解出每个状态$s$的$v(s)$。这里采用迭代法求解，随机初始化$v<em>0$，使用式子$(4)$进行更新：<br>\begin{align*}<br>v</em>{k+1}(s) &amp;= \mathbb{E}\left[R<em>{t+1} + \gamma v_k(S</em>{t+1})\ S<em>t=s\right]\<br>&amp;= \sum_a \pi(a|s)\sum</em>{s’,r}p(s’,r|s,a) \left[r + \gamma v<em>k(s’) \right] \tag{5}<br>\end{align*}<br>直到$v_k=v</em>{\pi}$到达一个fixed point，Bellman equation满足这个条件。当$k\rightarrow \infty$时收敛到$v<em>{\pi}$。这个算法叫做iterative policy evaluation。<br>在每一次$v_k$到$v</em>{k+1}$的迭代过程中，所有的$v(s)$都会被更新，$s$的旧值被后继状态$s’$的旧值加上reward替换，正如公式$(5)$中体现的那样。这个目标值被称为expected update，因为它是基于所有$s’$的期望计算出来的（利用环境的模型），而不是通过对$s’$采样计算的。<br>在实现iterative policy evaluation的时候，每一次迭代，都需要重新计算所有$s$的值。这里有一个问题，就是你在每次更新$s$的时候，使用的$s’$如果在本次迭代过程中已经被更新过了，那么是使用更新过的$s’$，还是使用没有更新的$s’$，这就和迭代法中的雅克比迭代以及高斯赛德尔迭代很像，如果使用更新后的$s’$，这里我们叫它in-place的算法，否则就不是。具体那种方法收敛的快，还是要看应用场景的，并不是in-place的就一定收敛的快，这是在数值分析上学到的。<br>下面给出in-place版本的iterative policy evation算法伪代码。<br><strong>iterative policy evation 算法</strong><br><strong>输入</strong>需要evaluation的policy $\pi$<br>给出算法的参数：阈值$\theta\gt 0$，当两次更新的差值小于这个阈值的时候，就停止迭代，随机初始化$V(s),\forall s\in S^{+}$，除了$V(terminal) = 0$。<br><strong>Loop</strong><br>$\qquad \delta \leftarrow 0$<br>$\qquad$ <strong>for</strong> each $s\in S$<br>$\qquad\qquad v\leftarrow V(s)$ （保存迭代之前的$V(s)$）<br>$\qquad\qquad V(s)\leftarrow\sum<em>a \pi(a|s)\sum</em>{s’,r}p(s’,r|s,a) \left[r + \gamma v_k(s’) \right] $<br>$\qquad\qquad \nabla \leftarrow max(\delta,|v-V(s)|)$<br>$\qquad$<strong>end for</strong><br><strong>until</strong> $\delta \lt \theta$</p><h2 id="Policy-Improvement"><a href="#Policy-Improvement" class="headerlink" title="Policy Improvement"></a>Policy Improvement</h2><p>为什么要进行policy evaluation，或者说为什么要计算value function？<br>其中一个原因是为了找到更好的policy。假设我们已经知道了一个deterministic的策略$\pi$，但是在其中一些状态，我们想要知道是不是有更好的action选择，如$a\neq \pi(s)$的时候，是不是这个改变后的策略会更好。好该怎么取评价，这个时候就可以使用值函数进行评价了，在某个状态，我们选择$a \neq \pi(s)$，在其余状态，依然遵循策略$\pi$。用公式表示为：<br>\begin{align*}<br>q<em>{\pi}(s,a) &amp;= \mathbb{E}\left[R</em>{t+1}+\gamma v<em>{\pi}(S</em>{t+1})|S<em>t=s,A_t = a\right]\<br>&amp;=\sum</em>{s’,r}p(s’,r|s,a)\left[r+\gamma v_{\pi}(s’)\right] \tag{6}<br>\end{align*}<br>那么，这个值是是比$v(s)$要大还是要小呢？如果比$v(s)$要大，那么这个新的策略就比$\pi$要好。<br>用$\pi$和$\pi’$表示任意一对满足下式的deterministic policy：</p><script type="math/tex; mode=display">q_{\pi}(s,\pi'(s)) \ge v_{\pi}(s) \tag{7}</script><p>那么$\pi’$至少和$\pi$一样好。可以证明，任意满足$(7)$的$s$都满足下式：</p><script type="math/tex; mode=display">v_{\pi'}(s) \ge v_{\pi}(s) \tag{8}</script><p>对于我们提到的$\pi$和$\pi’$来说，除了在状态$s$处，$v<em>{\pi’}(s) = a \neq v</em>{\pi}(s)$，在其他状态处$\pi$和$\pi’$是一样的，都有$q<em>{\pi}(s,\pi’(s)) = v</em>{\pi}(s)$。而在状态$s$处，如果$q<em>{\pi}(s,a) \gt v</em>{\pi}(s)$，注意这里$a=\pi’(s)$，那么$\pi’$一定比$\pi$好。<br>证明：<br>\begin{align*}<br>v<em>{\pi}(s) &amp;\le q</em>{\pi}(s,\pi’(s))\<br>&amp; = \mathbb{E}\left[R<em>{t+1} + \gamma v</em>{\pi}(S<em>{t+1})|S_t = s, A_t = \pi’(s) \right]\<br>&amp; = \mathbb{E}</em>{\pi’}\left[R<em>{t+1} + \gamma v</em>{\pi}(S<em>{t+1})|S_t = s \right]\<br>&amp; \le \mathbb{E}</em>{\pi’}\left[R<em>{t+1} + \gamma q</em>{\pi}(S<em>{t+1},\pi’(S</em>{t+1}))|S<em>t = s \right]\<br>&amp; = \mathbb{E}</em>{\pi’}\left[ R<em>{t+1} + \gamma \mathbb{E}</em>{\pi’}\left[R<em>{t+2} +\gamma v</em>{\pi}(S<em>{t+2})|S</em>{t+1}, A<em>{t+1}=\pi’(S</em>{t+1})|S<em>t = s \right]\right]\<br>&amp; = \mathbb{E}</em>{\pi’}\left[ R<em>{t+1} + \gamma R</em>{t+2} +\gamma^2 v<em>{\pi}(S</em>{t+2})|S<em>t = s \right]\<br>&amp; \le \mathbb{E}</em>{\pi’}\left[ R<em>{t+1} + \gamma R</em>{t+2} +\gamma^2 R<em>{t+3}  +\gamma^3 v</em>{\pi}(S<em>{t+3})|S_t = s \right]\<br>&amp; \le \mathbb{E}</em>{\pi’}\left[ R<em>{t+1} + \gamma R</em>{t+2} +\gamma^2 R<em>{t+3}  +\gamma^3 R</em>{t+4} + \cdots |S<em>t = s \right]\<br>&amp;=v</em>{\pi’}(s)<br>\end{align*}<br>所以，在计算出一个policy的value function的时候，很容易我们就直到某个状态$s$处的变化是好还是坏。扩展到所有状态和所有action的时候，在每个state，根据$q<em>{\pi}(s,a)$选择处最好的action，这样就得到了一个greedy策略$\pi’$，给出如下定义：<br>\begin{align*}<br>\pi’(s’) &amp;= argmax</em>{a} q<em>{\pi}(s,a)\<br>&amp; = argmax</em>{a} \mathbb{E}\left[R<em>{t+1} + \gamma v</em>{\pi}(S<em>{t+1} |S_t=a,A_t=a)\right] \tag{9}\<br>&amp; = argmax</em>{a} \sum<em>{s’,r}p(s’,r|s,a)\left[r+v</em>{\pi}(s’) \right]<br>\end{align*}<br>可以看出来，该策略的定义一定满足式子$(7)$，所以$\pi’$比$\pi$要好或者相等，这就叫做policy improvement。当$\pi’$和$\pi$相等时，，根据式子$(9)$我们有：<br>\begin{align*}<br>v<em>{\pi’}(s’)&amp; = max</em>{a} \mathbb{E}\left[R<em>{t+1} + \gamma v</em>{\pi’}(S<em>{t+1} |S_t=a,A_t=a)\right] \tag{9}\<br>&amp; = max</em>{a} \sum<em>{s’,r}p(s’,r|s,a)\left[r+v</em>{\pi’}(s’) \right]<br>\end{align*}<br>这和贝尔曼最优等式是一样的？？？殊途同归！！！<br>但是，需要说的一点是，目前我们假设的$\pi$和$\pi’$是deterministic，当$\pi$是stochastic情况的时候，其实也是一样的。只不过，原来我们每次选择的是使得$v_{\pi}$最大的action。对于stochastic的情况来说，输出的是每个动作的概率，可能有几个动作都能使得value function最大，那就让这几个动作的概率一样大，比如是$n$个动作，都是$\frac{1}{n}$。</p><h2 id="Policy-Iteration"><a href="#Policy-Iteration" class="headerlink" title="Policy Iteration"></a>Policy Iteration</h2><p>我们已经讲了Policy Evaluation和Policy Improvement，Evalution会计算出一个固定$\pi$的value function，Improvment会根据value function改进这个policy，然后计算出一个新的policy $\pi’$，对于新的策略，我们可以再次进行Evaluation，然后在Improvement，就这样一直迭代，对于有限的MDP，我们可以求解出最优的value function和policy。这就是Policy Iteration算法。</p><p><strong>Policy Iteration算法</strong><br><strong>1.初始化</strong><br>$V(s)\in R,\pi(s) in A(s)$<br>$\qquad$<br><strong>2.Policy Evaluation</strong><br><strong>Loop</strong><br>$\qquad\Delta\leftarrow 0 $<br>$\qquad$ <strong>For</strong> each $s\in S$<br>$\qquad\qquad v\leftarrow V(s)$<br>$\qquad\qquad V(s)\leftarrow \sum<em>{s’,r}p(s’,r|s,a)\left[r+\gamma V(s’)\right]$<br>$\qquad\qquad \Delta \leftarrow max(\Delta, |v-V(s)|) $<br><strong>until</strong> $\Delta \lt \theta$<br><strong>3.Policy Improvement</strong><br>$policy-stable\leftarrow true$<br><strong>For</strong> each $s \in S$<br>$\qquad old_action = \pi(s)$<br>$\qquad \pi(s) = argmax_a \sum</em>{s’,a’}p(s’,r|s,a)\left[r+\gamma V(s’)\right]$<br>$\qquad If\ old_action \neq \pi(s), policy-stable\leftarrow false$<br><strong>If policy-stable</strong>，停止迭代，返回$V$和$\pi$，否则回到2.Policy Evalution继续执行。</p><h2 id="Value-Iteration"><a href="#Value-Iteration" class="headerlink" title="Value Iteration"></a>Value Iteration</h2><p>从Policy Iteration算法中我们可以看出来，整个算法分为两步，第一步是Policy Evaluation，第二步是Policy Improvement。而每一次Policy Evaluation都要等到Value function收敛到一定程度才结束，这样子就会非常慢。一个替代的策略是我们尝试每一次Policy Evaluation只进行几步的话，一种特殊情况就是每一个Policy Evaluation只进行一步，这种就叫做Value Iteration。给出如下定义：<br>\begin{align*}<br>v<em>{k+1}(s) &amp;= max_a \mathbb{E}\left[R</em>{t+1} + \gamma v<em>k(S</em>{t+1})| S<em>t=s, A_t = a\right]\<br>&amp;= max_a \sum</em>{s’,r}p(s’,r|s,a) \left[r+\gamma v<em>k(s’)\right] \tag{10}<br>\end{align*}<br>它其实就是把两个步骤给合在了一起，原来分开是：<br>\begin{align*}<br>v</em>{\pi}(s) &amp;= \mathbb{E}\left[R<em>{t+1} + \gamma v_k(S</em>{t+1})| S<em>t=s, A_t = a\right]\<br>&amp;= \sum</em>{s’,r}p(s’,r|s,a) \left[r+\gamma v<em>k(s’)\right]\<br>v</em>{\pi’}(s) &amp;= max<em>a \sum</em>{s’,r}p(s’,r|s,a) \left[r+\gamma v_{\pi}(s’)\right]\<br>\end{align*}<br>另一种方式理解式$(10)$可以把它看成是使用贝尔曼最优等式进行迭代更新，Policy Evaluation用的是贝尔曼期望等式进行更新。下面给出完整的Value Iteration算法</p><p><strong>Value Iteration 算法</strong><br><strong>初始化</strong><br>阈值$\theta$，以及随机初始化的$V(s), s\in S^{+}$，$V(terminal)=0$。<br><strong>Loop</strong><br>$\qquad v\leftarrow V(s)$<br>$\qquad$<strong>Loop</strong> for each $s\in S$<br>$\qquad\qquad V(s) = max<em>a\sum</em>{s’,r}p(s’,r|s,a)\left[r+\gamma V(s’)\right]$<br>$\qquad\qquad\Delta \leftarrow max(Delta, |v-V(s)|)$<br><strong>until</strong> $\Delta \lt \theta$<br><strong>返回</strong> 输出一个策略$\pi\approx\pi<em>{*}$，这里书中说是deterministic，我觉得都可以，$\pi$也可以是stochastic的，最后得到的$\pi$满足:<br>$\pi(s) = argmax_a\sum</em>{s’,r}p(s’,r|s,a)\left[r+\gamma V(s’)\right]$</p><h2 id="Asychronous-Dynamic-Programming"><a href="#Asychronous-Dynamic-Programming" class="headerlink" title="Asychronous Dynamic Programming"></a>Asychronous Dynamic Programming</h2><p>之前介绍的这些DP方法，在每一次操作的时候，都有对所有的状态进行处理，这就很耗费资源。所以这里就产生了异步的DP算法，这类算法在更新的时候，不会使用整个的state set，而是使用部分state进行更新，其中一些state可能被访问了很多次，而另一些state一次也没有被访问过。<br>其中一种异步DP算法就是在plicy evalutaion的过程中，只使用一个state。<br>使用DP算法并不代表一定能减少计算量，他只是减少在策略没有改进之前陷入无意义的evaluation的可能。尽量选取那些重要的state用来进行更新。<br>同时，异步DP方便进行实时的交互。在使用异步DP更新的时候，同时使用一个真实场景中的agent经历进行更新。智能体的experience可以被用来确定使用哪些state进行更新，DP更新后的值也可以用来指导智能体的决策。</p><h2 id="Generalized-Policy-Iteration"><a href="#Generalized-Policy-Iteration" class="headerlink" title="Generalized Policy Iteration"></a>Generalized Policy Iteration</h2><p>之前介绍了三类方法，Policy Iteration,Value iteration以及Asychronous DP算法，它们都有两个过程在不断的迭代进行。一个是evaluation，一个是improvement，这类算法统一的被称为Generalized Policy Iteration(GPI)，可以根据不同的粒度进行细分。基本上所有的算法都是GPI，policy使用value function进行改进，value function朝着policy的真实值函数改进，如果value function和policy都稳定之后，那么说他们都是最优的了。<br>GPI中evalution和improvemetnt可以看成既有竞争又有合作。竞争是因为evaluation和improment的方向通常是相对的，policy改进意味着value function不适用于当前的policy,value function更新意味着policy不是greedy的。然后长期来说，他们共同作用，想要找到最优的值函数和policy。<br>GPI可以看成两个目标的交互过程，这两个目标不是正交的，改进一个目标也会使用另一个目标有所改进，直到最后，这两个交互过程使得总的目标变成最优的。</p><h2 id="Efficiency-of-Dynamic-Programming"><a href="#Efficiency-of-Dynamic-Programming" class="headerlink" title="Efficiency of Dynamic Programming"></a>Efficiency of Dynamic Programming</h2><p>用$n$和$k$表示MDP的状态数和动作数，DP算法保证在多项式时间内找到最优解，即使策略的总数是$k^n$个。<br>DP比任何在policy space内搜索的算法要快上指数倍，因为policy space搜索需要检查每一个算法。Linear Programming算法也可以用来解MDP问题，在某些情况下最坏的情况还要比DP算法快，但是LP要比只适合解决state数量小的问题。而DP也能处理states很大的情况。</p><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><ul><li>使用贝尔曼公式更新值函数，可以使用backup diagram看他们的直观表示。</li><li>基本上所有的强化学习算法都可以看成GPI(generalized policy iteraion)，先评估某个策略，然后改进这个策略，评估新的策略…这样子循环下去，直到收敛，找到一个不在变化的最优值函数和策略。<br>GPI不一定是收敛的，本章介绍的这些大多都是收敛的，但是还有一些没有被证明收敛。</li><li>可以使用异步的DP算法。</li><li>所有的DP算法都有一个属性叫做bootstrapping，就是他们更新自己的估计值也是基于其他的估计上。因为每一个state value的更新都需要用到他们的successor state的估计。<blockquote><p>They update estimates onthe basis of other estimates。</p></blockquote></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Dynamic-Programming&quot;&gt;&lt;a href=&quot;#Dynamic-Programming&quot; class=&quot;headerlink&quot; title=&quot;Dynamic Programming&quot;&gt;&lt;/a&gt;Dynamic Programming&lt;/h2&gt;&lt;p&gt;DP
      
    
    </summary>
    
      <category term="强化学习" scheme="http://mxxhcm.github.io/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="强化学习" scheme="http://mxxhcm.github.io/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="动态规划" scheme="http://mxxhcm.github.io/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"/>
    
  </entry>
  
  <entry>
    <title>reinforcement learning an introduction 第9章笔记</title>
    <link href="http://mxxhcm.github.io/2019/04/04/reinforcement-learning-an-introduction-%E7%AC%AC9%E7%AB%A0%E7%AC%94%E8%AE%B0/"/>
    <id>http://mxxhcm.github.io/2019/04/04/reinforcement-learning-an-introduction-第9章笔记/</id>
    <published>2019-04-04T02:14:08.000Z</published>
    <updated>2019-05-06T16:22:27.708Z</updated>
    
    <content type="html"><![CDATA[<h2 id="On-policy-Prediction-with-Approximation"><a href="#On-policy-Prediction-with-Approximation" class="headerlink" title="On-policy Prediction with Approximation"></a>On-policy Prediction with Approximation</h2><p>这一章讲的是利用on-policy的数据估计函数形式的值函数，on-policy就是说利用一个已知的policy $\pi$生成的experience来估计$v<em>{\pi}$。和之前讲的不同的是，前面几章讲的是表格形式的值函数，而这一章是使用参数为$\mathbf{w}\in R^d$的函数表示。即$\hat{v}(s,\mathbf{w})\approx v</em>{\pi}(s)$表示给定一个权值vector $\mathbf{w}$，state $s$的状态值。这个函数可以是任何形式的，可以是线性函数，也可以是神经网络，还可以是决策树。</p><h2 id="值函数估计"><a href="#值函数估计" class="headerlink" title="值函数估计"></a>值函数估计</h2><p>目前这本书介绍的所有prediction方法都是更新某一个state的估计值函数向backed-up value（或者叫update target）值移动。我们用符号$s\mapsto u$表示一次更新。其中$s$是要更新的状态，$u$是$s$的估计值函数的update target。例如，Monte Carlo更新的value prediction是：$S<em>t \mapsto G_t$，TD(0)的update是：$S_t \mapsto R</em>{t+1} + \gamma \hat{v}(S<em>{t+1}, \mathbf{w}_t)$，$n$-step TD update是：$S_t \mapsto G</em>{t:t+n}$。在DP policy evaluation update中是：$s\mapsto E<em>{\pi}[R</em>{t+1}+\gamma\hat{v}(S_{t+1}, \mathbf{w}_t)| S_t =s]$，任意一个状态$s$被更新了，同时在其他真实experience中遇到的$S_t$也被更新了。</p><p>之前表格的更新太trivial了，更次更新$s$向$u$移动，其他状态的值都保持不变。现在使用函数实现更新，在状态$s$处的更新，可以一次性更新很多个其他状态的值。就像监督学习学习input和output之间的映射一样，我们可以把$s\mapsto g$的更新看做一个训练样本。这样就可以使用很多监督学习的方法学习这样一个函数。<br>但是并不是所有的方法都适用于强化学习，因为许多复杂的神经网络和统计学方法都假设训练集是静态不变的。然而强化学习中，学习是online的，即智能体不断地与环境进行交互产生新的数据，这就需要这个方法能够从不断增加的数据中高效的学习。<br>此外，强化学习通常需要function approximation能够处理target function不稳定的情况，即target function随着事件在不断的变化。比如，在基于GPI的control方法中，在$\pi$不断变化的情况下，我们想要学习出$q_{\pi}$。即使policy保持不变，如果使用booststrapping方法（DP和TD学习），训练样本的target value也在不断的改变，因为下一个state的value值在不断的改变。所以不能处理这些不稳定情况的方法有点不适合强化学习。</p><h2 id="预测目标-The-Prediction-Objective"><a href="#预测目标-The-Prediction-Objective" class="headerlink" title="预测目标(The Prediction Objective)"></a>预测目标(The Prediction Objective)</h2><p>表格形式的值函数最终都会收敛到真值，状态值之间也都是解耦的，即更新一个state不影响另一个state。<br>但是使用函数拟合，更新一个state的估计值就会影响很多个其他状态，并且不可能精确的估计所有states的值。假设我们的states比weights多的多，让一个state的估计更精确也意味着使得其他的state越不accurate。我们用一个state $s$上的分布,$\mu(s)\ge 0,\sum<em>s\mu(s)=1$代表对每个state上error的权重。然后使用$\mu(s)$对approximate value $\hat{v}(s,\mathbf{w})$和true value $v</em>{\pi}(s)$的squared error进行加权，得到Mean Squared Value Error，表示为$\bar{VE}$：</p><script type="math/tex; mode=display">\bar{VE}(\mathbf{w}) = \sum_{s\in S}\mu(s)[v_{\pi}(s) - \hat{v}(s, \mathbf{w})]^2</script><p>通常情况下，$\mu(s)$是在state $s$处花费时间的百分比。在on-policy训练中，这叫做on-policy分布。在continuing tasks中，策略$\pi$下的on-policy分布是一个stationary distribution。<br>在episodic tasks中，on-policy分布有一些不同，因为它还取决于每个episodic的初始状态，用$h(s)$表示在一个episodic开始状态为$s$的概率，用$\eta(s)$表示在一个回合中，state $s$平均被访问的次数。</p><script type="math/tex; mode=display">\eta(s) = h(s) + \sum_{\bar{s}}\eta(\bar{s})\sum_a\pi(a|\bar{s})p(s|\bar{s},a), forall\ s \in S</script><p>其中$\bar{s}$是$s$的前一个状态，$s$处的时间为以状态$s$开始的概率$h(s)$加上它由前一个状态$\bar{s}$转换过来消耗的时间。<br>列出一个方程组，可以解出来$\eta(s)$的期望值。然后进行归一化，得到：</p><script type="math/tex; mode=display">\mu(s)=\frac{\eta{s}}{\sum_{s'}\eta{s'}}, \forall s \in S.</script><p>这是没有折扣因子的式子，如果有折扣因子的话，可以看成一种形式的</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;On-policy-Prediction-with-Approximation&quot;&gt;&lt;a href=&quot;#On-policy-Prediction-with-Approximation&quot; class=&quot;headerlink&quot; title=&quot;On-policy Pred
      
    
    </summary>
    
      <category term="强化学习" scheme="http://mxxhcm.github.io/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="强化学习" scheme="http://mxxhcm.github.io/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="函数近似" scheme="http://mxxhcm.github.io/tags/%E5%87%BD%E6%95%B0%E8%BF%91%E4%BC%BC/"/>
    
      <category term="on-policy" scheme="http://mxxhcm.github.io/tags/on-policy/"/>
    
      <category term="值函数" scheme="http://mxxhcm.github.io/tags/%E5%80%BC%E5%87%BD%E6%95%B0/"/>
    
  </entry>
  
  <entry>
    <title>引导和分区</title>
    <link href="http://mxxhcm.github.io/2019/04/03/%E5%BC%95%E5%AF%BC%E5%92%8C%E5%88%86%E5%8C%BA/"/>
    <id>http://mxxhcm.github.io/2019/04/03/引导和分区/</id>
    <published>2019-04-03T08:15:36.000Z</published>
    <updated>2019-05-06T16:22:27.708Z</updated>
    
    <content type="html"><![CDATA[<h2 id="硬盘逻辑划分"><a href="#硬盘逻辑划分" class="headerlink" title="硬盘逻辑划分"></a>硬盘逻辑划分</h2><p>分区可以说是对硬盘的一种格式化。创建分区设置好硬盘的各项物理参数，指定了硬盘主引导记录（即Master Boot Record，一般简称为MBR）和引导记录备份的存放位置。而对于文件系统以及其他操作系统管理硬盘所需要的信息则是通过以后的高级格式化，即 Format命令来实现。面、磁道和扇区硬盘分区后，将会被划分为面（Side）、磁道（Track）和扇区（Sector）。需要注意的是，这些只是个 虚拟的概念，并不是真正在硬盘上划轨道。</p><p><strong>面，磁头，柱面</strong> 硬盘一般是由一片或几片圆形薄片叠加而成的。每个圆形薄片都有两个“面”，这两个面都可以用来存储数据的。按照面的顺序，依次称为0 面，1面，…，每个面都都有一个读写磁头，也常用0头，1头，…，按照硬盘容量和规格的不同，硬盘面数(或头数)也各有差异。每个硬盘上所有硬盘面数磁道号相同的磁道叠起来，称为一个柱面(Cylinder)。</p><p><strong>磁道，扇区</strong> 由于磁盘通过旋转磁头读取或者写入数据，磁头旋转的时候就形成了一个圆周。这样的圆周就称为一个磁道。如果磁头沿着面的半径移动，就到了另外一个磁道。根据硬盘的不同，磁道数可以从几百到数千不等；一个磁道上可以容纳数KB 的数据，而主机读写时往往并不需要一次读写那么多，于是，磁道又被划分成若干段，每段称为一个扇区。一个扇区一般存放512字节的数据。对同一磁道中的扇区进行编号：1扇区，2扇区，…<br>计算机对硬盘的读写，出于效率的考虑，以扇区为基本单位。即计算机如果只需要硬盘上存储的某个字节，也必须一次把这个字节所在的扇区中的512字节全部 读入内存，再使用所需的那个字节。为了区分每个山区，在每个扇区存取的数据前、后两端，都有一些特定的数据，这些数据构成了扇区的界限标志，标志中含有扇区的编号和其他信息。计算机凭借着这些标志来识别扇区。</p><h2 id="硬盘分区"><a href="#硬盘分区" class="headerlink" title="硬盘分区"></a>硬盘分区</h2><p>硬盘的数据按照特点和作用可以分为$5$部分，引导区，DBR区，FAT区，DIR区和DATA区。<br>引导区常见的有MBR和GPT。<br>DBR是操作系统引导记录区<br>FAT区存放的是文件簇信息。常见的有FAT16和FAT32<br>DIR是根目录区<br>DATA区存放数据</p><h2 id="BIOS-UEFI和MBR-GPT"><a href="#BIOS-UEFI和MBR-GPT" class="headerlink" title="BIOS,UEFI和MBR,GPT"></a>BIOS,UEFI和MBR,GPT</h2><p>BIOS和UEFI是常见的引导，MBR和GPT是分区表类型。<br>BIOS(Basic Input Output System)<br>UEFI(Unifed Extensible Firmware Interface)<br>MBR(Master Boot Record)<br>GPT(GUID Partion Table)</p><h2 id="MBR"><a href="#MBR" class="headerlink" title="MBR"></a>MBR</h2><p>传统的MBR，位于整个硬盘的$0$磁道$0$柱面$1$扇区，也叫主引导扇区，总计$512$个字节。MBR只占用了$446$个字节，剩下的$64$个字节用来保存硬盘的分区表(Disk Partion Talbe, DPT)，最多只有四个表项，也就是我们常遇到的最多只能设置四个主分区（或者$3$个主分区，$1$个扩展分区和无限制个数的逻辑驱动器），每个表项只有$16$个字节，每一个分区使用$4$个字节存储总扇区数，每个分区不能大于$2TB(2^{32}\times 512 bytes$)，就是$2^{32}$个扇区，每个扇区按$512$字节来算，其他$12$个字节用来存储分区的其他信息。如图所示：<br><img src="/2019/04/03/引导和分区/mbr.jpeg" alt="mbr"></p><h2 id="GPT"><a href="#GPT" class="headerlink" title="GPT"></a>GPT</h2><p>GPT分区需要需要操作系统更支持，可以有任何个数个主分区，每个分区都可以大于$2$T，它是基于UEFI使用的磁盘分区架构。</p><h2 id="UEFI"><a href="#UEFI" class="headerlink" title="UEFI"></a>UEFI</h2><p>UEFI是用来取代BIOS的，UEFI启动系统引导的方法是查找硬盘分区中第一个FAT分区内的引导文件进行系统分区，不具体指定分区表区。<br>FAT分区内可以存放MBR分区表，也可以存放GPT分区表。</p><h2 id="从GPT硬盘启动"><a href="#从GPT硬盘启动" class="headerlink" title="从GPT硬盘启动"></a>从GPT硬盘启动</h2><p>从GPT分区硬盘启动需要满足三个条件：</p><ul><li>操作系统支持，windows只有64为操作系统支持</li><li>硬盘使用GPT分区</li><li>主板使用UEFI模式</li></ul><h2 id="引导和分区类型匹配"><a href="#引导和分区类型匹配" class="headerlink" title="引导和分区类型匹配"></a>引导和分区类型匹配</h2><h3 id="BIOS-MBR"><a href="#BIOS-MBR" class="headerlink" title="BIOS + MBR"></a>BIOS + MBR</h3><p>所有系统都支持，不支持大于$2$T的硬盘。</p><h3 id="BIOS-GPT"><a href="#BIOS-GPT" class="headerlink" title="BIOS + GPT"></a>BIOS + GPT</h3><p>BIOS可以使用GPT分布表，将GPT硬盘作为资料盘，但是不能用来引导系统，而且必须使用$64$位系统。</p><h3 id="UEFI-legacy-MBR"><a href="#UEFI-legacy-MBR" class="headerlink" title="UEFI(legacy) + MBR"></a>UEFI(legacy) + MBR</h3><p>可以将UEFI设置为legacy(传统模式)，支持MBR启动，和BIOS+MBR一样，也可以建立FAT分区，放置UEFI启动文件。</p><h3 id="UEFI-GPT"><a href="#UEFI-GPT" class="headerlink" title="UEFI + GPT"></a>UEFI + GPT</h3><p>可以把大于$2$T的硬盘当做系统盘，必须使用$64$位系统。</p><h2 id="双系统"><a href="#双系统" class="headerlink" title="双系统"></a>双系统</h2><p>安装双系统直接进windows，使用EasyUEFI/Easybcd(工具)添加linux启动项，或者使用windows命令，bcdedit进行编辑（文档参见msdn,推荐使用这种方法）。<br>双系统直接进ubuntu，使用grub引导，执行update-grub自动修改/boot/grub/grub.cfg 文件。然后重启就会发现有了这个开机启动项，见参考文献[3]。</p><p>可以参考参考文献[3]，或者参考文献[4]。</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>1.<a href="https://blog.csdn.net/hyy5801965/article/details/51136395" target="_blank" rel="noopener">https://blog.csdn.net/hyy5801965/article/details/51136395</a><br>2.<a href="https://www.cnblogs.com/zhangming-blog/articles/5392115.html" target="_blank" rel="noopener">https://www.cnblogs.com/zhangming-blog/articles/5392115.html</a><br>3.<a href="https://askubuntu.com/a/945988" target="_blank" rel="noopener">https://askubuntu.com/a/945988</a><br>4.<a href="https://askubuntu.com/a/217970" target="_blank" rel="noopener">https://askubuntu.com/a/217970</a><br>5.<a href="http://lanlingzi.cn/post/notes/2016/0313_grub_win10/" target="_blank" rel="noopener">http://lanlingzi.cn/post/notes/2016/0313_grub_win10/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;硬盘逻辑划分&quot;&gt;&lt;a href=&quot;#硬盘逻辑划分&quot; class=&quot;headerlink&quot; title=&quot;硬盘逻辑划分&quot;&gt;&lt;/a&gt;硬盘逻辑划分&lt;/h2&gt;&lt;p&gt;分区可以说是对硬盘的一种格式化。创建分区设置好硬盘的各项物理参数，指定了硬盘主引导记录（即Master Bo
      
    
    </summary>
    
      <category term="工具" scheme="http://mxxhcm.github.io/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="BIOS" scheme="http://mxxhcm.github.io/tags/BIOS/"/>
    
      <category term="UEFI" scheme="http://mxxhcm.github.io/tags/UEFI/"/>
    
      <category term="MBR" scheme="http://mxxhcm.github.io/tags/MBR/"/>
    
      <category term="GPT" scheme="http://mxxhcm.github.io/tags/GPT/"/>
    
      <category term="引导" scheme="http://mxxhcm.github.io/tags/%E5%BC%95%E5%AF%BC/"/>
    
      <category term="分区" scheme="http://mxxhcm.github.io/tags/%E5%88%86%E5%8C%BA/"/>
    
  </entry>
  
  <entry>
    <title>reinforcement learning an introduction 第13章笔记.md</title>
    <link href="http://mxxhcm.github.io/2019/04/03/reinforcement-learning-an-introduction-%E7%AC%AC13%E7%AB%A0%E7%AC%94%E8%AE%B0/"/>
    <id>http://mxxhcm.github.io/2019/04/03/reinforcement-learning-an-introduction-第13章笔记/</id>
    <published>2019-04-03T01:46:49.000Z</published>
    <updated>2019-05-06T16:22:27.708Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Policy-gradient"><a href="#Policy-gradient" class="headerlink" title="Policy gradient"></a>Policy gradient</h2><p>这章介绍的是使用一个参数化策略(parameterized policy)直接给出action，而不用借助一个value funciton选择action。但是需要说一下的是，Policy gradient方法也可以学习一个Value function，但是value function是用来帮助学习policy parameters的，而不是用来选择action。我们用$\mathbf{\theta} \in R^{d’}$表示policy’s parameters vector，用$\pi(a|s, \mathbf{\theta}) = Pr[A_t = a|S_t = s, \mathbf{\theta}_t = \mathbf{\theta}]$表示environment在时刻$t$处于state $s$时，智能体根据参数为$\mathbf{\theta}$的策略$\pi$选择action $a$。<br>如果policy gradient方法使用了一个value function,它的权重用$\mathbf{w} \in R^d$表示，即$\hat{v}(s,\mathbf{w})$。</p><p>用$J(\mathbf{\theta})$表示policy parameters的标量performance measure。使用梯度上升(gradient ascent) 方法来最大化这个performance：</p><script type="math/tex; mode=display">\mathbf{\theta}_{t+1} = \mathbf{\theta}_t + \alpha \widehat{\nabla J(\mathbf{\theta}_t}),\tag{1}</script><p>其中$\widehat{\nabla J(\mathbf{\theta}_t)} \in R^{d’}$是一个随机估计(stachastic estimate)，它的期望是performance measure对$\mathbf{\theta_t}$的梯度。不管它们是否使用value function，这种方法就叫做policy gradient方法。既学习policy，又学习value function的方法被称为actor-critic，其中actor指的是学到的policy，critic指的是学习到的value funciton,通常是state value function。</p><h2 id="policy估计和它的优势"><a href="#policy估计和它的优势" class="headerlink" title="policy估计和它的优势"></a>policy估计和它的优势</h2><h3 id="参数化policy的条件"><a href="#参数化policy的条件" class="headerlink" title="参数化policy的条件"></a>参数化policy的条件</h3><p>policy可以用任何方式参数化，只要$\pi(a|s,\mathbf{\theta}),\mathbf{\theta}\in R^{d’}$对于它的参数$\mathbf{\theta}$是可导的，即只要$\nabla_{\pi}(a|s,\mathbf{\theta})$（即：$\pi(a|s,\mathbf{\theta})$相对于$\mathbf{\theta}$的偏导数列向量）存在，并且$\forall s\in S, a\in A(s)$偏导数都是有限的即可。</p><h3 id="stochastic-policy"><a href="#stochastic-policy" class="headerlink" title="stochastic policy"></a>stochastic policy</h3><p>为了保证exploration，通常策略是stochastic，而不是deterministic，即$\forall s,a,\mathbf{\theta}, \pi(a|s,\mathbf{\theta})\in (0,1)$</p><h3 id="参数化方式的选择"><a href="#参数化方式的选择" class="headerlink" title="参数化方式的选择"></a>参数化方式的选择</h3><h4 id="softmax"><a href="#softmax" class="headerlink" title="softmax"></a>softmax</h4><p>对于有限且离散的action space，一个很自然的参数化方法就是对于每一个state-action对都计算一个参数化的数值偏好$h(s,a,\mathbf{\theta})\in R$。通过计算一个exponetial softmax，这个数值大的动作有更大的概率被选中：</p><script type="math/tex; mode=display">\pi(a|s,\mathbf{\theta}) = \frac{e^{h(s,a,\mathbf{\theta} )}}{\sum_be^{h(s,b,\mathbf{\theta} )}}, \tag{2}</script><p>其中$b$是在state $s$下所有可能采取的动作，它们的概率加起来为$1$，这种方法叫做softmax in aciton preferences。</p><h4 id="NN和线性方法"><a href="#NN和线性方法" class="headerlink" title="NN和线性方法"></a>NN和线性方法</h4><p>参数化还可以选择其他各种各样的方法，如AlphaGo中使用的NN，或者可以使用如下的线性方法：</p><script type="math/tex; mode=display">h(s,a, \mathbf{\theta}) = \mathbf{\theta}^Tx(s,a), \tag{3}</script><h3 id="优势"><a href="#优势" class="headerlink" title="优势"></a>优势</h3><p>和action value方法相比，policy gradient有多个优势。<br>第一个优势是使用action preferences的softmax，同时用$\epsilon-greedy$算法用$\epsilon$的概率随机选择action得到的策略可以接近一个deterministic policy。<br>而单单使用action values的方法并不会使得策略接近一个deterministic policy，但是action-value方法会逐渐收敛于它的true values，翻译成概率来表示就是在$0$和$1$之间的一个概率值。但是action preferences方法不收敛于任何值，它们产生optimal stochastic policy，如果optimal policy是deterministic，那么optimal action的preferences应该比其他所有suboptimal actions都要高。</p><p>第二个优势是使用action preferences方法得到的参数化策略可以使用任意的概率选择action。在某些问题中，最好的approximate policy可能是stochastic的，actor-value方法不能找到一个stochastic optimal policy，它总是根据action value值选出来一个值最大的action，但是这时候的结果通常不是最优的。</p><p>第三个优势是policy parameterization可能比action value parameterization更容易学习。当然，也有时候可能是action value更容易。这个要根据情况而定</p><p>第四个优势是policy parameterizaiton比较容易添加先验知识到policy中。</p><h2 id="policy-gradient理论"><a href="#policy-gradient理论" class="headerlink" title="policy gradient理论"></a>policy gradient理论</h2><p>除了上节说的实用优势之外，还有理论优势。policy parameterization学到关于参数的一个连续函数，action probability概率可以平滑的变化。然而$\epsilon-greedy$算法中，action-value改变以后，action probability可能变化很大。很大程度上是因为policy gradient方法的收敛性要比action value方法强的多。因为policy的连续性依赖于参数，使得policy gradient方法接近于gradient ascent。<br>这里讨论episodic情况。定义perfromance measure是episode初始状态的值。假设每一个episode，都从state $s_0$开始，定义：</p><script type="math/tex; mode=display">J(\mathbf{\theta}) = v_{\pi_\mathbf{\theta}}(s_0), \tag{4}</script><p>其中$v<em>{\pi</em>\mathbf{\theta}}(s<em>0)$是由参数$\mathbf{\theta}$确定的策略$\pi</em>{\mathbf{\theta}}$的true value function。假设在episodic情况下，$\gamma=1$。</p><p>使用function approximation，一个需要解决的问题就是如何确保每次更新policy parameter，performance measure都有improvement。因为performence不仅仅依赖于action的选择，还取决于state的分布，然后它们都受policy parameter的影响。给定一个state，policy parameter对于actions，reward的影响，都可以相对直接的利用参数知识计算出来。但是policy parameter对于state 分布的影响是一个环境的函数，通常是不知道的。当梯度依赖于policy改变对于state分布的影响未知时，我们该如何估计performance相对于参数的梯度。</p><h3 id="Episodic-case证明"><a href="#Episodic-case证明" class="headerlink" title="Episodic case证明"></a>Episodic case证明</h3><p>为了简化表示，用$\pi$表示参数为$\theta$的policy，所有的梯度都是相对于$\mathbf{\theta}$求的<br>\begin{align*}<br>\nabla v<em>{\pi}(s) &amp;= \nabla [ \sum_a \pi(a|s)q</em>{\pi}(s,a)], \forall s\in S \tag{5}\<br>&amp;= \sum<em>a [\nabla\pi(a|s)q</em>{\pi}(s,a)], \forall s\in S \tag{6}\<br>&amp;= \sum<em>a[\nabla\pi(a|s)q</em>{\pi}(s,a) + \pi(a|s)\nabla q<em>{\pi}(s,a)] \tag{7}\<br>&amp;= \sum_a[\nabla\pi(a|s)q</em>{\pi}(s,a) + \pi(a|s)\nabla \sum<em>{s’,r}p(s’,r|s,a)(r+\gamma v</em>{\pi}(s’))] \tag{8}\<br>&amp;= \sum<em>a[\nabla\pi(a|s)q</em>{\pi}(s,a) + \pi(a|s) \nabla \sum<em>{s’,r}p(s’,r|s,a)r + \pi(a|s)\nabla \sum</em>{s’,r}p(s’,r|s,a)\gamma v<em>{\pi}(s’))] \tag{9}\<br>&amp;= \sum_a[\nabla\pi(a|s)q</em>{\pi}(s,a) + 0 + \pi(a|s)\sum<em>{s’}\gamma p(s’|s,a)\nabla v</em>{\pi}(s’) ] \tag{10}\<br>&amp;= \sum<em>a[\nabla\pi(a|s)q</em>{\pi}(s,a) + 0 + \pi(a|s)\sum<em>{s’}\gamma p(s’|s,a)\<br>&amp;\ \ \ \ \ \ \ \ \sum</em>{a’}[\nabla\pi(a’|s’)q<em>{\pi}(s’,a’) + \pi(a’|s’)\sum</em>{s’’}\gamma p(s’’|s’,a’)\nabla v<em>{\pi}(s’’))] ],  \tag{11}展开\<br>&amp;= \sum</em>{x\in S}\sum<em>{k=0}^{\infty}Pr(s\rightarrow x, k,\pi)\sum_a\nabla\pi(a|x)q</em>{\pi}(x,a) \tag{12}<br>\end{align*}<br>第(5)式使用了$v<em>{\pi}(s) = \sum_a\pi(a|s)q(s,a)$进行展开。第(6)式将梯度符号放进求和里面。第(7)步使用product rule对q(s,a)求导。第(8)步利用$q</em>{\pi}(s, a) =\sum<em>{s’,r}p(s’,r|s,a)(r+v</em>{\pi}(s’)$ 对$q<em>{\pi}(s,a)$进行展开。第(9)步将(8)式进行分解。第(10)步对式(9)进行计算，因为$\sum</em>{s’,r}p(s’,r|s,a)r$是一个定制，求偏导之后为$0$。第(11)步对生成的$v<em>{\pi}(s’)$重复(5)-(10)步骤，得到式子(11)。如果对式子(11)中的$v</em>{\pi}(s)$一直展开，就得到了式子(12)。式子(12)中的$Pr(s\rightarrow x, k, \pi)$是在策略$\pi$下从state $s$经过$k$步转换到state $x$的概率，这里我有一个问题，就是为什么，$k$可以取到$\infty$，后来想了想，因为对第(11)步进行展开以后，可能会有重复的state，重复的意思就是从状态$s$开始，可能会多次到达某一个状态$x$，$k$就能取很多次，大不了$k=\infty$的概率为$0$就是了。</p><p>所以，对于$v<em>{\pi}(s_0)$，就有：<br>\begin{align*}<br>\nabla J(\mathbf{\theta}) &amp;= \nabla</em>{v<em>{\pi}}(s_0)\<br>&amp;= \sum</em>{s\in S}( \sum<em>{k=0}^{\infty}Pr(s_0\rightarrow s,k,\pi) ) \sum_a\nabla</em>{\pi}(a|s)q<em>{\pi}(s,a)\<br>&amp;=\sum</em>{s\in S}\eta(s)\sum<em>a \nabla</em>{\pi}(a|s)q<em>{\pi}(s,a)\<br>&amp;=\sum</em>{s’\in S}\eta(s’)\sum<em>s\frac{\eta(s)}{\sum</em>{s’}\eta(s’)}\sum<em>a \nabla</em>{\pi}(a|s)q<em>{\pi}(s,a)\<br>&amp;=\sum</em>{s’\in S}\eta(s’)\sum<em>s\mu(s)\sum_a \nabla</em>{\pi}(a|s)q<em>{\pi}(s,a)\<br>&amp;\propto \sum</em>{s\in S}\mu(s)\sum<em>a\nabla\pi(a|s)q</em>{\pi}(s,a)<br>\end{align*}<br>最后，我们可以看出来performance对policy求导不涉及state distribution的导数。Episodic 情况下的策略梯度如下所示：</p><script type="math/tex; mode=display">\nabla J(\mathbf{\theta})\propto \sum_{s\in S}\mu(s)\sum_aq_{\pi}(s,a)\nabla\pi(a|s,\mathbf{\theta}), \tag{13}</script><p>其中梯度是performacne指标$J$关于$\mathbf{\theta}$的偏导数列向量，$\pi$是参数$\mathbf{\theta}$对应的策略。在episodic情况下，比例常数是一个episode的平均长度，在continuing情况下，常数是$1$，实际上这个正比于就是一个等式。分布$\mu$是策略$\pi$下的on-policy分布。</p><h2 id="REINFORCE-Monte-Carlo-Policy-Gradient"><a href="#REINFORCE-Monte-Carlo-Policy-Gradient" class="headerlink" title="REINFORCE: Monte Carlo Policy Gradient"></a>REINFORCE: Monte Carlo Policy Gradient</h2><p>对于式子(1)，我们需要进行采样，让样本梯度的期望正比于performance measure对于$\mathbf{\theta}$的真实梯度。比例系数不需要确定，因为步长$\alpha$的大小是手动设置的。Policy gradient理论给出了一个正比于gradient的精确表达式，我们要做的就是选择采样方式，它的期望等于或者接近policy gradient理论给出的值。</p><h3 id="all-actions"><a href="#all-actions" class="headerlink" title="all-actions"></a>all-actions</h3><p>使用随机变量的期望替换对随机变量求和的取值，我们可以将式子(13)进行如下变化：<br>\begin{align*}<br>\nabla J(\mathbf{\theta})&amp;\propto \sum<em>{s\in S}\mu(s)\sum_aq</em>{\pi}(s,a)\nabla\pi(a|s,\mathbf{\theta})\<br>&amp;=\mathbb{E}<em>{\pi}\left[\sum_aq</em>{\pi}(S_t,a)\nabla\pi(a|S_t,\mathbf{\theta})\right]\tag{14}<br>\end{align*}<br>接下来，我们可以实例化该方法：</p><script type="math/tex; mode=display">\mathbf{\theta}_{t+1} = \mathbf{\theta}_t+\alpha\sum_a\hat{q}(S_t,s,\mathbf{w})\nabla\pi(a|S_t,\mathbf{\theta}), \tag{15}</script><p>其中$\hat{q}$是$q_{\pi}$的估计值，这个算法被称为all-actions方法，因为它的更新涉及到了所有的action。然而，我们这里介绍的REINFORCE仅仅使用了$t$时刻的action $A_t$。。</p><h3 id="REINFORCE"><a href="#REINFORCE" class="headerlink" title="REINFORCE"></a>REINFORCE</h3><p>和引入$S<em>t$的方法一样，使用随机变量的期望代替对与随机变量的可能取值进行求和，我们在式子(14)中引入$A_t$，<br>\begin{align*}<br>\nabla J(\mathbf{\theta}) &amp;= \mathbb{E}</em>{\pi}\left[\sum<em>aq</em>{\pi}(S<em>t,a)\nabla\pi(a|S_t,\mathbf{\theta})\right]\<br>&amp; = \mathbb{E}</em>{\pi}\left[\sum<em>aq</em>{\pi}(S<em>t,a)\pi(a|S_t,\mathbf{\theta})\frac{\nabla\pi(a|S_t,\mathbf{\theta})}{\pi(a|S_t,\mathbf{\theta})}\right]\<br>&amp; = \mathbb{E}</em>{\pi}\left[q_{\pi}(S_t,A_t)\frac{\nabla\pi(A_t|S_t,\mathbf{\theta})}{\pi(A_t|S_t,\mathbf{\theta})}\right]\<br>\end{align*}</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Policy-gradient&quot;&gt;&lt;a href=&quot;#Policy-gradient&quot; class=&quot;headerlink&quot; title=&quot;Policy gradient&quot;&gt;&lt;/a&gt;Policy gradient&lt;/h2&gt;&lt;p&gt;这章介绍的是使用一个参数化策略(pa
      
    
    </summary>
    
      <category term="强化学习" scheme="http://mxxhcm.github.io/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="强化学习" scheme="http://mxxhcm.github.io/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="Policy Gradient" scheme="http://mxxhcm.github.io/tags/Policy-Gradient/"/>
    
  </entry>
  
  <entry>
    <title>DQN-ops-tensorflow-实现与解析</title>
    <link href="http://mxxhcm.github.io/2019/03/28/DQN-ops-tensorflow-%E5%AE%9E%E7%8E%B0%E4%B8%8E%E8%A7%A3%E6%9E%90/"/>
    <id>http://mxxhcm.github.io/2019/03/28/DQN-ops-tensorflow-实现与解析/</id>
    <published>2019-03-28T08:02:40.000Z</published>
    <updated>2019-05-06T16:22:27.700Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="强化学习" scheme="http://mxxhcm.github.io/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="强化学习" scheme="http://mxxhcm.github.io/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="机器学习" scheme="http://mxxhcm.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="python" scheme="http://mxxhcm.github.io/tags/python/"/>
    
      <category term="tensorflow" scheme="http://mxxhcm.github.io/tags/tensorflow/"/>
    
      <category term="DQN" scheme="http://mxxhcm.github.io/tags/DQN/"/>
    
  </entry>
  
  <entry>
    <title>ImportError: cannot import name &#39;tqdm&#39;</title>
    <link href="http://mxxhcm.github.io/2019/03/28/ImportError-cannot-import-name-tqdm/"/>
    <id>http://mxxhcm.github.io/2019/03/28/ImportError-cannot-import-name-tqdm/</id>
    <published>2019-03-28T07:56:47.000Z</published>
    <updated>2019-05-06T16:22:27.704Z</updated>
    
    <content type="html"><![CDATA[<h2 id="cannot-import-name-tqdm"><a href="#cannot-import-name-tqdm" class="headerlink" title="cannot import name tqdm"></a>cannot import name tqdm</h2><p>谷歌了半天，没有发现原因，然后百度了一下，发现了原因，看来还是自己太菜了。。<br>因为自己起的文件名就叫tqdm，然后就和库中的tqdm冲突了，这也太蠢了吧。。。</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>1.<a href="https://blog.csdn.net/m0_37561765/article/details/78714603" target="_blank" rel="noopener">https://blog.csdn.net/m0_37561765/article/details/78714603</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;cannot-import-name-tqdm&quot;&gt;&lt;a href=&quot;#cannot-import-name-tqdm&quot; class=&quot;headerlink&quot; title=&quot;cannot import name tqdm&quot;&gt;&lt;/a&gt;cannot import nam
      
    
    </summary>
    
      <category term="Error" scheme="http://mxxhcm.github.io/categories/Error/"/>
    
    
      <category term="python" scheme="http://mxxhcm.github.io/tags/python/"/>
    
      <category term="Error" scheme="http://mxxhcm.github.io/tags/Error/"/>
    
      <category term="import" scheme="http://mxxhcm.github.io/tags/import/"/>
    
  </entry>
  
  <entry>
    <title>Can not convert a ndarray into a Tensor or Operation</title>
    <link href="http://mxxhcm.github.io/2019/03/27/Can-not-convert-a-ndarray-into-a-Tensor-or-Operation/"/>
    <id>http://mxxhcm.github.io/2019/03/27/Can-not-convert-a-ndarray-into-a-Tensor-or-Operation/</id>
    <published>2019-03-27T12:56:02.000Z</published>
    <updated>2019-05-06T16:22:27.700Z</updated>
    
    <content type="html"><![CDATA[<h2 id="错误描述"><a href="#错误描述" class="headerlink" title="错误描述"></a>错误描述</h2><p>执行tensorflow代码，报错：</p><blockquote><p>Can not convert a ndarray into a Tensor or Operation.</p></blockquote><p>原因是sess.run()前后参数名重了，比如outputs = sess.run(outputs)，outputs本来是自己定义的一个op，但是sess.run(outputs)之后outputs就成了一个变量，就把定义的outputs op覆盖了。</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>1.<a href="https://blog.csdn.net/michael__corleone/article/details/79007425" target="_blank" rel="noopener">https://blog.csdn.net/michael__corleone/article/details/79007425</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;错误描述&quot;&gt;&lt;a href=&quot;#错误描述&quot; class=&quot;headerlink&quot; title=&quot;错误描述&quot;&gt;&lt;/a&gt;错误描述&lt;/h2&gt;&lt;p&gt;执行tensorflow代码，报错：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Can not convert a ndarr
      
    
    </summary>
    
      <category term="Error" scheme="http://mxxhcm.github.io/categories/Error/"/>
    
    
      <category term="机器学习" scheme="http://mxxhcm.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="python" scheme="http://mxxhcm.github.io/tags/python/"/>
    
      <category term="tensorflow" scheme="http://mxxhcm.github.io/tags/tensorflow/"/>
    
      <category term="Error" scheme="http://mxxhcm.github.io/tags/Error/"/>
    
  </entry>
  
  <entry>
    <title>DQN replay buffer tensorflow 实现与解析</title>
    <link href="http://mxxhcm.github.io/2019/03/27/DQN-replay-buffer-tensorflow-%E5%AE%9E%E7%8E%B0%E4%B8%8E%E8%A7%A3%E6%9E%90/"/>
    <id>http://mxxhcm.github.io/2019/03/27/DQN-replay-buffer-tensorflow-实现与解析/</id>
    <published>2019-03-27T12:21:40.000Z</published>
    <updated>2019-05-06T16:22:27.700Z</updated>
    
    <content type="html"><![CDATA[<h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><p>这个DQN的Replay Buffer实现只用到了numpy库，可以很容易的进行扩展。主要有五个函数。接下来分函数进行解析。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ReplayBuffer</span>:</span></span><br><span class="line">    <span class="comment"># config : memory_size, batch_size, history_length, state_format, screen_height, screen_width,</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, config)</span>:</span></span><br><span class="line">        self.memory_size = config.memory_size</span><br><span class="line">        self.batch_size = config.batch_size</span><br><span class="line"></span><br><span class="line">        self.screens = np.empty((self.memory_size, config.screen_height, config.screen_width), dtype=np.float16)</span><br><span class="line">        self.actions = np.empty(self.memory_size, dtype=np.uint8)</span><br><span class="line">        self.rewards = np.empty(self.memory_size, dtype=np.int8)</span><br><span class="line">        self.terminals = np.empty(self.memory_size, dtype=np.bool)</span><br><span class="line">        self.history_length = config.history_length <span class="comment"># state使用多少张screens拼接在一起，论文中是4张</span></span><br><span class="line">        self.state_format = config.state_format</span><br><span class="line">        self.dims = (config.screen_height, config.screen_width)</span><br><span class="line">        <span class="comment"># state and next_state</span></span><br><span class="line">        self.states = np.empty((self.batch_size, self.history_length)+self.dims, dtype=np.float16)</span><br><span class="line">        self.next_states = np.empty((self.batch_size, self.history_length)+self.dims, dtype=np.float16)</span><br><span class="line"></span><br><span class="line">        self.count = <span class="number">0</span>  <span class="comment"># 记录总共有多少条记录</span></span><br><span class="line">        self.current = <span class="number">0</span> <span class="comment"># 获取当前是第几条</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add</span><span class="params">(self, screen, action, reward, terminal)</span>:</span></span><br><span class="line">        self.screens[self.current] = screen</span><br><span class="line">        self.actions[self.current] = action</span><br><span class="line">        self.rewards[self.current] = reward</span><br><span class="line">        self.terminals[self.current] = terminal</span><br><span class="line">        self.count = max(self.current + <span class="number">1</span>, self.count)</span><br><span class="line">        self.current = (self.current + <span class="number">1</span>) % self.memory_size</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.count</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">clear</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.current = <span class="number">0</span></span><br><span class="line">        self.count = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getState</span><span class="params">(self, index)</span>:</span></span><br><span class="line">        <span class="keyword">assert</span> self.count &gt; <span class="number">0</span></span><br><span class="line">        <span class="comment"># 每一个样本都要取self.history_length那么长。</span></span><br><span class="line">        <span class="keyword">if</span> index &gt;= self.history_length - <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> self.screens[index-(self.history_length - <span class="number">1</span>):index+<span class="number">1</span>, ...]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 如果当前下标比self.history_length还要小，那么就要从buffer的结尾处取了。</span></span><br><span class="line">            indexes = [(index - i )% self.count <span class="keyword">for</span> i <span class="keyword">in</span> reversed(range(self.history_length))]</span><br><span class="line">            <span class="keyword">return</span> self.screens[indexes, ...]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sample</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">assert</span> self.count &gt; self.history_length</span><br><span class="line">        indexes = []</span><br><span class="line">        <span class="keyword">while</span> len(indexes) &lt; self.batch_size:</span><br><span class="line">            <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">                index = random.randint(self.history_length, self.count + <span class="number">1</span>)    <span class="comment"># 相当于从self.histor_length之后进行采样</span></span><br><span class="line">                <span class="comment"># 如果包含current，就重新采样。（current是刚生成的样本）</span></span><br><span class="line">                <span class="keyword">if</span> index &gt; self.current <span class="keyword">and</span> self.current - self.history_length &lt;= index:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                <span class="comment"># 如果包含一个episode的结束状态，重新采样</span></span><br><span class="line">                <span class="keyword">if</span> self.terminals[(index - self.history_length):self.history_length].any():</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">            self.states[len(indexes),...] = self.getState(index - <span class="number">1</span>)</span><br><span class="line">            self.next_states[len(indexes),...] = self.getState(index)</span><br><span class="line">            indexes.append(index)</span><br><span class="line"></span><br><span class="line">        actions = self.actions[indexes]</span><br><span class="line">        rewards = self.rewards[indexes]</span><br><span class="line">        terminals = self.terminals[indexes]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.state_format == <span class="string">'NHWC'</span>:</span><br><span class="line">            <span class="keyword">return</span> np.transpose(self.states, (<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>)), actions, rewards, np.transpose(self.next_states, (<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>)),terminals</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> self.states, actions, rewards, self.next_states, terminals</span><br></pre></td></tr></table></figure></p><h2 id="init函数"><a href="#init函数" class="headerlink" title="init函数"></a>init函数</h2><p>ReplayBuffer的init的输入参数为一个config文件，包含了创建ReplayBuffer的参数，memory_size是Buffer大小，batch_size为训练和测试的batch大小，screens, actions, rewards, terminals分别存放的是每次采样得到的screen, action, reward和terminal(当前episode是否结束)。history_length是原文中提到的连续处理四张图片的四，而不仅仅是一张。state_format指的是’NHWC’还是’NCHW’，即depth通道在第$1$维还是第$3$维，states存放的是一个tensor，shape为$(batch_size, screen_height, screen_width, history_length)$，count记录当前Buffer的大小，current记录当前experience插入的地方。</p><h2 id="add方法"><a href="#add方法" class="headerlink" title="add方法"></a>add方法</h2><p>该方法实现了向ReplayBuffer中添加experience。</p><h2 id="len方法"><a href="#len方法" class="headerlink" title="len方法"></a><strong>len</strong>方法</h2><p>放回Buffer当前的大小</p><h2 id="clear方法"><a href="#clear方法" class="headerlink" title="clear方法"></a>clear方法</h2><p>清空Buffer</p><h2 id="sample方法"><a href="#sample方法" class="headerlink" title="sample方法"></a>sample方法</h2><p>从buffer中进行采样，返回一个元组，(states, actions, rewards, next_states, terminals)</p><h2 id="getState方法"><a href="#getState方法" class="headerlink" title="getState方法"></a>getState方法</h2><p>给定一个index，寻找它的前history_length - 1 个screens。</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>1.<a href="https://github.com/devsisters/DQN-tensorflow" target="_blank" rel="noopener">https://github.com/devsisters/DQN-tensorflow</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;代码&quot;&gt;&lt;a href=&quot;#代码&quot; class=&quot;headerlink&quot; title=&quot;代码&quot;&gt;&lt;/a&gt;代码&lt;/h2&gt;&lt;p&gt;这个DQN的Replay Buffer实现只用到了numpy库，可以很容易的进行扩展。主要有五个函数。接下来分函数进行解析。&lt;br&gt;&lt;fig
      
    
    </summary>
    
      <category term="强化学习" scheme="http://mxxhcm.github.io/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="强化学习" scheme="http://mxxhcm.github.io/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="机器学习" scheme="http://mxxhcm.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="python" scheme="http://mxxhcm.github.io/tags/python/"/>
    
      <category term="tensorflow" scheme="http://mxxhcm.github.io/tags/tensorflow/"/>
    
      <category term="DQN" scheme="http://mxxhcm.github.io/tags/DQN/"/>
    
      <category term="replay buffer" scheme="http://mxxhcm.github.io/tags/replay-buffer/"/>
    
  </entry>
  
  <entry>
    <title>Error! TimeLimit&#39; object has no attribute &#39;ale&#39;</title>
    <link href="http://mxxhcm.github.io/2019/03/27/Error-TimeLimit-object-has-no-attribute-ale/"/>
    <id>http://mxxhcm.github.io/2019/03/27/Error-TimeLimit-object-has-no-attribute-ale/</id>
    <published>2019-03-27T03:00:16.000Z</published>
    <updated>2019-05-06T16:22:27.704Z</updated>
    
    <content type="html"><![CDATA[<h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>运行github clone 下来的<a href="https://github.com/devsisters/DQN-tensorflow" target="_blank" rel="noopener">DQN-tensorflow</a>，报错:</p><blockquote><p>AttributeError: ‘TimeLimit’ object has no attribute ‘ale’.<br>是因为gym版本原因，在gym 0.7版本中，可以使用env.ale.lives()访问ale属性，但是0.8版本以及以上，就没有了该属性，可以在系列函数中添加如下修改：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, config)</span>:</span></span><br><span class="line">    self.step_info = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_step</span><span class="params">(self, action)</span>:</span></span><br><span class="line">    self._screen, self.reward, self.terminal, self.step_info = self.env.step(action)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lives</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> self.step_info <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> self.step_info[<span class="string">'ale.lives'</span>]</span><br></pre></td></tr></table></figure></p></blockquote><h2 id="ale属性是什么"><a href="#ale属性是什么" class="headerlink" title="ale属性是什么"></a>ale属性是什么</h2><p>我看官方文档也没有看清楚，但是我觉得就是生命值是否没有了</p><blockquote><p>info (dict): diagnostic information useful for debugging. It can sometimes be useful for learning (for example, it might contain the raw probabilities behind the environment’s last state change). However, official evaluations of your agent are not allowed to use this for learning.</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> gym</span><br><span class="line">env = gym.make(<span class="string">'CartPole-v0'</span>)</span><br><span class="line"><span class="keyword">for</span> i_episode <span class="keyword">in</span> range(<span class="number">20</span>):</span><br><span class="line">    observation = env.reset()</span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">        env.render()</span><br><span class="line">        print(observation)</span><br><span class="line">        action = env.action_space.sample()</span><br><span class="line">        observation, reward, done, info = env.step(action)</span><br><span class="line">        <span class="keyword">if</span> done:</span><br><span class="line">            print(<span class="string">"Episode finished after &#123;&#125; timesteps"</span>.format(t+<span class="number">1</span>))</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">env.close()</span><br></pre></td></tr></table></figure><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>1.<a href="https://github.com/devsisters/DQN-tensorflow/issues/29" target="_blank" rel="noopener">https://github.com/devsisters/DQN-tensorflow/issues/29</a><br>2.<a href="https://gym.openai.com/docs" target="_blank" rel="noopener">https://gym.openai.com/docs</a><br>3.<a href="https://github.com/openai/baselines/issues/42" target="_blank" rel="noopener">https://github.com/openai/baselines/issues/42</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;问题描述&quot;&gt;&lt;a href=&quot;#问题描述&quot; class=&quot;headerlink&quot; title=&quot;问题描述&quot;&gt;&lt;/a&gt;问题描述&lt;/h2&gt;&lt;p&gt;运行github clone 下来的&lt;a href=&quot;https://github.com/devsisters/DQN-t
      
    
    </summary>
    
      <category term="Error" scheme="http://mxxhcm.github.io/categories/Error/"/>
    
    
      <category term="机器学习" scheme="http://mxxhcm.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="python" scheme="http://mxxhcm.github.io/tags/python/"/>
    
      <category term="tensorflow" scheme="http://mxxhcm.github.io/tags/tensorflow/"/>
    
      <category term="Error" scheme="http://mxxhcm.github.io/tags/Error/"/>
    
      <category term="gym" scheme="http://mxxhcm.github.io/tags/gym/"/>
    
  </entry>
  
  <entry>
    <title>神经网络-dropout</title>
    <link href="http://mxxhcm.github.io/2019/03/23/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-dropout/"/>
    <id>http://mxxhcm.github.io/2019/03/23/神经网络-dropout/</id>
    <published>2019-03-23T11:26:18.000Z</published>
    <updated>2019-05-06T16:22:27.712Z</updated>
    
    <content type="html"><![CDATA[<h2 id="dropou是干什么的"><a href="#dropou是干什么的" class="headerlink" title="dropou是干什么的"></a>dropou是干什么的</h2><p>Dropout 是一种正则化技术，通过学习鲁棒的特征来防止过拟合。</p><h2 id="为什么会有过拟合"><a href="#为什么会有过拟合" class="headerlink" title="为什么会有过拟合"></a>为什么会有过拟合</h2><p>如果输入和正确输出之间有很复杂的映射关系，而网络又有足够多的隐藏单元去正确的建模，那么通常会用很多组权重都能在训练集上得到好的结果。但是每一组权重在测试集上的结果都比训练集差，因为它们只在训练集上训练了，而没有在测试集上训练。</p><h2 id="什么是dropout"><a href="#什么是dropout" class="headerlink" title="什么是dropout"></a>什么是dropout</h2><p>在网络中每一个隐藏单元的输出单元都有$0.5$的概率被忽略，所以每一个隐藏单元需要学会独立于其他的隐藏单元决定输出结果。</p><blockquote><p>This technique reduces complex co-adaptations of neurons, since a neuron cannot rely on the presence of particular other neurons. It is, therefore, forced to learn more robust features that are useful in conjunction with many different random subsets of the other neurons. [0]</p><p>On each presentation of each training case, each hidden unit is randomly omitted from the network with a probability of 0.5, so a hidden unit cannot rely on other hidden units being present.[1]</p><p>Dropout stops the mechanism of training neurons of any layers as a family, so reduces co-adaptability.[3]</p></blockquote><p>另一种方式可以把dropout看成对神经网络做平均。一种非常有效的减少测试误差的方法就是对一系列神经网络预测的结果取平均。理想的方式是训练很多个网络，然后分别在每个网络上进行测试，但是这样子的计算代价是很高的。随机的dropout让在合理的时间内训练大量不同的网络变得可能。当我们丢弃一个神经元的时候，它对loss函数没有任何贡献，所以在反向传播的时候，梯度为$0$，权值不会被更新。这就相当于我们对网络进行了一个下采样，训练过程的每次迭代中，采样网络的一部分进行训练，这样我们就得到了一个共享参数的集成模型。对于每一次训练，网络结构都是相同的，但是每次选择的参数都有很大可能是不同的，而且权重是共享的。</p><blockquote><p>The neurons which are “dropped out” in this way do not contribute to the forward pass and do not participate in backpropagation. So every time an input is presented, the neural network samples a different architecture, but all these architectures share weights.</p></blockquote><p>在测试的时候，使用”mean networks”，就是保留网络中所有的权重，但是要把激活函数的输出（activations)乘上$0.5$，因为相对训练的时候，每个神经元都有$0.5$的概率被激活，这个时候如果不乘上的话，最后就相当于测试的时候激活的神经元是训练时候的两倍。在实践中证明，这和对一系列经过dropout的网络取平均值的结果是很像的。（为什么就是两倍？）</p><blockquote><p>Dropout can also be thought of as an ensemble of models that share parameters. When we drop a neuron, it has no effect on the loss function and thus the gradient that flows through it during backpropagation is effectively zero and so its weights will not get updated. This means that we are basically subsampling a part of the neural network and we are training it on a single example. In every iteration of training, we will subsample a different part of the network and train that network on the datapoint at that point of time. Thus what we have essentially is an ensemble of models that share some parameters.[3]</p></blockquote><p>一个具有$N$个隐藏节点的网络，和一个用于计算类别标签的softmax输出层，使用mean networks就相当于对$2^N$个网络输出的标签概率做几何平均（并不是数学上的几何平均）。（为什么是几何平均？这里其实不是几何平均，只是一个等权重加权。）</p><blockquote><p>a) The authors of the referenced article don’t use the ‘geometric mean’ of the predictions, but “an equally weighted geometric mean” of them.<br>b) They propose geometric mean over arithmetic mean for giving more value to more frequent data, probably according to the understanding by them of the underlying relations.<br>If, for example, you take the arithmetic mean of ${10, 10, 100}$, you get $40$, but if you take their geometric mean you get $\sqrt[3]{10000} \approx 21.54$, meaning the ‘odd’ measurement ($100$) plays a smaller role to the mean.<br>c) Even the geometric mean might be misleading, if the data are not assigned their true ‘weight’, meaning their occurrence or probability of occurrence, while assuring that this assignment of weights is equally important for all data.<br>Hence “equally weighted geometric mean”.[2]</p></blockquote><p>如果采取dropout之后的网络输出不一样，那么mean network的输出能够保证赋值一个更高的可能性到正确标签。mean network的方根误差要比dropout网络方根误差的平均值要好，也就是说先对网络做平均然后计算误差要比先计算误差然后再平均要好。</p><p>实际上，$0.5$这个值不是固定的，可以根据不同情况进行微调。</p><h2 id="why-dropout-works"><a href="#why-dropout-works" class="headerlink" title="why dropout works"></a>why dropout works</h2><p>其实这个和上面介绍中差不多，给出一种直观的解释。给一个例子[4]，有一个三层的神经网络，在下图中，红圈中的节点对于正确的输出起到了决定性的作用，在BP的过程中，它的权值不断增加，但是它可能在训练集上效果很好，但是测试集上很差。<br><img src="/2019/03/23/神经网络-dropout/dropout_1.png" alt="dropout"><br>当采用了dropout以后，我们随意丢弃一些节点，如果把上图的关键节点丢了，那么网络必须重新学习其他的节点，才能够正确的进行分类。如下图，网络必须在另外可能没有丢弃的三个节点中选择一个用于正确分类。所以，这样子上图中的关键节点的作用就会被减轻，在新数据集上的鲁棒性可能就会更好。<br><img src="/2019/03/23/神经网络-dropout/dropout_2.png" alt="dropout"></p><h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><h3 id="numpy-实现"><a href="#numpy-实现" class="headerlink" title="numpy 实现"></a>numpy 实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(x, w1, w2, w3, training=False)</span>:</span></span><br><span class="line">  z1 = np.dot(x, w1)</span><br><span class="line">  y1 = np.tanh(z1)</span><br><span class="line"></span><br><span class="line">  z2 = np.dot(y1, w2)</span><br><span class="line">  y2 = np.dot(z2)</span><br><span class="line">  <span class="comment"># dropout in layer 2 </span></span><br><span class="line">  <span class="keyword">if</span> training:</span><br><span class="line">     m2 = np.random.binomial(<span class="number">1</span>, <span class="number">0.5</span>, size=z2.shape)</span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">     m2 = <span class="number">0.5</span></span><br><span class="line"></span><br><span class="line">  y2 *= m2</span><br><span class="line">  z3 = np.dot(y2, w3)</span><br><span class="line">  y3 = z3</span><br><span class="line">  <span class="keyword">return</span> y1, y2, y3, m2</span><br></pre></td></tr></table></figure><h3 id="pytorch库"><a href="#pytorch库" class="headerlink" title="pytorch库"></a>pytorch库</h3><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>1.<a href="https://arxiv.org/pdf/1207.0580.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1207.0580.pdf</a><br>2.<a href="https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf" target="_blank" rel="noopener">https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf</a><br>3.<a href="https://www.quora.com/What-is-dropout-in-deep-learning" target="_blank" rel="noopener">https://www.quora.com/What-is-dropout-in-deep-learning</a><br>4.<a href="https://www.quora.com/What-is-the-use-of-geometric-mean-in-dropout-neural-networks-It-says-that-by-approximating-an-equally-weighted-geometric-mean-of-the-predictions-of-an-exponential-number-of-learned-models-that-share-parameters" target="_blank" rel="noopener">https://www.quora.com/What-is-the-use-of-geometric-mean-in-dropout-neural-networks-It-says-that-by-approximating-an-equally-weighted-geometric-mean-of-the-predictions-of-an-exponential-number-of-learned-models-that-share-parameters</a><br>5.<a href="https://www.quora.com/Why-exactly-does-dropout-in-deep-learning-work" target="_blank" rel="noopener">https://www.quora.com/Why-exactly-does-dropout-in-deep-learning-work</a><br>6.<a href="https://www.quora.com/How-does-the-dropout-method-work-in-deep-learning-And-why-is-it-claimed-to-be-an-effective-trick-to-improve-your-network" target="_blank" rel="noopener">https://www.quora.com/How-does-the-dropout-method-work-in-deep-learning-And-why-is-it-claimed-to-be-an-effective-trick-to-improve-your-network</a><br>7.<a href="https://pgaleone.eu/deep-learning/regularization/2017/01/10/anaysis-of-dropout/" target="_blank" rel="noopener">https://pgaleone.eu/deep-learning/regularization/2017/01/10/anaysis-of-dropout/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;dropou是干什么的&quot;&gt;&lt;a href=&quot;#dropou是干什么的&quot; class=&quot;headerlink&quot; title=&quot;dropou是干什么的&quot;&gt;&lt;/a&gt;dropou是干什么的&lt;/h2&gt;&lt;p&gt;Dropout 是一种正则化技术，通过学习鲁棒的特征来防止过拟合。&lt;
      
    
    </summary>
    
      <category term="机器学习" scheme="http://mxxhcm.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://mxxhcm.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="深度学习" scheme="http://mxxhcm.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="神经网络" scheme="http://mxxhcm.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="dropout" scheme="http://mxxhcm.github.io/tags/dropout/"/>
    
  </entry>
  
  <entry>
    <title>matplotlib笔记</title>
    <link href="http://mxxhcm.github.io/2019/03/21/matplotlib%E7%AC%94%E8%AE%B0/"/>
    <id>http://mxxhcm.github.io/2019/03/21/matplotlib笔记/</id>
    <published>2019-03-21T07:29:17.000Z</published>
    <updated>2019-05-06T16:22:27.708Z</updated>
    
    <content type="html"><![CDATA[<h2 id><a href="#" class="headerlink" title=" "></a> </h2><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><p><a href="https://github.com/mxxhcm/matplotlib_tutorials" target="_blank" rel="noopener">https://github.com/mxxhcm/matplotlib_tutorials</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id&gt;&lt;a href=&quot;#&quot; class=&quot;headerlink&quot; title=&quot; &quot;&gt;&lt;/a&gt; &lt;/h2&gt;&lt;h2 id=&quot;代码&quot;&gt;&lt;a href=&quot;#代码&quot; class=&quot;headerlink&quot; title=&quot;代码&quot;&gt;&lt;/a&gt;代码&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;htt
      
    
    </summary>
    
      <category term="python" scheme="http://mxxhcm.github.io/categories/python/"/>
    
    
      <category term="python" scheme="http://mxxhcm.github.io/tags/python/"/>
    
      <category term="matplotlib" scheme="http://mxxhcm.github.io/tags/matplotlib/"/>
    
  </entry>
  
  <entry>
    <title>梯度下降和反向传播</title>
    <link href="http://mxxhcm.github.io/2019/03/18/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E5%92%8C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD/"/>
    <id>http://mxxhcm.github.io/2019/03/18/梯度下降和反向传播/</id>
    <published>2019-03-18T07:19:07.000Z</published>
    <updated>2019-05-06T16:22:27.708Z</updated>
    
    <content type="html"><![CDATA[<p>梯度下降和反向传播，他们两个之间的关系？</p><h2 id="导数，偏导数，梯度，方向倒数"><a href="#导数，偏导数，梯度，方向倒数" class="headerlink" title="导数，偏导数，梯度，方向倒数"></a>导数，偏导数，梯度，方向倒数</h2><h3 id="导数"><a href="#导数" class="headerlink" title="导数"></a>导数</h3><p>定义：</p><script type="math/tex; mode=display">f^{'}(x_0) = {\lim_{\Delta x \to 0}}\frac{\Delta y}{\Delta x} = \lim_{\Delta x \to 0}\frac{f(x_0+\Delta x)-f(x_0)}{\Delta x}</script><p>反映的是函数y=f(x)在某一点处沿x轴正方向的变化率。也能表示在x点处的斜率</p><h3 id="偏导数"><a href="#偏导数" class="headerlink" title="偏导数"></a>偏导数</h3><p>定义：</p><script type="math/tex; mode=display">\frac{\partial }{\partial x}f(x,y,z) = \lim_{\Delta x \to 0}\frac{f(x + \Delta x,y,z) - f(x,y,z)}{\Delta x}</script><p>导数与偏导数本质都是一样的，当自变量的变化量趋于0时，函数值的变化量与自变量变化量比值的极限，偏导数就是函数在某一点上沿坐标轴正方向上的变化率。比如函数f(x,y,z)，f(x,y,z)在某一点处可以分别求对于x，y，z轴正方向的偏导数。</p><h3 id="方向导数"><a href="#方向导数" class="headerlink" title="方向导数"></a>方向导数</h3><p>方向导数是某一点在某一趋近方向上的导数值，是函数在这个方向上的变化率。<br>定义：三元函数u=f(x,y,z)在点P(x,y,z)沿着l方向(方向角为$\alpha,\beta,\gamma$)的方向导数定义为</p><script type="math/tex; mode=display">\frac{\partial f}{\partial l} = \lim_{\rho \to 0}\frac{f(x+\Delta x,y+\Delta y,z+\Delta z)-f(x,y,z)}{\rho}</script><h3 id="梯度"><a href="#梯度" class="headerlink" title="梯度"></a>梯度</h3><p>梯度是方向导数中最大的那个向量，这个向量我们就称他为梯度，因为梯度是向量，所以才有梯度上升和下降的说法。梯度方向是函数增长最快的方向，梯度反方向是函数下降最快的方向。</p><h2 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h2><p>神经网络的训练一般是通过定义一个loss函数，然后通过优化这个loss函数，实现神经网络的训练，一般的loss函数主要是定义了训练样本的预测结果和真实结果之间的差异，比如说定义交叉熵等。<br>至于优化loss函数的方法，就是通过梯度下降法来实现，该算法从任一点开始，沿该点梯度的反方向运动一段距离，再沿新位置的梯度反方向运行一段距离 …… 如此迭代。解一直朝下坡最陡的方向运动，希望能运动到函数的全局最小点，梯度下降法是寻找函数局部最优解的有效方法（这里说的是局部最优解，而不是全局最优解，但是一般我们遇到的问题都是凸问题，局部最优解就是全局最优解），至于我们为什么不直接进行求解呢，因为计算量太大，如果有几百个参数的话，是不可行的（感觉这里说的不清楚，应该更具体的描述一下）。</p><h2 id="反向传播算法"><a href="#反向传播算法" class="headerlink" title="反向传播算法"></a>反向传播算法</h2><p>使用梯度下降算法的时候，我们需要计算函数的梯度，反向传播算法解释计算神经网络中误差函数梯度的一种方法。</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>1.<a href="https://zhuanlan.zhihu.com/p/25355758" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/25355758</a><br>2.<a href="https://www.zhihu.com/question/36301367/answer/142096153" target="_blank" rel="noopener">https://www.zhihu.com/question/36301367/answer/142096153</a><br>3.<a href="http://neuralnetworksanddeeplearning.com/" target="_blank" rel="noopener">http://neuralnetworksanddeeplearning.com/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;梯度下降和反向传播，他们两个之间的关系？&lt;/p&gt;
&lt;h2 id=&quot;导数，偏导数，梯度，方向倒数&quot;&gt;&lt;a href=&quot;#导数，偏导数，梯度，方向倒数&quot; class=&quot;headerlink&quot; title=&quot;导数，偏导数，梯度，方向倒数&quot;&gt;&lt;/a&gt;导数，偏导数，梯度，方向倒数&lt;/
      
    
    </summary>
    
      <category term="机器学习" scheme="http://mxxhcm.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://mxxhcm.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="梯度下降" scheme="http://mxxhcm.github.io/tags/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D/"/>
    
      <category term="反向传播" scheme="http://mxxhcm.github.io/tags/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD/"/>
    
  </entry>
  
  <entry>
    <title>pandas笔记</title>
    <link href="http://mxxhcm.github.io/2019/03/18/pandas%E7%AC%94%E8%AE%B0/"/>
    <id>http://mxxhcm.github.io/2019/03/18/pandas笔记/</id>
    <published>2019-03-18T07:15:54.000Z</published>
    <updated>2019-05-06T16:22:27.708Z</updated>
    
    <content type="html"><![CDATA[<h2 id="pd-read"><a href="#pd-read" class="headerlink" title="pd.read_*()"></a>pd.read_<em>*</em>()</h2><h3 id="pd-read-csv"><a href="#pd-read-csv" class="headerlink" title="pd.read_csv()"></a>pd.read_csv()</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas</span><br><span class="line">pandas.read_csv(filepath_or_buffer, sep=<span class="string">', '</span>, delimiter=<span class="literal">None</span>, header=<span class="string">'infer'</span>, names=<span class="literal">None</span>, index_col=<span class="literal">None</span>, usecols=<span class="literal">None</span>, squeeze=<span class="literal">False</span>, prefix=<span class="literal">None</span>, mangle_dupe_cols=<span class="literal">True</span>, dtype=<span class="literal">None</span>, engine=<span class="literal">None</span>, converters=<span class="literal">None</span>, true_values=<span class="literal">None</span>, false_values=<span class="literal">None</span>, skipinitialspace=<span class="literal">False</span>, skiprows=<span class="literal">None</span>, nrows=<span class="literal">None</span>, na_values=<span class="literal">None</span>, keep_default_na=<span class="literal">True</span>, na_filter=<span class="literal">True</span>, verbose=<span class="literal">False</span>, skip_blank_lines=<span class="literal">True</span>, parse_dates=<span class="literal">False</span>, infer_datetime_format=<span class="literal">False</span>, keep_date_col=<span class="literal">False</span>, date_parser=<span class="literal">None</span>, dayfirst=<span class="literal">False</span>, iterator=<span class="literal">False</span>, chunksize=<span class="literal">None</span>, compression=<span class="string">'infer'</span>, thousands=<span class="literal">None</span>, decimal=<span class="string">b'.'</span>, lineterminator=<span class="literal">None</span>, quotechar=<span class="string">'"'</span>, quoting=<span class="number">0</span>, escapechar=<span class="literal">None</span>, comment=<span class="literal">None</span>, encoding=<span class="literal">None</span>, dialect=<span class="literal">None</span>, tupleize_cols=<span class="literal">None</span>, error_bad_lines=<span class="literal">True</span>, warn_bad_lines=<span class="literal">True</span>, skipfooter=<span class="number">0</span>, skip_footer=<span class="number">0</span>, doublequote=<span class="literal">True</span>, delim_whitespace=<span class="literal">False</span>, as_recarray=<span class="literal">None</span>, compact_ints=<span class="literal">None</span>, use_unsigned=<span class="literal">None</span>, low_memory=<span class="literal">True</span>, buffer_lines=<span class="literal">None</span>, memory_map=<span class="literal">False</span>, float_precision=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure><p>filepath_or_buffer: 文件路径，或者一个字符串，url等等<br>sep: str,分隔符，默认是’,’<br>delimiter: str,定界符，如果指定该参数，sep参数失效<br>delimiter_whitespace: boolean,指定是否吧空格作为分界符如果指定该参数，则delimiter失效<br>headers: int or list of ints,指定列名字，默认是header=0,表示把第一行当做列名，如果header=[0,3,4],表示吧第0,3,4行都当做列名，真正的数据从第二行开始，如果没有列名，指定header=None<br>index_col: int or sequence or False,指定哪几列作为index，index_col=[0,1],表示用前两列的值作为一个index，去访问后面几列的值。<br>prefix: str,如果header为None的话，可以指定列名。<br>parse_dates: boolean or list of ints or names,or list of lists, or dict 如果是True，解析index，如果是list of ints，把每一个int代表的列都分别当做一个日期解析，如果是list of lists，将list中的list作为一个日期解析，如果是字典的话，将dict中key作为一个新的列名，value为这个新的列的值。<br>keep_date_col: boolean,如果parser_dates中是将多个列合并为一个日期的话，是否保留原始列<br>date_parser: function,用来解析parse_dates中给出的日期列，是自己写的函数，函数参数个数和一个日期的列数相同。</p><p>chunksize: 如果文件太大的话，分块读入<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">data = pd.read_csv(<span class="string">"input.csv"</span>,chunksize=<span class="number">1000</span>)</span><br><span class="line"><span class="keyword">for</span>  i  <span class="keyword">in</span>  data:</span><br><span class="line">  ...</span><br></pre></td></tr></table></figure></p><h2 id="DataFrame"><a href="#DataFrame" class="headerlink" title="DataFrame"></a>DataFrame</h2><h3 id="声明一个DataFrame"><a href="#声明一个DataFrame" class="headerlink" title="声明一个DataFrame"></a>声明一个DataFrame</h3><p>data = pandas.DataFrame(numpy.arange(16).reshape(4,4),index=list(‘abcd’),columns=(‘wxyz’)<br>    w  x  y  z<br>a  0  1  2  3<br>b  4  5  6  7<br>c  8  9  10  11<br>d  12  13  14  15<br>index 是index列的值<br>columns 是列名</p><h3 id="访问某一列"><a href="#访问某一列" class="headerlink" title="访问某一列"></a>访问某一列</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">data = pandas.DataFrame(numpy.arange(<span class="number">16</span>).reshape(<span class="number">4</span>,<span class="number">4</span>),index=list(<span class="string">'abcd'</span>),columns=(<span class="string">'wxyz'</span>)</span><br><span class="line">data[<span class="string">'w'</span>]</span><br><span class="line">data.w</span><br></pre></td></tr></table></figure><h3 id="写入某一列"><a href="#写入某一列" class="headerlink" title="写入某一列"></a>写入某一列</h3><p>只能先访问列 再访问行<br>data[‘w’] = []   # =左右两边shape必须一样<br>data[‘w’][0]  #某一列的第0行</p><h3 id="groupby"><a href="#groupby" class="headerlink" title="groupby"></a>groupby</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">data = pandas.DataFrame(np.arange(<span class="number">16</span>).reshape(<span class="number">4</span>,<span class="number">4</span>),index=list(<span class="string">'abcd'</span>),columns=(<span class="string">'wxyz'</span>))</span><br><span class="line"><span class="keyword">for</span> key,value <span class="keyword">in</span> data.groupby(<span class="string">"w"</span>):  <span class="comment"># group by 列名什么的，就是说某一列的值一样分一组</span></span><br><span class="line">  value = value.values  <span class="comment"># value是一个numpy数组</span></span><br><span class="line">  value_list = value.tolist()  <span class="comment">#将numpy数组转换为一个list</span></span><br><span class="line">  <span class="keyword">for</span> single_list <span class="keyword">in</span> value_list:</span><br><span class="line">     single_list = str(single_list)</span><br><span class="line">     ...</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;pd-read&quot;&gt;&lt;a href=&quot;#pd-read&quot; class=&quot;headerlink&quot; title=&quot;pd.read_*()&quot;&gt;&lt;/a&gt;pd.read_&lt;em&gt;*&lt;/em&gt;()&lt;/h2&gt;&lt;h3 id=&quot;pd-read-csv&quot;&gt;&lt;a href=&quot;#pd-re
      
    
    </summary>
    
      <category term="python" scheme="http://mxxhcm.github.io/categories/python/"/>
    
    
      <category term="python" scheme="http://mxxhcm.github.io/tags/python/"/>
    
      <category term="pandas" scheme="http://mxxhcm.github.io/tags/pandas/"/>
    
  </entry>
  
  <entry>
    <title>argparse笔记</title>
    <link href="http://mxxhcm.github.io/2019/03/18/argparse%E7%AC%94%E8%AE%B0/"/>
    <id>http://mxxhcm.github.io/2019/03/18/argparse笔记/</id>
    <published>2019-03-18T07:15:41.000Z</published>
    <updated>2019-05-06T16:22:27.704Z</updated>
    
    <content type="html"><![CDATA[<h2 id="简单的例子"><a href="#简单的例子" class="headerlink" title="简单的例子"></a>简单的例子</h2><h3 id="创建一个parser"><a href="#创建一个parser" class="headerlink" title="创建一个parser"></a>创建一个parser</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">parser = argparse.ArgumentParser(description=<span class="string">'Process Intergers'</span>)</span><br></pre></td></tr></table></figure><h3 id="添加参数"><a href="#添加参数" class="headerlink" title="添加参数"></a>添加参数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">parser.add_argument(,,)</span><br></pre></td></tr></table></figure><h3 id="解析参数"><a href="#解析参数" class="headerlink" title="解析参数"></a>解析参数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">arglist = parser.parse_args()</span><br></pre></td></tr></table></figure><h2 id><a href="#" class="headerlink" title="#"></a>#</h2><p>完整代码如下<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_args</span><span class="params">()</span>:</span></span><br><span class="line">    parser = argparse.ArgumentParser(<span class="string">"input parameters"</span>)</span><br><span class="line">    parser.add_argument(<span class="string">"--batch_size"</span>, type=int, default=<span class="number">32</span>)</span><br><span class="line">    parser.add_argument(<span class="string">"--episodes"</span>, type=int, default=<span class="number">1</span>)</span><br><span class="line">    parser.add_argument(<span class="string">"--lr"</span>, type=float, default=<span class="number">0.01</span>)</span><br><span class="line">    parser.add_argument(<span class="string">"--momentum"</span>, type=float, default=<span class="number">0.9</span>)</span><br><span class="line">    args_list = parser.parse_args()</span><br><span class="line">    <span class="keyword">return</span> args_list</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(args_list)</span>:</span></span><br><span class="line">print(args_list.batch_size)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    args_list = parse_args()</span><br><span class="line">    main(args_list)</span><br></pre></td></tr></table></figure></p><h2 id="ArgumentParser-objects"><a href="#ArgumentParser-objects" class="headerlink" title="ArgumentParser objects"></a>ArgumentParser objects</h2><blockquote><p>The ArgumentParser object will hold all the information necessary to parse the command line into python data types</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">argparse</span>.<span class="title">ArgumentParser</span><span class="params">(prog=None,usage=None,description=None,epilog=None,parents=[],formatter_class=argparse.HelpFormatter,prefix_chars=<span class="string">'-'</span>,fromfile_prefix_chars=None,argument_default=None,conflict_handler=<span class="string">'error'</span>,add_help=True)</span></span></span><br></pre></td></tr></table></figure><h3 id="创建一个名为test-py的程序如下"><a href="#创建一个名为test-py的程序如下" class="headerlink" title="创建一个名为test.py的程序如下"></a>创建一个名为test.py的程序如下</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">args = parser.parse_args()</span><br></pre></td></tr></table></figure><p>~#:python test.py -h</p><blockquote><p>usage: test.py [-h]</p><p>optional arguments:<br>  -h, —help  show this help message and exit</p></blockquote><h3 id="prog参数"><a href="#prog参数" class="headerlink" title="prog参数"></a>prog参数</h3><p>设置显示程序的名称</p><h4 id="直接使用默认显示的程序名"><a href="#直接使用默认显示的程序名" class="headerlink" title="直接使用默认显示的程序名"></a>直接使用默认显示的程序名</h4><p>~#:python test.py -h</p><blockquote><p>usage: test.py [-h]</p><p>optional arguments:<br>  -h, —help  show this help message and exit</p></blockquote><h4 id="使用prog参数进行设置"><a href="#使用prog参数进行设置" class="headerlink" title="使用prog参数进行设置"></a>使用prog参数进行设置</h4><p>修改test.py的程序如下<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser(prog=<span class="string">"mytest"</span>)</span><br><span class="line">args = parser.parse_args()</span><br></pre></td></tr></table></figure></p><p>~#:python test.py -h</p><blockquote><p>usage: mytest [-h]</p><p>optional arguments:<br>  -h, —help  show this help message and exit</p></blockquote><p>usage后的名称变为我们prog参数指定的名称</p><h3 id="usage"><a href="#usage" class="headerlink" title="usage"></a>usage</h3><h4 id="使用默认的usage"><a href="#使用默认的usage" class="headerlink" title="使用默认的usage"></a>使用默认的usage</h4><h4 id="使用指定的usage"><a href="#使用指定的usage" class="headerlink" title="使用指定的usage"></a>使用指定的usage</h4><h3 id="description"><a href="#description" class="headerlink" title="description"></a>description</h3><h4 id="使用默认的description"><a href="#使用默认的description" class="headerlink" title="使用默认的description"></a>使用默认的description</h4><h4 id="使用指定的description"><a href="#使用指定的description" class="headerlink" title="使用指定的description"></a>使用指定的description</h4><h3 id="epilog"><a href="#epilog" class="headerlink" title="epilog"></a>epilog</h3><h4 id="使用默认的epilog"><a href="#使用默认的epilog" class="headerlink" title="使用默认的epilog"></a>使用默认的epilog</h4><h4 id="使用指定的epilog"><a href="#使用指定的epilog" class="headerlink" title="使用指定的epilog"></a>使用指定的epilog</h4><h3 id="parents"><a href="#parents" class="headerlink" title="parents"></a>parents</h3><h3 id="formatter-class"><a href="#formatter-class" class="headerlink" title="formatter_class"></a>formatter_class</h3><h3 id="prefix-chars"><a href="#prefix-chars" class="headerlink" title="prefix_chars"></a>prefix_chars</h3><p>指定其他的prefix，默认的是-，比如可以指定可选参数的前缀为+</p><h3 id="fromfile-prefix-chars"><a href="#fromfile-prefix-chars" class="headerlink" title="fromfile_prefix_chars"></a>fromfile_prefix_chars</h3><h3 id="argument-default"><a href="#argument-default" class="headerlink" title="argument_default"></a>argument_default</h3><h3 id="conflict-handler"><a href="#conflict-handler" class="headerlink" title="conflict_handler"></a>conflict_handler</h3><p>将conflict_handler设置为resolve就可以防止override原来older arguments<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser(conflict_handler=<span class="string">'resolve'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'--foo'</span>,<span class="string">'-f'</span>,help=<span class="string">"old help"</span>)</span><br><span class="line">parser.add_argument(<span class="string">'-f'</span>,help=<span class="string">"new_help"</span>)</span><br><span class="line">parser.print_help()</span><br></pre></td></tr></table></figure></p><h3 id="add-help"><a href="#add-help" class="headerlink" title="add_help"></a>add_help</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser(add_help=<span class="literal">False</span>)</span><br><span class="line">parser.print_help()</span><br></pre></td></tr></table></figure><p>输出</p><blockquote><p>usage: [-h]</p><p>optional arguments:<br>  -h, —help  show this help message and exit<br>将add_help设置为false</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser(add_help=<span class="literal">False</span>)</span><br><span class="line">parser.print_help()</span><br></pre></td></tr></table></figure><p>输出</p><blockquote><p>usage: </p></blockquote><h2 id="The-add-argument-method"><a href="#The-add-argument-method" class="headerlink" title="The add_argument() method"></a>The add_argument() method</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ArgumentParser.add_argument(name <span class="keyword">or</span> flags...[,action],[,nargs],[,const],[,default],[,type],[,choices],[,required],[,help],[,metavar],[,dest])</span><br></pre></td></tr></table></figure><h3 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">'-f'</span>,<span class="string">'-foo'</span>,<span class="string">'-a'</span>, defaults=, type=, help=)</span><br><span class="line">parser.add_argument(<span class="string">'hello'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'hi'</span>)</span><br><span class="line">args = parser.parse_args([<span class="string">'Hello'</span>,<span class="string">'-f'</span>,<span class="string">'123'</span>,<span class="string">'Hi'</span>])</span><br><span class="line">print(args)</span><br></pre></td></tr></table></figure><h3 id="name-or-flags"><a href="#name-or-flags" class="headerlink" title="name or flags"></a>name or flags</h3><h4 id="添加可选参数"><a href="#添加可选参数" class="headerlink" title="添加可选参数"></a>添加可选参数</h4><p>parser.add_argument(‘-f’, ‘—foo’, ‘-fooo’)</p><h4 id="添加必选参数"><a href="#添加必选参数" class="headerlink" title="添加必选参数"></a>添加必选参数</h4><p>parser.add_argument(‘bar’)</p><h4 id="调用parse-args"><a href="#调用parse-args" class="headerlink" title="调用parse_args()"></a>调用parse_args()</h4><p>当parse_args()函数被调用的时候，可选参数会被-prefix所识别，剩下的参数会被分配给必选参数的位置。如下代码中，’3’对应的就是’hello’的参数，’this is hi’对应的就是’hi’的参数，而’123’是’-f’的参数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">'-f'</span>,<span class="string">'-foo'</span>,<span class="string">'-a'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'hello'</span>, type=int)</span><br><span class="line">parser.add_argument(<span class="string">'hi'</span>)</span><br><span class="line">args = parser.parse_args([<span class="string">'3'</span>,<span class="string">'-f'</span>,<span class="string">'123'</span>,<span class="string">'this is hi'</span>])</span><br><span class="line">print(args)</span><br></pre></td></tr></table></figure><p>输出</p><blockquote><p>Namespace(f=’123’, hello=’Hello’, hi=’Hi’)</p></blockquote><h3 id="action"><a href="#action" class="headerlink" title="action"></a>action</h3><h4 id="store-the-default-action"><a href="#store-the-default-action" class="headerlink" title="store,the default action"></a>store,the default action</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">'--foo'</span>)</span><br><span class="line">args = parser.parse_args([<span class="string">'--foo'</span>,<span class="string">'1'</span>])</span><br><span class="line">print(args)</span><br></pre></td></tr></table></figure><p>输出</p><blockquote><p>Namespace(foo=’1’)</p></blockquote><h4 id="store-const"><a href="#store-const" class="headerlink" title="store_const"></a>store_const</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">'--foo'</span>, action=<span class="string">'store_const'</span>, const=<span class="number">42</span>)</span><br><span class="line">args = parser.parse_args([<span class="string">'--foo'</span>)</span><br><span class="line">print(args)</span><br></pre></td></tr></table></figure><p>输出</p><blockquote><p>Namespace(foo=42)</p></blockquote><h4 id="store-true-and-store-false"><a href="#store-true-and-store-false" class="headerlink" title="store_true and store_false"></a>store_true and store_false</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">'--foo'</span>, action=<span class="string">'store_true'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'--bar'</span>, action=<span class="string">'store_false'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'--baz'</span>, action=<span class="string">'store_false'</span>)</span><br><span class="line">args = parser.parse_args(<span class="string">'--foo --bar'</span>.split())</span><br><span class="line">print(args)</span><br></pre></td></tr></table></figure><p>输出</p><blockquote><p>Namespace(bar=False, baz=True, foo=True)</p></blockquote><p>这里为什么是这样呢，因为默认存储的都是True，当你调用—bar,—foo参数时，会执行action操作，会把action指定的动作执行</p><h4 id="d-append"><a href="#d-append" class="headerlink" title="d.append"></a>d.append</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">'--foo'</span>, action=<span class="string">'append'</span>)</span><br><span class="line">args = parser.parse_args(<span class="string">'--foo 1 --foo 2 --foo 3'</span>.split())</span><br><span class="line">print(args)</span><br></pre></td></tr></table></figure><p>输出</p><blockquote><p>Namespace(foo=[‘1’, ‘2’, ‘3’])</p></blockquote><h4 id="append-const"><a href="#append-const" class="headerlink" title="append_const"></a>append_const</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">'--str'</span>, action=<span class="string">'append_const'</span>,const=str)</span><br><span class="line">parser.add_argument(<span class="string">'--int'</span>, action=<span class="string">'append_const'</span>,const=int)</span><br><span class="line">args = parser.parse_args(<span class="string">'--str --int'</span>.split())</span><br><span class="line">print(args)</span><br></pre></td></tr></table></figure><p>输出</p><blockquote><p>Namespace(int=[<class 'int'>], str=[<class 'str'>])</class></class></p></blockquote><h4 id="count"><a href="#count" class="headerlink" title="count"></a>count</h4><p>统计一个keyword argument出现了多少次<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">'--co'</span>, <span class="string">'-c'</span>,action=<span class="string">'count'</span>)</span><br><span class="line">args = parser.parse_args([<span class="string">'-ccc'</span>])</span><br><span class="line">print(args)</span><br></pre></td></tr></table></figure></p><p>输出</p><blockquote><p>Namespace(co=3)</p></blockquote><h4 id="help"><a href="#help" class="headerlink" title="help"></a>help</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">args = parser.parse_args(<span class="string">'--help'</span>.split())</span><br><span class="line">print(args)</span><br></pre></td></tr></table></figure><p>输出，如果是交互式环境的话，会退出python</p><blockquote><p>usage: [-h]</p><p>optional arguments:<br>  -h, —help  show this help message and exit</p></blockquote><h4 id="version"><a href="#version" class="headerlink" title="version"></a>version</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">'--version'</span>, action=<span class="string">'version'</span>,version=<span class="string">'version 3'</span>)</span><br><span class="line">args = parser.parse_args(<span class="string">'--version'</span>.split())</span><br><span class="line">print(args)</span><br></pre></td></tr></table></figure><p>输出,如果是交互式环境的话，会退出python</p><blockquote><p>version 3</p></blockquote><h3 id="nargs-指定参数个数"><a href="#nargs-指定参数个数" class="headerlink" title="nargs 指定参数个数"></a>nargs 指定参数个数</h3><h4 id="N"><a href="#N" class="headerlink" title="N"></a>N</h4><p>如果是可选参数的话，或者不指定这个参数，或者必须指定N个参数<br>如果是必选参数的话，必须指定N个参数，不能多也不能少，也不能为0个<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">'--foo'</span>,nargs=<span class="number">3</span>)</span><br><span class="line">parser.add_argument(<span class="string">'bar'</span>,nargs=<span class="number">4</span>)</span><br><span class="line">args = parser.parse_args(<span class="string">'bar 3 4 5'</span>.split())</span><br><span class="line">print(args)</span><br></pre></td></tr></table></figure></p><p>输出</p><blockquote><p>Namespace(bar=[‘bar’, ‘3’, ‘4’, ‘5’], foo=None)</p></blockquote><h4 id="-1"><a href="#-1" class="headerlink" title="?"></a>?</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">'--foo'</span>,nargs=<span class="string">'?'</span>,const=<span class="string">'c'</span>,default=<span class="string">'d'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'bar'</span>,nargs=<span class="string">'?'</span>,default=<span class="string">'d'</span>)</span><br><span class="line">args = parser.parse_args(<span class="string">'3'</span>.split())</span><br><span class="line">print(args)</span><br><span class="line">args = parser.parse_args(<span class="string">'3 --foo'</span>.split())</span><br><span class="line">print(args)</span><br></pre></td></tr></table></figure><p>输出</p><blockquote><p>Namespace(bar=’3’, foo=’d’)<br>Namespace(bar=’3’, foo=’c’)</p></blockquote><p>如果显式指定可选参数，但是不给它参数，那么如果有const的话，就会显示const的值，否则就会显示None</p><h4 id="-2"><a href="#-2" class="headerlink" title="*"></a>*</h4><p>nargs设置为*的话，不能直接用const=’’来设置const参数，需要使用其他方式<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">'--foo'</span>,nargs=<span class="string">'*'</span>,default=<span class="string">'d'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'bar'</span>,nargs=<span class="string">'*'</span>,default=<span class="string">'d'</span>)</span><br><span class="line">args = parser.parse_args(<span class="string">'3 --foo 3 4'</span>.split())</span><br><span class="line">print(args)</span><br></pre></td></tr></table></figure></p><p>输出</p><blockquote><p>Namespace(bar=[‘3’], foo=[‘3’, ‘4’])</p></blockquote><h4 id="-3"><a href="#-3" class="headerlink" title="+"></a>+</h4><p>nargs设置为+，参数个数必须大于等于1<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">'--foo'</span>,nargs=<span class="string">'+'</span>,default=<span class="string">'d'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'bar'</span>,nargs=<span class="string">'+'</span>,default=<span class="string">'d'</span>)</span><br><span class="line">args = parser.parse_args(<span class="string">'3 3'</span>.split())</span><br><span class="line">print(args)</span><br><span class="line">args = parser.parse_args(<span class="string">'--foo 3'</span>.split())</span><br><span class="line">print(args)</span><br></pre></td></tr></table></figure></p><p>输出</p><blockquote><p>Namespace(bar=[‘3’], foo=’d’)<br>Namespace(bar=[‘3’], foo=[‘3’])</p></blockquote><h3 id="const"><a href="#const" class="headerlink" title="const"></a>const</h3><h4 id="action-’’store-const”-or-action-”append-const”"><a href="#action-’’store-const”-or-action-”append-const”" class="headerlink" title="action=’’store_const” or action=”append_const”"></a>action=’’store_const” or action=”append_const”</h4><p>the examples are in the action<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">'--foo'</span>, action=<span class="string">'store_const'</span>, const=<span class="number">42</span>)</span><br><span class="line">args = parser.parse_args([<span class="string">'--foo'</span>)</span><br><span class="line">print(args)</span><br></pre></td></tr></table></figure></p><p>输出</p><blockquote><p>Namespace(foo=42)</p></blockquote><h4 id="like-f-or-—foo-and-nargs-’-’"><a href="#like-f-or-—foo-and-nargs-’-’" class="headerlink" title="like -f or —foo and nargs=’?’"></a>like -f or —foo and nargs=’?’</h4><p>the examples are the same as examples in the nargs=’?’<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">'--foo'</span>,nargs=<span class="string">'?'</span>,const=<span class="string">'c'</span>,default=<span class="string">'d'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'bar'</span>,nargs=<span class="string">'?'</span>,default=<span class="string">'d'</span>)</span><br><span class="line">args = parser.parse_args(<span class="string">'3'</span>.split())</span><br><span class="line">print(args)</span><br><span class="line">args = parser.parse_args(<span class="string">'3 --foo'</span>.split())</span><br><span class="line">print(args)</span><br></pre></td></tr></table></figure></p><p>输出</p><blockquote><p>Namespace(bar=’3’, foo=’d’)<br>Namespace(bar=’3’, foo=’c’)<br>如果显式指定可选参数，但是不给它参数，那么如果有const的话，就会显示const的值，否则就会显示None</p></blockquote><h3 id="default"><a href="#default" class="headerlink" title="default"></a>default</h3><p>default对于可选参数来说，是有用的，当可选参数没有在command line中显示出来时被使用，但是对于必选参数来说，只有nargs=?或者*才能起作用。</p><h4 id="对于可选参数"><a href="#对于可选参数" class="headerlink" title="对于可选参数"></a>对于可选参数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">'--foo'</span>,default=<span class="number">43</span>)</span><br><span class="line">args = parser.parse_args([])</span><br><span class="line">print(args)</span><br><span class="line">args = parser.parse_args(<span class="string">'--foo 3'</span>.split())</span><br><span class="line">print(args)</span><br></pre></td></tr></table></figure><p>输出</p><blockquote><p>Namespace(foo=’43’)<br>Namespace(foo=’3’)</p></blockquote><h4 id="对于必选参数"><a href="#对于必选参数" class="headerlink" title="对于必选参数"></a>对于必选参数</h4><p>对于nargs=‘+’是会出错<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(&apos;bar&apos;,nargs=&apos;+&apos;,default=&apos;d&apos;)</span><br><span class="line">args = parser.parse_args([])</span><br><span class="line">print(args)</span><br></pre></td></tr></table></figure></p><p>输出</p><blockquote><p>usage: [-h] bar [bar …]<br>: error: the following arguments are required: bar</p></blockquote><p>对于nargs=‘*’或者nargs=’?’就行了<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">'bar'</span>,nargs=<span class="string">'?'</span>,default=<span class="string">'d'</span>)</span><br><span class="line">args = parser.parse_args([])</span><br><span class="line">print(args)</span><br></pre></td></tr></table></figure></p><p>输出</p><blockquote><p>Namespace(bar=’d’)</p></blockquote><h3 id="type"><a href="#type" class="headerlink" title="type"></a>type</h3><p>将输入的字符串参数转换为你想要的参数类型<br>对于文件类型来说，这个文件必须在当前目录存在。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">'--door'</span>,type=int)</span><br><span class="line">parser.add_argument(<span class="string">'filename'</span>,type=file)</span><br><span class="line">parser.parse_args([<span class="string">'--door'</span>,<span class="string">'3'</span>,<span class="string">'hello.txt'</span>])</span><br></pre></td></tr></table></figure></p><p>输出</p><blockquote><p>Namespace(door=3)<br>这里的door就是int类型的</p></blockquote><h3 id="choices"><a href="#choices" class="headerlink" title="choices"></a>choices</h3><p>输入的参数必须在choices这个范围中，否则就会报错<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParse()</span><br><span class="line">parser.add_argument(<span class="string">'--door'</span>,type=int,choices=range(<span class="number">1</span>,<span class="number">9</span>))</span><br><span class="line">parser.parse_args([<span class="string">'--door'</span>,<span class="string">'3'</span>])</span><br></pre></td></tr></table></figure></p><p>输出</p><blockquote><p>Namespace(door=3)</p></blockquote><h3 id="required"><a href="#required" class="headerlink" title="required"></a>required</h3><p>如果将required设置为True的话，那么这个可选参数必须要设置的<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">'-f'</span>, <span class="string">'--foo-bar'</span>, <span class="string">'--foo'</span>,required=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure></p><h3 id="help-1"><a href="#help-1" class="headerlink" title="help"></a>help</h3><p>help可以设置某个参数的简要介绍。<br>使用help=argparse.SUPRESS可以在help界面中不显示这个参数的介绍<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">'-f'</span>, <span class="string">'--foo-bar'</span>, <span class="string">'--foo'</span>,help=<span class="string">'fool you '</span>)</span><br><span class="line">parser.add_argument(<span class="string">'-xs'</span>, <span class="string">'--y'</span>,help=argparse.SUPPRESS)</span><br><span class="line">parser.print_help()</span><br></pre></td></tr></table></figure></p><p>输出</p><blockquote><p>usage: [-h] [-f FOO_BAR]</p><p>optional arguments:<br>  -h, —help            show this help message and exit<br>  -f FOO_BAR, —foo-bar FOO_BAR, —foo FOO_BAR<br>                        fool you</p></blockquote><h3 id="dest"><a href="#dest" class="headerlink" title="dest"></a>dest</h3><p>dest就是在help输出时显示的optional和positional参数后跟的名字（没有指定metavar时）<br>如下,dest就是FOO<br>-foo FOO</p><h4 id="positional-argument"><a href="#positional-argument" class="headerlink" title="positional argument"></a>positional argument</h4><p>dest is normally supplied as the first argument to add_argument()</p><h4 id="可选参数"><a href="#可选参数" class="headerlink" title="可选参数"></a>可选参数</h4><p>对于optional argument选择，—参数最长的一个作为dest，如果没有最长的，选择第一个出现的，如果没有—参数名，选择-参数。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">'-f'</span>, <span class="string">'--foo-bar'</span>, <span class="string">'--foo'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'-xs'</span>, <span class="string">'--y'</span>)</span><br><span class="line">args = parser.parse_args(<span class="string">'-f 1 -xs 2'</span>.split())</span><br><span class="line">print(args)</span><br><span class="line">args = parser.parse_args(<span class="string">'--foo 1 --y 2'</span>.split())</span><br><span class="line">print(args)</span><br><span class="line">parser.print_help()</span><br></pre></td></tr></table></figure></p><p>输出</p><blockquote><p>Namespace(foo_bar=’1’, y=’2’)<br>Namespace(foo_bar=’1’, y=’2’)<br>usage: [-h] [-f FOO_BAR] [-xs Y]</p><p>optional arguments:<br>  -h, —help            show this help message and exit<br>  -f FOO_BAR, —foo-bar FOO_BAR, —foo FOO_BAR<br>  -xs Y, —y Y</p></blockquote><h3 id="metavar"><a href="#metavar" class="headerlink" title="metavar"></a>metavar</h3><p>如果指定metavar变量名的话，那么help输出的postional和positional参数后跟的名字就是metavar的名字而不是dest的名字</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">'-f'</span>, <span class="string">'--foo-bar'</span>, <span class="string">'--foo'</span>,metavar=<span class="string">"FOO"</span>)</span><br><span class="line">parser.add_argument(<span class="string">'-xs'</span>, <span class="string">'--y'</span>,metavar=<span class="string">'XY'</span>)</span><br><span class="line">args = parser.parse_args(<span class="string">'-f 1 -xs 2'</span>.split())</span><br><span class="line">print(args)</span><br><span class="line">args = parser.parse_args(<span class="string">'--foo 1 --y 2'</span>.split())</span><br><span class="line">print(args)</span><br><span class="line">parser.print_help()</span><br></pre></td></tr></table></figure><p>输出</p><blockquote><p>Namespace(foo_bar=’1’, y=’2’)<br>Namespace(foo_bar=’1’, y=’2’)<br>usage: [-h] [-f FOO] [-xs XY]</p><p>optional arguments:<br>  -h, —help            show this help message and exit<br>  -f FOO, —foo-bar FOO, —foo FOO<br>  -xs XY, —y XY</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;简单的例子&quot;&gt;&lt;a href=&quot;#简单的例子&quot; class=&quot;headerlink&quot; title=&quot;简单的例子&quot;&gt;&lt;/a&gt;简单的例子&lt;/h2&gt;&lt;h3 id=&quot;创建一个parser&quot;&gt;&lt;a href=&quot;#创建一个parser&quot; class=&quot;headerlink&quot; 
      
    
    </summary>
    
      <category term="python" scheme="http://mxxhcm.github.io/categories/python/"/>
    
    
      <category term="python" scheme="http://mxxhcm.github.io/tags/python/"/>
    
      <category term="argparse" scheme="http://mxxhcm.github.io/tags/argparse/"/>
    
  </entry>
  
  <entry>
    <title>numpy笔记</title>
    <link href="http://mxxhcm.github.io/2019/03/18/numpy%E7%AC%94%E8%AE%B0/"/>
    <id>http://mxxhcm.github.io/2019/03/18/numpy笔记/</id>
    <published>2019-03-18T07:15:29.000Z</published>
    <updated>2019-05-06T16:22:27.708Z</updated>
    
    <content type="html"><![CDATA[<h2 id="numpy数组初始化"><a href="#numpy数组初始化" class="headerlink" title="numpy数组初始化"></a>numpy数组初始化</h2><h3 id="numpy-ndarray"><a href="#numpy-ndarray" class="headerlink" title="numpy.ndarray"></a>numpy.ndarray</h3><h4 id="attribute-of-the-np-ndarray"><a href="#attribute-of-the-np-ndarray" class="headerlink" title="attribute of the np.ndarray"></a>attribute of the np.ndarray</h4><p>ndarray.shape        #array的shape<br>ndarray.ndim            #array的维度<br>ndarray.size            #the number of ndarray in array<br>ndarray.dtype        #type of the number in array，dtype可以是’S’,int等<br>ndarray.itemsize        #size of the element in array<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">array[array&gt;<span class="number">0</span>].size    <span class="comment">#统计一个数组有多少个非零元素，不论array的维度是多少</span></span><br></pre></td></tr></table></figure></p><h3 id="numpy-array-numpy-zeros-numpy-empty"><a href="#numpy-array-numpy-zeros-numpy-empty" class="headerlink" title="numpy.array(),numpy.zeros(),numpy.empty()"></a>numpy.array(),numpy.zeros(),numpy.empty()</h3><h4 id="numpy-array"><a href="#numpy-array" class="headerlink" title="numpy.array()"></a>numpy.array()</h4><blockquote><p>np.array(object,dtype=None,copy=True,order=False,subok=False,ndim=0)</p></blockquote><h4 id="numpy-zeros"><a href="#numpy-zeros" class="headerlink" title="numpy.zeros()"></a>numpy.zeros()</h4><blockquote><p>np.zeros(shape,dtype=float,order=’C’)</p></blockquote><p>例子<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">np.zeros((<span class="number">3</span>,<span class="number">4</span>),dtype=<span class="string">'i'</span>)</span><br><span class="line">``` </span><br><span class="line"></span><br><span class="line"><span class="comment">#### numpy.empty()</span></span><br><span class="line">&gt; np.empty(shape,dtype=float,order=<span class="string">'C'</span>)</span><br><span class="line">例子</span><br><span class="line">``` python</span><br><span class="line">np.empty((<span class="number">3</span>,<span class="number">4</span>),dtype=<span class="string">'f'</span>)</span><br></pre></td></tr></table></figure></p><h3 id="numpy-random"><a href="#numpy-random" class="headerlink" title="numpy.random()"></a>numpy.random()</h3><h4 id="numpy-random-randn"><a href="#numpy-random-randn" class="headerlink" title="numpy.random.randn()"></a>numpy.random.randn()</h4><p>返回标准正态分布的一个样本<br>numpy.random.randn(d0,d1,…,dn)<br>例子<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np.random.randn(<span class="number">3</span>,<span class="number">4</span>)</span><br></pre></td></tr></table></figure></p><blockquote><p>array([[ 0.47203644, -0.0869761 , -1.02814481, -0.45945482],<br>       [ 0.34586502, -0.63121119,  0.35510786,  0.82975136],<br>       [-2.00253326, -0.63773715, -0.82700167,  1.80724647]])</p></blockquote><h4 id="numpy-random-rand"><a href="#numpy-random-rand" class="headerlink" title="numpy.random.rand()"></a>numpy.random.rand()</h4><p>创建一个给定shape的数组，从区间[0,1)上的均匀分布中随机采样</p><blockquote><p>create an array of the given shape and populate it with random samples from a uniform disctribution over [0,1)</p></blockquote><p>numpy.random.rand(d0,d1,…,dn)<br>例子<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np.random.rand(<span class="number">3</span>,<span class="number">4</span>)</span><br></pre></td></tr></table></figure></p><h4 id="numpy-random-random"><a href="#numpy-random-random" class="headerlink" title="numpy.random.random()"></a>numpy.random.random()</h4><p>返回区间[0.0, 1.0)之间的随机浮点数</p><blockquote><p>return random floats in the half-open interval [0.0,1.0)</p></blockquote><p>numpy.random.random(size=None)<br>例子<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np.random.random((<span class="number">3</span>,<span class="number">4</span>))</span><br></pre></td></tr></table></figure></p><h5 id="Note"><a href="#Note" class="headerlink" title="Note"></a>Note</h5><p>注意，random.random()和random.rand()实现的功能都是一样的，就是输入的参数不同。见参考文献[1]。</p><h4 id="numpy-random-ranf"><a href="#numpy-random-ranf" class="headerlink" title="numpy.random.ranf()"></a>numpy.random.ranf()</h4><p>我觉得它和random.random()没啥区别</p><h4 id="numpy-random-randint"><a href="#numpy-random-randint" class="headerlink" title="numpy.random.randint()"></a>numpy.random.randint()</h4><blockquote><p>return random integers from low(inclusive) to high(exclusive),[low,high) if high is None,then results are from [0,low)</p></blockquote><p>numpy.random.randint(low,high=None,size=None,dtype=’l’)<br>例子<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">np.random.randint(<span class="number">3</span>,size=[<span class="number">3</span>,<span class="number">4</span>])</span><br><span class="line">np.random.randint(<span class="number">4</span>,<span class="number">6</span>,size=[<span class="number">6</span>,<span class="number">2</span>])</span><br></pre></td></tr></table></figure></p><h4 id="numpy-random-RandomState"><a href="#numpy-random-RandomState" class="headerlink" title="numpy.random.RandomState()"></a>numpy.random.RandomState()</h4><blockquote><p>class numpy.random.RandomState(seed=None)</p></blockquote><p>这是一个类，给定一个种子，它接下来产生的一系列随机数都是固定的。每次需要重新产生随机数的时候，就重置种子。<br>通过一个例子来看：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">rdm = np.randrom.RandomState()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">   rdm.seed(<span class="number">3</span>)</span><br><span class="line">   print(rdm.rand())</span><br><span class="line">   print(rdm.rand())</span><br><span class="line">   print(rdm.rand())</span><br><span class="line">   print(<span class="string">"\n"</span>)</span><br></pre></td></tr></table></figure></p><blockquote><p>0.9670298390136767<br>0.5472322491757223<br>0.9726843599648843</p><p>0.9670298390136767<br>0.5472322491757223<br>0.9726843599648843</p><p>0.9670298390136767<br>0.5472322491757223<br>0.9726843599648843</p><p>0.9670298390136767<br>0.5472322491757223<br>0.9726843599648843</p><p>0.9670298390136767<br>0.5472322491757223<br>0.9726843599648843</p></blockquote><h3 id="others"><a href="#others" class="headerlink" title="others"></a>others</h3><h4 id="numpy-arange"><a href="#numpy-arange" class="headerlink" title="numpy.arange()"></a>numpy.arange()</h4><h4 id="numpy-linspace"><a href="#numpy-linspace" class="headerlink" title="numpy.linspace()"></a>numpy.linspace()</h4><h3 id="改变数组数据类型"><a href="#改变数组数据类型" class="headerlink" title="改变数组数据类型"></a>改变数组数据类型</h3><p>将整形数组改为字符型<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a = numpy.zeros((<span class="number">3</span>,<span class="number">4</span>),dtype=<span class="string">'i'</span>)</span><br><span class="line">a.astype(<span class="string">'S'</span>)</span><br></pre></td></tr></table></figure></p><h3 id="将numpy转为list"><a href="#将numpy转为list" class="headerlink" title="将numpy转为list"></a>将numpy转为list</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a = np.zeros((<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>))</span><br><span class="line">b = a.tolist()</span><br><span class="line">print(b)</span><br><span class="line">print(len(b))</span><br><span class="line">print(len(b[<span class="number">0</span>]))</span><br></pre></td></tr></table></figure><blockquote><p>[[[0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0]], [[0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0]], [[0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0]]]<br>3<br>4</p></blockquote><h2 id="flatten-ndarray"><a href="#flatten-ndarray" class="headerlink" title="flatten ndarray"></a>flatten ndarray</h2><h3 id="reshape"><a href="#reshape" class="headerlink" title="reshape()"></a>reshape()</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">a = np.zeros((<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>))</span><br><span class="line">a.reshape(<span class="number">-1</span>,<span class="number">1</span>)</span><br></pre></td></tr></table></figure><h3 id="flatten"><a href="#flatten" class="headerlink" title="flatten"></a>flatten</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">a = np.zeros((<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>))</span><br><span class="line">a.flatten()</span><br></pre></td></tr></table></figure><p>参考文献<br>1.<a href="https://stackoverflow.com/questions/47231852/np-random-rand-vs-np-random-random" target="_blank" rel="noopener">https://stackoverflow.com/questions/47231852/np-random-rand-vs-np-random-random</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;numpy数组初始化&quot;&gt;&lt;a href=&quot;#numpy数组初始化&quot; class=&quot;headerlink&quot; title=&quot;numpy数组初始化&quot;&gt;&lt;/a&gt;numpy数组初始化&lt;/h2&gt;&lt;h3 id=&quot;numpy-ndarray&quot;&gt;&lt;a href=&quot;#numpy-nd
      
    
    </summary>
    
      <category term="python" scheme="http://mxxhcm.github.io/categories/python/"/>
    
    
      <category term="python" scheme="http://mxxhcm.github.io/tags/python/"/>
    
      <category term="numpy" scheme="http://mxxhcm.github.io/tags/numpy/"/>
    
  </entry>
  
  <entry>
    <title>jupyter notebook笔记</title>
    <link href="http://mxxhcm.github.io/2019/03/18/jupyter-notebook%E7%AC%94%E8%AE%B0/"/>
    <id>http://mxxhcm.github.io/2019/03/18/jupyter-notebook笔记/</id>
    <published>2019-03-18T07:14:33.000Z</published>
    <updated>2019-05-06T16:22:27.708Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、安装和运行"><a href="#一、安装和运行" class="headerlink" title="一、安装和运行"></a>一、安装和运行</h2><h3 id="1-安装"><a href="#1-安装" class="headerlink" title="1.安装"></a>1.安装</h3><h4 id="Anaconda安装"><a href="#Anaconda安装" class="headerlink" title="Anaconda安装"></a>Anaconda安装</h4><p>Anaconda自身已经集成了jupyter包，所以如果没有装python的话，可以选择安装Anaconda集成环境</p><h4 id="pip安装"><a href="#pip安装" class="headerlink" title="pip安装"></a>pip安装</h4><p>~#:pip install jupyter</p><h3 id="2-运行"><a href="#2-运行" class="headerlink" title="2.运行"></a>2.运行</h3><p>~#:jupyter notebook</p><h3 id="3-远程访问"><a href="#3-远程访问" class="headerlink" title="3.远程访问"></a>3.远程访问</h3><h4 id="1-直接使用命令"><a href="#1-直接使用命令" class="headerlink" title="(1).直接使用命令"></a>(1).直接使用命令</h4><p>这种方法是建立了一个session，会有一个token，这个会话结束之后，这个token就无效了，需要再重现建立新的session</p><h5 id="a-在前台运行以下命令"><a href="#a-在前台运行以下命令" class="headerlink" title="a.在前台运行以下命令"></a>a.在前台运行以下命令</h5><p>~#:jupyter notebook —ip=your_server_ip<br>输出如下</p><p>复制这个url到你的客户端浏览器，就可以直接访问服务器端。</p><h5 id="b-后台运行"><a href="#b-后台运行" class="headerlink" title="b.后台运行"></a>b.后台运行</h5><p>~#:nohup jupyter notebook —ip=10.4.21.214 &amp;</p><h4 id="2-创建配置文件"><a href="#2-创建配置文件" class="headerlink" title="(2).创建配置文件"></a>(2).创建配置文件</h4><h5 id="a-服务器端设置密码"><a href="#a-服务器端设置密码" class="headerlink" title="a.服务器端设置密码"></a>a.服务器端设置密码</h5><p>这里是使用notebook的passwd()函数生成自己设置密码的sha1哈希值。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> notebook.auth <span class="keyword">import</span> passwd</span><br><span class="line">passwd()</span><br></pre></td></tr></table></figure></p><p>输入两边自己设置的密码，然后将哈希值复制到下面的配置文件中即可。</p><h5 id="b-服务端设置配置文件"><a href="#b-服务端设置配置文件" class="headerlink" title="b.服务端设置配置文件"></a>b.服务端设置配置文件</h5><p>~#:jupyter notebook —generate-config<br>~#:vim ~/.jupyter/jupyter_notebook_config.py<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">c.NotebookApp.ip=&apos;localhost&apos;</span><br><span class="line">c.NotebookApp.password=u&apos;sha1:...&apos;</span><br><span class="line">c.NotebookApp.open_browser=False</span><br><span class="line">c.NotebookApp.port=8888(your_port)</span><br></pre></td></tr></table></figure></p><h5 id="c-服务器端启动"><a href="#c-服务器端启动" class="headerlink" title="c.服务器端启动"></a>c.服务器端启动</h5><p>~#:jupyter notebook</p><h5 id="d-客户端访问"><a href="#d-客户端访问" class="headerlink" title="d.客户端访问"></a>d.客户端访问</h5><p><a href="http://your_server_ip:port" target="_blank" rel="noopener">http://your_server_ip:port</a><br>输入密码即可</p><h2 id="二、使用"><a href="#二、使用" class="headerlink" title="二、使用"></a>二、使用</h2><h3 id="1-创建新的文档"><a href="#1-创建新的文档" class="headerlink" title="1.创建新的文档"></a>1.创建新的文档</h3><h2 id="三、快捷键"><a href="#三、快捷键" class="headerlink" title="三、快捷键"></a>三、快捷键</h2><p>Jupyter Notebook 有两种键盘输入模式。编辑模式，允许你往单元中键入代码或文本；这时的单元框线是绿色的。命令模式，键盘输入运行程序命令；这时的单元框线是灰色。</p><h3 id="1-命令模式-按键-Esc-开启"><a href="#1-命令模式-按键-Esc-开启" class="headerlink" title="1.命令模式 (按键 Esc 开启)"></a>1.命令模式 (按键 Esc 开启)</h3><p>Enter : 转入编辑模式<br>Shift-Enter : 运行本单元，选中下个单元<br>Ctrl-Enter : 运行本单元<br>Alt-Enter : 运行本单元，在其下插入新单元<br>Y : 单元转入代码状态<br>M :单元转入markdown状态<br>R : 单元转入raw状态<br>1 : 设定 1 级标题<br>2 : 设定 2 级标题<br>3 : 设定 3 级标题<br>4 : 设定 4 级标题<br>5 : 设定 5 级标题<br>6 : 设定 6 级标题<br>Up : 选中上方单元<br>K : 选中上方单元<br>Down : 选中下方单元<br>J : 选中下方单元<br>Shift-K : 扩大选中上方单元<br>Shift-J : 扩大选中下方单元<br>A : 在上方插入新单元<br>B : 在下方插入新单元<br>X : 剪切选中的单元<br>C : 复制选中的单元<br>Shift-V : 粘贴到上方单元<br>V : 粘贴到下方单元<br>Z : 恢复删除的最后一个单元<br>dd : 删除选中的单元<br>Shift-M : 合并选中的单元<br>Ctrl-S : 文件存盘<br>S : 文件存盘<br>L : 转换行号<br>O : 转换输出<br>Shift-O : 转换输出滚动<br>Esc : 关闭页面<br>Q : 关闭页面<br>H : 显示快捷键帮助<br>I,I : 中断Notebook内核<br>0,0 : 重启Notebook内核<br>Shift : 忽略<br>Shift-Space : 向上滚动<br>Space : 向下滚动</p><h3 id="2-编辑模式-Enter-键启动"><a href="#2-编辑模式-Enter-键启动" class="headerlink" title="2.编辑模式 ( Enter 键启动)"></a>2.编辑模式 ( Enter 键启动)</h3><p>Tab : 代码补全或缩进<br>Shift-Tab : 提示<br>Ctrl-] : 缩进<br>Ctrl-[ : 解除缩进<br>Ctrl-A : 全选<br>Ctrl-Z : 复原<br>Ctrl-Shift-Z : 再做<br>Ctrl-Y : 再做<br>Ctrl-Home : 跳到单元开头<br>Ctrl-Up : 跳到单元开头<br>Ctrl-End : 跳到单元末尾<br>Ctrl-Down : 跳到单元末尾<br>Ctrl-Left : 跳到左边一个字首<br>Ctrl-Right : 跳到右边一个字首<br>Ctrl-Backspace : 删除前面一个字<br>Ctrl-Delete : 删除后面一个字<br>Esc : 进入命令模式<br>Ctrl-M : 进入命令模式<br>Shift-Enter : 运行本单元，选中下一单元<br>Ctrl-Enter : 运行本单元<br>Alt-Enter : 运行本单元，在下面插入一单元<br>Ctrl-Shift— : 分割单元<br>Ctrl-Shift-Subtract : 分割单元<br>Ctrl-S : 文件存盘<br>Shift : 忽略<br>Up : 光标上移或转入上一单元<br>Down :光标下移或转入下一单元</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;一、安装和运行&quot;&gt;&lt;a href=&quot;#一、安装和运行&quot; class=&quot;headerlink&quot; title=&quot;一、安装和运行&quot;&gt;&lt;/a&gt;一、安装和运行&lt;/h2&gt;&lt;h3 id=&quot;1-安装&quot;&gt;&lt;a href=&quot;#1-安装&quot; class=&quot;headerlink&quot; titl
      
    
    </summary>
    
      <category term="工具" scheme="http://mxxhcm.github.io/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="python" scheme="http://mxxhcm.github.io/tags/python/"/>
    
      <category term="jupyter" scheme="http://mxxhcm.github.io/tags/jupyter/"/>
    
  </entry>
  
  <entry>
    <title>hdf5笔记</title>
    <link href="http://mxxhcm.github.io/2019/03/18/hdf5%E7%AC%94%E8%AE%B0/"/>
    <id>http://mxxhcm.github.io/2019/03/18/hdf5笔记/</id>
    <published>2019-03-18T07:12:03.000Z</published>
    <updated>2019-05-06T16:22:27.708Z</updated>
    
    <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><h3 id="创建和打开hdf5文件"><a href="#创建和打开hdf5文件" class="headerlink" title="创建和打开hdf5文件"></a>创建和打开hdf5文件</h3><p>f = hdf5.File(“pathname”,”w”)<br>w     create file, truncate if exist<br>w- or x  create file,fail if exists<br>r         readonly, file must be exist<br>r+        read/write,file must be exist<br>a        read/write if exists,create othrewise (default)</p><h3 id="删除一个dataset或者group"><a href="#删除一个dataset或者group" class="headerlink" title="删除一个dataset或者group"></a>删除一个dataset或者group</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">del</span> group[<span class="string">"dataset_name/group_name"</span>]</span><br></pre></td></tr></table></figure><h2 id="dataset"><a href="#dataset" class="headerlink" title="dataset"></a>dataset</h2><h3 id="什么是dataset"><a href="#什么是dataset" class="headerlink" title="什么是dataset"></a>什么是dataset</h3><p>datasets和numpy arrays挺像的</p><h3 id="创建一个dataset"><a href="#创建一个dataset" class="headerlink" title="创建一个dataset"></a>创建一个dataset</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">f = hdf5.File(<span class="string">"pathname"</span>,<span class="string">"w"</span>)</span><br><span class="line">f.create_dataset(<span class="string">"dataset_name"</span>, (<span class="number">10</span>,), dtype=<span class="string">'i'</span>)</span><br><span class="line">f.create_dataset(<span class="string">"dataset_name"</span>, (<span class="number">10</span>,), dtype=<span class="string">'c'</span>)</span><br></pre></td></tr></table></figure><p>第一个参数是dataset的名字, 第二个参数是dataset的shape, dtype参数是dataset中元素的类型。</p><h3 id="如何访问一个dataset"><a href="#如何访问一个dataset" class="headerlink" title="如何访问一个dataset"></a>如何访问一个dataset</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dataset = f[<span class="string">"dataset_name"</span>]                           <span class="comment"># acess like a python dict</span></span><br><span class="line">dataset = f.create_dateset(<span class="string">"dataset_name"</span>)  <span class="comment"># or create a new dataset</span></span><br></pre></td></tr></table></figure><h3 id="dataset的属性"><a href="#dataset的属性" class="headerlink" title="dataset的属性"></a>dataset的属性</h3><p>dataset.name        #输出dataset的名字<br>dataset.tdype        #输出dataset中elements的type<br>dataset.shape        #输出dataset的shape<br>dataset.value<br>dataset doesn’t hava attrs like keys,values,items,etc..</p><h3 id="给hdf5-dataset复制numpy-array"><a href="#给hdf5-dataset复制numpy-array" class="headerlink" title="给hdf5 dataset复制numpy array"></a>给hdf5 dataset复制numpy array</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">array = np.zero((<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">h[<span class="string">'array'</span>] = array        <span class="comment"># in hdf5 file, you need't to explicit declare the shape of array, just assign it an object of numpy array</span></span><br></pre></td></tr></table></figure><h2 id="group"><a href="#group" class="headerlink" title="group"></a>group</h2><h3 id="什么是group"><a href="#什么是group" class="headerlink" title="什么是group"></a>什么是group</h3><p>group和字典挺像的</p><h3 id="创建一个group"><a href="#创建一个group" class="headerlink" title="创建一个group"></a>创建一个group</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">group = f.create_group(<span class="string">"group_name"</span>)    <span class="comment">#在f下创建一个group</span></span><br><span class="line">group.create_group(<span class="string">"group_name"</span>)        <span class="comment">#在group下创建一个group</span></span><br><span class="line">group.create_dataset(<span class="string">"dataset_name"</span>)    <span class="comment">#在group下创建一个dataset</span></span><br></pre></td></tr></table></figure><h3 id="访问一个group-the-same-as-dataset"><a href="#访问一个group-the-same-as-dataset" class="headerlink" title="访问一个group(the same as dataset)"></a>访问一个group(the same as dataset)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">group = f[<span class="string">"group_name"</span>]                           <span class="comment"># acess like a python dict</span></span><br><span class="line">group = f.create_dateset(<span class="string">"group_name"</span>)  <span class="comment"># or create a new group</span></span><br></pre></td></tr></table></figure><h3 id="group的属性和方法"><a href="#group的属性和方法" class="headerlink" title="group的属性和方法"></a>group的属性和方法</h3><p>group.name        #输出group的名字<br>以下内容分为python2和python3版本<br><strong>python 2 版本</strong><br>group.values()    #输出group的value<br>group.keys()        #输出gorup的keys<br>group.items()    #输出group中所有的item，包含group和dataste<br><strong>python 3 版本</strong><br>list(group.keys())<br>list(group.values())<br>list(group.items())</p><h2 id="属性"><a href="#属性" class="headerlink" title="属性"></a>属性</h2><h3 id="设置dataset属性"><a href="#设置dataset属性" class="headerlink" title="设置dataset属性"></a>设置dataset属性</h3><p>dataset.attrs[“attr_name”]=”attr_value”    #设置attr<br>print(dataset.attrs[“attr_name”])                #访问attr</p><h3 id="设置group属性"><a href="#设置group属性" class="headerlink" title="设置group属性"></a>设置group属性</h3><p>group.attrs[“attr_name”]=”attr_value”    #设置attr<br>print(group.attrs[“attr_name”])                #访问attr</p><h2 id="numpy-and-hdf5"><a href="#numpy-and-hdf5" class="headerlink" title="numpy and hdf5"></a>numpy and hdf5</h2><p>f = h5py.File(pathname,”r”)<br>data = f[‘data’]</p><h2 id="type-是dataset"><a href="#type-是dataset" class="headerlink" title="type 是dataset"></a>type 是dataset</h2><p>data = f[‘data’][:]</p><h2 id="type是numpy-ndarray"><a href="#type是numpy-ndarray" class="headerlink" title="type是numpy ndarray"></a>type是numpy ndarray</h2><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>1.<a href="http://docs.h5py.org/en/latest/index.html" target="_blank" rel="noopener">http://docs.h5py.org/en/latest/index.html</a><br>2.<a href="https://stackoverflow.com/questions/31037088/discovering-keys-using-h5py-in-python3" target="_blank" rel="noopener">https://stackoverflow.com/questions/31037088/discovering-keys-using-h5py-in-python3</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h2&gt;&lt;h3 id=&quot;创建和打开hdf5文件&quot;&gt;&lt;a href=&quot;#创建和打开hdf5文件&quot; class=&quot;headerlink&quot; title=&quot;创建和
      
    
    </summary>
    
      <category term="python" scheme="http://mxxhcm.github.io/categories/python/"/>
    
    
      <category term="python" scheme="http://mxxhcm.github.io/tags/python/"/>
    
      <category term="hdf5" scheme="http://mxxhcm.github.io/tags/hdf5/"/>
    
  </entry>
  
  <entry>
    <title>MongoDB笔记</title>
    <link href="http://mxxhcm.github.io/2019/03/18/MongoDB%E7%AC%94%E8%AE%B0/"/>
    <id>http://mxxhcm.github.io/2019/03/18/MongoDB笔记/</id>
    <published>2019-03-18T07:06:56.000Z</published>
    <updated>2019-05-06T16:22:27.704Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、数据库的安装"><a href="#一、数据库的安装" class="headerlink" title="一、数据库的安装"></a>一、数据库的安装</h2><p>自行下载安装包并安装</p><h2 id="二、数据库的运行和连接-以及以下简单的使用"><a href="#二、数据库的运行和连接-以及以下简单的使用" class="headerlink" title="二、数据库的运行和连接,以及以下简单的使用"></a>二、数据库的运行和连接,以及以下简单的使用</h2><h3 id="1-windows命令行下连接"><a href="#1-windows命令行下连接" class="headerlink" title="1.windows命令行下连接"></a>1.windows命令行下连接</h3><h4 id="（1）设置数据库存放目录"><a href="#（1）设置数据库存放目录" class="headerlink" title="（1）设置数据库存放目录"></a>（1）设置数据库存放目录</h4><p>~#:md D:/data/db</p><h4 id="（2）运行mongodb服务"><a href="#（2）运行mongodb服务" class="headerlink" title="（2）运行mongodb服务"></a>（2）运行mongodb服务</h4><p>~#:mongod</p><h4 id="（3）连接mongodb数据库"><a href="#（3）连接mongodb数据库" class="headerlink" title="（3）连接mongodb数据库"></a>（3）连接mongodb数据库</h4><p>~#:mongo (database_name)<br>如果不输入数据库名会默认连接到mongodb自带的一个数据库test，如果指定了数据库名就会连接到该数据库</p><h3 id="2-使用python代码中连接到数据库"><a href="#2-使用python代码中连接到数据库" class="headerlink" title="2.使用python代码中连接到数据库"></a>2.使用python代码中连接到数据库</h3><h4 id="（1）导入python-pacakge"><a href="#（1）导入python-pacakge" class="headerlink" title="（1）导入python pacakge"></a>（1）导入python pacakge</h4><p>使用pip安装即可<br>import pymongo</p><h4 id="（2）连接到mongodb"><a href="#（2）连接到mongodb" class="headerlink" title="（2）连接到mongodb"></a>（2）连接到mongodb</h4><p>connection = MongoClient(‘localhost’, 27017)</p><h4 id="（3）连接到某个数据库"><a href="#（3）连接到某个数据库" class="headerlink" title="（3）连接到某个数据库"></a>（3）连接到某个数据库</h4><p>db = connection.test  #连接到test数据库<br>db现在指向的是test这个数据库</p><h4 id="（4）指向某个collection"><a href="#（4）指向某个collection" class="headerlink" title="（4）指向某个collection"></a>（4）指向某个collection</h4><p>collection = db.collection_one</p><h4 id="（5）查看collection中的内容"><a href="#（5）查看collection中的内容" class="headerlink" title="（5）查看collection中的内容"></a>（5）查看collection中的内容</h4><p>items = collection.find()<br>print(items[‘key’])</p><h3 id="3-一些简单的操作"><a href="#3-一些简单的操作" class="headerlink" title="3.一些简单的操作"></a>3.一些简单的操作</h3><h4 id="（1）切换数据库"><a href="#（1）切换数据库" class="headerlink" title="（1）切换数据库"></a>（1）切换数据库</h4><p>~#:use database_name</p><h4 id="（2）查看所有的数据库"><a href="#（2）查看所有的数据库" class="headerlink" title="（2）查看所有的数据库"></a>（2）查看所有的数据库</h4><p>~#:show databases;</p><h4 id="（3）查看所有的collection"><a href="#（3）查看所有的collection" class="headerlink" title="（3）查看所有的collection"></a>（3）查看所有的collection</h4><p>~#:show collections;</p><h2 id="三-CRUD操作"><a href="#三-CRUD操作" class="headerlink" title="三.CRUD操作"></a>三.CRUD操作</h2><h3 id="1-id的构成-12-bytes-hex"><a href="#1-id的构成-12-bytes-hex" class="headerlink" title="1.id的构成 12 bytes hex"></a>1.id的构成 12 bytes hex</h3><p>4+3+2+3<br>timestamp + mac address + pid + counter<br>timestamp是unix timestamp，mac address 是 mongd运行的网卡mac address，pid是process id，</p><h3 id="2-create-document"><a href="#2-create-document" class="headerlink" title="2. create document"></a>2. create document</h3><h4 id="（1）create-one-document-insertOne"><a href="#（1）create-one-document-insertOne" class="headerlink" title="（1）create one document(insertOne)"></a>（1）create one document(insertOne)</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">db.collection_one.insertOne(&#123;&quot;key_one&quot;:&quot;value&quot;,&quot;key_two&quot;:&quot;value&quot;&#125;)</span><br></pre></td></tr></table></figure><h4 id="（2）create-many-documents（有order-insertMany）"><a href="#（2）create-many-documents（有order-insertMany）" class="headerlink" title="（2）create many documents（有order,insertMany）"></a>（2）create many documents（有order,insertMany）</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">db.collection_one.insertMany(</span><br><span class="line">[</span><br><span class="line">&#123;&quot;key_one&quot;:&quot;value&quot;,&quot;key_two&quot;:&quot;value&quot;&#125;,</span><br><span class="line">&#123;&quot;key_one&quot;:&quot;value&quot;,&quot;key_two&quot;:&quot;value&quot;&#125;,</span><br><span class="line">&#123;&quot;key_one&quot;:&quot;value&quot;,&quot;key_two&quot;:&quot;value&quot;&#125;</span><br><span class="line">])</span><br></pre></td></tr></table></figure><h4 id="（3）create-many-documents（无order-insertMany）"><a href="#（3）create-many-documents（无order-insertMany）" class="headerlink" title="（3）create many documents（无order,insertMany）"></a>（3）create many documents（无order,insertMany）</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">db.collection_one.insertMany(</span><br><span class="line">db.collection_one.insertMany(</span><br><span class="line">[</span><br><span class="line">&#123;&quot;key_one&quot;:&quot;value&quot;,&quot;key_two&quot;:&quot;value&quot;&#125;,</span><br><span class="line">&#123;&quot;key_one&quot;:&quot;value&quot;,&quot;key_two&quot;:&quot;value&quot;&#125;,</span><br><span class="line">&#123;&quot;key_one&quot;:&quot;value&quot;,&quot;key_two&quot;:&quot;value&quot;&#125;</span><br><span class="line">] , &#123;&quot;ordered&quot;:false&#125;)</span><br></pre></td></tr></table></figure><h4 id="（4）upsert"><a href="#（4）upsert" class="headerlink" title="（4）upsert"></a>（4）upsert</h4><p>第一个参数是一个filter选择合适的 document，第二个参数是一个更新操作for the documents were selected，第三个参数是 that if there is no matching result,if the value of upsert is true,then insert a new document,else do nothing.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">db.collection_one.insertMany(</span><br><span class="line">db.movieDetails.updateOne(&#123; name:&quot;mxxhcm&quot;&#125;, &#123; \$set:&#123;lover:&quot;mahuihui&quot;&#125; &#125; , &#123;upsert : true&#125;)</span><br></pre></td></tr></table></figure></p><h4 id="（5）有无order的区别"><a href="#（5）有无order的区别" class="headerlink" title="（5）有无order的区别"></a>（5）有无order的区别</h4><p>有order的话遇到inset错误就会停下来，没有order的话在插入document的时候，遇到错误会跳过该条语句执行下一条语句。</p><h3 id="3-read-documents-query-documents"><a href="#3-read-documents-query-documents" class="headerlink" title="3.read documents(query documents)"></a>3.read documents(query documents)</h3><p>link:<br><a href="https://docs.mongodb.com/manual/reference/operator/query/" target="_blank" rel="noopener">https://docs.mongodb.com/manual/reference/operator/query/</a></p><h4 id="（1）查找document"><a href="#（1）查找document" class="headerlink" title="（1）查找document"></a>（1）查找document</h4><p>查找collection_one这个collection中所有的document<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">db.collection_one.find()</span><br></pre></td></tr></table></figure></p><p>查找collection_one这个collection中满足{}中条件的collection，{}中的条件需要满足anded<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">db.collection_one.find(&#123;&#125;)</span><br></pre></td></tr></table></figure></p><p>pretty()表示以规范的格式展现出来查询结果<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">db.collection_one.find().pretty()</span><br></pre></td></tr></table></figure></p><p>findOne表示只展示出第一条结果<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">db.collection_one.findOne()</span><br></pre></td></tr></table></figure></p><p>满足{}中条件的第一条结果<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">db.collection_one.findOne(&#123;&#125;)</span><br></pre></td></tr></table></figure></p><h4 id="（2）对document进行计数"><a href="#（2）对document进行计数" class="headerlink" title="（2）对document进行计数"></a>（2）对document进行计数</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">db.collection_one.count()</span><br></pre></td></tr></table></figure><h4 id="（3）设置查找的条件-equality-match"><a href="#（3）设置查找的条件-equality-match" class="headerlink" title="（3）设置查找的条件(equality match)"></a>（3）设置查找的条件(equality match)</h4><h5 id="a-scalar-equality-match"><a href="#a-scalar-equality-match" class="headerlink" title="a.scalar equality match"></a>a.scalar equality match</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">db.collection_one.find(&#123;&quot;key&quot;:&quot;value&quot;,&quot;key&quot;,&quot;value&quot;&#125;)</span><br></pre></td></tr></table></figure><h5 id="b-nested-documents-equality-match"><a href="#b-nested-documents-equality-match" class="headerlink" title="b.nested documents equality match"></a>b.nested documents equality match</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">db.collection_one.find(&#123;&quot;key.key2.key3&quot;:&quot;value&quot;&#125;)</span><br></pre></td></tr></table></figure><h5 id="c-equality-matches-on-arrays"><a href="#c-equality-matches-on-arrays" class="headerlink" title="c.equality matches on arrays"></a>c.equality matches on arrays</h5><h6 id="entire-array-value-match"><a href="#entire-array-value-match" class="headerlink" title="entire array value match"></a>entire array value match</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">db.collection_one.find(&#123;key:[value1,value2]&#125;)</span><br></pre></td></tr></table></figure><h6 id="any-array-element-fileds-match-a-specfic-value"><a href="#any-array-element-fileds-match-a-specfic-value" class="headerlink" title="any array element fileds match a specfic value"></a>any array element fileds match a specfic value</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">db.collection_one.find(&#123;key:&quot;value2&quot;&#125;)</span><br></pre></td></tr></table></figure><h6 id="a-specfiec-element-fields-match-a-specfic-value"><a href="#a-specfiec-element-fields-match-a-specfic-value" class="headerlink" title="a specfiec element fields match a specfic value"></a>a specfiec element fields match a specfic value</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">db.collection_one.find(&#123;key.0:&quot;value1&quot;&#125;)</span><br></pre></td></tr></table></figure><h4 id="（4）cursor"><a href="#（4）cursor" class="headerlink" title="（4）cursor"></a>（4）cursor</h4><h4 id="（5）projection"><a href="#（5）projection" class="headerlink" title="（5）projection"></a>（5）projection</h4><p>by default,mongodb return all fields in all matching documents for query.<br>Projection are supplied as the second argument<br>db.collection_one.find({“key1”:”value”,”key2”,”value”},{“key1”:1,”key2”:1,”key3”:0,”key4”:0}).pretty()</p><h4 id="（6）comparison-operation"><a href="#（6）comparison-operation" class="headerlink" title="（6）comparison operation"></a>（6）comparison operation</h4><p>$eq<br>$gt<br>$gte<br>$lt<br>$lte<br>$ne<br>$in<br>$nin</p><h5 id="a-在某个范围内"><a href="#a-在某个范围内" class="headerlink" title="a.在某个范围内"></a>a.在某个范围内</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">db.movieDetails.find(&#123; runtime : &#123; \$gt: 70,  \$lte:100 &#125; &#125;).pretty()</span><br></pre></td></tr></table></figure><h5 id="b-不等于-ne"><a href="#b-不等于-ne" class="headerlink" title="b.不等于($ne)"></a>b.不等于($ne)</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">db.movieDetails.find(&#123; rated : &#123; \$ne:&quot;unrated&quot; &#125; &#125;).pretty()</span><br></pre></td></tr></table></figure><h5 id="c-在-in"><a href="#c-在-in" class="headerlink" title="c.在($in)"></a>c.在($in)</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">db.movieDetails.find(&#123;rated : &#123; \$in : [&quot;G&quot;,&quot;PG&quot;,&quot;PG-13&quot;] &#125;  &#125;).pretty()</span><br></pre></td></tr></table></figure><h4 id="（7）element-operator"><a href="#（7）element-operator" class="headerlink" title="（7）element operator"></a>（7）element operator</h4><h5 id="a-存在某个filed-exists"><a href="#a-存在某个filed-exists" class="headerlink" title="a.存在某个filed($exists)"></a>a.存在某个filed($exists)</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">db.movieDetail.find( &#123; filed_name : &#123; \$exists: true|false &#125; &#125; ).pretty()</span><br></pre></td></tr></table></figure><h5 id="b-某个字段的类型-type"><a href="#b-某个字段的类型-type" class="headerlink" title="b.某个字段的类型($type)"></a>b.某个字段的类型($type)</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">db.movieDetail.find( &#123; filed_name : &#123; \$type :&quot;string&quot;&#125; &#125;).pretty()</span><br></pre></td></tr></table></figure><h4 id="（8）logical-operator"><a href="#（8）logical-operator" class="headerlink" title="（8）logical operator"></a>（8）logical operator</h4><p>$or<br>$and<br>$not<br>$nor </p><h5 id="a-逻辑或-or"><a href="#a-逻辑或-or" class="headerlink" title="a.逻辑或($or)"></a>a.逻辑或($or)</h5><p>$or需要数组作为参数<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">db.movieDetails.find( &#123; \$or: [ &#123; field_one : &#123;\$type : &quot;string&quot;&#125; &#125; , &#123;field_two : &#123;\$exist: &quot;name&quot; &#125; &#125; ] &#125; ).pretty()</span><br></pre></td></tr></table></figure></p><h5 id="b-逻辑与-and"><a href="#b-逻辑与-and" class="headerlink" title="b.逻辑与($and)"></a>b.逻辑与($and)</h5><p>$and操作支持我们在同一个filed指定多个约束条件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">db.movieDetails.find(&#123; \$and: [ &#123;field_one: &#123;\$ne :null&#125; &#125; , &#123; field_one: &#123;\$gt:60, \$lte: 100&#125; &#125; ] &#125;).pretty()</span><br></pre></td></tr></table></figure></p><h4 id="（9）regex-operator"><a href="#（9）regex-operator" class="headerlink" title="（9）regex operator"></a>（9）regex operator</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">db.movieDetails.find(&#123; &quot;awards.text&quot;: &#123; \$regex: /^Won\s/&#125;  &#125;).pretty()</span><br></pre></td></tr></table></figure><h4 id="（10）array-operator"><a href="#（10）array-operator" class="headerlink" title="（10）array operator"></a>（10）array operator</h4><p>$all<br>$size<br>$elementMatch</p><h5 id="a-all"><a href="#a-all" class="headerlink" title="a.all"></a>a.all</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">db.movieDetails.find(&#123;genres : &#123;\$all :[&quot;comedy&quot;,&quot;crime&quot;,&quot;drama&quot;]&#125; &#125;).pretty()</span><br><span class="line">db.movieDetails.find(&#123;genres :  [&quot;comedy&quot;,&quot;crime&quot;,&quot;drama&quot;]  &#125;).pretty()</span><br></pre></td></tr></table></figure><p>上面两个式子是有区别的，第一个式子会匹配genres中包含”comedy”,”crime”,”drama”的document<br>而第二个只会匹配genres为”comedy”,”crime”,”drama”的document。</p><h5 id="b-size"><a href="#b-size" class="headerlink" title="b.size"></a>b.size</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">db.movieDetails.find(&#123;country : &#123;\$size : 3&#125; &#125;).pretty()</span><br></pre></td></tr></table></figure><h5 id="c-elementMatch"><a href="#c-elementMatch" class="headerlink" title="c.elementMatch"></a>c.elementMatch</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">db.movieDetails.find(&#123; boxOffice: &#123; country: &quot;UK&quot;, revenue: &#123; \$gt: 15 &#125; &#125; &#125;)</span><br></pre></td></tr></table></figure><h3 id="9-update-documents"><a href="#9-update-documents" class="headerlink" title="9.update documents"></a>9.update documents</h3><p>link:<br><a href="https://docs.mongodb.com/manual/reference/operator/update/" target="_blank" rel="noopener">https://docs.mongodb.com/manual/reference/operator/update/</a></p><h4 id="（0）some-update-operator"><a href="#（0）some-update-operator" class="headerlink" title="（0）some update operator"></a>（0）some update operator</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">db.movieDetails.updateOne( &#123; name : &quot;mxxhcm&quot; &#125; , &#123; \$inc : &#123; age: 1&#125; &#125;)</span><br></pre></td></tr></table></figure><h4 id="（1）updateOne"><a href="#（1）updateOne" class="headerlink" title="（1）updateOne"></a>（1）updateOne</h4><h5 id="a-update-for-scalar-fields"><a href="#a-update-for-scalar-fields" class="headerlink" title="a.update for scalar fields"></a>a.update for scalar fields</h5><p>$set<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">db.movieDetails.updateOne( &#123; name : &quot;mxxhcm&quot; &#125; , &#123; \$set : &#123; age: 19&#125; &#125;)</span><br></pre></td></tr></table></figure></p><p>$unset<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">db.movieDetails.updateOne( &#123; name : &quot;mxxhcm&quot; &#125; , &#123; \$unset : &#123; age: 19&#125; &#125;)</span><br></pre></td></tr></table></figure></p><p>$inc<br>age后是在原来的age上加的数值<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">db.movieDetails.updateOne( &#123; name : &quot;mxxhcm&quot; &#125; , &#123; \$set : &#123; age: 19&#125; &#125;)</span><br></pre></td></tr></table></figure></p><p>updateOne has two arguments, the first one is a selector,the second argument is how we want to update the document.</p><h5 id="b-update-for-array-fields"><a href="#b-update-for-array-fields" class="headerlink" title="b.update for array fields"></a>b.update for array fields</h5><p>$push<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">db.movieDetails.updateOne(&#123;name:&quot;mxxhcm&quot;&#125; , &#123;\$push: &#123; reviews: &#123; key1:value,key2:value...&#125;  &#125;  &#125; )</span><br><span class="line">db.movieDetails.updateOne(&#123;name:&quot;mxxhcm&quot;&#125; , &#123;\$push: &#123; reviews:</span><br><span class="line">                                                                                                &#123; \$each: [&#123; key1:value,key2:value...&#125; ,                                                                                                                        &#123;key1:value,key2:value...&#125; ]  &#125;  </span><br><span class="line">                                                                                              &#125;   &#125; )</span><br><span class="line">db.movieDetails.updateOne(&#123;name:&quot;mxxhcm&quot;&#125; , &#123;\$push: &#123; reviews:</span><br><span class="line">                                                                                                &#123; \$each: [&#123; key1:value,key2:value...&#125; ,                                                                                                                        &#123;key1:value,key2:value...&#125; ] ,                                                                                                             \$slice:3 &#125;  </span><br><span class="line">                                                                                              &#125;   &#125; )</span><br><span class="line">db.movieDetails.updateOne(&#123;name:&quot;mxxhcm&quot;&#125; , &#123;\$push: &#123; reviews:</span><br><span class="line">                                                                                                &#123; \$each: [&#123; key1:value,key2:value...&#125; ,                                                                                                                        &#123;key1:value,key2:value...&#125; ] ,                                                                                                             \$position:0,  </span><br><span class="line">                                                                                                  \$slice:3 &#125;  </span><br><span class="line">                                                                                              &#125;   &#125; )</span><br></pre></td></tr></table></figure></p><h4 id="（2）updateMany"><a href="#（2）updateMany" class="headerlink" title="（2）updateMany"></a>（2）updateMany</h4><p>the same as updateOne</p><h4 id="（3）replaceOne"><a href="#（3）replaceOne" class="headerlink" title="（3）replaceOne"></a>（3）replaceOne</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">db.movieDetail.replcaeOne(&#123;&#125;,&#123;&#125;)</span><br></pre></td></tr></table></figure><p>the first argument is a filter,the second argument is the thing that replace what the filter choose,it can be a document,or a variable point to a document.</p><h3 id="10-using-mongdb-by-pymongo"><a href="#10-using-mongdb-by-pymongo" class="headerlink" title="10. using mongdb by pymongo"></a>10. using mongdb by pymongo</h3><p>见代码</p><h4 id="（1）sort，skip，limit"><a href="#（1）sort，skip，limit" class="headerlink" title="（1）sort，skip，limit"></a>（1）sort，skip，limit</h4><p>sort &gt; skip &gt; limit<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cursor.sort(&apos;student_id&apos;,pymongo.ASCENDING).skip(4).limit(3)</span><br><span class="line">in python file:</span><br><span class="line">cursor.sort(  [ (&apos;student_id&apos;,pymongo.ASCENDING) , (&apos;score&apos;,pymongo.DESCENDING) ] ).skip(4).limit(3)</span><br><span class="line">in mongo shell:</span><br><span class="line">cursor.sort(  [ &#123;&apos;student_id&apos;:1&#125;, &#123;&apos;score&apos;,-1)&#125; ] ).skip(4).limit(3)</span><br></pre></td></tr></table></figure></p><h4 id="（2）find-find-one-cursors"><a href="#（2）find-find-one-cursors" class="headerlink" title="（2）find,find_one,cursors"></a>（2）find,find_one,cursors</h4><h4 id="（3）project"><a href="#（3）project" class="headerlink" title="（3）project"></a>（3）project</h4><h4 id="（4）regex"><a href="#（4）regex" class="headerlink" title="（4）regex"></a>（4）regex</h4><h4 id="（5）insert"><a href="#（5）insert" class="headerlink" title="（5）insert"></a>（5）insert</h4><h4 id="（6）update"><a href="#（6）update" class="headerlink" title="（6）update"></a>（6）update</h4><h4 id="（7）"><a href="#（7）" class="headerlink" title="（7）"></a>（7）</h4><p>There is a intervening between find and update,so maybe you find and update is not the same one.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;一、数据库的安装&quot;&gt;&lt;a href=&quot;#一、数据库的安装&quot; class=&quot;headerlink&quot; title=&quot;一、数据库的安装&quot;&gt;&lt;/a&gt;一、数据库的安装&lt;/h2&gt;&lt;p&gt;自行下载安装包并安装&lt;/p&gt;
&lt;h2 id=&quot;二、数据库的运行和连接-以及以下简单的使用&quot;&gt;
      
    
    </summary>
    
      <category term="数据库" scheme="http://mxxhcm.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
      <category term="数据库" scheme="http://mxxhcm.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="MongoDB" scheme="http://mxxhcm.github.io/tags/MongoDB/"/>
    
      <category term="非关系型数据库" scheme="http://mxxhcm.github.io/tags/%E9%9D%9E%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>神经网络-激活函数</title>
    <link href="http://mxxhcm.github.io/2019/03/14/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/"/>
    <id>http://mxxhcm.github.io/2019/03/14/神经网络-激活函数/</id>
    <published>2019-03-14T03:45:46.000Z</published>
    <updated>2019-05-06T16:22:27.712Z</updated>
    
    <content type="html"><![CDATA[<h2 id="激活函数的一些问题"><a href="#激活函数的一些问题" class="headerlink" title="激活函数的一些问题"></a>激活函数的一些问题</h2><h3 id="为什么要使用non-linear激活函数不使用linear激活函数？"><a href="#为什么要使用non-linear激活函数不使用linear激活函数？" class="headerlink" title="为什么要使用non-linear激活函数不使用linear激活函数？"></a>为什么要使用non-linear激活函数不使用linear激活函数？</h3><p><img src="/2019/03/14/神经网络-激活函数/fnn.png" alt="fnn"><br>给定一个如图所示的前馈神经网络。有一个输入层，一个隐藏层，一个输出层。输入是$2$维的，有$4$个隐藏单元，输出是$2$维的。<br>则：$ \hat{f}(x) = \sigma(w_1x+b_1)w_2 + b_2$<br>这里$\sigma$是一个线性的激活函数，不妨设$\sigma(x) = x$。<br>那么就有：<br>\begin{align*}<br>\hat{f}(x) &amp;= \sigma(w_1x+b_1)w_2 + b_2\<br>&amp;= (w_1x+b_1)w_2 + b_2\<br>&amp;= w_1w_2x + w_2b1 + b_2\<br>&amp;= (w_1w_2) x + (w_2b1 + b_2)\<br>&amp;= w’ x + b’<br>\end{align*}<br>因此，当使用线性激活函数的时候，我们可以把一个多层感知机模型化简成一个线性模型。当使用线性激活函数时，增加网络的深度没有用，使用线性激活函数的十层感知机和一层感知机没有区别，并不能增加网络的表达能力。因为任意两个仿射函数的组合还是仿射函数。</p><h3 id="为什么ReLU激活函数是non-linear的？"><a href="#为什么ReLU激活函数是non-linear的？" class="headerlink" title="为什么ReLU激活函数是non-linear的？"></a>为什么ReLU激活函数是non-linear的？</h3><p>ReLU的数学表达形式如下：</p><script type="math/tex; mode=display">g(x) = max(0, x)</script><p>首先考虑一下什么是linear function,什么是non-linear function。在微积分上，平面内的任意一条直线是线性函数，否则就是非线性函数。<br>考虑这样一个例子，输入数据的维度为$1$，输出数据的维度也为$1$，用$g(ax+b)$表示ReLU激活函数。如果我们使用两个隐藏单元，那么$h_1(x) = g(x)+g(-x)$可以用来表示$f(x)=|x|$，而函数$|x|$是一个非线性函数，函数图像如下所示。<br><img src="/2019/03/14/神经网络-激活函数/absolute.png" alt="f(x)=|x|"><br>我们还可以用ReLU逼近二次函数$f(x) = x^2$，如使用函数$h_2(x) = g(x) + g(-x) + g(2x-2) + g(2x+2)$逼近二次函数，对应的图像如下。<br><img src="/2019/03/14/神经网络-激活函数/quadratic.png" alt="h_2(x)"><br>使用的项越多，最后近似出来的图像也就和我们要逼近的二次函数越像。<br>同理，可以使用ReLU激活函数去逼近任意非线性函数。</p><h3 id="为什么ReLU比sigmod还有tanh激活函数要好？"><a href="#为什么ReLU比sigmod还有tanh激活函数要好？" class="headerlink" title="为什么ReLU比sigmod还有tanh激活函数要好？"></a>为什么ReLU比sigmod还有tanh激活函数要好？</h3><p>ReLU收敛的更快，因为梯度更大。<br>当CNN的层数越来越深的时候，实验表明，使用ReLU的CNN要比使用sigmod或者tanh的CNN训练的更容易，更快收敛。<br>为什么会这样，目前有两种理论，见参考文献[4]。<br>第一个，$tanh(x)$有梯度消散问题(vanishing gradient)。当$x$趋向于$\pm\infty$时，$tanh(x)$的导数趋向于$0$。如下图所示。</p><blockquote><p>Vanishing gradients occur when lower layers of a DNN have gradients of nearly 0 because higher layer units are nearly saturated at -1 or 1, the asymptotes of the tanh function. Such vanishing gradients cause slow optimization convergence, and in some cases the final trained network converges to a poor local minimum.</p><p>One way ReLUs improve neural networks is by speeding up training. The gradient computation is very simple (either 0 or 1 depending on the sign of x). Also, the computational step of a ReLU is easy: any negative elements are set to 0.0 — no exponentials, no multiplication or division operations.</p></blockquote><p><img src="/2019/03/14/神经网络-激活函数/tanh.png" alt="tanh(x)"><br>ReLU是non-saturating nonlinearity的激活函数，sigmod和tanh是saturating nonlinearity激活函数，会将输出挤压到一个区间内。</p><blockquote><p>f是non-saturating 当且仅当$|lim<em>{z\rightarrow -\infty} f(z)| \rightarrow + \infty$或者$|lim</em>{z\rightarrow +\infty} f(z)| \rightarrow + \infty$</p></blockquote><p>tanh和sigmod将输入都挤压在某一个很小的区间内，比如(0,1)，输入发生很大的变化，经过激活函数以后变化很小，经过好几层之后，基本上就没有差别了。而当网络很深的时候，反向传播主要集中在后几层，而输入层附近的权值没办法好好学习。而对于ReLU来说，任意深度的神经网络，都不存在梯度消失。</p><p>第二种理论是说有一些定理能够证明，在某些假设条件下，局部最小就是全局最小。如果使用sigmod或者tanh激活函数的时候，这些假设不能成立，而使用ReLU的话，这些条件就会成立。</p><h3 id="为什么发生了梯度消失以后训练结构很差？"><a href="#为什么发生了梯度消失以后训练结构很差？" class="headerlink" title="为什么发生了梯度消失以后训练结构很差？"></a>为什么发生了梯度消失以后训练结构很差？</h3><p>我的想法是，</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>1.<a href="https://stats.stackexchange.com/a/391971" target="_blank" rel="noopener">https://stats.stackexchange.com/a/391971</a><br>2.<a href="https://stats.stackexchange.com/a/299933" target="_blank" rel="noopener">https://stats.stackexchange.com/a/299933</a><br>3.<a href="https://stats.stackexchange.com/a/141978" target="_blank" rel="noopener">https://stats.stackexchange.com/a/141978</a><br>4.<a href="https://stats.stackexchange.com/a/335972" target="_blank" rel="noopener">https://stats.stackexchange.com/a/335972</a><br>5.<a href="https://stats.stackexchange.com/a/174438" target="_blank" rel="noopener">https://stats.stackexchange.com/a/174438</a><br>6.<a href="https://stats.stackexchange.com/questions/391968/relu-vs-a-linear-activation-function" target="_blank" rel="noopener">https://stats.stackexchange.com/questions/391968/relu-vs-a-linear-activation-function</a><br>7.<a href="https://stats.stackexchange.com/questions/141960/why-are-rectified-linear-units-considered-non-linear" target="_blank" rel="noopener">https://stats.stackexchange.com/questions/141960/why-are-rectified-linear-units-considered-non-linear</a><br>8.<a href="https://stats.stackexchange.com/questions/299915/how-does-the-rectified-linear-unit-relu-activation-function-produce-non-linear" target="_blank" rel="noopener">https://stats.stackexchange.com/questions/299915/how-does-the-rectified-linear-unit-relu-activation-function-produce-non-linear</a><br>9.<a href="https://stats.stackexchange.com/questions/226923/why-do-we-use-relu-in-neural-networks-and-how-do-we-use-it/226927#226927" target="_blank" rel="noopener">https://stats.stackexchange.com/questions/226923/why-do-we-use-relu-in-neural-networks-and-how-do-we-use-it/226927#226927</a><br>10.<a href="https://www.zhihu.com/question/264163033" target="_blank" rel="noopener">https://www.zhihu.com/question/264163033</a><br>11.<a href="http://ai.stanford.edu/~amaas/papers/relu_hybrid_icml2013_final.pdf" target="_blank" rel="noopener">http://ai.stanford.edu/~amaas/papers/relu_hybrid_icml2013_final.pdf</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;激活函数的一些问题&quot;&gt;&lt;a href=&quot;#激活函数的一些问题&quot; class=&quot;headerlink&quot; title=&quot;激活函数的一些问题&quot;&gt;&lt;/a&gt;激活函数的一些问题&lt;/h2&gt;&lt;h3 id=&quot;为什么要使用non-linear激活函数不使用linear激活函数？&quot;&gt;&lt;
      
    
    </summary>
    
      <category term="机器学习" scheme="http://mxxhcm.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://mxxhcm.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="深度学习" scheme="http://mxxhcm.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="神经网络" scheme="http://mxxhcm.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="激活函数" scheme="http://mxxhcm.github.io/tags/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/"/>
    
      <category term="ReLU" scheme="http://mxxhcm.github.io/tags/ReLU/"/>
    
      <category term="tanh" scheme="http://mxxhcm.github.io/tags/tanh/"/>
    
      <category term="sigmod" scheme="http://mxxhcm.github.io/tags/sigmod/"/>
    
  </entry>
  
  <entry>
    <title>CNN</title>
    <link href="http://mxxhcm.github.io/2019/03/13/CNN/"/>
    <id>http://mxxhcm.github.io/2019/03/13/CNN/</id>
    <published>2019-03-13T07:21:27.000Z</published>
    <updated>2019-05-06T16:22:27.700Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Alexnet-2012"><a href="#Alexnet-2012" class="headerlink" title="Alexnet(2012)"></a>Alexnet(2012)</h2><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>作者训练了一个深度卷积神经网络用来将Imagenet数据集中1000个类别中的120万张图片进行分类。整个网络结构包含五个卷积层，三个全连接层，以及一个1000-way的softmax层，整个网络共有6000万参数，65000个神经元。此外，作者提出了一些方法用来提高性能和减少训练的时间，并且介绍了一些防止过拟合的技巧。最后，在测试集上，它们跑出$37.5%$的top-1 error以及$17.0%$的top-5 error。</p><h3 id="存在的问题"><a href="#存在的问题" class="headerlink" title="存在的问题"></a>存在的问题</h3><p>1.之前的数据集太小，都是数以万计的，需要更大的数据集。</p><h3 id="创新"><a href="#创新" class="headerlink" title="创新"></a>创新</h3><h4 id="ReLU非线性激活函数"><a href="#ReLU非线性激活函数" class="headerlink" title="ReLU非线性激活函数"></a>ReLU非线性激活函数</h4><h5 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h5><p>作者说实验表明ReLU可以加速训练过程。</p><h5 id="saturating-nonlinearity"><a href="#saturating-nonlinearity" class="headerlink" title="saturating nonlinearity"></a>saturating nonlinearity</h5><p>一个饱和的激活函数会将输出挤压到一个区间内。</p><blockquote><p>A saturating activation function squeezes the input.</p></blockquote><p><strong>定义</strong><br>f是non-saturating 当且仅当$|lim<em>{z\rightarrow -\infty} f(z)| \rightarrow + \infty$或者$|lim</em>{z\rightarrow +\infty} f(z)| \rightarrow + \infty$<br>f是saturating 当且仅当f不是non-saturating<br><strong>例子</strong><br>ReLU就是non-saturating nonlinearity的激活函数，因为$f(x) = max(0, x)$，如下图所示。<br><img src="/2019/03/13/CNN/relu.png" alt="relu"><br>当$x$趋于无穷时，$f(x)$也趋于无穷。<br>sigmod和tanh是saturating nonlinearity激活函数，如下图所示。<br><img src="/2019/03/13/CNN/sigmod.png" alt="sigmo"><br><img src="/2019/03/13/CNN/tanh.png" alt="tanh"></p><h4 id="多块GPU并行"><a href="#多块GPU并行" class="headerlink" title="多块GPU并行"></a>多块GPU并行</h4><p>作者使用了两块GPU一块运行，每个GPU中的参数个数是一样的，在一些特定层中，两个GPU中的参数信息可以进行通信。</p><h4 id="Overlapping-Pooling"><a href="#Overlapping-Pooling" class="headerlink" title="Overlapping Pooling"></a>Overlapping Pooling</h4><p>就是Pooling kernel的size要比stride大。比如一个$12\times 12$的图片，用$5\times 5$的pooling kernel，步长为$3$，步长要比kernel核小，即$3$比$5$小。<br>为什么这能减小过拟合？</p><ul><li>可能是减小了Pooling过程中信息的丢失。</li></ul><blockquote><p>If the pooling regions do not overlap, the pooling regions are disjointed and if that is the case, more information is lost in each pooling layer. If some overlap is allowed the pooling regions overlap with some degree and less spatial information is lost in each layer.[4]</p></blockquote><h4 id="数据增强"><a href="#数据增强" class="headerlink" title="数据增强"></a>数据增强</h4><p>防止过拟合</p><h5 id="裁剪和翻转"><a href="#裁剪和翻转" class="headerlink" title="裁剪和翻转"></a>裁剪和翻转</h5><p>输入是$256\times 256 \times 3$的图像。<br>训练：对每张图片都提取多个$224\times 224$大小的patch，这样子总共就多产生了$(256-224)\times (256-224) = 1024$个样本，然后对每个patch做一个水平翻转，就有$1024\times 2 = 2048$个样本。<br>测试：通过对每张图片裁剪五个（四个角落加中间）$224\times 224$的patches，并且对它们做翻转，也就是有$10$个patches，网络对十个patch的softmax层输出做平均作为预测结果。</p><h5 id="在图片上调整RGB通道的密度"><a href="#在图片上调整RGB通道的密度" class="headerlink" title="在图片上调整RGB通道的密度"></a>在图片上调整RGB通道的密度</h5><p>使用PCA对RGB值做主成分分析。对于每张训练图片，加上主成分，其大小正比于特征值乘上一个均值为$0$，方差为$0.1$的高斯分布产生的随机变量。对于一张图片$x,y$点处的像素值$I<em>{xy}=[I</em>{xy}^R, I<em>{xy}^G,I</em>{xy}^B]^T$，加上$[\bold{p_1},\bold{p_2},\bold{p_3}][\alpha_1\lambda_1,\alpha_2\lambda_2,\alpha_3\lambda_3]$，其中$[\bold{p_1},\bold{p_2},\bold{p_3}]$是特征向量，$\lambda_i$是特征值，$\alpha_i$就是前面说的随机变量。</p><h4 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h4><p>通过学习鲁棒的特征防止过拟合。<br>在训练的时候，每个隐藏单元的输出有$p$的概率被设置为$0$，在该次训练中，如果这个神经元的输出被设置为$0$，它就对loss函数没有贡献，反向传播也不会被更新。对于一层有$N$个神经单元的全连接层，总共有$2^N$种神经元的组合结果，这就相当于训练了一系列共享参数的模型。<br>在测试的时候，所有隐藏单元的输出都不丢弃，但是会乘上$p$的概率，相当于对一系列集成模型取平均。具体可见<a href="https://mxxhcm.github.io/2019/03/23/神经网络-dropout/">dropout</a><br>在该模型中，作者在三层全连接层的前两层输出上加了dropout。</p><h4 id="局部响应归一化-Local-Response-Normalizaiton"><a href="#局部响应归一化-Local-Response-Normalizaiton" class="headerlink" title="局部响应归一化(Local Response Normalizaiton)"></a>局部响应归一化(Local Response Normalizaiton)</h4><p>事实上，后来发现这个东西没啥用。但是这里还是给出一个公式。</p><script type="math/tex; mode=display">b^i_{x,y} = \frac{a^i_{x,y}}{(k+\alpha \sum^{min(N-1,\frac{i+n}{2})}_{j=max(0,\frac{i-n}{2})}(a^j_{x,y})^2)^{\beta}}</script><p>其中$a^i_{x,y}$是在点$(x,y)$处使用kernel $i$之后，在经过ReLU激活函数。$k,n,\alpha,\beta$是超参数。</p><blockquote><p>It seems that these kinds of layers have a minimal impact and are not used any more. Basically, their role have been outplayed by other regularization techniques (such as dropout and batch normalization), better initializations and training methods.</p></blockquote><h3 id="整体架构"><a href="#整体架构" class="headerlink" title="整体架构"></a>整体架构</h3><h4 id="目标函数"><a href="#目标函数" class="headerlink" title="目标函数"></a>目标函数</h4><p>多峰logistic回归。</p><h4 id="并行框架"><a href="#并行框架" class="headerlink" title="并行框架"></a>并行框架</h4><p>下图是并行的架构，分为两层，上面一层用一个GPU，下面一层用一个GPU，它们只在第三个卷积层有交互。<br><img src="/2019/03/13/CNN/alexnet.png" alt="alexnet"></p><h4 id="简化框架"><a href="#简化框架" class="headerlink" title="简化框架"></a>简化框架</h4><p>下图是简化版的结构，不需要使用两个GPU。<br><img src="/2019/03/13/CNN/alexnet_simple.png" alt="alexnet_simple"></p><h4 id="数据流（简化框架）"><a href="#数据流（简化框架）" class="headerlink" title="数据流（简化框架）"></a>数据流（简化框架）</h4><p>输入是$224\times 224 \times 3$的图片，第一层是$96$个stride为$4$的$11\times 11\times 3$卷积核构成的卷积层，输出经过max pooling(步长为2，kernel size为3)输入到第二层；第二层有$256$个$5\times 5\times 96$个卷积核，输出经过max pooling(步长为2，kernel size为3)输入到第三层；第三层到第四层，第四层到第五层之间没有经过pooling和normalization)，第三层有384个$3\times 3\times 256$个卷积核，第四层有$384$个$3\times 3\times 384$个卷积核，第五层有$256$个$3\times 3\times 384$个卷积核。然后接了两个$2048$个神经元的全连接层和一个$1000$个神经元的全连接层。</p><h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><h4 id="Datasets"><a href="#Datasets" class="headerlink" title="Datasets"></a>Datasets</h4><p>ILSVRC-2010</p><h4 id="Baselines"><a href="#Baselines" class="headerlink" title="Baselines"></a>Baselines</h4><ul><li>Sparse coding</li><li>SIFT+FV</li><li>CNN</li></ul><h4 id="Metric"><a href="#Metric" class="headerlink" title="Metric"></a>Metric</h4><ul><li>top-1 error rate</li><li>top-5 error rate</li></ul><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><p>pytorch实现<br><a href="https://github.com/mxxhcm/myown_code/blob/master/CNN/alexnet.py" target="_blank" rel="noopener">https://github.com/mxxhcm/myown_code/blob/master/CNN/alexnet.py</a></p><h2 id="Vggnet-2013"><a href="#Vggnet-2013" class="headerlink" title="Vggnet(2013)"></a>Vggnet(2013)</h2><h3 id="概述-1"><a href="#概述-1" class="headerlink" title="概述"></a>概述</h3><h3 id="存在的问题-1"><a href="#存在的问题-1" class="headerlink" title="存在的问题"></a>存在的问题</h3><h3 id="方案"><a href="#方案" class="headerlink" title="方案"></a>方案</h3><h4 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h4><h4 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h4><h4 id="代码-1"><a href="#代码-1" class="headerlink" title="代码"></a>代码</h4><h2 id><a href="#" class="headerlink" title=" "></a> </h2><h3 id="概述-2"><a href="#概述-2" class="headerlink" title="概述"></a>概述</h3><h3 id="存在的问题-2"><a href="#存在的问题-2" class="headerlink" title="存在的问题"></a>存在的问题</h3><h3 id="方案-1"><a href="#方案-1" class="headerlink" title="方案"></a>方案</h3><h4 id="背景-1"><a href="#背景-1" class="headerlink" title="背景"></a>背景</h4><h4 id="算法-1"><a href="#算法-1" class="headerlink" title="算法"></a>算法</h4><h4 id="代码-2"><a href="#代码-2" class="headerlink" title="代码"></a>代码</h4><h1 id="-1"><a href="#-1" class="headerlink" title="#"></a>#</h1><h3 id="概述-3"><a href="#概述-3" class="headerlink" title="概述"></a>概述</h3><h3 id="存在的问题-3"><a href="#存在的问题-3" class="headerlink" title="存在的问题"></a>存在的问题</h3><h3 id="方案-2"><a href="#方案-2" class="headerlink" title="方案"></a>方案</h3><h4 id="背景-2"><a href="#背景-2" class="headerlink" title="背景"></a>背景</h4><h4 id="算法-2"><a href="#算法-2" class="headerlink" title="算法"></a>算法</h4><h4 id="代码-3"><a href="#代码-3" class="headerlink" title="代码"></a>代码</h4><h1 id="-2"><a href="#-2" class="headerlink" title="#"></a>#</h1><h3 id="概述-存在的问题"><a href="#概述-存在的问题" class="headerlink" title="概述 ### 存在的问题"></a>概述 ### 存在的问题</h3><h3 id="方案-3"><a href="#方案-3" class="headerlink" title="方案"></a>方案</h3><h4 id="背景-3"><a href="#背景-3" class="headerlink" title="背景"></a>背景</h4><h4 id="算法-3"><a href="#算法-3" class="headerlink" title="算法"></a>算法</h4><h4 id="代码-4"><a href="#代码-4" class="headerlink" title="代码"></a>代码</h4><h1 id="-3"><a href="#-3" class="headerlink" title="#"></a>#</h1><h3 id="概述-4"><a href="#概述-4" class="headerlink" title="概述"></a>概述</h3><h3 id="存在的问题-4"><a href="#存在的问题-4" class="headerlink" title="存在的问题"></a>存在的问题</h3><h3 id="方案-4"><a href="#方案-4" class="headerlink" title="方案"></a>方案</h3><h4 id="背景-4"><a href="#背景-4" class="headerlink" title="背景"></a>背景</h4><h4 id="算法-4"><a href="#算法-4" class="headerlink" title="算法"></a>算法</h4><h4 id="代码-5"><a href="#代码-5" class="headerlink" title="代码"></a>代码</h4><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>1.<a href="https://stats.stackexchange.com/a/174438" target="_blank" rel="noopener">https://stats.stackexchange.com/a/174438</a><br>2.<a href="https://www.zhihu.com/question/264163033/answer/277481519" target="_blank" rel="noopener">https://www.zhihu.com/question/264163033/answer/277481519</a><br>3.<a href="https://stats.stackexchange.com/questions/145768/importance-of-local-response-normalization-in-cnn" target="_blank" rel="noopener">https://stats.stackexchange.com/questions/145768/importance-of-local-response-normalization-in-cnn</a><br>4.<a href="https://stats.stackexchange.com/a/386304" target="_blank" rel="noopener">https://stats.stackexchange.com/a/386304</a><br>5.<a href="https://blog.csdn.net/luoyang224/article/details/78088582/" target="_blank" rel="noopener">https://blog.csdn.net/luoyang224/article/details/78088582/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Alexnet-2012&quot;&gt;&lt;a href=&quot;#Alexnet-2012&quot; class=&quot;headerlink&quot; title=&quot;Alexnet(2012)&quot;&gt;&lt;/a&gt;Alexnet(2012)&lt;/h2&gt;&lt;h3 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class
      
    
    </summary>
    
      <category term="机器学习" scheme="http://mxxhcm.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="CNN" scheme="http://mxxhcm.github.io/tags/CNN/"/>
    
      <category term="卷积神经网络" scheme="http://mxxhcm.github.io/tags/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="alexnet" scheme="http://mxxhcm.github.io/tags/alexnet/"/>
    
  </entry>
  
  <entry>
    <title>pytorch踩坑（不定期更新）</title>
    <link href="http://mxxhcm.github.io/2019/03/13/pytorch%E8%B8%A9%E5%9D%91%EF%BC%88%E4%B8%8D%E5%AE%9A%E6%9C%9F%E6%9B%B4%E6%96%B0%EF%BC%89/"/>
    <id>http://mxxhcm.github.io/2019/03/13/pytorch踩坑（不定期更新）/</id>
    <published>2019-03-13T07:10:22.000Z</published>
    <updated>2019-05-06T16:22:27.708Z</updated>
    
    <content type="html"><![CDATA[<h2 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h2><h3 id="RuntimeError-CUDNN-STATUS-ARCH-MISMATCH"><a href="#RuntimeError-CUDNN-STATUS-ARCH-MISMATCH" class="headerlink" title="RuntimeError: CUDNN_STATUS_ARCH_MISMATCH"></a>RuntimeError: CUDNN_STATUS_ARCH_MISMATCH</h3><p>CUDNN doesn’t support CUDA arch 2.1 cards.<br>CUDNN requires Compute Capability 3.0, at least.<br>意思是GPU的加速能力不够，CUDNN只支持CUDA Capability 3.0以上的GPU加速，实验室主机是GT620的显卡，2.1的加速能力。<br>GPU对应的capability: <a href="https://developer.nvidia.com/cuda-gpus" target="_blank" rel="noopener">https://developer.nvidia.com/cuda-gpus</a><br>所以，对于不能使用cudnn对cuda加速的显卡，我们可以设置cudnn加速为False，这个默认是为True的<br>torch.backends.cudnn.enabled=False<br>但是，由于显卡版本为2.1，太老了，没有二进制版本。所以，还是会报其他错误，因此，就别使用cpu进行加速啦。</p><h3 id="查看cuda版本"><a href="#查看cuda版本" class="headerlink" title="查看cuda版本"></a>查看cuda版本</h3><p>~#:nvcc —version</p><h2 id="神经网络参数初始化"><a href="#神经网络参数初始化" class="headerlink" title="神经网络参数初始化"></a>神经网络参数初始化</h2><h3 id="方法-1-Model-apply-fn"><a href="#方法-1-Model-apply-fn" class="headerlink" title="方法$1$.Model.apply(fn)"></a>方法$1$.Model.apply(fn)</h3><p><a href="https://github.com/mxxhcm/myown_code/blob/master/pytorch/tutorials/initialize/apply.py" target="_blank" rel="noopener">示例</a>如下<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">init_weights</span><span class="params">(m)</span>:</span></span><br><span class="line">  print(m)</span><br><span class="line">  <span class="keyword">if</span> type(m) == nn.Linear:</span><br><span class="line">    m.weight.data.fill_(<span class="number">1.0</span>)</span><br><span class="line">    print(m.weight)</span><br><span class="line"></span><br><span class="line">net = nn.Sequential(nn.Linear(<span class="number">2</span>, <span class="number">2</span>), nn.Linear(<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">net.apply(init_weights)</span><br></pre></td></tr></table></figure></p><p>输出结果如下：</p><blockquote><p>Linear(in_features=2, out_features=2, bias=True)<br>Parameter containing:<br>tensor([[1., 1.],<br>        [1., 1.]], requires_grad=True)<br>Linear(in_features=2, out_features=2, bias=True)<br>Parameter containing:<br>tensor([[1., 1.],<br>        [1., 1.]], requires_grad=True)<br>Sequential(<br>  (0): Linear(in_features=2, out_features=2, bias=True)<br>  (1): Linear(in_features=2, out_features=2, bias=True)<br>)<br>Linear(in_features=2, out_features=2, bias=True)<br>Linear(in_features=2, out_features=2, bias=True)</p></blockquote><p>其中最后两行为net对象调用self.children()函数返回的模块，就是模型中所有网络的参数。事实上，调用net.apply(fn)函数，会对self.children()中的所有模块应用fn函数，</p><h2 id="torch-multiprocessing"><a href="#torch-multiprocessing" class="headerlink" title="torch.multiprocessing"></a>torch.multiprocessing</h2><h3 id="join"><a href="#join" class="headerlink" title="join"></a>join</h3><p>等待调用join()方法的线程执行完毕，然后继续执行。<br>可参见github<a href="https://github.com/mxxhcm/myown_code/tree/master/pytorch/tutorials/multiprocess_torch/mnist_hogwild" target="_blank" rel="noopener">官方demo</a>。</p><h3 id="sharememory"><a href="#sharememory" class="headerlink" title="sharememory\()"></a>share<em>memory\</em>()</h3><p>在多个线程之间共享参数，如下<a href="https://github.com/mxxhcm/myown_code/blob/master/pytorch/tutorials/multiprocess_torch/share_memory.py" target="_blank" rel="noopener">代码</a>所示。可以用来实现A3C。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.multiprocessing <span class="keyword">as</span> mp</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">proc</span><span class="params">(sec, x)</span>:</span></span><br><span class="line">   print(os.getpid(),<span class="string">"  "</span>, x)</span><br><span class="line">   time.sleep(sec)</span><br><span class="line">   print(os.getpid(), <span class="string">"  "</span>, x)</span><br><span class="line">   x += sec</span><br><span class="line">   print(str(os.getpid()) + <span class="string">"  over.  "</span>, x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">   num_processes = <span class="number">3</span></span><br><span class="line">   processes = []</span><br><span class="line">   x = torch.ones([<span class="number">3</span>,])</span><br><span class="line">   x.share_memory_()</span><br><span class="line">   <span class="keyword">for</span> rank <span class="keyword">in</span> range(num_processes):</span><br><span class="line">     p = mp.Process(target=proc, args=(rank + <span class="number">1</span>, x))</span><br><span class="line">     p.start() </span><br><span class="line">     processes.append(p)</span><br><span class="line">   <span class="keyword">for</span> p <span class="keyword">in</span> processes:</span><br><span class="line">     p.join()</span><br><span class="line">   print(x)</span><br></pre></td></tr></table></figure></p><p>输出结果如下所示：</p><blockquote><p>python share_memory.py<br>7739    tensor([1., 1., 1.])<br>7738    tensor([1., 1., 1.])<br>7737    tensor([1., 1., 1.])<br>7737    tensor([1., 1., 1.])<br>7737  over.   tensor([2., 2., 2.])<br>7738    tensor([2., 2., 2.])<br>7738  over.   tensor([4., 4., 4.])<br>7739    tensor([4., 4., 4.])<br>7739  over.   tensor([7., 7., 7.])<br>tensor([7., 7., 7.])</p></blockquote><p>我们可以发现$7739$这个线程中，传入的$x$还是和最开始的一样，但是在$7738$线程更新完$x$之后，$7739$使用的$x$就已经变成了更新后的$x$。所以，我猜测这里面应该是有一个对$x$的锁，保证$x$在同一时刻只能被一个线程访问。</p><h2 id="torch-distributions"><a href="#torch-distributions" class="headerlink" title="torch.distributions"></a>torch.distributions</h2><p>这个库和gym.space库很相似，都是提供一些分布，然后从中采样。<br>常见的有ExponentialFamily,Bernoulli,Binomial,Categorical,Exponential,Gamma,Independent,Laplace,Multinomial,MultivariateNormal。这里不做过程陈述，可以看<a href="http://localhost:4000/2019/04/12/gym%E4%BB%8B%E7%BB%8D/" target="_blank" rel="noopener">gym</a>中。</p><h3 id="Categorical"><a href="#Categorical" class="headerlink" title="Categorical"></a>Categorical</h3><p>对应tensorflow中的<a href="https://github.com/mxxhcm/myown_code/blob/master/tf/some_ops/tf_multinominal.py" target="_blank" rel="noopener">tf.multinomial</a>。<br>类原型：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CLASS torch.distributions.categorical.Categorical(probs=<span class="literal">None</span>, logits=<span class="literal">None</span>, validate_args=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure></p><p>参数probs只能是$1$维或者$2$维，而且必须是非负，有限非零和的，然后将其归一化到和为$1$。<br>这个类和torch.multinormal是一样的，从${0,\cdots, K-1}$中按照probs的概率进行采样，$K$是probs.size(-1)，即是size()矩阵的最后一列，$2$维时把第$1$维当成了batch。</p><p>举一个简单的例子，<a href>代码</a>。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.distributions <span class="keyword">as</span> diss</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">torch.manual_seed(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">m = diss.Categorical(torch.tensor([<span class="number">0.25</span>, <span class="number">0.25</span>, <span class="number">0.25</span>, <span class="number">0.25</span> ]))</span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">5</span>):</span><br><span class="line">    print(m.sample())</span><br><span class="line"></span><br><span class="line">m = diss.Categorical(torch.tensor([[<span class="number">0.5</span>, <span class="number">0.25</span>, <span class="number">0.25</span>], [<span class="number">0.25</span>, <span class="number">0.25</span>, <span class="number">0.5</span>]]))</span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">5</span>):</span><br><span class="line">    print(m.sample())</span><br></pre></td></tr></table></figure></p><p>输出结果如下：</p><blockquote><p>tensor(2)<br>tensor(1)<br>tensor(1)<br>tensor(1)<br>tensor(1)<br>tensor([2, 2])<br>tensor([1, 2])<br>tensor([0, 1])<br>tensor([0, 2])<br>tensor([0, 0])</p></blockquote><p>作为对比，gym.spaces.Discrete示例如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> gym <span class="keyword">import</span> spaces</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1.Discrete</span></span><br><span class="line"><span class="comment"># 取值是&#123;0, 1, ..., n - 1&#125;</span></span><br><span class="line">dis = spaces.Discrete(<span class="number">5</span>)</span><br><span class="line">dis.seed(<span class="number">5</span>)</span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">5</span>):</span><br><span class="line">    print(dis.sample())</span><br></pre></td></tr></table></figure></p><p>输出结果是：</p><blockquote><p>3<br>0<br>1<br>0<br>4</p></blockquote><h2 id="torch"><a href="#torch" class="headerlink" title="torch"></a>torch</h2><h3 id="torch-cat"><a href="#torch-cat" class="headerlink" title="torch.cat"></a>torch.cat</h3><h4 id="函数原型"><a href="#函数原型" class="headerlink" title="函数原型"></a>函数原型</h4><p>将多个tensor在某一个维度上（默认是第0维）拼接到一起（除了拼接的维度上，其他维度的shape必须一定），最后返回一个tensor。<br>torch.cat(tensors, dim=0, out=None) → Tensor</p><blockquote><p>Concatenates the given sequence of seq tensors in the given dimension. All tensors must either have the same shape (except in the concatenating dimension) or be empty.</p></blockquote><h4 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h4><p>tensors (sequence of Tensors) – 任意类型相同python序列或者tensor<br>dim (int, optional) - 在第几个维度上进行拼接(只有在拼接的维度上可以不同，其余维度必须相同。<br>out (Tensor, optional) – 输出的tensor</p><h4 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">x1 = torch.randn(<span class="number">3</span>, <span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line">x2 = torch.randn(<span class="number">3</span>, <span class="number">1</span>, <span class="number">4</span>)</span><br><span class="line">x = torch.cat([x1, x2], <span class="number">1</span>)</span><br><span class="line">print(x.size())</span><br></pre></td></tr></table></figure><p>输出如下：</p><blockquote><p>torch.Size([3, 5, 4])</p></blockquote><h3 id="torch中图像-img-格式"><a href="#torch中图像-img-格式" class="headerlink" title="torch中图像(img)格式"></a>torch中图像(img)格式</h3><p>torch中图像的shape是(‘RGB’,width, height)，而numpy和matplotlib中都是(width, height, ‘RGB’)<br>matplotlib.pyplot.imshow()需要的参数是图像矩阵，如果矩阵中是整数，那么它的值需要在区间[0,255]之内，如果是浮点数，需要在[0,1]之间。</p><blockquote><p>Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).</p></blockquote><h2 id="torch-autograd-torch-autograd-Variable和torch-autograd-Function"><a href="#torch-autograd-torch-autograd-Variable和torch-autograd-Function" class="headerlink" title="torch.autograd(torch.autograd.Variable和torch.autograd.Function)"></a>torch.autograd(torch.autograd.Variable和torch.autograd.Function)</h2><h3 id="Variable-class-torch-autograd-Variable"><a href="#Variable-class-torch-autograd-Variable" class="headerlink" title="Variable(class torch.autograd.Variable)"></a>Variable(class torch.autograd.Variable)</h3><h4 id="声明一个tensor"><a href="#声明一个tensor" class="headerlink" title="声明一个tensor"></a>声明一个tensor</h4><p>torch.zeros,torch.ones,torch.rand,torch.Tensor<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">torch.manual_seed(<span class="number">5</span>)</span><br><span class="line">x = torch.empty(<span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line">print(torch.empty(<span class="number">5</span>, <span class="number">3</span>)) <span class="comment"># construct a 5x3 matrix, uninitialized</span></span><br><span class="line"><span class="comment"># tensor([[4.6179e-38, 4.5845e-41, 4.6179e-38],</span></span><br><span class="line"><span class="comment">#         [4.5845e-41, 6.3010e-36, 6.3010e-36],</span></span><br><span class="line"><span class="comment">#         [2.5204e-35, 6.3010e-36, 1.0082e-34],</span></span><br><span class="line"><span class="comment">#         [6.3010e-36, 6.3010e-36, 6.6073e-30],</span></span><br><span class="line"><span class="comment">#         [6.3010e-36, 6.3010e-36, 6.3010e-36]])</span></span><br><span class="line"></span><br><span class="line">print(torch.rand(<span class="number">3</span>, <span class="number">4</span>))  <span class="comment"># construct a 4x3 matrix, uniform [0,1] </span></span><br><span class="line"><span class="comment"># tensor([[0.8303, 0.1261, 0.9075, 0.8199],</span></span><br><span class="line"><span class="comment">#         [0.9201, 0.1166, 0.1644, 0.7379],</span></span><br><span class="line"><span class="comment">#         [0.0333, 0.9942, 0.6064, 0.5646]])</span></span><br><span class="line"></span><br><span class="line">print(torch.randn(<span class="number">5</span>, <span class="number">3</span>)) <span class="comment"># construct a 5x3 matrix, normal distribution</span></span><br><span class="line"><span class="comment"># tensor([[-1.4017, -0.7626,  0.6312],</span></span><br><span class="line"><span class="comment">#         [-0.8991, -0.5578,  0.6907],</span></span><br><span class="line"><span class="comment">#         [ 0.2225, -0.6662,  0.6846],</span></span><br><span class="line"><span class="comment">#         [ 0.5740, -0.5829,  0.7679],</span></span><br><span class="line"><span class="comment">#         [ 0.5740, -0.5829,  0.7679],</span></span><br><span class="line"></span><br><span class="line">print(torch.randn(<span class="number">2</span>, <span class="number">3</span>).type())</span><br><span class="line"><span class="comment"># torch.FloatTensor</span></span><br><span class="line"></span><br><span class="line">print(torch.zeros(<span class="number">5</span>, <span class="number">3</span>)) <span class="comment"># construct a 5x3 matrix filled zeros</span></span><br><span class="line"><span class="comment"># tensor([[0., 0., 0.],</span></span><br><span class="line"><span class="comment">#         [0., 0., 0.],</span></span><br><span class="line"><span class="comment">#         [0., 0., 0.],</span></span><br><span class="line"><span class="comment">#         [0., 0., 0.],</span></span><br><span class="line"><span class="comment">#         [0., 0., 0.]])</span></span><br><span class="line"></span><br><span class="line">print(torch.ones(<span class="number">5</span>, <span class="number">3</span>)) <span class="comment"># construct a 5x3 matrix filled ones</span></span><br><span class="line"><span class="comment"># tensor([[1., 1., 1.],</span></span><br><span class="line"><span class="comment">#         [1., 1., 1.],</span></span><br><span class="line"><span class="comment">#         [1., 1., 1.],</span></span><br><span class="line"><span class="comment">#         [1., 1., 1.],</span></span><br><span class="line"><span class="comment">#         [1., 1., 1.]])</span></span><br><span class="line"></span><br><span class="line">print(torch.ones(<span class="number">5</span>, <span class="number">3</span>, dtype=torch.long)) <span class="comment"># construct a tensor with dtype=torch.long</span></span><br><span class="line"><span class="comment"># tensor([[1, 1, 1],</span></span><br><span class="line"><span class="comment">#         [1, 1, 1],</span></span><br><span class="line"><span class="comment">#         [1, 1, 1],</span></span><br><span class="line"><span class="comment">#         [1, 1, 1],</span></span><br><span class="line"><span class="comment">#         [1, 1, 1]])</span></span><br><span class="line"></span><br><span class="line">print(torch.tensor([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])) <span class="comment"># construct a tensor direct from data</span></span><br><span class="line"><span class="comment"># tensor([1, 2, 3])</span></span><br><span class="line"></span><br><span class="line">print(x.new_ones(<span class="number">5</span>,<span class="number">4</span>)) <span class="comment"># constuct a tensor has the same property as x</span></span><br><span class="line"><span class="comment"># tensor([[1., 1., 1., 1.],</span></span><br><span class="line"><span class="comment">#         [1., 1., 1., 1.],</span></span><br><span class="line"><span class="comment">#         [1., 1., 1., 1.],</span></span><br><span class="line"><span class="comment">#         [1., 1., 1., 1.],</span></span><br><span class="line"><span class="comment">#         [1., 1., 1., 1.]])</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(torch.full([<span class="number">4</span>,<span class="number">3</span>],<span class="number">9</span>))  <span class="comment"># construct a tensor with a value </span></span><br><span class="line"><span class="comment"># tensor([[9., 9., 9.],</span></span><br><span class="line"><span class="comment">#         [9., 9., 9.],</span></span><br><span class="line"><span class="comment">#         [9., 9., 9.],</span></span><br><span class="line"><span class="comment">#         [9., 9., 9.]])</span></span><br><span class="line"></span><br><span class="line">print(x.new_ones(<span class="number">5</span>,<span class="number">4</span>,dtype=torch.int)) <span class="comment"># construct a tensor with the same property as x, and also can have the specified type.</span></span><br><span class="line"><span class="comment"># tensor([[1, 1, 1, 1],</span></span><br><span class="line"><span class="comment">#         [1, 1, 1, 1],</span></span><br><span class="line"><span class="comment">#         [1, 1, 1, 1],</span></span><br><span class="line"><span class="comment">#         [1, 1, 1, 1],</span></span><br><span class="line"><span class="comment">#         [1, 1, 1, 1]], dtype=torch.int32)</span></span><br><span class="line"></span><br><span class="line">print(torch.randn_like(x,dtype=torch.float)) <span class="comment"># construct a tensor with the same shape with x, </span></span><br><span class="line"><span class="comment"># tensor([[ 0.4699, -1.9540, -0.5587],</span></span><br><span class="line"><span class="comment">#         [ 0.4295, -2.2643, -0.2017],</span></span><br><span class="line"><span class="comment">#         [ 1.0677,  0.3246, -0.0684],</span></span><br><span class="line"><span class="comment">#         [-0.9959,  1.1563, -0.3992],</span></span><br><span class="line"><span class="comment">#         [ 1.2153, -0.8115, -0.8848]])</span></span><br><span class="line"></span><br><span class="line">print(torch.ones_like(x))</span><br><span class="line"><span class="comment"># tensor([[1., 1., 1.],</span></span><br><span class="line"><span class="comment">#         [1., 1., 1.],</span></span><br><span class="line"><span class="comment">#         [1., 1., 1.],</span></span><br><span class="line"><span class="comment">#         [1., 1., 1.],</span></span><br><span class="line"><span class="comment">#         [1., 1., 1.]])</span></span><br><span class="line"></span><br><span class="line">print(torch.zeros_like(x))</span><br><span class="line"><span class="comment"># tensor([[0., 0., 0.],</span></span><br><span class="line"><span class="comment">#         [0., 0., 0.],</span></span><br><span class="line"><span class="comment">#         [0., 0., 0.],</span></span><br><span class="line"><span class="comment">#         [0., 0., 0.],</span></span><br><span class="line"><span class="comment">#         [0., 0., 0.]])</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(torch.Tensor(<span class="number">3</span>,<span class="number">4</span>))</span><br><span class="line"><span class="comment"># tensor([[-3.8809e-21,  3.0948e-41,  2.3822e-44,  0.0000e+00],</span></span><br><span class="line"><span class="comment">#         [        nan,  7.2251e+28,  1.3733e-14,  1.8888e+31],</span></span><br><span class="line"><span class="comment">#         [ 4.9656e+28,  4.5439e+30,  7.1426e+22,  1.8759e+28]])</span></span><br><span class="line"></span><br><span class="line">print(torch.Tensor(<span class="number">3</span>,<span class="number">4</span>).uniform_(<span class="number">0</span>,<span class="number">1</span>))</span><br><span class="line"><span class="comment"># tensor([[0.8437, 0.1399, 0.2239, 0.3462],</span></span><br><span class="line"><span class="comment">#         [0.5668, 0.3059, 0.1890, 0.4087],</span></span><br><span class="line"><span class="comment">#         [0.2560, 0.5138, 0.1299, 0.3750]])</span></span><br><span class="line"></span><br><span class="line">print(torch.Tensor(<span class="number">3</span>,<span class="number">4</span>).normal_(<span class="number">0</span>,<span class="number">1</span>))</span><br><span class="line"><span class="comment"># tensor([[-0.5490, -0.0838, -0.1387, -0.5289],</span></span><br><span class="line"><span class="comment">#         [-0.4919, -0.4646, -0.0588,  1.2624],</span></span><br><span class="line"><span class="comment">#         [ 1.1935,  1.5696, -0.8977, -0.1139]])</span></span><br><span class="line"></span><br><span class="line">print(torch.Tensor(<span class="number">3</span>,<span class="number">4</span>).fill_(<span class="number">5</span>))</span><br><span class="line"><span class="comment"># tensor([[5., 5., 5., 5.],</span></span><br><span class="line"><span class="comment">#         [5., 5., 5., 5.],</span></span><br><span class="line"><span class="comment">#         [5., 5., 5., 5.]])</span></span><br><span class="line"></span><br><span class="line">print(torch.arange(<span class="number">1</span>, <span class="number">3</span>, <span class="number">0.4</span>))</span><br><span class="line"><span class="comment"># tensor([1.0000, 1.4000, 1.8000, 2.2000, 2.6000])</span></span><br></pre></td></tr></table></figure></p><h4 id="tensor的各种操作"><a href="#tensor的各种操作" class="headerlink" title="tensor的各种操作"></a>tensor的各种操作</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">a = torch.ones(<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">b = torch.ones(<span class="number">2</span>,<span class="number">3</span>)</span><br></pre></td></tr></table></figure><h5 id="加操作"><a href="#加操作" class="headerlink" title="加操作"></a>加操作</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">print(a+b)                <span class="comment">#方法1</span></span><br><span class="line">c = torch.add(a,b)    <span class="comment">#方法2</span></span><br><span class="line">torch.add(a,b,result)    <span class="comment">#方法3</span></span><br><span class="line">a.add(b)                    <span class="comment">#方法4,将a加上b，且a不变</span></span><br><span class="line">a.add_(b)                <span class="comment">#方法5,将a加上b并将其赋值给a</span></span><br></pre></td></tr></table></figure><h5 id="转置操作"><a href="#转置操作" class="headerlink" title="转置操作"></a>转置操作</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(a.t())               <span class="comment"># 打印出tensor a的转置</span></span><br><span class="line">print(a.t_())                 <span class="comment">#将tensor a 转置，并将其赋值给a</span></span><br></pre></td></tr></table></figure><h5 id="求最大行和列"><a href="#求最大行和列" class="headerlink" title="求最大行和列"></a>求最大行和列</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">torch.max(tensor,dim)</span><br><span class="line">np.max(array,dim)</span><br></pre></td></tr></table></figure><h5 id="和relu功能比较类似。"><a href="#和relu功能比较类似。" class="headerlink" title="和relu功能比较类似。"></a>和relu功能比较类似。</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">torch.clamp(tensor, min, max,out=<span class="literal">None</span>)</span><br><span class="line">np.maximun(x1, x2)  <span class="comment"># x1 and x2 must hava the same shape</span></span><br></pre></td></tr></table></figure><h4 id="tensor和numpy转化"><a href="#tensor和numpy转化" class="headerlink" title="tensor和numpy转化"></a>tensor和numpy转化</h4><h5 id="convert-tensor-to-numpy"><a href="#convert-tensor-to-numpy" class="headerlink" title="convert tensor to numpy"></a>convert tensor to numpy</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a = torch.ones(<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">b = a.numpy()</span><br></pre></td></tr></table></figure><h5 id="convert-numpy-to-tensor"><a href="#convert-numpy-to-tensor" class="headerlink" title="convert numpy to tensor"></a>convert numpy to tensor</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a =  numpy.ones(<span class="number">4</span>,<span class="number">3</span>)</span><br><span class="line">b = torch.from_numpy(a)</span><br></pre></td></tr></table></figure><h4 id="Variable和Tensor"><a href="#Variable和Tensor" class="headerlink" title="Variable和Tensor"></a>Variable和Tensor</h4><p>Variable<br>图1.Variable</p><h5 id="属性"><a href="#属性" class="headerlink" title="属性"></a>属性</h5><p>如图1,Variable wrap a Tensor,and it has six attributes,data,grad,requies_grad,volatile,is_leaf and grad_fn.We can acess the raw tensor through .data operation, we can accumualte gradients w.r.t this Variable into .grad,.Finally , creator attribute will tell us how the Variable were created,we can acess the creator attibute by .grad_fn,if the Variable was created by the user,then the grad_fn is None,else it will show us which Function created the Variable.<br>if the grad_fn is None,we call them graph leaves<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Variable.shape  <span class="comment">#查看Variable的size</span></span><br><span class="line">Variable.size()</span><br></pre></td></tr></table></figure></p><h5 id="parameters"><a href="#parameters" class="headerlink" title="parameters"></a>parameters</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.autograd.Variable(data,requires_grad=<span class="literal">False</span>,volatile=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><p>requires_grad : indicate whether the backward() will ever need to be called</p><h5 id="backward"><a href="#backward" class="headerlink" title="backward"></a>backward</h5><p>backward(gradient=None,retain_graph=None,create_graph=None,retain_variables=None)<br>如果Variable是一个scalar output，我们不需要指定gradient，但是如果Variable不是一个scalar，而是有多个element，我们就需要根据output指定一下gradient，gradient的type可以是tensor也可以是Variable，里面的值为梯度的求值比例，例如<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = Variable(torch.Tensor([<span class="number">3</span>,<span class="number">6</span>,<span class="number">4</span>]),requires_grad=<span class="literal">True</span>)</span><br><span class="line">y = Variable(torch.Tensor([<span class="number">5</span>,<span class="number">3</span>,<span class="number">6</span>]),requires_grad=<span class="literal">True</span>)</span><br><span class="line">z = x+y</span><br><span class="line">z.backward(gradient=torch.Tensor([<span class="number">0.1</span>,<span class="number">1</span>,<span class="number">10</span>]))</span><br></pre></td></tr></table></figure></p><p>这里[0.1,1,10]分别表示的是对正常梯度分别乘上$0.1,1,10$，然后将他们累积在leaves Variable上<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">detach()    <span class="comment">#</span></span><br><span class="line">detach_()</span><br><span class="line">register_hook()</span><br><span class="line">register_grad()</span><br></pre></td></tr></table></figure></p><h3 id="Function-class-torch-autograd-Funtion"><a href="#Function-class-torch-autograd-Funtion" class="headerlink" title="Function(class torch.autograd.Funtion)"></a>Function(class torch.autograd.Funtion)</h3><h4 id="用法"><a href="#用法" class="headerlink" title="用法"></a>用法</h4><p>Function一般只定义一个操作，并且它无法保存参数，一般适用于激活函数，pooling等，它需要定义三个方法，<strong>init</strong>(),forward(),backward()（这个需要自己定义怎么求导）<br>Model保存了参数，适合定义一层，如线性层(Linear layer),卷积层(conv layer),也适合定义一个网络。<br>和Model的区别，model只需要定义<strong>init()</strong>,foward()方法，backward()不需要我们定义，它可以由自动求导机制计算。</p><p>Function定义只是一个函数，forward和backward都只与这个Function的输入和输出有关</p><h4 id="functions"><a href="#functions" class="headerlink" title="functions"></a>functions</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyReLU</span><span class="params">(torch.autograd.Function)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    We can implement our own custom autograd Functions by subclassing</span></span><br><span class="line"><span class="string">    torch.autograd.Function and implementing the forward and backward passes</span></span><br><span class="line"><span class="string">    which operate on Tensors.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, input)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        In the forward pass we receive a Tensor containing the input and return a</span></span><br><span class="line"><span class="string">        Tensor containing the output. You can cache arbitrary Tensors for use in the</span></span><br><span class="line"><span class="string">        backward pass using the save_for_backward method.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.save_for_backward(input)</span><br><span class="line">        <span class="keyword">return</span> input.clamp(min=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span><span class="params">(self, grad_output)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        In the backward pass we receive a Tensor containing the gradient of the loss</span></span><br><span class="line"><span class="string">        with respect to the output, and we need to compute the gradient of the loss</span></span><br><span class="line"><span class="string">        with respect to the input.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        input, = self.saved_tensors</span><br><span class="line">        grad_input = grad_output.clone()</span><br><span class="line">        grad_input[input &lt; <span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">        <span class="keyword">return</span> grad_input</span><br><span class="line"></span><br><span class="line">dtype = torch.FloatTensor</span><br><span class="line"><span class="comment"># dtype = torch.cuda.FloatTensor # Uncomment this to run on GPU</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># N is batch size; D_in is input dimension;</span></span><br><span class="line"><span class="comment"># H is hidden dimension; D_out is output dimension.</span></span><br><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create random Tensors to hold input and outputs, and wrap them in Variables.</span></span><br><span class="line">x = Variable(torch.randn(N, D_in).type(dtype), requires_grad=<span class="literal">False</span>)</span><br><span class="line">y = Variable(torch.randn(N, D_out).type(dtype), requires_grad=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create random Tensors for weights, and wrap them in Variables.</span></span><br><span class="line">w1 = Variable(torch.randn(D_in, H).type(dtype), requires_grad=<span class="literal">True</span>)</span><br><span class="line">w2 = Variable(torch.randn(H, D_out).type(dtype), requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">1e-6</span></span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> range(<span class="number">500</span>):</span><br><span class="line">    <span class="comment"># Construct an instance of our MyReLU class to use in our network</span></span><br><span class="line">    relu = MyReLU()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Forward pass: compute predicted y using operations on Variables; we compute</span></span><br><span class="line">    <span class="comment"># ReLU using our custom autograd operation.</span></span><br><span class="line">    y_pred = relu(x.mm(w1)).mm(w2)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Compute and print loss</span></span><br><span class="line">    loss = (y_pred - y).pow(<span class="number">2</span>).sum()</span><br><span class="line">    print(t, loss.data[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Use autograd to compute the backward pass.</span></span><br><span class="line">    loss.backward()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Update weights using gradient descent</span></span><br><span class="line">    w1.data -= learning_rate * w1.grad.data</span><br><span class="line">    w2.data -= learning_rate * w2.grad.data</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Manually zero the gradients after updating weights</span></span><br><span class="line">    w1.grad.data.zero_()</span><br><span class="line">    w2.grad.data.zero_()</span><br></pre></td></tr></table></figure><h2 id="torch-nn"><a href="#torch-nn" class="headerlink" title="torch.nn"></a>torch.nn</h2><h3 id="Container"><a href="#Container" class="headerlink" title="Container"></a>Container</h3><h4 id="Module"><a href="#Module" class="headerlink" title="Module"></a>Module</h4><p>Module是所有模型的基类。<br>它有以下几个常用的函数和常见的属性。</p><h5 id="常见的函数"><a href="#常见的函数" class="headerlink" title="常见的函数"></a>常见的函数</h5><ul><li>Module.forward() # 前向传播</li><li>Module.modules()  # 返回module中所有的module，包含整个module，详情可见<a href="htts">module.modules()</a></li><li>Module.named_modules() # 同时返回module的名字</li><li>Module.children() # 返回module中所有的子module，不包含整个module，详情可见<a href="htts">module.modules()</a></li><li>Module.named_children() # 同时返回子module的名字</li><li>Module.parameters() # 返回模型的参数</li><li>Module.named_parameters() # 同时返回parameter的名字</li><li>Module.state_dict()  # 保存模型参数</li><li>Module.load_state_dict()  # 加载模型参数</li><li>Module.to() # </li><li>Module.cuda()</li><li>Module.cpu() </li><li>Module.apply(fn) # 对模型中的每一个module都调用fn函数</li><li>Module._apply()</li></ul><h5 id="常见的属性"><a href="#常见的属性" class="headerlink" title="常见的属性"></a>常见的属性</h5><ul><li>self._backend = thnn_backend</li><li>self._parameters = OrderedDict()</li><li>self._buffers = OrderedDict()</li><li>self._backward_hooks = OrderedDict()</li><li>self._forward_hooks = OrderedDict()</li><li>self._forward_pre_hooks = OrderedDict()</li><li>self._state_dict_hooks = OrderedDict()</li><li>self._load_state_dict_pre_hooks = OrderedDict()</li><li>self._modules = OrderedDict()</li><li>self.training = True</li></ul><h5 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h5><p>关于module,children_modules,parameters的<a href>代码</a></p><h4 id="Sequential"><a href="#Sequential" class="headerlink" title="Sequential"></a>Sequential</h4><h3 id="Convolution-Layers"><a href="#Convolution-Layers" class="headerlink" title="Convolution Layers"></a>Convolution Layers</h3><h4 id="torch-nn-Conv2d"><a href="#torch-nn-Conv2d" class="headerlink" title="torch.nn.Conv2d"></a>torch.nn.Conv2d</h4><h5 id="类声明"><a href="#类声明" class="headerlink" title="类声明"></a>类声明</h5><p>应用2维卷积到输入信号中。<br>torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True)</p><blockquote><p>Applies a 2D convolution over an input signal composed of several input planes.</p></blockquote><h5 id="参数声明"><a href="#参数声明" class="headerlink" title="参数声明"></a>参数声明</h5><p>in_channels (int) – 输入图像的通道<br>out_channels (int) – 卷积产生的输出通道数（也就是有几个kernel）<br>kernel_size (int or tuple) – kernel的大小<br>stride (int or tuple, optional) – 卷积的步长，默认为$1$<br>padding (int or tuple, optional) – 向输入数据的各边添加Zero-padding的数量，默认为$0$<br>dilation (int or tuple, optional) – Spacing between kernel elements. Default: 1<br>groups (int, optional) – Number of blocked connections from input channels to output channels. Default: 1<br>bias (bool, optional) – If True, adds a learnable bias to the output</p><h5 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h5><h6 id="例子1"><a href="#例子1" class="headerlink" title="例子1"></a>例子1</h6><p>用$6$个$5\times 5$的filter处理维度为$32\times 32\times 1$的图像。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">model = torch.nn.Conv2d(<span class="number">1</span>, <span class="number">6</span>, <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">input = torch.randn(<span class="number">16</span>, <span class="number">1</span>, <span class="number">32</span>, <span class="number">32</span>)</span><br><span class="line">output = model(input)</span><br><span class="line">print(output.size())</span><br></pre></td></tr></table></figure></p><p>输出是：</p><blockquote><p>torch.Size([16, 6, 28, 28])</p></blockquote><h6 id="例子2"><a href="#例子2" class="headerlink" title="例子2"></a>例子2</h6><p>stride和padding<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"></span><br><span class="line">inputs = Variable(torch.randn(<span class="number">64</span>,<span class="number">3</span>,<span class="number">32</span>,<span class="number">32</span>))</span><br><span class="line"></span><br><span class="line">m1 = nn.Conv2d(<span class="number">3</span>,<span class="number">16</span>,<span class="number">3</span>)</span><br><span class="line">print(m1)</span><br><span class="line">output1 = m1(inputs)</span><br><span class="line">print(output1.size())</span><br><span class="line"></span><br><span class="line">m2 = nn.Conv2d(<span class="number">3</span>, <span class="number">16</span>, <span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">print(m2)</span><br><span class="line">output2 = m2(inputs)</span><br><span class="line">print(output2.size())</span><br></pre></td></tr></table></figure></p><p>输出</p><blockquote><p>Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))<br>torch.Size([64, 16, 30, 30])<br>Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>torch.Size([64, 16, 32, 32])</p></blockquote><h3 id="Pooling-Layers"><a href="#Pooling-Layers" class="headerlink" title="Pooling Layers"></a>Pooling Layers</h3><h4 id="MaxPool2dd"><a href="#MaxPool2dd" class="headerlink" title="MaxPool2dd"></a>MaxPool2dd</h4><p>MaxPool2d这个layer stride默认是和kernel_size相同的<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">from torch import nn</span><br><span class="line">from torch.autograd import Variable</span><br><span class="line"></span><br><span class="line"># maxpool2d</span><br><span class="line"># class torch.nn.MaxPool2d(kernel_size,stride=None,padding=0,dilation=1,return_indices=False,ceil_mode=False)</span><br><span class="line"></span><br><span class="line">print(&quot;input:&quot;)</span><br><span class="line">input = Variable(torch.randn(30,20,32,32))</span><br><span class="line">print(input.size())</span><br><span class="line"></span><br><span class="line">m2 = nn.MaxPool2d(5)</span><br><span class="line">print(m2)</span><br><span class="line"></span><br><span class="line">for param in m2.parameters():</span><br><span class="line">  print(param)</span><br><span class="line"></span><br><span class="line">print(m2.state_dict().keys())</span><br><span class="line"></span><br><span class="line">output = m2(input)</span><br><span class="line">print(&quot;output:&quot;)</span><br><span class="line">print(output.size())</span><br></pre></td></tr></table></figure></p><p>输出</p><blockquote><p>input:<br>torch.Size([30, 20, 32, 32])<br>MaxPool2d (size=(5, 5), stride=(5, 5), dilation=(1, 1))<br>[]<br>output:<br>torch.Size([30, 20, 6, 6])</p></blockquote><h3 id="Padding-Layers"><a href="#Padding-Layers" class="headerlink" title="Padding Layers"></a>Padding Layers</h3><h3 id="Linear-layers"><a href="#Linear-layers" class="headerlink" title="Linear layers"></a>Linear layers</h3><h3 id="Dropout-layers"><a href="#Dropout-layers" class="headerlink" title="Dropout layers"></a>Dropout layers</h3><h4 id="Drop2D"><a href="#Drop2D" class="headerlink" title="Drop2D"></a>Drop2D</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line">m = nn.Dropout2d(<span class="number">0.3</span>)</span><br><span class="line">print(m)</span><br><span class="line">inputs = torch.randn(<span class="number">1</span>,<span class="number">28</span>,<span class="number">28</span>)</span><br><span class="line">outputs = m(inputs)</span><br><span class="line">print(outputs)</span><br></pre></td></tr></table></figure><p>输出：</p><blockquote><p>Dropout2d(p=0.3)<br>([[[ 0.8535,  1.0314,  2.7904,  1.2136,  2.7561, -2.0429,  0.0772,<br>     -1.9372, -0.0864, -1.4132, -0.1648,  0.2403,  0.5727,  0.8102,<br>      0.4544,  0.1414,  0.1547, -0.9266, -0.6033,  0.5813, -1.3541,<br>     -0.0536,  0.9574,  0.0554,  0.8368,  0.7633, -0.3377, -1.4293],<br>    [ 0.0000,  0.0000, -0.0000, -0.0000,  0.0000, -0.0000,  0.0000,<br>      0.0000,  0.0000, -0.0000, -0.0000,  0.0000, -0.0000, -0.0000,<br>      0.0000, -0.0000,  0.0000, -0.0000,  0.0000,  0.0000, -0.0000,<br>     -0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000],<br>      …<br>    [ 0.6452, -0.6455,  0.2370,  0.1088, -0.5421, -0.5120, -2.2915,<br>      0.2061,  1.6384,  2.2276,  2.4022,  0.2033,  0.6984,  0.1254,<br>      1.1627,  1.0699, -2.1868,  1.1293, -0.7030,  0.0454, -1.5428,<br>      -2.4052, -0.3204, -1.5984,  0.1282,  0.2127, -2.3506, -2.2395]]])</p></blockquote><p>会发现输出的数组中有很多被置为$0$了。</p><h3 id="Loss-function"><a href="#Loss-function" class="headerlink" title="Loss function"></a>Loss function</h3><h2 id="torch-nn-functional"><a href="#torch-nn-functional" class="headerlink" title="torch.nn.functional"></a>torch.nn.functional</h2><h3 id="convoludion-functions"><a href="#convoludion-functions" class="headerlink" title="convoludion functions"></a>convoludion functions</h3><h4 id="conv2d"><a href="#conv2d" class="headerlink" title="conv2d"></a>conv2d</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">import torch.nn as nn</span><br><span class="line">import torch.nn.functional as F</span><br><span class="line">from torch.autograd import Variable</span><br><span class="line"></span><br><span class="line">inputs = Variable(torch.randn(64,3,32,32))</span><br><span class="line"></span><br><span class="line">filters1 = Variable(torch.randn(16,3,3,3))</span><br><span class="line">output1 = F.conv2d(inputs,filters1)</span><br><span class="line">print(output1.size())</span><br><span class="line"></span><br><span class="line">filters2 = Variable(torch.randn(16,3,3,3))</span><br><span class="line">output2 = F.conv2d(inputs,filters2,padding=1)</span><br><span class="line">print(output2.size())</span><br></pre></td></tr></table></figure><p>输出</p><blockquote><p>torch.Size([64, 16, 30, 30])<br>torch.Size([64, 16, 32, 32])</p></blockquote><h3 id="relu-functions"><a href="#relu-functions" class="headerlink" title="relu functions"></a>relu functions</h3><h3 id="pooling-functions"><a href="#pooling-functions" class="headerlink" title="pooling functions"></a>pooling functions</h3><h3 id="dropout-functions"><a href="#dropout-functions" class="headerlink" title="dropout functions"></a>dropout functions</h3><h4 id="例子-1"><a href="#例子-1" class="headerlink" title="例子"></a>例子</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"> </span><br><span class="line">x = torch.randn(<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line">y = F.dropout(x, <span class="number">0.5</span>, <span class="literal">True</span>)</span><br><span class="line">y = F.dropout2d(x, <span class="number">0.5</span>)</span><br><span class="line"> </span><br><span class="line">print(y)</span><br></pre></td></tr></table></figure><p>注意$9$中说的问题，不过可能已经被改正了，注意一些就是了。</p><h3 id="linear-functions"><a href="#linear-functions" class="headerlink" title="linear functions"></a>linear functions</h3><h3 id="loss-functions"><a href="#loss-functions" class="headerlink" title="loss functions"></a>loss functions</h3><h2 id="torch-optim"><a href="#torch-optim" class="headerlink" title="torch.optim"></a>torch.optim</h2><h3 id="基类class-Optimizer-object"><a href="#基类class-Optimizer-object" class="headerlink" title="基类class Optimizer(object)"></a>基类class Optimizer(object)</h3><p>Optimizer是所有optimizer的基类。<br>调用任何优化器都要先初始化Optimizer类，这里拿Adam优化器举例子。Adam optimizer的init函数如下所示：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Adam</span><span class="params">(Optimizer)</span>:</span></span><br><span class="line">    <span class="string">r"""Implements Adam algorithm.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    It has been proposed in `Adam: A Method for Stochastic Optimization`_.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">        params (iterable): iterable of parameters to optimize or dicts defining</span></span><br><span class="line"><span class="string">            parameter groups</span></span><br><span class="line"><span class="string">        lr (float, optional): learning rate (default: 1e-3)</span></span><br><span class="line"><span class="string">        betas (Tuple[float, float], optional): coefficients used for computing</span></span><br><span class="line"><span class="string">            running averages of gradient and its square (default: (0.9, 0.999))</span></span><br><span class="line"><span class="string">        eps (float, optional): term added to the denominator to improve</span></span><br><span class="line"><span class="string">            numerical stability (default: 1e-8)</span></span><br><span class="line"><span class="string">        weight_decay (float, optional): weight decay (L2 penalty) (default: 0)</span></span><br><span class="line"><span class="string">        amsgrad (boolean, optional): whether to use the AMSGrad variant of this</span></span><br><span class="line"><span class="string">            algorithm from the paper `On the Convergence of Adam and Beyond`_</span></span><br><span class="line"><span class="string">            (default: False)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    .. _Adam\: A Method for Stochastic Optimization:</span></span><br><span class="line"><span class="string">        https://arxiv.org/abs/1412.6980</span></span><br><span class="line"><span class="string">    .. _On the Convergence of Adam and Beyond:</span></span><br><span class="line"><span class="string">        https://openreview.net/forum?id=ryQu7f-RZ</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, params, lr=<span class="number">1e-3</span>, betas=<span class="params">(<span class="number">0.9</span>, <span class="number">0.999</span>)</span>, eps=<span class="number">1e-8</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                 weight_decay=<span class="number">0</span>, amsgrad=False)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="number">0.0</span> &lt;= lr:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">"Invalid learning rate: &#123;&#125;"</span>.format(lr))</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="number">0.0</span> &lt;= eps:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">"Invalid epsilon value: &#123;&#125;"</span>.format(eps))</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="number">0.0</span> &lt;= betas[<span class="number">0</span>] &lt; <span class="number">1.0</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">"Invalid beta parameter at index 0: &#123;&#125;"</span>.format(betas[<span class="number">0</span>]))</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="number">0.0</span> &lt;= betas[<span class="number">1</span>] &lt; <span class="number">1.0</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">"Invalid beta parameter at index 1: &#123;&#125;"</span>.format(betas[<span class="number">1</span>]))</span><br><span class="line">        defaults = dict(lr=lr, betas=betas, eps=eps,</span><br><span class="line">                        weight_decay=weight_decay, amsgrad=amsgrad)</span><br><span class="line">        super(Adam, self).__init__(params, defaults)</span><br></pre></td></tr></table></figure></p><p>上述代码将学习率lr,beta,epsilon,weight_decay,amsgrad等封装在一个dict中，然后将其传给Optimizer的init函数，其代码如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Optimizer</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="string">r"""Base class for all optimizers.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    .. warning::</span></span><br><span class="line"><span class="string">        Parameters need to be specified as collections that have a deterministic</span></span><br><span class="line"><span class="string">        ordering that is consistent between runs. Examples of objects that don't</span></span><br><span class="line"><span class="string">        satisfy those properties are sets and iterators over values of dictionaries.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">        params (iterable): an iterable of :class:`torch.Tensor` s or</span></span><br><span class="line"><span class="string">            :class:`dict` s. Specifies what Tensors should be optimized.</span></span><br><span class="line"><span class="string">        defaults: (dict): a dict containing default values of optimization</span></span><br><span class="line"><span class="string">            options (used when a parameter group doesn't specify them).</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, params, defaults)</span>:</span></span><br><span class="line">        self.defaults = defaults</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> isinstance(params, torch.Tensor):</span><br><span class="line">            <span class="keyword">raise</span> TypeError(<span class="string">"params argument given to the optimizer should be "</span></span><br><span class="line">                            <span class="string">"an iterable of Tensors or dicts, but got "</span> +</span><br><span class="line">                            torch.typename(params))</span><br><span class="line"></span><br><span class="line">        self.state = defaultdict(dict)</span><br><span class="line">        self.param_groups = []</span><br><span class="line"></span><br><span class="line">        param_groups = list(params)</span><br><span class="line">        <span class="keyword">if</span> len(param_groups) == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">"optimizer got an empty parameter list"</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> isinstance(param_groups[<span class="number">0</span>], dict):</span><br><span class="line">            param_groups = [&#123;<span class="string">'params'</span>: param_groups&#125;]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> param_group <span class="keyword">in</span> param_groups:</span><br><span class="line">            self.add_param_group(param_group)</span><br></pre></td></tr></table></figure></p><p>从这里可以看出来，每个pytorch给出的optimizer至少有以下三个属性和四个函数：<br>属性：</p><ul><li>self.defaults # 字典类型，主要包含学习率等值</li><li>self.state # defaultdict(\<class 'dict'\>, {}) state存放的是</class></li><li>self.param_gropus # \<class 'list'\>:[]，prama_groups是一个字典类型的列表，用来存放parameters。</class></li></ul><p>函数：</p><ul><li>self.zero_grad()  # 将optimizer中参数的梯度置零</li><li>self.step()  # 将梯度应用在参数上</li><li>self.state_dict() # 返回optimizer的state,包括state和param_groups。</li><li>self.load_state_dict()  # 加载optimizer的state。</li><li>self.add_param_group()  # 将一个param group添加到param_groups。可以用在fine-tune上，只添加我们需要训练的层数，然后其他层不动。</li></ul><p>如果param已经是一个字典列表的话，就无需操作，否则就需要把param转化成一个字典param_groups。然后对param_groups中的每一个param_group调用add_param_group(param_group)函数将param_group字典和defaults字典拼接成一个新的param_group字典添加到self.param_groups中。</p><h2 id="torchvision"><a href="#torchvision" class="headerlink" title="torchvision"></a>torchvision</h2><h3 id="torchvision-datasets"><a href="#torchvision-datasets" class="headerlink" title="torchvision.datasets"></a>torchvision.datasets</h3><p>torchvision提供了很多数据集<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line">print(torchvision.datasets.__all__)</span><br></pre></td></tr></table></figure></p><blockquote><p>(‘LSUN’, ‘LSUNClass’, ‘ImageFolder’, ‘DatasetFolder’, ‘FakeData’, ‘CocoCaptions’,     ‘CocoDetection’, ‘CIFAR10’, ‘CIFAR100’, ‘EMNIST’, ‘FashionMNIST’, ‘MNIST’, ‘STL10’,     ‘SVHN’, ‘PhotoTour’, ‘SEMEION’, ‘Omniglot’)</p></blockquote><h3 id="CIFAR10"><a href="#CIFAR10" class="headerlink" title="CIFAR10"></a>CIFAR10</h3><h4 id="原型"><a href="#原型" class="headerlink" title="原型"></a>原型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">calss torchvision.datasets.CIFAR10(root, train=<span class="literal">True</span>, transform=<span class="literal">None</span>, target_transform=<span class="literal">None</span>, download=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><h4 id="参数-1"><a href="#参数-1" class="headerlink" title="参数"></a>参数</h4><p>root (string) – cifar-10-batches-py的存放目录或者download设置为True时将会存放的目录。<br>train (bool, optional) – 设置为True的时候, 从training set创建dataset, 否则从test set创建dataset.<br>transform (callable, optional) – 输入是一个 PIL image，返回一个transformed的版本。如，transforms.RandomCrop<br>target_transform (callable, optional) – A function/transform that takes in the target and transforms it.<br>download (bool, optional) – If true, downloads the dataset from the internet and puts it in root directory. If dataset is already downloaded, it is not downloaded again.</p><h4 id="例子-2"><a href="#例子-2" class="headerlink" title="例子"></a>例子</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line">trainset = torchvision.datasets.CIFAR100(root=<span class="string">"./datasets"</span>, train=<span class="literal">True</span>, transform=    <span class="literal">None</span>, download=<span class="literal">True</span>)</span><br><span class="line">testset = torchvision.datasets.CIFAR100(root=<span class="string">"./datasets"</span>, train=<span class="literal">False</span>, transform=    <span class="literal">None</span>, download=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><h3 id="torchvision-models"><a href="#torchvision-models" class="headerlink" title="torchvision.models"></a>torchvision.models</h3><p>模型</p><h3 id="torchvision-transforms"><a href="#torchvision-transforms" class="headerlink" title="torchvision.transforms"></a>torchvision.transforms</h3><p>transform</p><h3 id="torchvision-utils"><a href="#torchvision-utils" class="headerlink" title="torchvision.utils"></a>torchvision.utils</h3><p>一些工具包</p><h2 id="torch-utils-data"><a href="#torch-utils-data" class="headerlink" title="torch.utils.data"></a>torch.utils.data</h2><h3 id="Dataloader"><a href="#Dataloader" class="headerlink" title="Dataloader"></a>Dataloader</h3><h4 id="原型-1"><a href="#原型-1" class="headerlink" title="原型"></a>原型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">torch</span>.<span class="title">utils</span>.<span class="title">data</span>.<span class="title">DataLoader</span><span class="params">(dataset, batch_size=<span class="number">1</span>, shuffle=False, sampler=None, batch_sampler=None, num_workers=<span class="number">0</span>, collate_fn=&lt;function default_collate&gt;, pin_memory=False, drop_last=False, timeout=<span class="number">0</span>, worker_init_fn=None)</span></span></span><br></pre></td></tr></table></figure><h4 id="参数-2"><a href="#参数-2" class="headerlink" title="参数"></a>参数</h4><p>dataset (Dataset) – 从哪加载数据<br>batch_size (int, optional) – batch大小 (default: 1).<br>shuffle (bool, optional) – 每个epoch的数据是否打乱 (default: False).<br>sampler (Sampler, optional) – 定义采样策略。如果指定这个参数, shuffle必须是False.<br>batch_sampler (Sampler, optional) – like sampler, but returns a batch of indices at a time. Mutually exclusive with batch_size, shuffle, sampler, and drop_last.<br>num_workers (int, optional) – 多少个子进程用来进行数据加载。0代表使用主进程加载数据 (default: 0)<br>collate_fn (callable, optional) – merges a list of samples to form a mini-batch.<br>pin_memory (bool, optional) – If True, the data loader will copy tensors into CUDA pinned memory before returning them.<br>drop_last (bool, optional) – set to True to drop the last incomplete batch, if the dataset size is not divisible by the batch size. If False and the size of dataset is not divisible by the batch size, then the last batch will be smaller. (default: False)<br>timeout (numeric, optional) – if positive, the timeout value for collecting a batch from workers. Should always be non-negative. (default: 0)<br>worker_init_fn (callable, optional) – If not None, this will be called on each worker subprocess with the worker id (an int in [0, num_workers - 1]) as input, after seeding and before data loading. (default: None)</p><h4 id="例子-3"><a href="#例子-3" class="headerlink" title="例子"></a>例子</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line">dataset = torchvision.datasets.CIFAR100(root=<span class="string">'./data'</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>, transform=<span class="literal">None</span>)</span><br><span class="line">train_loader = torch.utils.data.DataLoader(dataset, bath_size=<span class="number">16</span>, shuffle=<span class="literal">False</span>, num_worker=<span class="number">2</span>)</span><br></pre></td></tr></table></figure><h4 id="如何访问DataLoader返回值"><a href="#如何访问DataLoader返回值" class="headerlink" title="如何访问DataLoader返回值"></a>如何访问DataLoader返回值</h4><p>train_loader不是整数，所以不能用range，这里用enumerate()，i是<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i, data <span class="keyword">in</span> enumerate(train_loader):</span><br><span class="line">    images, labels = data</span><br></pre></td></tr></table></figure></p><h2 id="torch-distributed"><a href="#torch-distributed" class="headerlink" title="torch.distributed"></a>torch.distributed</h2><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>1.<a href="https://pytorch.org/docs/stable/torch.html" target="_blank" rel="noopener">https://pytorch.org/docs/stable/torch.html</a><br>2.<a href="https://pytorch.org/docs/stable/nn.html" target="_blank" rel="noopener">https://pytorch.org/docs/stable/nn.html</a><br>3.<a href="http://pytorch.org/tutorials/beginner/pytorch_with_examples.html" target="_blank" rel="noopener">http://pytorch.org/tutorials/beginner/pytorch_with_examples.html</a><br>4.<a href="https://discuss.pytorch.org/t/distributed-model-parallelism/10377" target="_blank" rel="noopener">https://discuss.pytorch.org/t/distributed-model-parallelism/10377</a><br>5.<a href="https://ptorch.com/news/40.html" target="_blank" rel="noopener">https://ptorch.com/news/40.html</a><br>6.<a href="https://discuss.pytorch.org/t/distributed-data-parallel-freezes-without-error-message/8009" target="_blank" rel="noopener">https://discuss.pytorch.org/t/distributed-data-parallel-freezes-without-error-message/8009</a><br>7.<a href="https://discuss.pytorch.org/t/runtimeerror-cudnn-status-arch-mismatch/3580" target="_blank" rel="noopener">https://discuss.pytorch.org/t/runtimeerror-cudnn-status-arch-mismatch/3580</a><br>8.<a href="https://discuss.pytorch.org/t/error-when-using-cudnn/577/7" target="_blank" rel="noopener">https://discuss.pytorch.org/t/error-when-using-cudnn/577/7</a><br>9.<a href="https://www.zhihu.com/question/67209417" target="_blank" rel="noopener">https://www.zhihu.com/question/67209417</a><br>10.<a href="https://pytorch.org/docs/stable/distributions.html#categorical" target="_blank" rel="noopener">https://pytorch.org/docs/stable/distributions.html#categorical</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;常见问题&quot;&gt;&lt;a href=&quot;#常见问题&quot; class=&quot;headerlink&quot; title=&quot;常见问题&quot;&gt;&lt;/a&gt;常见问题&lt;/h2&gt;&lt;h3 id=&quot;RuntimeError-CUDNN-STATUS-ARCH-MISMATCH&quot;&gt;&lt;a href=&quot;#Runtim
      
    
    </summary>
    
      <category term="python" scheme="http://mxxhcm.github.io/categories/python/"/>
    
    
      <category term="机器学习" scheme="http://mxxhcm.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="python" scheme="http://mxxhcm.github.io/tags/python/"/>
    
      <category term="深度学习" scheme="http://mxxhcm.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="pytorch" scheme="http://mxxhcm.github.io/tags/pytorch/"/>
    
  </entry>
  
  <entry>
    <title>&#39;dict_values&#39; object does not support indexing</title>
    <link href="http://mxxhcm.github.io/2019/03/13/dict-values-object-does-not-support-indexing/"/>
    <id>http://mxxhcm.github.io/2019/03/13/dict-values-object-does-not-support-indexing/</id>
    <published>2019-03-13T02:40:03.000Z</published>
    <updated>2019-05-06T16:22:27.704Z</updated>
    
    <content type="html"><![CDATA[<h2 id="python3-dict"><a href="#python3-dict" class="headerlink" title="python3 dict"></a>python3 dict</h2><p>python3 中调用字典对象的一些函数，返回值是view objects。如果要转换为list的话，需要使用list()强制转换。<br>而python2的返回值直接就是list。</p><blockquote><p>The objects returned by dict.keys(), dict.values() and dict.items() are view objects. They provide a dynamic view on the dictionary’s entries, which means that when the dictionary changes, the view reflects these changes.</p></blockquote><h3 id="代码示例"><a href="#代码示例" class="headerlink" title="代码示例"></a>代码示例</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">m_dict = &#123;<span class="string">'a'</span>: <span class="number">10</span>, <span class="string">'b'</span>: <span class="number">20</span>&#125;</span><br><span class="line">values = m_dict.values()</span><br><span class="line">print(type(values))</span><br><span class="line">print(values)</span><br><span class="line">print(<span class="string">"\n"</span>)</span><br><span class="line"></span><br><span class="line">items = m_dict.items()</span><br><span class="line">print(type(items))</span><br><span class="line">print(items)</span><br><span class="line">print(<span class="string">"\n"</span>)</span><br><span class="line"></span><br><span class="line">keys = m_dict.keys()</span><br><span class="line">print(type(keys))</span><br><span class="line">print(keys)</span><br><span class="line">print(<span class="string">"\n"</span>)</span><br></pre></td></tr></table></figure><p>如果使用python3执行以上代码，输出结果如下所示：</p><blockquote><p>class ‘dict_values’<br>dict_values([10, 20])</p><p>class ‘dict_items’<br>dict_items([(‘a’, 10), (‘b’, 20)])</p><p>class ‘dict_keys’<br>dict_keys([‘a’, ‘b’])</p></blockquote><p>如果使用python2执行以上代码，输出结果如下所示：</p><blockquote><p>type ‘list’<br>[10, 20]                                                                                </p><p>type ‘list’<br>[(‘a’, 10), (‘b’, 20)]                                                                  </p><p>type ‘list’<br>[‘a’, ‘b’]</p></blockquote><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>1.<a href="https://www.cnblogs.com/timxgb/p/8905290.html" target="_blank" rel="noopener">https://www.cnblogs.com/timxgb/p/8905290.html</a><br>2.<a href="https://docs.python.org/3/library/stdtypes.html#dictionary-view-objects" target="_blank" rel="noopener">https://docs.python.org/3/library/stdtypes.html#dictionary-view-objects</a><br>3.<a href="https://stackoverflow.com/questions/43663206/typeerror-unsupported-operand-types-for-dict-values-and-int" target="_blank" rel="noopener">https://stackoverflow.com/questions/43663206/typeerror-unsupported-operand-types-for-dict-values-and-int</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;python3-dict&quot;&gt;&lt;a href=&quot;#python3-dict&quot; class=&quot;headerlink&quot; title=&quot;python3 dict&quot;&gt;&lt;/a&gt;python3 dict&lt;/h2&gt;&lt;p&gt;python3 中调用字典对象的一些函数，返回值是view 
      
    
    </summary>
    
      <category term="Error" scheme="http://mxxhcm.github.io/categories/Error/"/>
    
    
      <category term="python" scheme="http://mxxhcm.github.io/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>markdown帮助</title>
    <link href="http://mxxhcm.github.io/2019/03/09/markdown%E5%B8%AE%E5%8A%A9/"/>
    <id>http://mxxhcm.github.io/2019/03/09/markdown帮助/</id>
    <published>2019-03-09T11:53:32.000Z</published>
    <updated>2019-05-06T16:22:27.708Z</updated>
    
    <content type="html"><![CDATA[<h2 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h2><h3 id="代码引用"><a href="#代码引用" class="headerlink" title="代码引用"></a>代码引用</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br></pre></td></tr></table></figure><h3 id="文字引用"><a href="#文字引用" class="headerlink" title="文字引用"></a>文字引用</h3><blockquote><p>实际是人类进步的阶梯。　－－高尔基</p></blockquote><h2 id="表格"><a href="#表格" class="headerlink" title="表格"></a>表格</h2><div class="table-container"><table><thead><tr><th style="text-align:center">name</th><th style="text-align:center">age</th><th style="text-align:center">gender</th></tr></thead><tbody><tr><td style="text-align:center">Alice</td><td style="text-align:center">11</td><td style="text-align:center">female</td></tr><tr><td style="text-align:center">Bob</td><td style="text-align:center">82</td><td style="text-align:center">male</td></tr></tbody></table></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;引用&quot;&gt;&lt;a href=&quot;#引用&quot; class=&quot;headerlink&quot; title=&quot;引用&quot;&gt;&lt;/a&gt;引用&lt;/h2&gt;&lt;h3 id=&quot;代码引用&quot;&gt;&lt;a href=&quot;#代码引用&quot; class=&quot;headerlink&quot; title=&quot;代码引用&quot;&gt;&lt;/a&gt;代码引用&lt;/h
      
    
    </summary>
    
      <category term="工具" scheme="http://mxxhcm.github.io/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="markdown" scheme="http://mxxhcm.github.io/tags/markdown/"/>
    
  </entry>
  
  <entry>
    <title>tensorflow踩坑（不定期更新）</title>
    <link href="http://mxxhcm.github.io/2019/03/07/tensorflow%E8%B8%A9%E5%9D%91%EF%BC%88%E4%B8%8D%E5%AE%9A%E6%9C%9F%E6%9B%B4%E6%96%B0%EF%BC%89/"/>
    <id>http://mxxhcm.github.io/2019/03/07/tensorflow踩坑（不定期更新）/</id>
    <published>2019-03-07T06:51:01.000Z</published>
    <updated>2019-05-06T16:22:27.708Z</updated>
    
    <content type="html"><![CDATA[<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><ol><li>TypeError: The value of a feed cannot be a tf.Tensor object<br>Sess.run(train, feed_dict={x:images, y:labels}的输入不能是tensor，可以使用sess.run(tensor)得到numpy.array形式的数据再喂给feed_dict。<blockquote><p>Once you have launched a sess, you can use your_tensor.eval(session=sess) or sess.run(your_tensor) to get you feed tensor into the format of numpy.array and then feed it to your placeholder.</p></blockquote></li></ol><h2 id="用法"><a href="#用法" class="headerlink" title="用法"></a>用法</h2><h3 id="tf-app-flags"><a href="#tf-app-flags" class="headerlink" title="tf.app.flags"></a>tf.app.flags</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">flags.py</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">flags = tf.app.flags</span><br><span class="line">flags.DEFINE_string(<span class="string">'model'</span>, <span class="string">'mxx'</span>, <span class="string">'Type of model'</span>)</span><br><span class="line">flags.DEFINE_boolean(<span class="string">'gpu'</span>,<span class="string">'True'</span>, <span class="string">'use gpu?'</span>)</span><br><span class="line">FLAGS = flags.FLAGS</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(_)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> k,v <span class="keyword">in</span> FLAGS.flag_values_dict().items():</span><br><span class="line">        print(k, v)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    tf.app.run(main)</span><br></pre></td></tr></table></figure><p>传递参数的方法有两种，一种是命令行~$:python flags.py —model hhhh ，一种是pycharm中传递参数。</p><h3 id="tf-train-Saver"><a href="#tf-train-Saver" class="headerlink" title="tf.train.Saver()"></a>tf.train.Saver()</h3><h4 id="代码示例-可运行"><a href="#代码示例-可运行" class="headerlink" title="代码示例(可运行)"></a>代码示例(可运行)</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">graph = tf.Graph()</span><br><span class="line"><span class="keyword">with</span> graph.as_default():</span><br><span class="line">    W = tf.Variable([<span class="number">0.3</span>], dtype=tf.float32)</span><br><span class="line">    b = tf.Variable([<span class="number">-0.3</span>], dtype=tf.float32)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># input and output</span></span><br><span class="line">    x = tf.placeholder(tf.float32)</span><br><span class="line">    y = tf.placeholder(tf.float32)</span><br><span class="line">    predicted_y = W*x+b</span><br><span class="line"></span><br><span class="line">    <span class="comment"># MSE loss</span></span><br><span class="line">    loss = tf.reduce_mean(tf.square(y - predicted_y))</span><br><span class="line">    <span class="comment"># optimizer</span></span><br><span class="line">    optimizer = tf.train.GradientDescentOptimizer(<span class="number">0.01</span>)</span><br><span class="line">    train_op = optimizer.minimize(loss)</span><br><span class="line"></span><br><span class="line">inputs = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]</span><br><span class="line">outputs = [<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session(graph=graph) <span class="keyword">as</span> sess:</span><br><span class="line">    saver = tf.train.Saver()</span><br><span class="line">    init_op = tf.global_variables_initializer()</span><br><span class="line">    sess.run(init_op)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">5000</span>):</span><br><span class="line">        sess.run(train_op, feed_dict=&#123;x: inputs, y: outputs&#125;)</span><br><span class="line">    l_, W_, b_ = sess.run([loss, W, b], feed_dict=&#123;x: inputs, y: outputs&#125;)</span><br><span class="line">    print(<span class="string">"loss: "</span>, l_, <span class="string">"w: "</span>, W_, <span class="string">"b:"</span>, b_)</span><br><span class="line">    checkpoint = <span class="string">"./checkpoint/saver1.ckpt"</span></span><br><span class="line">    save_path = saver.save(sess, checkpoint)</span><br><span class="line">    print(<span class="string">"Model has been saved in %s."</span> % save_path)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session(graph=graph) <span class="keyword">as</span> sess:</span><br><span class="line">    saver = tf.train.Saver()</span><br><span class="line">    saver.restore(sess, checkpoint)</span><br><span class="line">    l_, W_, b_ = sess.run([loss, W, b], feed_dict=&#123;x: inputs, y: outputs&#125;)</span><br><span class="line">    print(<span class="string">"loss: "</span>, l_, <span class="string">"w: "</span>, W_, <span class="string">"b:"</span>, b_)</span><br><span class="line">    print(<span class="string">"Model has been restored."</span>)</span><br></pre></td></tr></table></figure><h3 id="tf-summary"><a href="#tf-summary" class="headerlink" title="tf.summary"></a>tf.summary</h3><h4 id="api"><a href="#api" class="headerlink" title="api"></a>api</h4><p>函数<br>tf.summary.scalar(name, tensor, collections=None, family=None)<br>定义一个summary标量</p><p>类<br>tf.summary.FileWriter(self, logdir,　graph=None, max_queue=10,flush_secs=120, graph_def=None, filename_suffix=None)<br>定义将数据写入文件的类</p><p>类内函数<br>tf.summary.FileWriter.add_summary(self, summary, global_step=None)<br>将summary类型变量转换为事件 </p><h4 id="代码示例-无法运行"><a href="#代码示例-无法运行" class="headerlink" title="代码示例(无法运行)"></a>代码示例(无法运行)</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">summary_loss = tf.summary.scalar(<span class="string">'loss'</span>, loss)</span><br><span class="line">summary_weights = tf.summary.scalar(<span class="string">'weights'</span>, weights)</span><br><span class="line">writer = tf.summary.FileWriter(<span class="string">"./summary/"</span>)</span><br><span class="line">sess = tf.Session()</span><br><span class="line">loss_, weights_ = sess.run([summary_loss, summary_weights], feed_dict=&#123;&#125;)</span><br><span class="line">writer.add_summary(loss_)</span><br><span class="line">writer.add_summary(weights_)</span><br><span class="line"><span class="comment"># 或者先把loss和weights merge 一下，然后再run</span></span><br><span class="line">merged = tf.summary.merge_all()</span><br><span class="line">merged_ = sess.rum([merged], feed_dict=&#123;&#125;)</span><br><span class="line">writer.add_summary(merged_, global_step)</span><br></pre></td></tr></table></figure><p>使用tensorboard —logdir ./summary/打开tensorboard</p><h3 id="tf-multinomial"><a href="#tf-multinomial" class="headerlink" title="tf.multinomial"></a>tf.multinomial</h3><p>多项分布，采样。<br>如下<a href="https://github.com/mxxhcm/myown_code/blob/master/tf/some_ops/tf_multinominal.py" target="_blank" rel="noopener">示例</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># tf.multinomial(logits, num_samples, seed=None, name=None)</span></span><br><span class="line"><span class="comment"># logits 是一个二维张量，指定概率，num_samples是采样个数</span></span><br><span class="line">sess = tf.Session()</span><br><span class="line">sample = tf.multinomial([[<span class="number">5.0</span>, <span class="number">5.0</span>, <span class="number">5.0</span>], [<span class="number">5.0</span>, <span class="number">4</span>, <span class="number">3</span>]], <span class="number">10</span>) <span class="comment"># 注意logits必须是float</span></span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">5</span>):</span><br><span class="line">  print(sess.run(sample))</span><br></pre></td></tr></table></figure></p><p>输出结果如下:</p><blockquote><p>[[2 1 2 1 0 2 1 1 1 0]<br> [1 0 0 1 0 1 0 1 0 0]]<br>[[2 2 0 2 2 0 2 0 1 2]<br> [1 0 0 2 0 1 0 1 1 0]]<br>[[0 0 0 2 0 0 1 2 0 1]<br> [0 0 0 1 0 1 0 0 0 0]]<br>[[2 1 0 1 1 1 0 0 2 0]<br> [1 0 0 2 0 0 0 0 0 1]]<br>[[1 0 1 0 0 1 2 2 0 0]<br> [1 0 0 0 0 1 1 1 2 0]]</p></blockquote><h3 id="tf-max"><a href="#tf-max" class="headerlink" title="tf.max"></a>tf.max</h3><h4 id="tf-maximum"><a href="#tf-maximum" class="headerlink" title="tf.maximum"></a>tf.maximum</h4><p>比较两个tensor，返回element-wise两个tensor的最大值。<br>如下<a href="https://github.com/mxxhcm/myown_code/blob/master/tf/some_ops/tf_maximum.py" target="_blank" rel="noopener">示例</a>：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">sess = tf.Session()</span><br><span class="line">a = tf.Variable([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">b = tf.Variable([<span class="number">2</span>, <span class="number">1</span>, <span class="number">4</span>])</span><br><span class="line"></span><br><span class="line">sess.run(tf.global_variables_initializer())</span><br><span class="line">print(<span class="string">"a: "</span>, sess.run(a))</span><br><span class="line">print(<span class="string">"b: "</span>, sess.run(b))</span><br><span class="line">c = tf.maximum(a, b)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"tf.maximum(a, b):\n  "</span>, sess.run(c))</span><br></pre></td></tr></table></figure></p><p>输出如下：</p><blockquote><p>a:  [1 2 3]<br>b:  [2 1 4]<br>tf.maximum(a, b):<br>   [2 2 4]</p></blockquote><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>1.<a href="https://github.com/tensorflow/tensorflow/issues/4842" target="_blank" rel="noopener">https://github.com/tensorflow/tensorflow/issues/4842</a><br>2.<a href="https://www.bilibili.com/read/cv681031/" target="_blank" rel="noopener">https://www.bilibili.com/read/cv681031/</a><br>3.<a href="https://cv-tricks.com/tensorflow-tutorial/save-restore-tensorflow-models-quick-complete-tutorial/" target="_blank" rel="noopener">https://cv-tricks.com/tensorflow-tutorial/save-restore-tensorflow-models-quick-complete-tutorial/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;问题&quot;&gt;&lt;a href=&quot;#问题&quot; class=&quot;headerlink&quot; title=&quot;问题&quot;&gt;&lt;/a&gt;问题&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;TypeError: The value of a feed cannot be a tf.Tensor object&lt;br&gt;S
      
    
    </summary>
    
      <category term="python" scheme="http://mxxhcm.github.io/categories/python/"/>
    
    
      <category term="机器学习" scheme="http://mxxhcm.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="tensorflow" scheme="http://mxxhcm.github.io/tags/tensorflow/"/>
    
      <category term="深度学习" scheme="http://mxxhcm.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>pip 使用国内源</title>
    <link href="http://mxxhcm.github.io/2019/03/07/python-pip-%E4%BD%BF%E7%94%A8%E5%9B%BD%E5%86%85%E6%BA%90/"/>
    <id>http://mxxhcm.github.io/2019/03/07/python-pip-使用国内源/</id>
    <published>2019-03-07T01:56:54.000Z</published>
    <updated>2019-05-06T16:51:39.146Z</updated>
    
    <content type="html"><![CDATA[<h2 id="暂时使用国内pip源"><a href="#暂时使用国内pip源" class="headerlink" title="暂时使用国内pip源"></a>暂时使用国内pip源</h2><p>使用清华源<br>~#:pip install -i <a href="https://pypi.tuna.tsinghua.edu.cn/simple" target="_blank" rel="noopener">https://pypi.tuna.tsinghua.edu.cn/simple</a> package-name<br>使用阿里源<br>~#:pip install -i <a href="https://mirrors.aliyun.com/pypi/simple" target="_blank" rel="noopener">https://mirrors.aliyun.com/pypi/simple</a> package-name</p><h2 id="将国内pip源设为默认"><a href="#将国内pip源设为默认" class="headerlink" title="将国内pip源设为默认"></a>将国内pip源设为默认</h2><p>~#:pip install pip -U<br>~#:pip config set global.index-url <a href="https://pypi.tuna.tsinghua.edu.cn/simple" target="_blank" rel="noopener">https://pypi.tuna.tsinghua.edu.cn/simple</a></p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>1.<a href="https://mirrors.tuna.tsinghua.edu.cn/help/pypi/" target="_blank" rel="noopener">https://mirrors.tuna.tsinghua.edu.cn/help/pypi/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;暂时使用国内pip源&quot;&gt;&lt;a href=&quot;#暂时使用国内pip源&quot; class=&quot;headerlink&quot; title=&quot;暂时使用国内pip源&quot;&gt;&lt;/a&gt;暂时使用国内pip源&lt;/h2&gt;&lt;p&gt;使用清华源&lt;br&gt;~#:pip install -i &lt;a href=&quot;ht
      
    
    </summary>
    
      <category term="工具" scheme="http://mxxhcm.github.io/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="python" scheme="http://mxxhcm.github.io/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>lychee图床搭建</title>
    <link href="http://mxxhcm.github.io/2019/03/04/lychee%E5%9B%BE%E5%BA%8A%E6%90%AD%E5%BB%BA/"/>
    <id>http://mxxhcm.github.io/2019/03/04/lychee图床搭建/</id>
    <published>2019-03-04T13:03:55.000Z</published>
    <updated>2019-05-06T16:22:27.708Z</updated>
    
    <content type="html"><![CDATA[<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><h3 id="基本要求"><a href="#基本要求" class="headerlink" title="基本要求"></a>基本要求</h3><ol><li>web server (Apache, nginx, etc)</li><li>A MySQL database (MariaDB also works)</li><li>PHP 7.1 or later with the following extensions: session, exif, mbstring, gd, mysqli, json, zip, and optionally, imagick<br>~#:apt install nginx<br>~#:apt install mysql-server<br>~#:apt install php<h3 id="配置nginx"><a href="#配置nginx" class="headerlink" title="配置nginx"></a>配置nginx</h3>重新安装nginx出现问题，见参考文献2。<h3 id="配置mysql"><a href="#配置mysql" class="headerlink" title="配置mysql"></a>配置mysql</h3>~#:mysql -u root -p<br>默认密码是回车？？？<br>修改密码<br>~#:</li></ol><h3 id="配置php"><a href="#配置php" class="headerlink" title="配置php"></a>配置php</h3><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>1.<a href="https://juejin.im/post/5c1b869b6fb9a049ad770424" target="_blank" rel="noopener">https://juejin.im/post/5c1b869b6fb9a049ad770424</a><br>2.<a href="https://segmentfault.com/a/1190000014027697?utm_source=tag-newest" target="_blank" rel="noopener">https://segmentfault.com/a/1190000014027697?utm_source=tag-newest</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;安装&quot;&gt;&lt;a href=&quot;#安装&quot; class=&quot;headerlink&quot; title=&quot;安装&quot;&gt;&lt;/a&gt;安装&lt;/h2&gt;&lt;h3 id=&quot;基本要求&quot;&gt;&lt;a href=&quot;#基本要求&quot; class=&quot;headerlink&quot; title=&quot;基本要求&quot;&gt;&lt;/a&gt;基本要求&lt;/h
      
    
    </summary>
    
      <category term="工具" scheme="http://mxxhcm.github.io/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="图床" scheme="http://mxxhcm.github.io/tags/%E5%9B%BE%E5%BA%8A/"/>
    
  </entry>
  
  <entry>
    <title>查看python package的安装位置</title>
    <link href="http://mxxhcm.github.io/2019/03/04/%E6%9F%A5%E7%9C%8Bpython-package%E7%9A%84%E5%AE%89%E8%A3%85%E4%BD%8D%E7%BD%AE/"/>
    <id>http://mxxhcm.github.io/2019/03/04/查看python-package的安装位置/</id>
    <published>2019-03-04T06:52:16.000Z</published>
    <updated>2019-05-06T16:22:27.708Z</updated>
    
    <content type="html"><![CDATA[<p>使用pip install package-name之后，不知道该包存在了哪个路径下。<br>可以再次使用pip install package-name，这时候就会给出该包存放在哪个路径下。</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ol><li><a href="https://blog.csdn.net/weixin_41712059/article/details/82940516" target="_blank" rel="noopener">https://blog.csdn.net/weixin_41712059/article/details/82940516</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;使用pip install package-name之后，不知道该包存在了哪个路径下。&lt;br&gt;可以再次使用pip install package-name，这时候就会给出该包存放在哪个路径下。&lt;/p&gt;
&lt;h2 id=&quot;参考文献&quot;&gt;&lt;a href=&quot;#参考文献&quot; class=
      
    
    </summary>
    
      <category term="工具" scheme="http://mxxhcm.github.io/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="python" scheme="http://mxxhcm.github.io/tags/python/"/>
    
      <category term="技巧" scheme="http://mxxhcm.github.io/tags/%E6%8A%80%E5%B7%A7/"/>
    
  </entry>
  
  <entry>
    <title>shadowsocks服务端以及客户端配置</title>
    <link href="http://mxxhcm.github.io/2019/03/04/shadowsocks%E6%9C%8D%E5%8A%A1%E7%AB%AF%E4%BB%A5%E5%8F%8A%E5%AE%A2%E6%88%B7%E7%AB%AF%E9%85%8D%E7%BD%AE/"/>
    <id>http://mxxhcm.github.io/2019/03/04/shadowsocks服务端以及客户端配置/</id>
    <published>2019-03-04T05:03:57.000Z</published>
    <updated>2019-05-06T16:22:27.708Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-服务器端配置"><a href="#1-服务器端配置" class="headerlink" title="1.服务器端配置"></a>1.服务器端配置</h2><p>首先需要有一个VPS账号，vultr,digitalocean,搬瓦工等等都行。</p><h3 id="1-1-启用BBR加速"><a href="#1-1-启用BBR加速" class="headerlink" title="1.1.启用BBR加速"></a>1.1.启用BBR加速</h3><p>~#:apt update<br>~#:apt upgrade<br>~#:echo “net.core.default_qdisc=fq” &gt;&gt; /etc/sysctl.conf<br>~#:echo “net.ipv4.tcp_congestion_control=bbr” &gt;&gt; /etc/sysctl.conf<br>~#:sysctl -p<br>上述命令就完成了BBR加速，执行以下命令验证：<br>~#:lsmod |grep bbr<br>看到输出包含tcp_bbr就说明已经成功了。</p><h3 id="1-2-搭建shadowsocks-server"><a href="#1-2-搭建shadowsocks-server" class="headerlink" title="1.2.搭建shadowsocks server"></a>1.2.搭建shadowsocks server</h3><h4 id="1-2-1-安装shadowsocks-server"><a href="#1-2-1-安装shadowsocks-server" class="headerlink" title="1.2.1.安装shadowsocks server"></a>1.2.1.安装shadowsocks server</h4><p>~#:apt install python-pip<br>~#:pip install shadowsocks</p><h4 id="1-2-2-创建shadowsocks配置文件"><a href="#1-2-2-创建shadowsocks配置文件" class="headerlink" title="1.2.2.创建shadowsocks配置文件"></a>1.2.2.创建shadowsocks配置文件</h4><p>如果你的VPS支持ipv6的话，那么可以开多进程分别运行ipv4和ipv6的shadowsocks server。本地只有ipv4的话，可以用本地ipv4访问ipv6，从而访问byr等网站，但是六维空间对此做了屏蔽。如果本地有ipv6的话，还可以用本地的ipv6访问ipv6实现校园网不走ipv4流量。</p><h5 id="1-2-2-1-ipv4配置"><a href="#1-2-2-1-ipv4配置" class="headerlink" title="1.2.2.1.ipv4配置"></a>1.2.2.1.ipv4配置</h5><p>~#:vim /etc/shadowsocks_v4.json<br>配置文件如下<br>{<br>“server”:”0.0.0.0”,<br>“server_port”:8889,<br>“local_address”:”127.0.0.1”,<br>“local_port”:1080,<br>“password”:”你的密码”,<br>“timeout”:600,<br>“method”:”aes-256-cfb”<br>}</p><h5 id="1-2-2-2-ipv6配置"><a href="#1-2-2-2-ipv6配置" class="headerlink" title="1.2.2.2.ipv6配置"></a>1.2.2.2.ipv6配置</h5><p>~#:vim /etc/shadowsocks_v6.json<br>配置文件如下<br>{<br>“server”:”::”,<br>“server_port”:8888,<br>“local_address”:”127.0.0.1”,<br>“local_port”:1080,<br>“password”:”你的密码”,<br>“timeout”:600,<br>“method”:”aes-256-cfb”<br>}<br>注意这两个文件的server_port一定要不同，以及双引号必须是英文引号。</p><h5 id="1-2-2-3-手动运行shadowsocks-server"><a href="#1-2-2-3-手动运行shadowsocks-server" class="headerlink" title="1.2.2.3.手动运行shadowsocks server"></a>1.2.2.3.手动运行shadowsocks server</h5><p>~#:ssserver -c /etc/shadowsock_v4.json -d start —pid-file ss1.pid<br>~#:ssserver -c /etc/shadowsock_v6.json -d start —pid-file ss2.pid<br>注意这里要给两条命令分配不同的进程号。</p><h3 id="1-3-设置shadowsocks-server开机自启"><a href="#1-3-设置shadowsocks-server开机自启" class="headerlink" title="1.3.设置shadowsocks server开机自启"></a>1.3.设置shadowsocks server开机自启</h3><p>如果重启服务器的话，就需要重新手动执行上述命令，这里我们可以把它写成开机自启脚本。<br>~#:vim /etc/init.d/shadowsocks_v4<br>内容如下：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>!/bin/sh</span><br><span class="line"><span class="meta">#</span>## BEGIN INIT INFO</span><br><span class="line"><span class="meta">#</span> Provides:          apache2</span><br><span class="line"><span class="meta">#</span> Required-Start:    $local_fs $remote_fs $network $syslog</span><br><span class="line"><span class="meta">#</span> Required-Stop:     $local_fs $remote_fs $network $syslog</span><br><span class="line"><span class="meta">#</span> Default-Start:     2 3 4 5</span><br><span class="line"><span class="meta">#</span> Default-Stop:      0 1 6</span><br><span class="line"><span class="meta">#</span> Short-Description: apache2 service</span><br><span class="line"><span class="meta">#</span> Description:       apache2 service daemon</span><br><span class="line"><span class="meta">#</span>## END INIT INFO</span><br><span class="line">start()&#123;</span><br><span class="line">  ssserver -c /etc/shadowsocks_v4.json -d start --pid-file ss2.pid</span><br><span class="line">&#125;</span><br><span class="line">stop()&#123;</span><br><span class="line">  ssserver -c /etc/shadowsocks_v4.json -d stop --pid-file ss2.pid</span><br><span class="line">&#125;</span><br><span class="line">case "$1" in</span><br><span class="line">start)</span><br><span class="line">  start</span><br><span class="line">  ;;</span><br><span class="line">stop)</span><br><span class="line">  stop</span><br><span class="line">  ;;</span><br><span class="line">restart)</span><br><span class="line">  stop</span><br><span class="line">  start</span><br><span class="line">  ;;</span><br><span class="line">*)</span><br><span class="line">  echo "Uasage: $0 &#123;start|reload|stop&#125;$"</span><br><span class="line">  exit 1</span><br><span class="line">  ;;</span><br><span class="line">esac</span><br></pre></td></tr></table></figure></p><p>~#:vim /etc/init.d/shadowsocks_v6<br>内容如下：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>!/bin/sh</span><br><span class="line"><span class="meta">#</span>## BEGIN INIT INFO</span><br><span class="line"><span class="meta">#</span> Provides:          apache2</span><br><span class="line"><span class="meta">#</span> Required-Start:    $local_fs $remote_fs $network $syslog</span><br><span class="line"><span class="meta">#</span> Required-Stop:     $local_fs $remote_fs $network $syslog</span><br><span class="line"><span class="meta">#</span> Default-Start:     2 3 4 5</span><br><span class="line"><span class="meta">#</span> Default-Stop:      0 1 6</span><br><span class="line"><span class="meta">#</span> Short-Description: apache2 service</span><br><span class="line"><span class="meta">#</span> Description:       apache2 service daemon</span><br><span class="line"><span class="meta">#</span>## END INIT INFO</span><br><span class="line">start()&#123;</span><br><span class="line">  ssserver -c /etc/shadowsocks_v6.json -d start --pid-file ss1.pid</span><br><span class="line">&#125;</span><br><span class="line">stop()&#123;</span><br><span class="line">  ssserver -c /etc/shadowsocks_v6.json -d stop --pid-file ss1.pid</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">case "$1" in</span><br><span class="line">start)</span><br><span class="line">  start</span><br><span class="line">  ;;</span><br><span class="line">stop)</span><br><span class="line">  stop</span><br><span class="line">  ;;</span><br><span class="line">restart)</span><br><span class="line">  stop</span><br><span class="line">  start</span><br><span class="line">  ;;</span><br><span class="line">*)</span><br><span class="line">  echo "Uasage: $0 &#123;start|reload|stop&#125;$"</span><br><span class="line">  exit 1</span><br><span class="line">  ;;</span><br><span class="line">esac</span><br></pre></td></tr></table></figure></p><p>然后执行下列命令即可：<br>~#:chmod a+x /etc/init.d/shadowsocks_v4<br>~#:chmod a+x /etc/init.d/shadowsocks_v6<br>~#:update-rc.d shadowsocks_v4 defaults<br>~#:update-rc.d shadowsocks_v6 defaults</p><p>至此，服务器端配置完成。</p><h2 id="2-客户端配置"><a href="#2-客户端配置" class="headerlink" title="2.客户端配置"></a>2.客户端配置</h2><h3 id="2-1-Windows客户端配置"><a href="#2-1-Windows客户端配置" class="headerlink" title="2.1.Windows客户端配置"></a>2.1.Windows客户端配置</h3><h4 id="2-1-1安装shadowsock客户端"><a href="#2-1-1安装shadowsock客户端" class="headerlink" title="2.1.1安装shadowsock客户端"></a>2.1.1安装shadowsock客户端</h4><p>到该网址 <a href="https://github.com/shadowsocks/shadowsocks-windows/releases" target="_blank" rel="noopener">https://github.com/shadowsocks/shadowsocks-windows/releases</a> 下载相应的windows客户端程序。<br>然后配置服务器即可～</p><h3 id="2-2-Linux客户端配置"><a href="#2-2-Linux客户端配置" class="headerlink" title="2.2.Linux客户端配置"></a>2.2.Linux客户端配置</h3><h4 id="2-2-1-安装shadowsocks程序"><a href="#2-2-1-安装shadowsocks程序" class="headerlink" title="2.2.1.安装shadowsocks程序"></a>2.2.1.安装shadowsocks程序</h4><p>~$:sudo pip install shadowsocks</p><h4 id="2-2-2-运行shadowsocks客户端程序"><a href="#2-2-2-运行shadowsocks客户端程序" class="headerlink" title="2.2.2.运行shadowsocks客户端程序"></a>2.2.2.运行shadowsocks客户端程序</h4><p>~$:sudo vim /etc/shadowsocks.json<br>填入以下配置文件<br>{<br>“server”:”填上自己的shadowsocks server ip地址”,<br>“server_port”:”8888”,//填上自己的shadowsocks server 端口”<br>“local_port”:1080,<br>“password”:”mxxhcm150929”,<br>“timeout”:600,<br>“method”:”aes-256-cfb”<br>}</p><p>接下来可以执行以下命令运行shadowsocks客户端：<br>~$:sudo sslocal -c /etc/shadowsocks.json<br>然后报错：</p><blockquote><p>INFO: loading config from /etc/shadowsocks.json<br>2019-03-04 14:37:49 INFO     loading libcrypto from libcrypto.so.1.1<br>Traceback (most recent call last):<br>  File “/usr/local/bin/sslocal”, line 11, in <module><br>    load<em>entry<em>point(‘shadowsocks==2.8.2’, ‘console<em>scripts’, ‘sslocal’)()<br>  File “/usr/local/lib/python2.7/dist-packages/shadowsocks/local.py”, line 39, in main<br>    config = shell.get<em>config(True)<br>  File “/usr/local/lib/python2.7/dist-packages/shadowsocks/shell.py”, line 262, in get<em>config<br>    check<em>config(config, is<em>local)<br>  File “/usr/local/lib/python2.7/dist-packages/shadowsocks/shell.py”, line 124, in check<em>config<br>    encrypt.try<em>cipher(config[‘password’], config[‘method’])<br>  File “/usr/local/lib/python2.7/dist-packages/shadowsocks/encrypt.py”, line 44, in try<em>cipher<br>    Encryptor(key, method)<br>  File “/usr/local/lib/python2.7/dist-packages/shadowsocks/encrypt.py”, line 83, in <strong>init</strong><br>    random<em>string(self.<em>method_info[1]))<br>  File “/usr/local/lib/python2.7/dist-packages/shadowsocks/encrypt.py”, line 109, in get_cipher<br>    return m<a href="method, key, iv, op">2</a><br>  File “/usr/local/lib/python2.7/dist-packages/shadowsocks/crypto/openssl.py”, line 76, in __init</em></em><br>    load_openssl()<br>  File “/usr/local/lib/python2.7/dist-packages/shadowsocks/crypto/openssl.py”, line 52, in load_openssl<br>    libcrypto.EVP_CIPHER_CTX_cleanup.argtypes = (c_void_p,)<br>  File “/usr/lib/python2.7/ctypes/__init</em></em>.py”, line 379, in __getattr</em></em><br>    func = self.__getitem</em></em>(name)<br>  File “/usr/lib/python2.7/ctypes/__init</em></em>.py”, line 384, in __getitem</em></em><br>    func = self._FuncPtr((name_or_ordinal, self))<br>AttributeError: /usr/lib/x86_64-linux-gnu/libcrypto.so.1.1: undefined symbol: EVP_CIPHER_CTX_cleanup</module></p></blockquote><p>按照参考文献4的做法，是在openssl 1.1.0版本中放弃了EVP_CIPHER_CTX_cleanup函数</p><blockquote><p>EVP_CIPHER_CTX was made opaque in OpenSSL 1.1.0. As a result, EVP_CIPHER_CTX_reset() appeared and EVP_CIPHER_CTX_cleanup() disappeared.<br>EVP_CIPHER_CTX_init() remains as an alias for EVP_CIPHER_CTX_reset().</p></blockquote><p>将openssl库中的EVP_CIPHER_CTX_cleanup改为EVP_CIPHER_CTX_reset即可。<br>再次执行以下命令，查看shadowsocks安装位置<br>~#:pip install shadowsocks<br>Requirement already satisfied: shadowsocks in /usr/local/lib/python2.7/dist-packages<br>~#:cd /usr/local/lib/python2.7/dist-packages/shadowsocks<br>~#:vim crypto/openssl.py<br>搜索cleanup，将其替换为reset<br>具体位置在第52行libcrypto.EVP_CIPHER_CTX_cleanup.argtypes = (c_void_p,)和第111行libcrypto.EVP_CIPHER_CTX_cleanup(self._ctx) </p><h4 id="2-2-3-开机自启shadowsocks-client"><a href="#2-2-3-开机自启shadowsocks-client" class="headerlink" title="2.2.3.开机自启shadowsocks client"></a>2.2.3.开机自启shadowsocks client</h4><p>但是这样子的话，每次开机都要重新运行上述命令，太麻烦了。可以写个开机自启脚本。执行以下命令：<br>~$:sudo vim /etc/init.d/shadowsocks<br>内容为以下shell脚本</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>!/bin/sh</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span>## BEGIN INIT INFO</span><br><span class="line"><span class="meta">#</span> Provides:          shadowsocks local</span><br><span class="line"><span class="meta">#</span> Required-Start:    $local_fs $remote_fs $network $syslog</span><br><span class="line"><span class="meta">#</span> Required-Stop:     $local_fs $remote_fs $network $syslog</span><br><span class="line"><span class="meta">#</span> Default-Start:     2 3 4 5</span><br><span class="line"><span class="meta">#</span> Default-Stop:      0 1 6</span><br><span class="line"><span class="meta">#</span> Short-Description: shadowsocks service</span><br><span class="line"><span class="meta">#</span> Description:       shadowsocks service daemon</span><br><span class="line"><span class="meta">#</span>## END INIT INFO</span><br><span class="line">start()&#123;</span><br><span class="line">　　  sslocal -c /etc/shadowsocks.json -d start</span><br><span class="line">&#125;</span><br><span class="line">stop()&#123;</span><br><span class="line">　　  sslocal -c /etc/shadowsocks.json -d stop</span><br><span class="line">&#125;</span><br><span class="line">case “$1” in</span><br><span class="line">start)</span><br><span class="line">　　　start</span><br><span class="line">　　　;;</span><br><span class="line">stop)</span><br><span class="line">　　　stop</span><br><span class="line">　　　;;</span><br><span class="line">reload)</span><br><span class="line">　　　stop</span><br><span class="line">　　　start</span><br><span class="line">　　　;;</span><br><span class="line">*)</span><br><span class="line">　　　echo “Usage: $0 &#123;start|reload|stop&#125;”</span><br><span class="line">　　　exit 1</span><br><span class="line">　　　;;</span><br><span class="line">esac</span><br></pre></td></tr></table></figure><p>然后执行以下命令即可：<br>~$:sudo chomod a+x /etc/init.d/shadowsocks<br>~$:sudo update_rc.d shadowsocks defaults<br>上述命令执行完成以后，进行测试<br>~$:sudo service shadosowcks start</p><h4 id="2-2-4-配置代理"><a href="#2-2-4-配置代理" class="headerlink" title="2.2.4.配置代理"></a>2.2.4.配置代理</h4><p>上一步的目的是建立了shadowsocks服务的本地客户端，socks5流量会走该通道，但是浏览器的网页的流量是https的，我们需要配置相应的代理，将https流量转换为socks5流量，走ss客户端到达ss服务端。当然，也可以把其他各种流量，如tcp,udp等各种流量都转换为socks5流量，这个可以通过全局代理实现，也可以通过添加特定的代理规则实现。</p><h5 id="2-2-4-1-配置全局代理"><a href="#2-2-4-1-配置全局代理" class="headerlink" title="2.2.4.1.配置全局代理"></a>2.2.4.1.配置全局代理</h5><p>如下图所示，添加ubuntu socks5系统代理：</p><p>然后就可以成功上网了。</p><h5 id="2-2-4-2-使用SwitchyOmega配置chrome代理"><a href="#2-2-4-2-使用SwitchyOmega配置chrome代理" class="headerlink" title="2.2.4.2.使用SwitchyOmega配置chrome代理"></a>2.2.4.2.使用SwitchyOmega配置chrome代理</h5><p>首先到 <a href="https://github.com/FelisCatus/SwitchyOmega/releases" target="_blank" rel="noopener">https://github.com/FelisCatus/SwitchyOmega/releases</a> 下载SyitchyOmega.crx。然后在chrome的地址栏输入chrome://extensions，将刚才下载的插件拖进去。<br>然后在浏览器右上角就有了这个插件，接下来配置插件。如下图：<br><img src="https:" alt="mxx"><br>直接配置proxy，添加如图所示的规则，这样chrome打开的所有网站都是走代理的。</p><h2 id="3-参考文献"><a href="#3-参考文献" class="headerlink" title="3.参考文献"></a>3.参考文献</h2><ol><li><a href="http://godjose.com/2017/06/14/new-article/" target="_blank" rel="noopener">http://godjose.com/2017/06/14/new-article/</a></li><li><a href="https://www.polarxiong.com/archives/搭建ipv6-VPN-让ipv4上ipv6-下载速度提升到100M.html" target="_blank" rel="noopener">https://www.polarxiong.com/archives/搭建ipv6-VPN-让ipv4上ipv6-下载速度提升到100M.html</a></li><li><a href="https://blog.csdn.net/li1914309758/article/details/86510127" target="_blank" rel="noopener">https://blog.csdn.net/li1914309758/article/details/86510127</a></li><li><a href="https://blog.csdn.net/blackfrog_unique/article/details/60320737" target="_blank" rel="noopener">https://blog.csdn.net/blackfrog_unique/article/details/60320737</a></li><li><a href="https://blog.csdn.net/qq_31851531/article/details/78410146" target="_blank" rel="noopener">https://blog.csdn.net/qq_31851531/article/details/78410146</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;1-服务器端配置&quot;&gt;&lt;a href=&quot;#1-服务器端配置&quot; class=&quot;headerlink&quot; title=&quot;1.服务器端配置&quot;&gt;&lt;/a&gt;1.服务器端配置&lt;/h2&gt;&lt;p&gt;首先需要有一个VPS账号，vultr,digitalocean,搬瓦工等等都行。&lt;/p&gt;
&lt;
      
    
    </summary>
    
      <category term="工具" scheme="http://mxxhcm.github.io/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="科学上网" scheme="http://mxxhcm.github.io/tags/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/"/>
    
      <category term="shadowsocks" scheme="http://mxxhcm.github.io/tags/shadowsocks/"/>
    
      <category term="google" scheme="http://mxxhcm.github.io/tags/google/"/>
    
  </entry>
  
  <entry>
    <title>DQN</title>
    <link href="http://mxxhcm.github.io/2019/03/02/DQN/"/>
    <id>http://mxxhcm.github.io/2019/03/02/DQN/</id>
    <published>2019-03-02T11:29:35.000Z</published>
    <updated>2019-05-06T16:22:27.700Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Playing-Atari-with-Deep-Reinforcement-Learning"><a href="#Playing-Atari-with-Deep-Reinforcement-Learning" class="headerlink" title="Playing Atari with Deep Reinforcement Learning"></a>Playing Atari with Deep Reinforcement Learning</h2><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>本文首次成功的将深度学习模型应用到强化学习领域，直接从高维的感知输入中学习控制策略。作者提出用一个卷积神经网络来表示值函数，用Q-learning算法的变种来训练这个神经网络。神经网络的输入是原始的图片信息，输出是这个图片对应状态的估计值函数。<br>Atari 2600是一个强化学习的benchmark，共有2600个游戏，每个智能体会得到一个高维的图像输入(210 x 160 RGB视频60Hz)。本文的目标是设计出一个神经网络能够尽可能成功的学会更多的游戏，这个网络的输入只有视频信息，reward和terminal信号以及可能采取的action，和人类玩家得到的信息是一模一样的，当然是计算机能看得懂的信号。</p><h3 id="存在的问题"><a href="#存在的问题" class="headerlink" title="存在的问题"></a>存在的问题</h3><ol><li>目前绝大多数深度学习问题都需要大量有标记的训练数据。</li><li>强化学习需要从一个稀疏的，有噪音的，通常是time-delayed(延迟的)标量信号中学习。这个延迟存在于action和reward之间，而且可以达到几千个时间步那么远，和监督学习中输入和输入之间关系相比要复杂的多。</li><li>绝大多数深度学习算法假设样本之间都是独立的，然而强化学习的一个sequence(序列)通常是高度相关的。</li><li>当强化学习算法学习到一个新的行为时，数据服从的分布可能会改变，然而深度学习通常假设数据服从一个固定的分布。</li></ol><h3 id="方案"><a href="#方案" class="headerlink" title="方案"></a>方案</h3><h4 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h4><ol><li>智能体与环境进行交互，这里的环境是Atari模拟器。智能体不能观测到模拟器的内部状态，只能得到当前屏幕的一个数字化表示。注意目前智能体的得分取决于之间所有序列上的action和observation。一个action的feedback可能等到好几千个timesteps之后才能得到。</li><li>因为智能体只能得到当前屏幕上的图像，所以这个task可以认为是部分可观测的，因为仅仅从当前的屏幕图像$x_t$上是不能完全理解当前的状况的。所有的序列都认为在有限步骤内是会结束的。</li><li>智能体的目标是通过采取action和智能体交互最大化未来的reward。定义$t$时刻的回报return为$R<em>t = \sum^T</em>{t’=t}\gamma^{t’-t}r_{t’}$，其中$\gamma$是折扣因子，$T$是游戏终止的时间步。</li><li>定义最优的动作值函数$Q^{*}(s,a)$是遵循某个最优策略在状态$s$处采取动作$a$能获得的最大的期望回报，$Q^{*(s,a)} = max_{\pi}E[R_t|s_t=s,a_t=a,\pi]$。</li><li>最优的动作值函数遵循Bellman equation。如果在下个时间步的状态$s’$处，对于所有可能的$a’$，$Q^{*}(s’,a’)$的最优值是已知的（这里就是对于每一个$a’$，都会有一个最优的$Q(s’,a’)$，最优的策略就是选择最大化$r+Q^{*}(s’,a’)$的动作$a’$：<script type="math/tex; mode=display">Q^{*}(s,a) = E_{s\sim E}[r+ \gamma max_{a'} Q^{*}(s',a')|s,a]</script>强化学习的一个思路就是使用Bellman equation更新动作值函数，$Q_{i+1}(s,a) = E[r + \gamma Q_i(s’,a’)|s,a]$，当$i\rightarrow \infty$时，$Q_i \rightarrow Q^{*}$。</li><li>在实践中，上述的方法是不可行的，因为动作值函数是基于每一个序列进行评估的，并没有进行泛化，当有无穷多个序列的时候，这就是不可行的，这时候可以采用函数来估计动作值函数，$Q(s,a;\theta) \approx Q^{*}(s,a)$。一般来说，通常采用线性函数进行估计，当然可以采用非线性的函数，如神经网络等等。这里就采用神经网络，用$\theta$表示网络的参数，这里我们把这个网络叫做Q网络，Q网络可以通过最小化下列loss进行训练：<script type="math/tex; mode=display">L_i(\theta_i) = E_{s,a\sim \rho(\cdot)}\left[(y_i - Q(s,a;\theta_i))^2\right]</script>其中$y<em>i = E</em>{s’\sim E}[r+\gamma max<em>{a’}Q(s’,a’;\theta</em>{i-1})]$是第$i$次迭代的target值，其中$\rho(s,a)$是$(s,a)$服从的概率分布。</li><li>注意在优化$L<em>i(\theta_i)$时，上一次迭代的$\theta</em>{i-1}$是不变的，注意网络的target是取决于网络参数的，和监督学习作对比，监督学习的target和网络无关，在一开始时就是固定的。</li><li>对Loss函数进行求导，得到下列的gradient信息：<script type="math/tex; mode=display">\nabla_{\theta_i}L_i(\theta_i) = E_{s,a~\rho(\cdot),s'\sim E}\left[(r+\gamma max_{a'}Q(s',a';\theta_{i-1})-Q(s,a;\theta_i))\nabla_{\theta_i}Q(s,a;\theta_i)\right]</script>作者通过SGD优化loss函数而不是计算整个期望。如果权重是每隔几个timestep进行更新，并且用从分布$\rho$和环境$E$中采样得到的样本取代期望，就可以得到熟悉的Q-learning算法[2]。(这个具体为什么是这样，我也不清楚，可以看参考文献2)</li><li>这个算法是一个Model-Free的模型，因为它直接从环境$E$中采样，并没有显式的对环境进行建模。</li><li>它是一个off-policy算法，它评估策略的时候采用的是贪心策略，但是生成数据的策略和评估时是不同。生成数据的策略包含了对环境的exploration(探索)，而评估策略采用的是贪心策略，不包含探索。<blockquote><p>On-policy methods attempt to evaluate or improve the policy that is used to make decisions, whereas  off-policy methods evaluate or improve a policy different from that used to generate the data.</p></blockquote></li></ol><p>Sarsa和Q-learning的区别在于更新$Q(s,a)$时,$s’$处action采用的是原来的策略(behaviour policy（行为策略），$\epsilon$-贪心策略)还是现在新的策略(贪心策略)决定，这其实就是policy evaluation和value iteration的区别，policy evaluation使用动态规划算法更新$V(s)$，但是并没有改变行为策略，更新迭代用的数据都是利用之前的行为策略生成的。而值迭代是policy evaluation+policy improvement，每一步都用贪心策略选择出最大的$a$更新$V(s)$，评估用的策略（贪心策略）和行为策略（$\epsilon$-策略）是不同的。</p><h4 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h4><ol><li>DQN使用了experience replay，将多个episodes中的经验存储到同一个replay buffer中。在更新$Q$值的时候，从replay buffer中进行采样更新。当前时间步动作的选择采用的是$\epsilon$-greedy策略，保持探索。因为replay buffer中存放的有很久之前的experience，所以更新$Q$值的策略(replay buffer)和真实采取动作的策略($epsilon$-greedy)是不一样的，所以是off-policy的方法。采用experience replay的online算法[5]和标准的online算法相比有三个好处[4]，第一个是每一个experience可以多次用来更新参数，提高了数据训练效率；第二个是直接从连续的样本中进行学习是低效的，因为样本之间存在强关联性。第三个是on-policy的学习中，当前的参数决定下一次采样的样本，就可能使学习出来的结果发生偏移。</li><li>replay buffer中只存储最近N个experience。</li><li>原始图像是$210\times 160$的RGB图像，预处理首先将它变为灰度图，并进行下采样得到一个$110\times 84$的图像，然后从这个图像中截取一个$84\times 84$的图像。</li><li>作者使用预处理函数$\phi$处理连续四张的图像，而不是仅仅一张，然后将这个预处理后的结果输入$Q$函数。</li><li>预处理函数$\phi$是一个卷积神经网络，输入是$84\times 84\times 4$的图像矩阵，经过$16$个stride为$4$的$8\times 8$filter，经过relu激活函数，再经过$32$个stride为$2$的$4\times 4$filter，经过relu激活函数，最后接一个256个单元的全连接层。输出层的单元根据动作的个数决定。</li><li>$Q$函数的输入是预处理后的图像，也就是状态，输出是所有action的$Q$值，也就是说给定一个状态，这个网络能够计算所有的action的值。</li><li>DQN是不收敛的。</li></ol><h3 id="伪代码"><a href="#伪代码" class="headerlink" title="伪代码"></a>伪代码</h3><p>Algorithm 1 Deep Q-learning with Experience Replay<br>Initialize replay memory D to capacity N<br>Initialize action-value function Q with random weights<br>for episode = $1, M$ do<br>$\ \ \ \ \ \ \ \ $Initialize sequence $s<em>1 = {x_1}$ and preprocessed sequenced $\phi_1 = \phi(s_1)$<br>$\ \ \ \ \ \ \ \ $for $t = 1,T$ do<br>$\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ $With probability $\epsilon$ select a random action $a_t$<br>$\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ $otherwise select $a_t = max_a Q^{∗}(\phi(s_t), a; θ)$<br>$\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ $Execute action $a_t$ in emulator and observe reward $r_t$ and image $x</em>{t+1}$<br>$\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ $Set $s<em>{t+1} = s_t, a_t, x</em>{t+1}$ and preprocess $\phi<em>{t+1} = \phi(s</em>{t+1})$<br>$\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ $Store transition $(\phi<em>t, a_t, r_t, \phi</em>{t+1})$ in D<br>$\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ $Sample random minibatch of transitions $(\phi<em>j, a_j, r_j, \phi</em>{j+1})$ from D<br>$\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ $Set $y<em>j = \begin{cases}r_j&amp;\ \ \ \ for\ terminal\ \phi</em>{j+1}\r<em>j+\gamma max</em>{a’}Q(\phi<em>{j+1},a’|\theta)&amp;\ \ \ \ for\ non-terminal\ \phi</em>{j+1}\end{cases}$<br>$\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ $Perform a gradient descent step on $(y_j − Q(\phi_j, a_j; θ))^2$<br>$\ \ \ \ \ \ \ \ $end for<br>end for</p><h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><h4 id="Datasets"><a href="#Datasets" class="headerlink" title="Datasets"></a>Datasets</h4><p>七个Atari 2600 games: B.Rider, Breakout, Enduro, Pong, Q bert, Seaquest, S.Invaders。<br>在六个游戏上DQN的表现超过了之前所有的方法，在三个游戏上DQN的表现超过了人类。</p><h4 id="Settings"><a href="#Settings" class="headerlink" title="Settings"></a>Settings</h4><ol><li>不同游戏的reward变化很大，这里把正的reward全部设置为$1$，把负的reward全部设置为$-1$，reward为$0$的保持不变。这样子在不同游戏中也可以统一学习率。</li><li>采用RMSProp优化算法，batchsize为$32$，behaviour policy采用的是$epsilon-greedy$，在前$100$万步内，$epsilon$从$1$变到$0.1$，接下来保持不变。</li><li>使用了跳帧技术，每隔$k$步，智能体才选择一个action，在中间的$k-1$步中，保持原来的action不变。这里选择了$k=4$，有的游戏设置的为$k=3$。</li></ol><h4 id="Metrics"><a href="#Metrics" class="headerlink" title="Metrics"></a>Metrics</h4><h5 id="average-reward"><a href="#average-reward" class="headerlink" title="average reward"></a>average reward</h5><p>第一个metric是在一个episode或者一次游戏内total reward的平均值。这个metric带有很大噪音，因为policy权值一个很小的改变可能就会对policy访问states的分布造成很大的影响。</p><h5 id="action-value-function"><a href="#action-value-function" class="headerlink" title="action value function"></a>action value function</h5><p>第二个metric是估计的action-value function，这里作者的做法是在训练开始前使用random policy收集一个固定的states set，然后track这个set中states最大预测$Q$值的平均。</p><h4 id="Baselines"><a href="#Baselines" class="headerlink" title="Baselines"></a>Baselines</h4><ol><li>Sarsa</li><li>Contingency</li><li>DQN</li><li>Human</li></ol><h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><p><a href="https://github.com/devsisters/DQN-tensorflow" target="_blank" rel="noopener">https://github.com/devsisters/DQN-tensorflow</a></p><h2 id="Nature-DQN"><a href="#Nature-DQN" class="headerlink" title="Nature DQN"></a>Nature DQN</h2><h3 id="非线性拟合函数不收敛的原因"><a href="#非线性拟合函数不收敛的原因" class="headerlink" title="非线性拟合函数不收敛的原因"></a>非线性拟合函数不收敛的原因</h3><ol><li>序列中状态的高度相关性。</li><li>$Q$值的一点更新就会对policy改变造成很大的影响，从而改变数据的分布。</li><li>待优化的$Q$值和target value(目标Q值)之间的关系，每次优化时的目标Q值都是固定上次的参数得来的，优化目标随着优化过程一直在变。<br>前两个问题是通过replay buffer解决的，第三个问题是Natura DQN中解决的，在初始版本中没有解决，解决方案是在固定时间步内，固定目标Q值的参数，更新待优化Q值的参数，然后每隔固定步数将待优化Q值的参数拷贝给目标Q值。<blockquote><p>This instability has several causes: the correlations present in the sequence of observations, the fact that small updates to Q may significantly change the policy and therefore change the data distribution, and the correlations between the action-values (Q) and the target values $r+\gamma max_{a’}Q(s’,a’)$.<br>We address these instabilities with a novel variant of Q-learning, which uses two key ideas. First, we used a biologically inspired mechanism termed experience replay that randomizes over the data, thereby removing correlations in the observation sequence and smoothing over changes in the data distribution. Second, we used an iterative update that adjusts the action-values (Q) towards target values that are only periodically updated, thereby reducing correlations with the target.</p></blockquote></li></ol><h3 id="Nature-DQN改进"><a href="#Nature-DQN改进" class="headerlink" title="Nature DQN改进"></a>Nature DQN改进</h3><ol><li>预处理的结构变了,CNN的层数增加了一层，</li><li>加了target network，</li><li>将error限制在$[-1,1]$之间。<blockquote><p>clip the error term from the update $r + \gamma max_{a’} Q(s’,a’;\theta_i^{-} - Q(s,a;\theta_i)$ to be between $-1$ and $1$. Because the absolute value loss function $|x|$ has a derivative of $-1$ for all negative values of $x$ and a derivative of $1$ for all positive values of $x$, clipping the squared error to be between $-1$ and $1$ corresponds to using an absolute value loss function for errors outside of the $(-1,1)$ interval. </p></blockquote></li></ol><h3 id="框架"><a href="#框架" class="headerlink" title="框架"></a>框架</h3><p>DNQ的框架如下所示<br><img src="/2019/03/02/DQN/nature_dqn.png" alt="ndqn"></p><h3 id="伪代码-1"><a href="#伪代码-1" class="headerlink" title="伪代码"></a>伪代码</h3><p>Algorithm 2 deep Q-learning with experience replay, target network<br>Initialize replay memory D to capacity N<br>Initialize action-value function Q with random weights $\theta$<br>Initialize target action-value function $\hat{Q}$ with weights $\theta^{-}=\theta$<br>for episode = $1, M$ do<br>$\ \ \ \ \ \ \ \ $Initialize sequence $s<em>1 = {x_1}$ and preprocessed sequenced $\phi_1 = \phi(s_1)$<br>$\ \ \ \ \ \ \ \ $for $t = 1,T$ do<br>$\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ $With probability $\epsilon$ select a random action $a_t$<br>$\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ $otherwise select $a_t = max_a Q^{∗}(\phi(s_t), a; θ)$<br>$\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ $Execute action $a_t$ in emulator and observe reward $r_t$ and image $x</em>{t+1}$<br>$\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ $Set $s<em>{t+1} = s_t, a_t, x</em>{t+1}$ and preprocess $\phi<em>{t+1} = \phi(s</em>{t+1})$<br>$\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ $Store transition $(\phi<em>t, a_t, r_t, \phi</em>{t+1})$ in D<br>$\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ $Sample random minibatch of transitions $(\phi<em>j, a_j, r_j, \phi</em>{j+1})$ from D<br>$\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ $Set $y<em>j = \begin{cases}r_j&amp;\ \ \ \ for\ terminal\ \phi</em>{j+1}\r<em>j+\gamma max</em>{a’}Q(\phi<em>{j+1},a’|\theta^{-})&amp;\ \ \ \ for\ non-terminal\ \phi</em>{j+1}\end{cases}$<br>$\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ $Perform a gradient descent step on $(y_j − Q(\phi_j, a_j; θ))^2$ with respect to the network parameters $\theta$<br>$\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ $Every $C$ steps reset $\hat{Q} = Q$<br>$\ \ \ \ \ \ \ \ $end for<br>end for</p><h2 id="Double-DQN"><a href="#Double-DQN" class="headerlink" title="Double DQN"></a>Double DQN</h2><h2 id="Prioritized-DDQN"><a href="#Prioritized-DDQN" class="headerlink" title="Prioritized DDQN"></a>Prioritized DDQN</h2><h2 id="Dueling-DQN"><a href="#Dueling-DQN" class="headerlink" title="Dueling DQN"></a>Dueling DQN</h2><h2 id="Distributed-DQN"><a href="#Distributed-DQN" class="headerlink" title="Distributed DQN"></a>Distributed DQN</h2><h2 id="Noisy-DQN"><a href="#Noisy-DQN" class="headerlink" title="Noisy DQN"></a>Noisy DQN</h2><h2 id="Rainbow"><a href="#Rainbow" class="headerlink" title="Rainbow"></a>Rainbow</h2><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>1.<a href="https://blog.csdn.net/yangshaokangrushi/article/details/79774031" target="_blank" rel="noopener">https://blog.csdn.net/yangshaokangrushi/article/details/79774031</a><br>2.<a href="https://link.springer.com/article/10.1007%2FBF00992698" target="_blank" rel="noopener">https://link.springer.com/article/10.1007%2FBF00992698</a><br>3.<a href="https://www.jianshu.com/p/b92dac7a4225" target="_blank" rel="noopener">https://www.jianshu.com/p/b92dac7a4225</a><br>4.<a href="https://datascience.stackexchange.com/questions/20535/what-is-experience-replay-and-what-are-its-benefits/20542#20542" target="_blank" rel="noopener">https://datascience.stackexchange.com/questions/20535/what-is-experience-replay-and-what-are-its-benefits/20542#20542</a><br>5.<a href="https://stats.stackexchange.com/questions/897/online-vs-offline-learning" target="_blank" rel="noopener">https://stats.stackexchange.com/questions/897/online-vs-offline-learning</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Playing-Atari-with-Deep-Reinforcement-Learning&quot;&gt;&lt;a href=&quot;#Playing-Atari-with-Deep-Reinforcement-Learning&quot; class=&quot;headerlink&quot; title=&quot;
      
    
    </summary>
    
      <category term="强化学习" scheme="http://mxxhcm.github.io/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="强化学习" scheme="http://mxxhcm.github.io/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="机器学习" scheme="http://mxxhcm.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="值迭代" scheme="http://mxxhcm.github.io/tags/%E5%80%BC%E8%BF%AD%E4%BB%A3/"/>
    
      <category term="深度学习" scheme="http://mxxhcm.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Modeling Others using Oneself in Multi-Agent Reinforcement Learning</title>
    <link href="http://mxxhcm.github.io/2019/01/29/Modeling-Others-using-Oneself-in-Multi-Agent-Reinforcement-Learning/"/>
    <id>http://mxxhcm.github.io/2019/01/29/Modeling-Others-using-Oneself-in-Multi-Agent-Reinforcement-Learning/</id>
    <published>2019-01-29T05:19:33.000Z</published>
    <updated>2019-05-06T16:22:27.704Z</updated>
    
    <content type="html"><![CDATA[<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>我们考虑使用不完全信息的多智能体强化学习问题，每个智能体的目标是最大化自身的效用。奖励函数取决于两个智能体的隐藏状态（或者目标），每一个智能体必须从它观察到的行为中推断出其他玩家的隐藏目标从而完成任务。我们提出了一种新的方法在这些领域中进行学习：自我其他建模（SOM），智能体使用自己的策略来预测其他智能体的动作并实时更新其他智能体隐藏状态的置信度。我们在三个不同的任务上对该方法进行了评估，结果表明智能体无论在合作还是对抗环境中都能使用他们对其他玩家隐藏状态的估计来学习到更好的策略。</p><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>在多智能体系统中推理其他智能体的意图并预测它们的行为是很重要的，这些智能体可能有不同的甚至是竞争的目标集。由于多智能体系统的不稳定性，这仍然是一个非常具有挑战性的问题。<br>在本文中，我们介绍了一种从其他智能体的行为中估计对应的未知的目标和并利用这些估计的目标选择动作的新方法。我们证明了在本文提到的任务中，在游戏中显式的对其他玩家进行建模比将其他智能体看做环境的一部分会有更好的性能。我们将问题定义为双人随机游戏，也叫双人马尔可夫游戏，其中环境对于智能体是完全可见的，但是没有关于其他智能体目标的明确知识而且没有沟通信道。每个智能体在回合结束时收到的奖励取决于两个智能体的目标，因此是每个智能体最优的策略都必须考虑到所有智能体的目标。<br>认知科学研究表明，人类维持与他们联系的其他人的模型，这些模型用来捕捉那些人的目标，信仰或偏好。在某些情况下，人类利用自己的心理过程来模拟他人的行为。这使他们能够理解其他人的意图或动机，并能在社交场合采取相应的行动。受这些研究的启发，关键想法是要理解游戏中其他玩家正在做什么，智能体应该问自己“如果我扮演另一个玩家的角色，我的目标是什么？”。我们通过使用一个多层循环神经网络参数化智能体的动作和值函数来实现这个想法，该神经网络将状态和目标作为输入。当智能体玩游戏时，它通过直接使用自己的动作函数优化目标来最大化对方行动的可能性，从而推断出其他智能体的未知目标。</p><h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><p><strong>背景</strong> 两个智能体的马尔可夫游戏由描述所有智能体的可能配置的一组状态集合$S$，两组动作集合$A<em>1$，$A_2$和两个智能体的观察$O_1$，$O_2$以及转换函数$\Tau$：$S\times A_1 \times A_2 \rightarrow S$作为当前状态和动作的函数给出下一个状态的概率分布。每个智能体$i$通过从随机策略$\pi</em>{\theta<em>i}:S\times A_i\rightarrow [0,1]$中采样选择动作。每个智能体都有一个奖励函数，它取决于智能体的状态和动作：$r_i：S\times A_i\rightarrow R$。每个智能体$i$试图最大化自己的总预期收益$R_i = \sum</em>{t =0}^T\gamma^tr<em>i^t$，其中$\gamma$是折扣因子，$T$是时间范围。在本文中，我们考虑了合作以及竞争环境。<br>接下来介绍自我其他模型（SOM），这是一种在一个回合内以实时方式推断其他智能体的目标并使用这些估计来选择动作的新方法。为了决定一个动作并估计一个状态的值，我们使用一个神经网络$f$将它自己的目标$z</em>{self}$，另一个玩家的估计目标$\hat{z}<em>{self}$，并且他自己的角度的观察状态$s</em>{self}$作为输入，输出动作$\pi$的一个概率分布和值估计$V$，即对于每个玩游戏的智能体，有： </p><script type="math/tex; mode=display">\begin{bmatrix}\pi^i\\V^i\end{bmatrix}=f^i(s_{self}^i,z_{self}^i,\hat{z}_{other}^i;\theta^i)</script><p>其中$\theta<em>i$是智能体$i$的神经网络$f$的参数，包括一个softmax层输出策略，一个线性层输出值函数，所有非输出层是共享的。动作是从策略$\pi$中采样得到的。观察状态$s</em>{self}^i$包含$f^i$智能体的位置，以及其他智能体的位置。每个智能体都有两个网络（为了简洁，省略了智能体上标$i$），一个计算它自己的动作和值函数，一个计算其他智能体的估计值，如下：<br>\begin{equation}<br>f<em>{self}(s</em>{self},z<em>{self},\hat{z}</em>{other};\theta<em>{self})<br>\end{equation}<br>\begin{equation}<br>f</em>{other}(s<em>{other},\hat{z}</em>{other},z<em>{self};\theta</em>{self})<br>\end{equation}<br>这两个网络使用的方式不同：$f<em>{self}$用于计算智能体自己的行为和价值，并以前馈方式运行。给出其他智能体观察到的动作，智能体使用$f</em>{other}$通过优化$\hat{z}<em>{other}$推断其他智能体的目标。<br>我们建议每个智能体使用自己的策略模拟其他玩家的行为，这样$f</em>{other}$的参数与$f<em>{self}$的参数是相同的。但请注意，两个网络的输入$z</em>{self}$和$\hat{z}<em>{other}$的相对位置不同。另外，由于环境是完全可观测的，两个智能体的观察状态的不同仅通过地图上智能体的身份体现出来（即，每个智能体将能够区分其自己的位置和另一个智能体的位置）。因此，在acting模式下，$f</em>{self}$网络将$s<em>{self}$作为输入；在推理模式下，$f</em>{other}$网络将$s<em>{other}$作为输入。在游戏的每一步，智能体需要推理$\hat{z}</em>{other}$将其作为(1)的输入并选择其动作。为了实现这个目的，在每一步中，智能体观察另一个智能体采取的行动，并且在下一步中，智能体使用先前观察到的另一个智能体的动作作为监督信号，使用式子(2)反向传播并优化其$\hat{z}<em>{other}$，如图1所示。<br>推理过程优化器中采取的步数是一个可根据游戏的不同而变化的超参数。因此，在游戏的每一步中其他智能体的目标估计$\hat{z}</em>{other}$会被更新多次。参数$\theta<em>{self}$在每个回合结束时使用和带有智能体获得的奖励信号的Asynchronous Advantage Actor-Critic（A3C）进行更新。<br>算法1给出了一个回合内训练SOM智能体的伪代码。这里考虑的所有任务的目标都是离散的，智能体的目标$\hat{z}</em>{self}$被<br>表示独热向量，维度是智能体目标所有可能的情况数。另一个玩家的目标嵌入$\hat{z}<em>{other}$有相同的维度。为了估计经过离散而不可微的变量$\hat{z}</em>{other}$的梯度，我们用Gumbel-Softmax分布上的一个可微样本$\hat{z}<em>{other}^G$代替它。这种重新参数化技巧被证明可以有效地产生低方差偏置的梯度。使用该方法在每一步优化过$\hat{z}</em>{other}$之后，$\hat{z}<em>{other}$通常偏离独热向量。在下一步中，$f</em>{self}$将对应于先前更新的$z<em>{other}$ argmax的一个独热向量量$\hat{z}</em>{other}^OH$作为输入。<br>智能体的策略由长短期记忆（LSTM）单元参数化，以及两个全连接的线性层和指数线性单元（ELU）激活函数。神经网络的权重用半正交矩阵初始化。<br>由于$f<em>{other}$的循环性，当推理步数$\gt 1$时必须特别小心。在这种情况下，在游戏的每一步中，我们在推理模式中的第一次前向传播之前保存$f</em>{other}$的循环状态，并且在每个推理步骤将循环状态初始化为此值。这个过程可以确保在动作和推理模式下$f_{other}$可以展开相同数量的步骤。</p><h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><p>不完全信息的游戏中对手建模一直在被广泛研究。但是，大多数以前的方法都侧重于研究特定领域内的概率先验或参数化策略的模型。相比之下，本文的工作为对手建模提出了一个更通用的框架。给定比赛历史，Davidson使用MLP预测对手的动作，但是智能体无法实时适应对手的行为。Lockett等人设计了一种神经网络结构，通过在给定的一组主要对手上学习权重的值来识别对手类型。然而，游戏并没有在强化学习框架内展开。<br>大量多智能体深度强化学习的研究中侧重于部分可见的，完全合作和紧急通信等环境。本文不允许智能体之间进行任何沟通，因此玩家必须利用他们观察到的行为间接推理他们对手的意图。作为对比，Leibo等考虑半合作多智能体环境，智能体根据任务类型和奖励结构制定合作和竞争策略。类似地，Lowe等人提出了一种集中AC框架，用于在具有混合策略的环境中进行高效的训练。 Lerer和Peysakhovich通过将针锋相对的著名游戏理论策略推广到多智能体马尔可夫游戏，设计了能够在复杂社会困境中保持合作的强化学习智能体。最近认知科学方面的工作试图通过使用分层的社会智能体模型来理解人类的决策，它能推断出其他人类智能体的意图，从而决定是否采取合作或竞争策略。然而，这些论文都没有设计出能够显式模拟环境中其他人工智能体或者估计他们意图的算法来改善智能体的决策。<br>逆强化学习领域也与本文考虑的问题有关。逆强化学习的目的是通过观察智能体的行为来推断智能体的奖励函数。相反，我们的方法使用观察到其他玩家的行为以在线方式直接推断他们的目标，然后在环境的acting模式中由智能体使用。这避免为了估计奖励函数收集其他智能体状态-动作对离线样本的需要，然后使用它来学习最大化该效用的单独策略。最近Hadfield-Menell等的论文也关注推理他人意图的问题，但他们关注的是人机交互和价值调整。在类似目标的推动下，Chandrasekaran等人考虑建立人工智能理论的问题，以改善人工智能交互和人工智能系统的可解释性。为了这个目标，他们展示了可以使用少量示例训练人们预测视觉问答模型的响应。<br>Foerster等人和He等人的工作与我们的工作最接近。Foerster等人设计强化学习智能体在更新自己的策略时同时考虑到环境中其他智能体的学习。这使得智能体能够发现自私而又协作的策略，例如在迭代囚徒困境中的针锋相对策略。虽然我们的工作没有明确地试图塑造其他智能体的学习，但它的优点是智能体可以在一个回合中更新他们的信念并以在线方式更新策略以获得更多奖励。我们的设置也有所不同，它认为每个智能体都有一些其他玩家所需的隐藏信息，以便最大化其回报。<br>我们的工作非常符合He等人的工作，作者构建了一个用于在强化学习环境中构建其他智能体的一般框架。He等人提出了一个模型，通过将对手的观察使用DQN进行编码，共同学习一个策略和对手的行为对手。他们的混合专家架构能够在两个纯对抗性任务中发现不同对手的策略模式。我们的工作与He等人的工作之间的一个区别在于，我们的目标不是推断其他智能体的策略，而是专注于显式估计他们在环境中的目标。此外，在这项工作中，智能体不是使用其他智能体动作的人工设计特征，而是根据自己的模型端到端的学习其他智能体模型。另一个区别是，在这项工作中，智能体使用优化推断其他智能体的隐藏状态，而不是通过前馈网络推断其他智能体的隐藏状态。在下面的实验中，我们表明SOM优于He等人的方法。</p><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>在本节中，我们在三个任务上评估SOM模型：</p><ul><li>硬币游戏，这是一个完全合作的任务，智能体的角色是对称的。</li><li>配方游戏，它是对抗的，但具有对称角色。</li><li>门禁游戏，它是完全合作的，但是两个玩家拥有不对称的角色。</li></ul><p>我们将SOM与其他三个baselines以及一个可以访问其他智能体目标的ground truth的模型进行比较。所有任务都是在Mazebase gridworld环境中创建的。</p><h3 id="Baselines"><a href="#Baselines" class="headerlink" title="Baselines"></a>Baselines</h3><p>TRUE-OTHER-GOAL（TOG）：我们提供了一个给出的模型性能上限的策略网络，该网络将其他智能体的真正目标$z<em>{other}$，以及状态特征$s</em>{self}$和自己的目标$z<em>{self}$作为输入。因为这个模型可以直接访问其他智能体真正的目标，因此不需要单独的网络来模拟其他智能体的行为。 TOG的结构与SOM的一个策略网络$f</em>{self}$相同。 NO-OTHER-MODEL（NOM）：我们使用的第一个baseline仅使用观察状态$s<em>{self}$和自身目标$z</em>{self}$作为输入。NOM与SOM的一个策略网络$f<em>{self}$有相同的架构。该baseline没有对其他智能体的显式建模或估计它们的目标。<br>集成-策略-预测器（IPP）：从NOM的体系结构和输入开始，我们构建了一个更强的baseline IPP，它有一个额外的最终线性层输出另一个智能体下一个动作的概率分布。除了用于训练该网络策略的A3C损失函数，我们还添加交叉熵损失项训练其他智能体的行为的预测。<br>分离-策略-预测器（SPP）：He等人提出了一个基于DQN的对手建模框架。在他们的方法中，给定对手特有的人工提取的状态信息，训练一个神经网络预测对手的动作。该网络的中间隐藏表示用作Q网络的输入。<br>我们修改了He等人的模型应用到本文的场景中。特别的，我们使用A3C而不是DQN，我们不使用特定领域的特征表示对手的隐藏状态。<br>最后产生的SPP模型由两个独立的网络组成，一个策略网络用于决定智能体的动作，一个对手网络用于预测其他智能体的动作。对手网络将世界状态$s$和自己的目标$z</em>{self}$作为输入，并输出其他智能体在下一步采取动作的概率分布，以及其隐藏状态（由网络的循环给出）。与IPP一样，我们使用其他智能体的真实动作训练对手策略预测器的交叉熵损失。在每一步中，该网络输出的隐藏状态以及智能体观察状态和智能体自身的目标被作为智能体的策略网络的输入。策略网络和对手策略预测器都是与SOM结构相同的LSTM网络。<br>与SOM作对比，SPP没有显式推断出其他智能体的目标。相反，它通过预测智能体在每个时间步的动作来隐式的构建对手模型。在SOM中，一个参考的目标作为策略网络的附加输入。而在SPP，类似的参考目标是从对手策略预测器得到的隐藏表示，把它作为策略网络的附加输入。<br><strong>训练细节</strong>。在我们的所有实验中，我们使用系数为$0.01$的熵，价值损失系数为$0.5$，折扣系数为$0.99$的A3C训练智能体的策略。使用Adam优化智能体商策略的参数，其中$\beta<em>1= 0.9,\beta_2= 0.999,\epsilonn =1\times 10^{-8}$，权重衰减为$0$。学习率为$0.1$的SGD用于推断另一个智能体的目标，$\hat{z}</em>{other}$。<br>硬币和食谱游戏中策略网络的隐藏层维度为$64$，门游戏中为$128$。所有游戏和模型的学习率都是$1\times 10^{-4}$。<br>观测状态$s$用一些独热向量表示，包括环境中所有物体的位置，以及智能体和另一个智能体的位置。这个输入状态的维度是$1\times n$特征，其中Coin，Recipe和Door游戏的特征数分别为$384$,$192$和$900$。对于每个实验，我们使用5个不同的随机种子训练模型。除非特殊说明，否则论文中展示的所有游戏结果都是每步进行的10次优化更新的结果。</p><!--### 硬币游戏。首先，我们在一个完全合作的任务上评估模型，在这个任务中，当智能体使用他们两个的目标而不仅仅是他们自己的目标时，他们可以获得更多的奖励。因此，估计其他玩家的目标并在采取行动时使用该信息符合每个智能体人的最佳利益。如图4的左图所示，游戏在8×8网格上进行，该网格包含12个3种不同颜色的硬币（每种颜色4个硬币）。在每集开始时，智能体被随机分配三种颜色中的一种。动作空间包括：上，下，左，右或通过。一旦智能体人踩到硬币，那个硬币就会从网格中消失。游戏在20个步骤后结束（即每个智能体需要10个步骤）。两名特工在比赛结束时收到的奖励由下面的公式给出：2），其他n其他Cself是自我目标颜色的硬币数量，由其他智能体人收集，而n self Cneither是与自己收集的智能体人目标相对应的硬币数量。对于图4中的示例，智能体1具有Cself =橙色和Cother =青色，而智能体2的Cself是青色而Cother是橙色。对于两种药剂，两者都是红色的。收集不符合任何智能体人目标的硬币的惩罚的作用是避免收敛到暴力政策，在这种政策中，智能体人可以通过收集其附近的所有硬币而获得不可忽视的奖励金额，而不是关于他们的颜色。为了最大化其回报，每个智能体人需要收集自己的硬币或其合作者的颜色，而不是剩余颜色的硬币。因此，当两个智能体人能够在游戏中尽可能早地高精度地推断其合作者的目标时.--><h2 id="讨论"><a href="#讨论" class="headerlink" title="讨论"></a>讨论</h2><p>在本文中，我们介绍了一种新方法，用于从其他智能体的行为中推断他们的隐藏状态，并使用这些估计来选择动作。我们证明了智能体能够在合作和竞争环境中估计其他参与者的隐藏目标，这使他们能够收敛到更好的政策并获得更高的回报。在本文提出的任务中，对其他智能体的显式建模比仅仅考虑其他代理成为环境的一部分更好的性能。     SOM的一个限制是它比其他baseline需要更长的训练时间，因为我们在每一步都进行了反向传播。但是，它的online更新方式对于适应环境中其他智能体的动作变化至关重要。SOM的一些主要优点是简单性和灵活性，它不需要任何额外参数来模拟环境中的其他代理，可以使用任何强化学习算法进行训练，并且可以轻松地与任何策略参数化或网络结构集成。SOM可以适应具有两个以上智能体的环境，因为智能体可以使用自己的策略来模拟任意数量的智能体的动作并推断其目标。而且，它可以很容易地推广到许多不同的环境和任务。<br>我们计划通过评估更复杂环境中的模型来扩展这项工作，包括两个以上的参与者，混合策略，更多样化的智能体类型（例如具有不同动作空间的智能体，奖励函数，角色或策略），以及假设其他玩家和自己一样的模型偏差。<br>未来研究的其他重要途径是设计能够适应环境中其他智能体非平稳策略的模型，处理具有分层目标的任务，并在测试时遇到新智能体时表现良好。<br>最后，许多研究领域可以从拥有其他智能体的模型中受益，这些智能体能够推理其他智能体的意图并预测他们的动作。这些模型可能对人机或师生互动，以及价值对齐问题有恒大帮助。此外，这些方法可用于多智能体任务中基于模型的强化学习，因为前向模型的准确性很大程度上取决于预测其他智能体动作的能力。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;摘要&quot;&gt;&lt;a href=&quot;#摘要&quot; class=&quot;headerlink&quot; title=&quot;摘要&quot;&gt;&lt;/a&gt;摘要&lt;/h2&gt;&lt;p&gt;我们考虑使用不完全信息的多智能体强化学习问题，每个智能体的目标是最大化自身的效用。奖励函数取决于两个智能体的隐藏状态（或者目标），每一个智能
      
    
    </summary>
    
      <category term="强化学习" scheme="http://mxxhcm.github.io/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="强化学习" scheme="http://mxxhcm.github.io/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="深度学习" scheme="http://mxxhcm.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Policy Gradient With Value Function Approximation For Collective Multiagent Planning</title>
    <link href="http://mxxhcm.github.io/2019/01/26/Policy-Gradient-With-Value-Function-Approximation-For-Collective-Multiagent-Planning/"/>
    <id>http://mxxhcm.github.io/2019/01/26/Policy-Gradient-With-Value-Function-Approximation-For-Collective-Multiagent-Planning/</id>
    <published>2019-01-26T11:33:50.000Z</published>
    <updated>2019-05-06T16:22:27.704Z</updated>
    
    <content type="html"><![CDATA[<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>分布式的部分可观测马尔科夫决策过程(Dec POMDP)为解决多智能体系统中的序列决策问题提供了一个框架。考虑到POMDP的计算复杂度，最近的研究主要集中在Dec-POMDP中一些易于处理但是比较实用的子问题。本文解决的就是其中的一个子问题叫做CDec-POMDP其中一系列智能体的共同行为影响了它们公共的reward和环境变化。本文的主要贡献是提出了一个actor-critic(AC)强化学习算法优化CDec-POMDP问题的policy。普通的AC算法对于大型问题收敛的很慢，为了解决这个问题，本文展示了如何将智能体的估计动作值函数进行分解从而产生有效的更新以及推导出一个基于局部奖励信号的新的critic训练方式。通过在一个合成的benchmark以及真实的出租车车队优化问题上和其他方法进行对比，结果表明本文的AC方法提供了比之前最好的方法还要高质量的方法。</p><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>近些年来，分布式的部分可观测马尔科夫决策过程已经发展成了解决多智能体协作的序列决策问题的一个很有前景的(promising)方法。Dec-POMDP对智能体基于环境和其他智能体的不同部分观测最大化一个全局的目标进行建模。Dec-POMDP的具体应用包括协调行星探测，多机器人协调控制以及无线网络的吞吐量优化。然而，解决分布式的部分马尔科夫决策过程是相当困难的，即使对于只有$2$个智能体的问题呢是NP难的。<br>为了增大规模和提高真实问题中的应用，过去的研究已经探索了智能体之间严格的交互，如状态转换和观测独立，事件驱动的的交互以及智能体之间的弱耦合性。最近，一系列工作开始关注于智能体的身份不影响它们之间的交互上，环境的变化主要受到智能体的共同影响，和著名的阻塞游戏很像。一些城市交通中的问题如出租车调度可以用这样的协同规划模型进行建模。<br>在本文中，作者着重于集中的Dec-POMDP框架将一类不确定情况下的集中多智能体序列决策问题形式化。Nguyen等人提出了一个采样方法优化CDec-POMDP模型中的policy。之前方法的一个主要缺点是policy是用表格形式展现的，随着智能体的observation spaces改变时，表格形式的policy不能很好的进行扩展。受到最近一些强化学习工作的启发，本文的贡献是一个AC框架的强化学习算法用来优化CDec-POMDP的policy。Policy用函数如神经网络来表示可以避免表格形式的policy的扩展性问题。我们推导出了策略梯度并且基于CDec-POMDP中智能体的交互提出了一个估计的因子动作值函数。普通的AC算法因为学习全局reward的原因，在解决大型多智能体系统问题时收敛的很慢。为了解决这个问题，本文提出了一种新的方式去训练critic，高效利用智能体的局部值函数的估计动作值函数。<br>我们在一个合成的多机器人导航领域和现实世界中一个亚洲城市的出租车调度问题上测试了本文的方法，结果展示了本文的方法可以扩展到大型多智能体系统上。根据经验，我们因式AC方法比以前最好的方法给出的解决方案都要好。因式AC方法收敛的也比普通的AC方法快很多，验证了我们提出的critic训练方法的有效性。<br><strong>相关工作</strong> 我们的工作基于具有近似值函数的策略梯度框架。然而，根据以往的经验显示，直接应用原始的策略梯度到多智能体任务中，尤其是CDec-POMDP模型中会产生较高方差。在本文中，我们展示了一个和CDec-POMDP兼容的估计值函数，它能产生高效且低方差的策略梯度更新。Peshkin很早之前就研究过了应用于分布式policy的强化学习，Guestrin还提出使用REINFORCE从协调图中训练一个因子值函数的softmax策略。然而，这些以前的工作中，策略梯度都是从全局的经验回报而不是分解后的critic中估计的。我们在第四章中展示了一个分解后ciritc和基于训练这个critic得到的一个单个值函数对于高效的采样学习是很重要的。我们的实验结果表明了我们提出的critic训练方式比用全局经验回报训练收敛的还要快。</p><h2 id="集中分布式POMDP模型"><a href="#集中分布式POMDP模型" class="headerlink" title="集中分布式POMDP模型"></a>集中分布式POMDP模型</h2><p>我们首先介绍一下Nguyen提出的CDec-POMDP模型。一个对应于这个模型的$T$步的动态贝叶斯网络如图所示。它由以下几个部分组成：</p><ul><li>一个有限的计划范围$H$</li><li>智能的数量$M$，一个智能体m可能处在state space $S$中的任意一个状态，联合state space是$\times_{m=1}^MS$，我们用$i\in S$表示一个state。</li><li>每一个智能体m都有一个action spaceA，我们用$j\in A$表示一个action。</li><li>用$(s<em>{1:H},a</em>{1:H})^m=(s_1^m,a_1^m,\cdots,s_H^m,a_H^m)$表示一个智能体m完整的state-action轨迹。用随机变量$s_t^m,a_t^m$表示智能体$m$在$t$时刻的state和action。不同的指示函数$I_t(\cdot)$如表$1$所示。给定每一个智能体$m\in M$的轨迹，定义以下的计数方式：<script type="math/tex; mode=display">n_t(i,j,i') = \sum_{m=1}^M I_t^m(i,j,i'),\forall i,i'\in S,j\in A.</script>如表$1$所示，计数器$n<em>t(i,j,i’)$表示在$t$时刻处于state $i$，采取action $j$，转换到state $i’$的智能体数量。其他计数器$n_t(i)$和$n_t(i,j)$的定义类似。使用这些计数器，我们可以定义$t$时刻的计数表$\bf{n}</em>{s<em>t}$和$\bf{n}</em>{s_ta_t}$如表$1$所示。</li><li>我们假设一个普遍的部分观测环境，其中智能体基于其他智能体的总体影响可以有不同的ovservation。一个智能体观测到它的局部state $s<em>t^m$。此外在$t$时刻基于它的局部状态$s_t^m$和计数表$\bf{n}</em>{s_t}$观测到$o_t^m$。例如，一个智能体m在$t$时刻处于state $i$，可以观测到其他也处在state $i(=n_t(i))$的智能体或者其他处在state $i$临近状态$j$的智能体，即$n_t(j),\forall j\in Nb(i)$。</li><li>状态转换函数是$\Phi<em>t(s</em>{t+1}^m=i’|s<em>t^m=i,a_t^m=j,\bf{N}</em>{s<em>t})$。所有智能体的状态转换函数是一样的，注意它会受到$\bf{n}</em>{s<em>t}$的影响，而$\bf{n}</em>{s_t}$依赖于智能体的共同行为。</li><li>每一个智能体m有一个不平稳的policy $\pi<em>t^m(j|i,o_t^m(i,\bf{n}</em>{s<em>t}))$，表示在$t$时刻给定智能体m的observation $(i,o_t^m(i,\bf{n}</em>{s_t})$之后，智能体采取action $j$的概率。我们用$\pi^m=(\pi_1,\cdots,\pi_H)$表示智能体m水平范围的policy。</li><li>一个智能体接收到的reward $r<em>t^m=r_t(i,j,\bf{n}</em>{s<em>t}$取决于它的局部state和action，以及计数表$\bf{n}</em>{s_t}$。</li><li>初始的state分布，$b_o=(P(i)\forall i \in S)$，对于所有的智能体都是相同的。</li></ul><p>我们在这里展示了最简单的版本，所有的智能体的类型都相同，并且有相似的state transition，observation和reward模型。模型也可以处理多种类型的智能体，不同类型的智能体有不同的变化。我们还可以引入一个不受智能体action影响的external state，如交通领域的出租车需求。我们的结果也可以扩展到解决类似的问题。<br>像CDec-POMDP之类的模型对于解决智能体数量很大或者智能体的身份不影响reward或者transition function之类的问题是很有用的。其中一个应用是出租车车队优化问题，这个问题是计算出出租车调度的policy使得车队的利润最大化。一个出租车的决策过程如下。在时刻$t$时，每个出租车观测到它当前的城市空间$z$，不同的空间构成了state space $S$，以及当前空间和它的相邻空间的其他出租车的计数和当前局部请求的一个估计。这构成了出租车基于计数的observation $o(\cdot)$。基于这个observation，出租车必须决定待在当前空间$z$寻找乘客还是移动到下一个空间。这些决策选择取决于不同的因子，如请求比率和当前空间其他出租车的计数。类似的，环境是随机的，在不同时间出租车请求是变化的。使用出租车车队的的GPS记录可以得到这些历史的请求数据。<br><strong>基于计数的统计数据用于规划</strong> CDec-POMDP模型的一个关键属性是模型的变换取决于智能体的集中交互而不是智能体的身份。在出租车车队优化问题中，智能体数量可以相当大（大约有$8000$个智能体在现实世界的实验中）。给出这么大数量的智能体个数，为每一个智能体计算出独一无二的policy是不可能的。因此，和之前的工作类似，我们的目标是对所有智能体计算出一个相同的policy $\pi$。因为policy $\pi$取决于计数，它代表了一种富有表现力的policy。<br>对于一个固定的数量M来说，用${(s<em>{1:T},a</em>{1:T})^m\forall m}$表示从图$1$的DBN网络中采样得到的不同智能体的state-action轨迹。用$\mathbf{n}<em>{1:T}={(\mathbf{n}</em>{s<em>t},\mathbf{n}</em>{s<em>ta_t},\mathbf{n}</em>{s<em>ta_ts</em>{t+1}})\forall t=1:T}$表示每一个时间步$t$的结果计数表的组合向量。Nguyen等人展示了计数器$\mathbf{n}$中拥有足够的统计数据用来规划。也就是说，一个policy $\pi$在水平范围H内的联合值函数可以通过计数器的期望进行计算：</p><script type="math/tex; mode=display">V(\pi) = \sum_{m=1}^M\sum_{T=1}^H E[r_T^m] = \sum_{\mathbf{n}\in \Omega_{1:H}}P(\mathbf{n};\pi) \left[\sum_{T=1}^H\sum_{i\in S,j\in A} n_T(i,j)r_T(i,j,\mathbf{n}_T)\right]</script><p>集合$\Omega_{1:H}$是所有允许的一致计数表的集合，如下所示：</p><script type="math/tex; mode=display">\sum_{i\in S}n_T(i) = M \forall T;</script><script type="math/tex; mode=display">\sum_{j\in A}n_T(i,j) = n_T(i) = \forall j \forall T;</script><script type="math/tex; mode=display">\sum_{i'\in S}n_T(i,j,i') = n_T(i,j)\forall i\in S,\forall j \in A, \forall T;</script><p>$P(\mathbf{n},\pi)$是计数器的分布。这个结果的一个关键好处是我们可以直接从分布$P(\mathbf{n})$中对计数器$\mathbf{n}$采样而不是对单个不同智能体的轨迹$(s<em>{1:H},a</em>{1:H})进行采样来$评估policy $\pi$，这显著节省了计算开销。我们的目标是计算最优的policy $\pi$来最大化$V(\pi)$。我们假设一个集中式学习，分布式执行的强化学习设置。我们假设有一个模拟器可以从$P(\mathbf{n};\pi)$中提供计数器样本。</p><h2 id="CDec-POMDP的策略梯度"><a href="#CDec-POMDP的策略梯度" class="headerlink" title="CDec-POMDP的策略梯度"></a>CDec-POMDP的策略梯度</h2><p>之前的工作提出了一个基于采样的EM算法来优化policy $\pi$。这个policy被表示成计数器$\mathbf{n}$空间中的一个线性分段表policy，其中每一个线性片段指定了下一个action的分布。然而，这种表格形式的表示限制了它的表达能力，因为片段的数量是固定的先验，并且每个范围都必须手动定义，这可能会对性能产生不利影响。此外，当observation o是多维的时候，即，一个智能体观测到它位置相邻区域的计数器时，需要指数多个片段。为了解决这个问题，我们的目标是优化函数形式（如神经网络）的policy。<br>我们首先扩展策略梯度理论到CDec-POMDP上，用$\theta$表示policy参数的向量。我们接下来展示如何计算$\Delta_\theta V(\pi)$。用$\mathbf{s}_t,\mathbf{a}_t$表示$t$时刻所有智能体的联合state和联合action。给定一个policy $\pi$，值函数表示形式如下：</p><script type="math/tex; mode=display">V_t(\pi)=\sum_{\mathbf{s}_t,\mathbf{a}_t}P^{\pi}(\mathbf{s}_t,\mathbf{a}_t|b_o,\pi)Q_t^{\pi}(\mathbf{s}_t,\mathbf{a}_T)</script><p>其中$P^{\pi}(\mathbf{s}<em>t,\mathbf{a}_t|b_o)=\sum</em>{\mathbf{s}<em>{1:t-1},\mathbf{a}</em>{1:t-1}}P^{\pi}(\mathbf{s}<em>{1:t},\mathbf{a}</em>{1:t}|b_o)$是policy $\pi$下联合state $\mathbf{s}_t$，和联合action $\mathbf{a}_t$的分布。值函数$Q_t^{\pi}(\mathbf{s}_t,\mathbf{a}_t)$的计算过程如下：</p><script type="math/tex; mode=display">Q_t^{\pi}(\mathbf{s}_t,\mathbf{a}_t) = r_t(\mathbf{s}_t,\mathbf{a}_t)+\sum_{\mathbf{s}_{t+1},\mathbf{a}_{t+1})}P^{\pi}(\mathbf{s}_{t+1},\mathbf{a}_{t+1}|\mathbf{s}_t,\mathbf{a}_t))Q_{t+1}^{\pi}(\mathbf{s}_{t+1},\mathbf{a}_{t+1})</script><p>接下来介绍以下CDec-POMDP的策略梯度理论：<br><strong>定理1.</strong> 对于任何CDec-POMDP，策略梯度计算公式如下：</p><script type="math/tex; mode=display">\Delta_{\theta}V_1(\pi)=\sum_{t=1}^HE_{\mathbf{s}_t,\mathbf{a}_t)|b_o,\pi}\left[Q_t^{\pi}(\mathbf{s}_t,\mathbf{a}_t)\sum_{i\in S,j\in A}n_t(i,j)\Delta_{\theta}log\pi_{t}(j|i,o(i,\mathbf{n}_{s_t}))\right]</script><p>这个定理的证明和其他后续结果在附录中。<br>注意由于许多原因利用上述结果计算策略梯度是不切实际的。联合state-action $\mathbf{a}_t,\mathbf{s}_t$空间是组合的。考虑到智能体的个数可能有很多个，对每一个智能体的轨迹进行采样是计算上不可行的。为了补救，我们接下来会展示类似policy评估直接对计数器$\mathbf{n}~P(\mathbf{n};\pi)$进行采样计算梯度。类似的，也可以使用经验回报作为动作值函数$Q_t^{\pi}(\mathbf{s}_t,\mathbf{a}_t)$的一个近似估计。这是标准的REINFORCE算法在CDec-POMDP上的应用。众所周知，REINFORCE可能比其他使用学习的动作值函数的方法学习的慢。因此，我们提出了一个$Q_t^{\pi}$的近似函数，展示了直接采样计数器$\mathbf{n}$来计算策略梯度。</p><h3 id="使用估计动作值函数的策略梯度"><a href="#使用估计动作值函数的策略梯度" class="headerlink" title="使用估计动作值函数的策略梯度"></a>使用估计动作值函数的策略梯度</h3><p>估计动作值函数$Q_t^{\pi}(\mathbf{s}_t,\mathbf{a}_t)$有几种不同的方式。我们考虑下列特征形式的近似值函数$f_w$：</p><script type="math/tex; mode=display">Q_t^{\pi}(\mathbf{s}_t,\mathbf{a}_t)\approx f_w(\mathbf{s}_t,\mathbf{a}_t)=\sum_{m=1}^Mf_w^m(s_t^m,o(s_t^m,\mathbf{n_{s_t}}),s_t^m)</script><p>每一个智能体m都定义了一个$f<em>w^m$，它的输入是智能体的局部state，action和observation。注意不同的$f_w^m$是相关的，因为它们依赖于公共的计数器表$\mathbf{n}</em>{s_t}$。这样的一种分解方式是很有用的，因为它产生了有效的策略梯度计算方式。此外，CDec-POMDP中一类很重要的这种形式的估计值函数是兼容值函数最后会产生一个无偏的策略梯度。<br><strong>命题1</strong> CDec-POMDP中的兼容值函数可以分解成：</p><script type="math/tex; mode=display">f_w(\mathbf{s}_t\mathbf{a}_t) = \sum_mf_w^m(s_t^m,o(s_t^m,\mathbf{n}_{s_t}),a^m)</script><p>我们可以直接用估计值函数$f_w$取代$Q^{\pi}(\cdot)$。经验上来说，我们发现使用这个估计的方差很大。我们利用$f_w$的结构进一步分解策略梯度会有更好的效果。<br><strong>定理2</strong> 对于任何具有如下的分解的值函数：</p><script type="math/tex; mode=display">f_w(\mathbf{s}_t\mathbf{a}_t) = \sum_mf_w^m(s_t^m,o(s_t^m,\mathbf{n}_{s_t}),a^m)</script><p>策略梯度可以写成：</p><script type="math/tex; mode=display">\Delta_{\theta}V_1(\pi)=\sum_{t=1}^HE_{\mathbf{s}_t,\mathbf{a}_t)|b_o,\pi}\left[\sum_m\Delta_{\theta}log\pi(a_t^m|s_t^m,o(s_t^m,\mathbf{n}_{s_t}))f_w^m(s_t^m,o(s_t^m,\mathbf{n}_{s_t}),a_t^m)\right]</script><p>上述结果展示了如果估计值函数被分解了，那么得到的策略梯度也是分解的。上述结果也可以应用到多种类型的智能体上，只要我们假设不同的智能体有不同的函数$f_t^m$。最简单的情况下，所有的智能体都是相同类型的，每一个智能体都有相同的函数$f_w$，推断出下式：</p><script type="math/tex; mode=display">f_w(\mathbf{s}_t,\mathbf{a}_t) = \sum_{i,j}n_t(i,j)f_w(i,j,o(i,\mathbf{n}_{s_t}))</script><p>使用上式，我们可以将策略梯度简化成：</p><script type="math/tex; mode=display">\Delta_{\theta}V_1(\pi) = \sum_tE_{\mathbf{s}_t,\mathbf{a}_t}\left[\sum_{i,j}n_t(i,j)\Delta_{\theta}log\pi (j|i,o(i,\mathbf{n}_{s_t}))f_w(i,j,o(i,\mathbf{n}_{s_t}))\right]</script><h3 id="基于计数器的策略梯度计算"><a href="#基于计数器的策略梯度计算" class="headerlink" title="基于计数器的策略梯度计算"></a>基于计数器的策略梯度计算</h3><p>注意在上式中，期望仍然和联合state，action，$(\mathbf{s}<em>t,\mathbf{a}_t)$相关，当智能体的个数很大时效率很低。为了解决这个问题是<br><strong>定理3</strong> 对于任何拥有形式$f_w(\mathbf{s}_t,\mathbf{a}_t) = \sum</em>{i,j}n<em>t(i,j)f_w(i,j,o(i,\mathbf{n}</em>{s<em>t}))$的值函数，策略梯度都可以用下式计算：<br>\begin{equation}<br>E</em>{\mathbf{n}<em>{1:H}\in \Omega</em>{1:H}} \left[\sum<em>{t=1}^H\sum</em>{i\in S,j\in A}n<em>t(i,j) \Delta</em>{\theta}log\pi (j|i,o(i,\mathbf{n}<em>t)) f_w(i,j,o(i,\mathbf{n}_t))\right]<br>\end{equation}<br>上述结果展示了策略梯度可以类似于计算policy的值函数一样通过从底层分布$P(\cdot)$中采样计数表向量$\mathbf{n}</em>{1:H}$来计算策略梯度，在智能体数量很大的情况下也是可行的。</p><h2 id="训练动作值函数"><a href="#训练动作值函数" class="headerlink" title="训练动作值函数"></a>训练动作值函数</h2><p>在我们的方法中，在计数器样本$\mathbf{n}<em>{1:H}$生成用来计算策略梯度后，我们还需要调整critic $f_w$的参数。注意对于每一个动作值函数$f_w(\mathbf{s}_t,\mathbf{a}_t)$只取决于联合state，action $(\mathbf{s}_t,\mathbf{a}_t)$生成的计数器。训练$f_w$可以通过一个梯度步最下化下列loss函数实现：<br>\begin{equation}<br>min_w\sum</em>{\xi=1}^K\sum<em>{t=1}^H\left(f_w(\mathbf{n}_t^{\xi})-R_t^{\xi}\right)^2<br>\end{equation}<br>其中$\mathbf{n}</em>{1:H}^{\xi}$是从分布$P(\mathbf{n};\pi)$中生成的一个计数器样本；$f<em>w(\mathbf{n}_t^{\xi})$是动作值函数，$R_t^{\xi}$是用式子$(1)$计算的$t$时刻的所有经验回报：<br>\begin{equation}<br>f_w(\mathbf{n}_t^{\xi}) = \sum</em>{i,j}n<em>t^{\xi}(i,j)f_w(i,j,o(i,\mathbf{n}_t^{\xi});R_t^{\xi}=\sum</em>{T=t}^H]\sum<em>{i\in S,j\in A}n_T{\xi}(i,j)r_T(i,j,\mathbf{n}_T^{\xi})<br>\end{equation}<br>然而，我们发现公式$(11)$中的loss函数在训练较大问题的critic时表现并不好。需要一定数量的计数器样本可靠的训练$f_w$，这对于拥有较多数量智能体的大问题的扩展有不利影响。已知在多智能体强化学习中单独利用全局reward信号的算法要比利用局部reward信号的方法多用一些样本。受到这些现象的启发，接下来我们提出了一个基于策略的局部reward信号去训练critic $f_w$。<br><strong>单个值函数</strong> 用$\mathbf{n}</em>{1:H}^{\xi}$表示一个计数器样本。给定计数器样本$\mathbf{n}<em>{1:H}^{\xi}$，用$V_t^{\xi}(i,j)=E\left[\sum</em>{t’=t}^Hr<em>{t’}^m|s_t^m=i,a_m^t=j,n</em>{1:H}^{\xi}\right]$表示一个智能体在时刻$t$处于state $i$，采取action $j$，所能得到的所有期望reward。这个单个的值函数可以用动态规划算法来计算。基于这个值函数，我们接下来展示了式子$(12)$中全局经验reward的重新参数化：<br><strong>引理(Lemma)1</strong> 给定计数器样本$\mathbf{1:H}^{\xi}$，$t$时刻的经验回报$R_t^{\xi}$可以被重新参数化为：</p><script type="math/tex; mode=display">R_t^{\xi} = \sum_{i\in S,j\in A}n_t^{\xi}(i,j)V_t^{\xi}(i,j).</script><p><strong>基于单个值函数的loss</strong> 给出引理$1$，我们推导出式子$11$中真实loss的上界，它有效利用了单个值函数：<br>\begin{align*}<br>&amp;\sum<em>{\xi}\sum_t\left(f_w(\mathbf{n}^{\xi})-R_t^{\xi}\right)^2 \<br>= &amp;\sum</em>{\xi}\sum<em>t\left(\sum</em>{i,j}n<em>t^{\xi}(i,j)f_w(i,j,o(i,\mathbf{n}_t^{\xi}))-\sum</em>{i,j}n<em>t^{\xi}(i,j)V_t^{\xi}(i,h)\right)^2\<br>= &amp;\sum</em>{\xi}\sum<em>t\left( \sum</em>{i,j}n<em>t^{\xi}(i,j)(f_w(i,j,o(i,\mathbf{n}_t^{\xi}))-V_t^{\xi}(i,h))\right)^2\<br>\le &amp;M\sum</em>{\xi}\sum_{t,i,j}n_t(i,j)\left(f_w(i,j,o(i,\mathbf{n}_t^{\xi}))-V_t^{\xi}(i,j)\right)^2<br>\end{align*}<br>其中最后一部用了柯西施瓦茨不等式。我们用式子(14)中修改过的loss训练critic。按照经验来说，对于较大的问题，式子(14)中的新loss比式子(13)中的原始loss要收敛的快很多。直观上来说，这是因为式子(14)中的新loss尝试调整每一个critic组件$f_w(i,j,o(i,\mathbf{n}_t^{\xi}))$更接近它的经验回报$V_t^{\xi}(i,j)$。然而，原始的式子(13)中的loss着重于最小化全局loss，而不是调整每一个单个的critic因子$f_w(\cdot)$到相对应的每一个经验回报。<br>算法$1$展示了CDec-POMDP中AC算法的大纲。第$7$行和第$8$行展示了两种不同的方式训练critic。第$7$行代表基于局部值函数的critic更新，也可以称为factored cirtic更新(fC)。第$8$行展示了基于全局reward或者全局critic的更新(C)。第$10$行展示了使用定理$2$(fA)计算的策略梯度。第$11$行展示了直接使用$f_w$计算的梯度。</p><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>这一节中比较了我们的AC算法和另外两个解决CDec-POMDP问题的算法，Soft-Max based flow update(SMFU)，和期望最大化方法。SMFU只能优化智能体的action依赖于局部state的policy，$\pi(a_t^m|s_t^m)$，因为它通过计算在规划阶段单个最有可能的计数器向量来估计计数器$\mathbf{n}$的作用。EM方法优化基于计数器的分段线性policy，其中$\pi(a_t^m|s_t^m,\cdot)$是所有可能的计数器observation $o_t$空间上的一个分段函数。<br>算法$1$展示了更新critic的两种方式（第$7$行和第$8$行）和更新actor的两种方式（第$10$行和第$11$行），所以就有四种可能的AC方法－fAfC,AC,FfC,fAC。我们也研究了不同actor-critic方法的属性。在附录中有神经网络的结构和其他一些实验设置。<br>为了和之前方法公平的进行比较，我们使用了三种不同的模型用于基于计数的observation $o_t$。在$o0$设置中，policy只取决于智能体的局部state $s_t^m$并不需要计数器。在$o1$设置中，policy取决于局部state $s_t^m$和单个计数器observation $n_t(s_t^m)$。也就是说，智能体只能观测到其他也在当前状态$s_t^m$的智能体的计数器。在$oN$设置中，智能体能观测到它的局部state $s_t^m$和当前状态$s_t^m$的局部相邻状态内其他智能体的计数器。$oN$ observation模型提供给智能体最多的信息。然而，它也是最难优化的因为policy有更多的参数。SMFU方法只能在$o0$设置中起作用，EM方法和本文中的AC方法在所有设置中都能起作用。<br><!--**出租车调度** 我们在第二节中介绍的现实世界中的域测试了本文的方法。在这个问题中，目标是计算出租车policy优化整个车队的收入。数据包含亚洲一个大城市超过一年的出租车轨迹数据。我们使用了从数据集中提取到的车辆请求信息。平均来说，每天大概有$8000$辆出租车。整个城市被划分为$81$个空间，时间范围是$24$个小时划分为$48$个半小时的区间。图$2(a)$中展示了不同方法在不同的观测模型（$'o0','o1','oN'$)上的量化比较。我们测试了$4000$和$8000$辆出租车来验证是否出租车的数量会影响不同方法的性能。$y$轴展示了整个车队每天的利润。在$'o0'$设置下，所有的方法（fAfC-$o0$,SMFU,EM-$o0$）给出质量差不多的解，在$8000$个出租车上fAfC-$o0$和EM-$o0$表现的比SMFU稍微好一些。在$'o1'$设置下，--></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;摘要&quot;&gt;&lt;a href=&quot;#摘要&quot; class=&quot;headerlink&quot; title=&quot;摘要&quot;&gt;&lt;/a&gt;摘要&lt;/h2&gt;&lt;p&gt;分布式的部分可观测马尔科夫决策过程(Dec POMDP)为解决多智能体系统中的序列决策问题提供了一个框架。考虑到POMDP的计算复杂度，最近
      
    
    </summary>
    
      <category term="强化学习" scheme="http://mxxhcm.github.io/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="强化学习" scheme="http://mxxhcm.github.io/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="深度学习" scheme="http://mxxhcm.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="论文" scheme="http://mxxhcm.github.io/tags/%E8%AE%BA%E6%96%87/"/>
    
      <category term="actor-critic" scheme="http://mxxhcm.github.io/tags/actor-critic/"/>
    
  </entry>
  
  <entry>
    <title>EM(Expectation Maximization)算法</title>
    <link href="http://mxxhcm.github.io/2019/01/21/EM%E7%AE%97%E6%B3%95/"/>
    <id>http://mxxhcm.github.io/2019/01/21/EM算法/</id>
    <published>2019-01-21T02:22:45.000Z</published>
    <updated>2019-05-06T16:22:27.704Z</updated>
    
    <content type="html"><![CDATA[<h2 id="引言-Introduction"><a href="#引言-Introduction" class="headerlink" title="引言(Introduction)"></a>引言(Introduction)</h2><h3 id="什么是期望最大化算法"><a href="#什么是期望最大化算法" class="headerlink" title="什么是期望最大化算法"></a>什么是期望最大化算法</h3><p>期望最大化算法(Expectation Maximization,EM)，是利用参数估计的迭代法求解最大似然估计的一种方法。</p><h3 id="EM和MLE关系"><a href="#EM和MLE关系" class="headerlink" title="EM和MLE关系"></a>EM和MLE关系</h3><p>MLE的目标是求解已知分布类型的单个分布的参数。<br>EM的目标是求解已知分布类型的多个混合分布的参数。<br>一般我们用到的极大似然估计都是求某种已知分布类型的单个分布的参数，如求高斯分布的均值和方差；而EM算法是用来求解已知分布类型，多个该已知类型分布的混合分布的参数，这句话听起来可能有些拗口，举个最常见的例子，高斯混合分布参数的求解，这个混合分布都是高斯分布，只是每个分布的参数不同而已。如果一个高斯分布，一个卡方分布是没有办法求解的。</p><h3 id="为什么叫它EM算法"><a href="#为什么叫它EM算法" class="headerlink" title="为什么叫它EM算法"></a>为什么叫它EM算法</h3><p>因为这个算法总共有两个迭代步骤，E步和M步。第一步是对多个分布求期望，固定每一个分布的参数，计算出混合分布的参数，即E步，第二步是对这个混合分布利用最大似然估计方法进行参数估计，即M步。</p><h2 id="推理过程"><a href="#推理过程" class="headerlink" title="推理过程"></a>推理过程</h2><p>假设我们要求一个混合分布p的参数$\theta$，比如校园内男生和女生的身高参数，显然，男生和女生的身高服从的分布类型是相同的，但是参数是不一样的。这里通过引入一个隐变量$z$，求解出对应不同$z$取值的参数$\theta$的值。<br>\begin{align*}<br>p(x|\theta) &amp;= \sum_zp(x,z|\theta)\<br>&amp;=\sum_zp(z|\theta)p(x|\theta, z) \tag{0}<br>\end{align*}<br>如果我们假设男女生的身高分布是一个高斯混合模型，现在要求它的参数$\theta$。混合模型的表达式可以写为：<br>\begin{align*}<br>p(x|\theta) &amp;= \sum_zw(z)N(x|\mu_z,\sigma_z)\<br>&amp;=\sum_zp(z|\theta)p(x|\theta,z)<br>\end{align*}<br>其中$\sum_zw(z) = 1,\theta={w, \mu, \sigma}$，如果用最大似然估计来解该问题的话，log函数内有和式，不好优化，所以就要换种方法。<br>观测数据：$x=(x_1,\cdots, x_N)$<br>对应的隐变量：$z=(z_1,\cdots, z_N)$，$z_i$有$c$种取值。</p><p>\begin{align*}<br>l(\theta;x) &amp;= log p(x|\theta) \tag{1}\<br>&amp;= log\prod<em>{i=1}^N\ p(x_i|\theta) \tag{2}\<br>&amp;= \sum</em>{i=1}^Nlog\ p(x<em>i|\theta) \tag{3}\<br>&amp;= \sum</em>{i=1}^Nlog\sum_zp(x_i,z|\theta) \tag{4}\<br>\end{align*}<br>这里式子(4)中$\sum_zp(x,z|\theta)$该怎么变形，因为现在解不出来了。<br>最开始我想的是使用条件概率进行展开，即：</p><script type="math/tex; mode=display">\sum_zp(x_i, z|\theta) = \sum_zp(x_i|z, \theta)p(z|\theta)</script><p>但是如果展开成这样子，就变成了文章开头给出的式子(0)，并没有什么用，不能继续化简了。<br>所以就对式子(4)做个变形<br>\begin{align*}<br>&amp;\ \ \ \ \sum<em>{i=1}^Nlog\sum_zp(x_i,z|\theta) \tag{4}\<br>&amp;= \sum</em>{i=1}^Nlog\sum<em>zq(z|x_i)\frac{p(x_i,z|\theta)}{q(z|x_i)}, \ \ s.t.\sum_zq(z|x_i)=1 \tag{5}\<br>&amp;\ge \sum</em>{i=1}^N \underbrace{\sum<em>zq(z|x_i)log\frac{p(x_i,z|\theta)}{q(z|x_i)}}</em>{L(q,\theta)},\ \ s.t. \sum_zq(z|x_i)=1 \tag{6}\<br>\end{align*}<br>第(4)步到第(5)步引入了一个分布$q(z|x)$，就是给定一个观测数据$x$，隐变量$z$取值的概率分布。注意，$q(z)$是一个函数，但是给定$x$之后，$q(z|x)$是一个变量。然后因为变形之后还是没有求解，就利用杰森不等式做了缩放，将$log(sum())$变成了$sum(log())$，就变成了(6)式。<br>这里使用Jensen不等式的目的是使得缩放后的值还能取得和原式相等的值，重要的是等号能够取到。</p><h3 id="Jensen不等式"><a href="#Jensen不等式" class="headerlink" title="Jensen不等式"></a>Jensen不等式</h3><p>对于随机变量的Jensen不等式，当函数$f(x)$是凸函数的时候可以用下式表示：</p><script type="math/tex; mode=display">f(E(x)) \le E(f(x))</script><p>当$f(x)$是凹函数的时候，有</p><script type="math/tex; mode=display">f(E(x)) \ge E(f(x))</script><p>接下来我们就要求解使得式子(6)中杰森不等式等号成立的$q$分布的取值。这里有两种方法可以求解。</p><h3 id="拉格朗日乘子法"><a href="#拉格朗日乘子法" class="headerlink" title="拉格朗日乘子法"></a>拉格朗日乘子法</h3><p>令</p><script type="math/tex; mode=display">L(q,\theta) = \sum_z q(z|x_i)log{\frac{p(x_i,z|\theta)}{q(z|x_i)}}, s.t.\sum q(z|x_i) = 1 \tag{7}</script><p>构建拉格朗日目标函数：<br>\begin{align*}<br>L &amp;= L(q, \theta) + \lambda(\sum_zq(z|x)- 1) \tag{8}\<br>&amp;= \sum_z q(z|x_i)log{\frac{p(x_i,z|\theta)}{q(z|x_i)}} + \lambda(\sum_z q(z|x_i) - 1)  \tag{9}<br>\end{align*}</p><p>对$L$求导，得到：</p><script type="math/tex; mode=display">\frac{\partial L}{\partial q(z|x_i)} = log\frac{p(x_i, z|\theta)}{q(z|x_i)} + q(z|x_i)(-\frac{1}{q(z|x_i)}) + \lambda \tag{10}</script><p>令$\frac{\partial L}{\partial q(z|x_i)}$等于$0$，得到：<script type="math/tex">log\frac{p(x_i, z|\theta)}{q(z|x_i)} = 1 - \lambda</script><br>两边同取$e$的对数：</p><script type="math/tex; mode=display">\frac{p(x_i, z|\theta)}{q(z|x_i)} = e^{1-\lambda} \tag{11}</script><script type="math/tex; mode=display">q(z|x_i) = e^{\lambda - 1}p(x_i, z|\theta) \tag{12}</script><p>两边同时求和得：</p><script type="math/tex; mode=display">1 = e^{\lambda - 1}\sum_z p(x_i, z|\theta) \tag{13}</script><p>用$p$表示$e^{\lambda-1}$得到：</p><script type="math/tex; mode=display">e^{\lambda-1} = \frac{1}{\sum_z p(x_i, z|\theta)}</script><p>将其代入式子(12)得：<br>\begin{align*}<br>q(z|x_i) &amp;= \frac{p(x_i, z|\theta)}{\sum_z p(x_i, z|\theta)}\<br>&amp;= \frac{p(z, x_i|\theta)}{p(x_i|\theta)}\<br>&amp;= p(z|x_i, \theta)  \tag{14}<br>\end{align*}</p><p>最后求出来$q(z|x_i) = p(z|x_i, \theta)$。</p><h3 id="杰森不等式成立条件"><a href="#杰森不等式成立条件" class="headerlink" title="杰森不等式成立条件"></a>杰森不等式成立条件</h3><p>杰森不等式成立条件是常数，即：</p><script type="math/tex; mode=display">\frac{p(x_i, z|\theta)}{q(z|x_i)} = c,  s.t. \sum q(z|x_i)=1 \tag{15}</script><p>则有:</p><script type="math/tex; mode=display">p(x, z_i|\theta) = cq(z_i|x) \tag{16}</script><p>同时对式子左右两边求和，得到：</p><script type="math/tex; mode=display">\sum p(x_i, z|\theta) = \sum cq(z|x_i) = c \tag{17}</script><p>将$c = \sum p(x_i, z|\theta)$代入式子(14)得：<br>\begin{align*}<br>q(z|x_i) &amp;= \frac{p(x_i, z|\theta)}{\sum p(x_i,z|\theta)}\<br>&amp;= \frac{p(x_i, z)|\theta}{p(x_i|\theta)}\<br>&amp;= p(z|x_i, \theta) \tag{18}<br>\end{align*}</p><h3 id="等号成立证明"><a href="#等号成立证明" class="headerlink" title="等号成立证明"></a>等号成立证明</h3><p>上面两个方法都算出来在$q(z|x_i) = p(z|x_i, \theta)$时$L$能取得最大值。接下来证明这个这个$L$的最大值和$l$相等。<br>将$q = p(z|x_i, \theta)$代入$L(q, \theta)$得：<br>\begin{align*}<br>L(q, \theta) &amp;= L(p(z|x_i, \theta^t), \theta^t)\<br>&amp;= \sum_z p(z|x_i, \theta^t) log\frac{p(z, x_i|\theta^t)}{p(z|x_i, \theta^t)} \<br>&amp;= \sum_z p(z|x_i, \theta^t) log p(x_i|\theta^t)\<br>&amp;= 1\cdot log p(x_i|\theta^t)\<br>&amp;= log p(x_i|\theta^t)\<br>&amp;= l(\theta^t; x_i)<br>\end{align*}</p><h3 id="另一种等号成立推导"><a href="#另一种等号成立推导" class="headerlink" title="另一种等号成立推导"></a>另一种等号成立推导</h3><p>\begin{align*}<br>l(\theta; x) - L(q, \theta) &amp;= l(\theta; x_i) - \sum_z q(z|x_i) log{\frac{p(z, x_i|\theta)}{q(z|x_i)}}\<br>&amp;= \sum_z q(z|x_i) log p(x_i|\theta) - \sum_z q(z|x_i) log{\frac{p(z, x_i|\theta)}{q(z|x_i)}}\<br>&amp;= \sum_z q(z|x_i)log {\frac{p(x_i|\theta)q(z|x_i)}{p(z, x_i|\theta)}}\<br>&amp;= \sum_z q(z|x_i)log {\frac{q(z|x_i)}{p(z|x_i, \theta)}}\<br>&amp;= KL(q(z|x_i)||p(z|x_i,\theta))<br>\end{align*}<br>最后算出来两个函数之差是一个KL散度，是从$p$到$q$的KL散度。当前仅当$p=q$时取等，否则就非负。</p><h3 id="M步"><a href="#M步" class="headerlink" title="M步"></a>M步</h3><p>\begin{align*}<br>L(q, \theta) &amp; = \sum<em>z q(z|x_i) log\frac{p(z, x_i|\theta)}{q(z|x_i)} \<br>&amp; = \underbrace{\sum_z q(z|x_i)log{p(z, x_i|\theta)}}</em>{Expected complete log-likelyhood} - \underbrace{\sum<em>z q(z|x_i)l{q(z|x_i)}}</em>{Entropy}<br>\end{align*}</p><h2 id="EM流程"><a href="#EM流程" class="headerlink" title="EM流程"></a>EM流程</h2><h3 id="计算流程"><a href="#计算流程" class="headerlink" title="计算流程"></a>计算流程</h3><p>（１）首先随机初始化模型的不同隐变量对应的参数，<br>（２）对于每一个观测，首先判断它对应的隐变量的分布。<br>（３）求期望<br>（４）最大似然估计求参数<br>用公式来表示如下：<br>E步：$q^{t+1} = arg\ max<em>q L(q, \theta^t)$<br>M步：$\theta^{t+1} = arg max</em>{\theta}L(q^{t+1}, \theta)$<br>E步就是根据$t$时刻的$\theta^t$利用概率$q$求出$L$的期望，然后M步使用最大似然估计计算出新的$\theta$，就这样迭代下去。</p><h2 id="EM收敛性分析"><a href="#EM收敛性分析" class="headerlink" title="EM收敛性分析"></a>EM收敛性分析</h2><p>EM算法的收敛性就是要证明$L(q=p(z|x_i, \theta^t) , \theta)$的值一直在增大。<br>\begin{align*}<br>L(p(z|x_i, \theta^{t+1}) , \theta^{t+1}) - L(p(z|x_i, \theta^{t}) , \theta^{t}) &amp;= log p(x_i|\theta^{t+1}) - log p(x_i|\theta^t)\<br>&amp; \ge 0<br>\end{align*}</p><h2 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h2><p>假如有两个硬币A和B，假设随机从A,B中选一个硬币，掷$10$次，重复$5$次实验，分别求出两个硬币正面向上的概率。假设硬币服从二项分布<br>$5$次实验结果如下：<br>5H5T<br>9H1T<br>8H2T<br>4H6T<br>7H3T</p><p>这个时候有两种情况</p><h3 id="知道每次选的是A还是B"><a href="#知道每次选的是A还是B" class="headerlink" title="知道每次选的是A还是B"></a>知道每次选的是A还是B</h3><p>这个时候就变成了极大似然估计。</p><h3 id="不知道每次选的是A还是B"><a href="#不知道每次选的是A还是B" class="headerlink" title="不知道每次选的是A还是B"></a>不知道每次选的是A还是B</h3><p>这个时候就用EM算法了。<br>首先随机初始化$\theta<em>A = 0.5, \theta_B = 0.5$，<br>对于每一个观测，首先判断它对应的隐变量的分布。<br>$i={1,2,3,4,5}$，分别代表$5$个实验。<br>首先求出$\theta_A$的参数。<br>$P(z = A|x_i, \theta_A, \theta_B) = \frac{P(z = A|x_i, \theta_A)}{P(z = A|x_i, \theta_A) + P(z = B|x_i, \theta_B)}$<br>$P(z = B|x_i, \theta_A, \theta_B) = 1 - P(z = A|x_i,\theta_A,\theta_B)$<br>然后计算下式：<br>\begin{align*}<br>L(q,\theta_A) &amp;= \sum</em>{i=1}^5 \sum<em>zp(z|x_i, \theta_A, \theta_B)log p(x_i|\theta)\<br>&amp;= \sum</em>{i=1}^5 (p(z=A|x_i, \theta_A)log p(x_i|\theta_A) + p(z=B|x_i, \theta_B)log p(x_i|\theta_B))<br>\end{align*}<br>然后利用极大既然估计计算$\theta_A$和$\theta_B$的值。</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>1.<a href="https://www.zhihu.com/question/27976634/answer/153567695" target="_blank" rel="noopener">https://www.zhihu.com/question/27976634/answer/153567695</a><br>2.<a href="https://en.wikipedia.org/wiki/Jensen%27s_inequality" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Jensen%27s_inequality</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;引言-Introduction&quot;&gt;&lt;a href=&quot;#引言-Introduction&quot; class=&quot;headerlink&quot; title=&quot;引言(Introduction)&quot;&gt;&lt;/a&gt;引言(Introduction)&lt;/h2&gt;&lt;h3 id=&quot;什么是期望最大化算法&quot;
      
    
    </summary>
    
      <category term="机器学习" scheme="http://mxxhcm.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://mxxhcm.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="非监督学习" scheme="http://mxxhcm.github.io/tags/%E9%9D%9E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="最大似然估计" scheme="http://mxxhcm.github.io/tags/%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/"/>
    
      <category term="EM" scheme="http://mxxhcm.github.io/tags/EM/"/>
    
      <category term="期望最大化" scheme="http://mxxhcm.github.io/tags/%E6%9C%9F%E6%9C%9B%E6%9C%80%E5%A4%A7%E5%8C%96/"/>
    
      <category term="Jensen不等式" scheme="http://mxxhcm.github.io/tags/Jensen%E4%B8%8D%E7%AD%89%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>Bayesian Networks</title>
    <link href="http://mxxhcm.github.io/2019/01/06/Bayesian-Networks/"/>
    <id>http://mxxhcm.github.io/2019/01/06/Bayesian-Networks/</id>
    <published>2019-01-06T06:32:55.000Z</published>
    <updated>2019-05-06T16:22:27.700Z</updated>
    
    <content type="html"><![CDATA[<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>贝叶斯网络是一个有向无环图(directed acyclic graphs)，它用节点代表随机变量，用边代表变量之间的依赖关系。</p><h2 id="意义"><a href="#意义" class="headerlink" title="意义"></a>意义</h2><p>贝叶斯网络可以用来表示任意的联合分布。</p><h2 id="推理"><a href="#推理" class="headerlink" title="推理"></a>推理</h2><p>贝叶斯网络的一个基本任务就是求后验概率。<br>在AI这本书中，贝叶斯网络中的变量被分为了证据变量(evidence variable)，隐变量(hidden variable)和查询变量(query variable)。<br>而在PRML这本书中，贝叶斯网络中的变量被分为了观测变量(observed variable)和隐变量(latent variable,hidden variable)。</p><h2 id><a href="#" class="headerlink" title=" "></a> </h2><p>具体的可以看另外两篇笔记有详细的记录。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;介绍&quot;&gt;&lt;a href=&quot;#介绍&quot; class=&quot;headerlink&quot; title=&quot;介绍&quot;&gt;&lt;/a&gt;介绍&lt;/h2&gt;&lt;p&gt;贝叶斯网络是一个有向无环图(directed acyclic graphs)，它用节点代表随机变量，用边代表变量之间的依赖关系。&lt;/p&gt;
&lt;
      
    
    </summary>
    
      <category term="机器学习" scheme="http://mxxhcm.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="人工智能" scheme="http://mxxhcm.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="机器学习" scheme="http://mxxhcm.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="模式识别" scheme="http://mxxhcm.github.io/tags/%E6%A8%A1%E5%BC%8F%E8%AF%86%E5%88%AB/"/>
    
      <category term="概率图模型" scheme="http://mxxhcm.github.io/tags/%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B/"/>
    
      <category term="贝叶斯网络" scheme="http://mxxhcm.github.io/tags/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BD%91%E7%BB%9C/"/>
    
      <category term="有向图" scheme="http://mxxhcm.github.io/tags/%E6%9C%89%E5%90%91%E5%9B%BE/"/>
    
      <category term="监督学习" scheme="http://mxxhcm.github.io/tags/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>AI chapter 14 Probabilistic reasoning</title>
    <link href="http://mxxhcm.github.io/2019/01/06/AI-chapter-14-Probabilistic-reasoning/"/>
    <id>http://mxxhcm.github.io/2019/01/06/AI-chapter-14-Probabilistic-reasoning/</id>
    <published>2019-01-06T06:32:16.000Z</published>
    <updated>2019-05-06T16:22:27.700Z</updated>
    
    <content type="html"><![CDATA[<p>在这里加一些自己的总结，这一章主要讲的是贝叶斯网络，首先介绍了贝叶斯网络的定义，是一个有向无环图，节点代表随机变量，边代表因果关系。这里给出了贝叶斯公式的两个意义，一个是数值意义，用贝叶斯网络表示全概率分布，另一个是拓扑意义，给定某个节点的父节点，这个节点条件独立于所有它的非后裔节点，或者给定某个节点的马尔科夫毯，这个节点条件独立于所有其他节点。接下来讲了条件独立的高效表示，噪音或模型表示离散型父节点和离散型子节点之间的关系，用参数化模型表示连续型父节点和连续型子节点之间的关系，用probit模型或者logit模型表示连续型父节点和离散型子节点之间的关系。接下来就介绍了贝叶斯精确推理计算后验分布的集中方法，一种是枚举推理，一种是消元法。因为精确推理的复杂度太高了，没有实际应用价值，所以就给出了一些估计推理的方法，直接采样，拒绝采样，以及可能性加权，还有另一类采样方法，蒙特卡洛算法，主要介绍了吉布森采样，大概就是这些。后面的两个小节没有看。</p><p>第$13$章讲的是概率论的基础知识并且强调了在概率表示中独立(independence)和条件独立(conditional independence)之间的关系。本章引入了一个系统的方式—贝叶斯网络去表现独立和条件独立之间的关系。概括的来说，本章的内容可以分为以下五部分：</p><ol><li>首先定义了贝叶斯网络的语法(syntax)和语义(semantics)，并且展示了如何用贝叶斯网络表示不确定知识。</li><li>接下来介绍了概率推理在最坏的情况下是很难计算的(computionally intratable)，但是在很多情况下可以高效的完成。</li><li>介绍了一系列在精确推理(exact inference)不可行时可以采用的估计推理算法(approximate inference algorithms)。</li><li>介绍了一些在概率论中可以被应用到带对象和关系的世界的方法，即与命题，表示相对的一阶模型。</li><li>最后，介绍了一些其它不确定性推理的方法。 </li></ol><h2 id="不确定域的知识表示-Representing-knowledge-in-an-uncertain-domain"><a href="#不确定域的知识表示-Representing-knowledge-in-an-uncertain-domain" class="headerlink" title="不确定域的知识表示(Representing knowledge in an uncertain domain)"></a>不确定域的知识表示(Representing knowledge in an uncertain domain)</h2><p>我们可以根据联合概率分布(full joint probability distribution)算出任何想要的概率值，但是随着随机变量个数的增加，联合概率分布可能会变得特别大。此外，一个一个的指定可能世界中的概率是不可行的。</p><h3 id="贝叶斯网络的定义"><a href="#贝叶斯网络的定义" class="headerlink" title="贝叶斯网络的定义"></a>贝叶斯网络的定义</h3><p>如果在联合概率中引入独立和条件独立，将会显著的减少定义联合概率分布所需要的概率。所以这节就介绍了贝叶斯网络来表示变量之间的依赖关系。本质上贝叶斯网络可以表示任何联合概率分布，而且在很多情况下是非常精确地表示。一个贝叶斯网络是一个有向图，图中的节点包含量化后的概率信息。具体的说明如下：</p><ol><li>每一个节点对应一个随机变量，这个随机变量可以是离散的也可以是连续的。</li><li>有向边或者箭头连接一对节点。如果箭头是从节点$X$到节点$Y$，那么节点$X$称为节点$Y$的父节点。图中不能有环，因此贝叶斯网络是一个有向无环图(directed acyclic graph,DAG)。</li><li>每一个节点$X_i$有一个条件概率分布$P(x_i|Parents(X_i))$量化(quantifiy)父节点对其影响。</li></ol><p>网络的拓扑，即节点和边的集合，指定了条件概率分布之间的关系。箭头的直观意义是节点$X$对节点$Y$有直接的影响，$Y$发生的原因是其父节点的影响。通常对于一个领域(domain)的专家来说，指出该域受哪些因素的直接影响要比直接给出它的概率值简单的多。一旦贝叶斯网络的拓扑结构定了，给出一个变量的父节点，我们仅仅需要给出每个节点的条件概率分布。我们能看出，拓扑和条件概率的组合能计算出所有变量的联合概率分布。</p><h3 id="贝叶斯网络的示例"><a href="#贝叶斯网络的示例" class="headerlink" title="贝叶斯网络的示例"></a>贝叶斯网络的示例</h3><h4 id="牙疼和天气"><a href="#牙疼和天气" class="headerlink" title="牙疼和天气"></a>牙疼和天气</h4><p>给定一组随机变量牙疼(Toothache)，蛀牙(Cavity)，拔牙(Catch)和天气(Weather)。Weather是独立于另外三个随机变量的，此外，给定Cavity，Catch和Toothache是条件独立的，即给定Cavity，Catch和Toothache是相互不受影响的，如下图所示。正式的：给定Cavity，Toochache和Catch是条件独立的，图中Toothache和Catch之间缺失的边体现出了条件独立。直观上，网络表现出Cavity是Toothache和Catch发生的直接原因，然而在Toothache和Catch之间没有直接的因果关系。<br><img src="/2019/01/06/AI-chapter-14-Probabilistic-reasoning/" alt="figure 14.1"> </p><h4 id="警报和打电话"><a href="#警报和打电话" class="headerlink" title="警报和打电话"></a>警报和打电话</h4><p>我家里有一个新安装的防盗警报(burglar alarm)，这个警报对于小偷的检测是相当可靠的，但是也会对偶然发生的微小的地震响应。我有两个邻居(Mary和John)，他们听到警报后会打电话给我。John有时会把电话铃和警报弄混了，也会打电话。Mary听音乐很大声，经常会错过警报。现在给出John或者Mary谁是否打电话，估计警报响了的概率。<br><img src="/2019/01/06/AI-chapter-14-Probabilistic-reasoning/" alt="figure 14.2"><br>该例子的贝叶斯网络如上图所示。该网络体现了小偷和地震两个因素会直接影响警报响的概率，但是John和Mary会不会打电话只取决于警报有没有响。贝叶斯网络展示出了我们的假设，即John和Mary不直接观察小偷有没有来，也不直接观察小的地震是否，也不受之前是否打过电话的影响。上图中的条件概率分布以一个条件概率分布表(conditional probability table,CPT)的形式展现了出来。这个表适合离散型的随机变量，但是不适合连续性随机变量。没有父节点的节点只有一行，用来表示随机变量的可能取值的先验概率(prior probabilities)。<br>注意到这个网络中没有节点对应Mary听音乐很大时，也没有节点对应John把电话铃声当成了警报。事实上这些因素都被包含在和边Alarm到JohnCalls和MaryCall相关的不确定性中了，概率包含了无数种情况可能让警报失灵（停电，老鼠咬坏了，等等）或者John和Mary没有打电话的原因（吃饭去了，午睡了，休假了等等），这些不确定性都包含在了概率中了。</p><h2 id="贝叶斯网络的意义-the-semantics-of-bayesian-networks"><a href="#贝叶斯网络的意义-the-semantics-of-bayesian-networks" class="headerlink" title="贝叶斯网络的意义(the semantics of bayesian networks)"></a>贝叶斯网络的意义(the semantics of bayesian networks)</h2><p>上一节主要讲的是什么是贝叶斯网络，但是没有讲它的意义。本节主要给出两种方式可以理解贝叶斯网络的意义。第一个是一种数值化的意义，即”numerical semantics”，把它当成联合概率分布的一种表示形式。第二个是一种拓扑的意义，即”topological semantics”，将它看成条件独立的一种编码方式。事实上，这两种方式是等价的，但是第一种方式更有助于理解如何构建贝叶斯网络，第二种方式更有助于设计推理过程。</p><h3 id="贝叶斯网络表示联合分布-Representing-the-full-joint-distribution"><a href="#贝叶斯网络表示联合分布-Representing-the-full-joint-distribution" class="headerlink" title="贝叶斯网络表示联合分布(Representing the full joint distribution)"></a>贝叶斯网络表示联合分布(Representing the full joint distribution)</h3><h4 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h4><p>一个贝叶斯网络是一个有向无环图，并且每个节点都有一个数值参数。数值方式给出这个网络的意义是，它代表了所有变量的联合概率分布。之前说过节点上的值代表的是条件概率分布$P(X_i|Parents(X_i)$，这是对的，但是当赋予整个网络意义以后，这里我们认为它们只是一些数字$\theta(X_i|Parents(X_i)$。<br>联合概率中的一个具体项(entry)表示的是每一个随机变量取某个值的联合概率，如$P(X_1=x_1 \wedge \cdots\wedge X_n = x_n)$，缩写为$P(x_1,\cdots,x_n)$。这个项的值可以通过以下公式进行计算：</p><script type="math/tex; mode=display">P(x_1,\cdots,x_n) = \prod_{i=1}^n \theta(x_i|parents(X_i)),</script><p>其中$parents(X_i)$表示节点$X_i$在$x_1,\cdots,x_n$中的父节点。因此，联合概率分布中的每一项都可以用贝叶斯网络中某些条件概率的乘积表示。从定义中可以看出，很容易证明$\theta(x_i|parents(X_i))$就是条件概率$P(x_i|parents(X_i))$，因此，我们可以把上式写成：</p><script type="math/tex; mode=display">P(x_1,\cdots,x_n) = \prod_{i=1}^n P(x_i|parents(X_i)),</script><p>换句话说：根据上上个式子定义的贝叶斯网络的意义，我们之前叫的条件概率表真的是条件概率表。（这句话。。。）</p><h4 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h4><p>我们可以计算出警报响了，但是没有小偷或者地震发生，John和Mary都打电话了的概率。即计算联合分布$P(j,m,a,\neg b, \neg e)$（使用小写字母表示变量的值）：<br>\begin{align*}<br>P(j,m,a,\neg b, \neg e) &amp;=P(j|a)P(m|a)P(a|\neg b \wedge \neg e)P(\neg b)P(\neg e)\<br>&amp;=0.90\times 0.70\times 0.001 \times 0.999 \times 0.998\<br>&amp;=0.000628<br>\end{align*}</p><h4 id="构建贝叶斯网络-Constructing-Bayesian-networks"><a href="#构建贝叶斯网络-Constructing-Bayesian-networks" class="headerlink" title="构建贝叶斯网络(Constructing Bayesian networks)"></a>构建贝叶斯网络(Constructing Bayesian networks)</h4><p>上面给出了贝叶斯网络的一种意义，接下来给出如何根据这种意义去构建一个贝叶斯网络。确定的条件独立可以用来指导网络拓扑的构建。首先，我们把联合概率的项用乘法公式写成条件概率表示：</p><script type="math/tex; mode=display">P(x_1,\cdots,x_n) = P(x_n|x_{n-1},\cdots,x_1)P(x_{n-1},\cdots,x_1)</script><p>接下来重复这个过程，将联合概率(conjunctive probability)分解成一个条件概率和一个更小的联合概率。最后得到下式：<br>\begin{align*}<br>P(x<em>1,\cdots,x_n) &amp;= P(x_n|x</em>{n-1},\cdots,x<em>1)P(x</em>{n-1}|,x<em>{n-2}\cdots,x_1)\cdots P(x_2|x_1)P(x_1)\<br>&amp;= \prod</em>{i=1}^nP(x<em>i|x</em>{i-1},\cdots,x<em>1)<br>\end{align*}<br>这个公式被称为链式法则，它对于任意的随机变量集都成立。对于贝叶斯网络中的每一个变量$X_i$，如果给定$Parents(X_i) \subset {X</em>{i-1},\cdots,X_1}$（每一个节点的序号应该和图结构的偏序结构一致），那么有：</p><script type="math/tex; mode=display">P(x_1,\cdots,x_n) = \prod_{i=1}^n P(x_i|parents(X_i)),</script><p>将它和上式对比，得出：</p><script type="math/tex; mode=display">P(X_i|X_{i-1},\cdots,X_1) = P(X_i|Parents(X_i).</script><p>这个公式成立的条件是给定每个节点的父节点，它条件独立于所有它的非父前置节点。这里给出一个生成贝叶斯网络的方式：</p><ol><li>节点：首先，确定需要对领域建模所需要的随机变量集合。对它们进行排序：${X_1,\cdots,X_n}$，任意顺序都行，但是如果随机变量的因(causes)在果(effects)之前，最终的结果会更加紧凑。</li><li>边：从$i = 1$到$n$，<ul><li>从$X<em>1,\cdots,X</em>{i-1}$中选出$X_i$的最小父节点集合。</li><li>对于每一个父节点，插入一条从父节点到$X_i$的边。</li><li>写下条件概率表，$P(X_i| Parents(X_i))$。</li></ul></li></ol><p>直观上，$X<em>i$的父节点应该包含$X_1,\cdots,X</em>{i-1}$中所有直接影响$X_i$的节点。因为每一个节点都只和它前面的节点相连，这就保证了每个网络都是无环的(acyclic)。此外，贝叶斯网络还不包含冗余的概率值，如果有冗余值，就会产生不一致：不可能生成一个违反概率论公理的贝叶斯网络。</p><h4 id="紧凑性和节点顺序-Compactness-and-node-ordering"><a href="#紧凑性和节点顺序-Compactness-and-node-ordering" class="headerlink" title="紧凑性和节点顺序(Compactness and node ordering)"></a>紧凑性和节点顺序(Compactness and node ordering)</h4><h5 id="紧凑性-compactness"><a href="#紧凑性-compactness" class="headerlink" title="紧凑性(compactness)"></a>紧凑性(compactness)</h5><p>因为不包含冗余信息，贝叶斯网络会比联合概率分布更加紧凑，这让它能够处理拥有很多变量的任务。贝叶斯网络的紧凑性是稀疏(sparse)系统或者局部结构化(local structured)系统普遍拥有的稀疏性的一个例子。在一个局部结构化系统中，每一个子部件仅仅和有限数量的其他部件进行交互，而不用管整个系统。局部结构化的复杂度通常是线性增加的而不是指数增加的。在贝叶斯网络中，一个随机变量往往最多受$k$个其他随机变量直接影响，这里的$k$是一个常数。为了简化问题，我们假设有$n$个布尔变量，指定一个条件概率表所需要的数字最多是$2^k$个，整个网络则需要$n2^k$个值；作为对比，联合概率分布需要$2^n$个值。举个例子，如果我们有$n=30$个节点，每一个节点至多有五个父节点(k=5)，那么贝叶斯网络只需要$960$个值，而联合概率分布需要超过十亿个值。<br>但是在某些领域，可能每一个节点都会被所有其他节点直接影响，这时候网络就成了全连接的网络(fully connected)，它和联合概率分布需要同样多的信息。有时候，增加一条边，也就是一个依赖关系，可能会对结果产生影响，但是如果这个依赖很弱(tenuous)，添加这条边的花费比获得的收益还要大，那么就没有必要加这条边了。比如，警报的那个例子，如果John和Mary感受到了地震，他们认为警报是地震引起的，所以就不打电话了。是否添加Earthquake到JohnCalls和MaryCalls这两条边取决于额外的花费和得到更高的警报率之间的关系。</p><h5 id="节点顺序-node-ordering"><a href="#节点顺序-node-ordering" class="headerlink" title="节点顺序(node ordering)"></a>节点顺序(node ordering)</h5><p>即使在一个局部结构化的领域，只有当我们选择好的节点顺序的时候，我们才能得到一个紧凑的贝叶斯网络。考虑警报的例子，我们给出下图：<br><img src="/2019/01/06/AI-chapter-14-Probabilistic-reasoning/" alt="figure 14.3"><br>Figure 14.2和Figure 14.3两张图中的三个贝叶斯网络表达的都是同一个联合分布，但是Figure 14.3中的两张图没有表现出来条件独立，尤其是Figure 14.3(b)中的贝叶斯网络，它需要用和联合分布差不多相同个数的值才能表现出来。可以看出来，节点的顺序会影响紧凑性。</p><h3 id="贝叶斯网络中的条件独立-Conditional-independence-relations-in-Bayesion-networks"><a href="#贝叶斯网络中的条件独立-Conditional-independence-relations-in-Bayesion-networks" class="headerlink" title="贝叶斯网络中的条件独立(Conditional independence relations in Bayesion networks)"></a>贝叶斯网络中的条件独立(Conditional independence relations in Bayesion networks)</h3><p>贝叶斯网络的一个数值意义(“numerical” semantics)是用来表示联合概率分布。根据这个意义，给定每个节点的父节点，使得每一个节点条件独立于它的父节点之外的节点，我们能构建一个贝叶斯网络。此外我们也可以从用图结构编码整个条件独立关系的拓扑意义出发，然后推导出贝叶斯网络的数值意义。拓扑语义说的是给定每个节点的父节点，则该节点条件独立于所有它的非后裔(non-descendants)节点。举例来说，Figure 14.2的警报例子中，给定alarm后，JohnCalls独立于Burglary,Eqrthquake和MaryCalls。如图Figuree 14.4(a)中所示。从条件独立断言(assertions)和网络参数$\theta(x_i|parents(X_i))$就是条件概率$P(x_i|parents(X_i))$的解释中，联合概率可以计算出来。在这种情况下，数值意义和拓扑语义是相同的。<br>另一个拓扑意义的重要属性是：给定某个节点的马尔科夫毯(Markov blanket)，即节点的父节点，子节点，子节点的父节点，这个节点条件独立于所有其他的节点。如图Figure 14.4(b)所示。</p><h2 id="条件分布的高效表示-Efficient-representation-of-conditional-distributions"><a href="#条件分布的高效表示-Efficient-representation-of-conditional-distributions" class="headerlink" title="条件分布的高效表示(Efficient representation of conditional distributions)"></a>条件分布的高效表示(Efficient representation of conditional distributions)</h2><p>即使每个节点有$k$个父节点，一个节点的CPT还需要$O(2^k)$，最坏的情况下父节点和子节点是任意连接的。一般情况下，这种关系可以用符合一些标准模式(standard pattern)的规范分布(canonical distribution)表示，这样子就可以仅仅提供分布的一些参数就能生成整个CPT。<br>最简单的例子是确定性节点(deterministic node)。一个确定性节点的值被它的父节点的值精确确定。这个确定性关系可以是逻辑关系：父节点是加拿大，美国和墨西哥，子节点是北美洲，它们之间的关系是子节点是父节点所在的洲。这个关系也可以是数值型的，一条河的流量是流入它的流量减去流出它的流量。<br>不确定关系通常称为噪音逻辑关系(noisy logical relationships)。一个例子是噪音或(noisy-OR)，它是逻辑或的推广。在命题逻辑中，当且仅当感冒(Cold)，流感(Flu)或者疟疾(Malaria)是真的时候，发烧(Fever)才是真的。噪音或模型允许不确定性，即每一个父节点都有可能让子节点为真，可能父节点和子节点之间的关系被抑制了(inhibited)，可能一个人感冒了，但是没有表现出发烧。这个模型做了两个假设。第一个，它假设所有的原因都被列了出来，有时候会加一个节点(leak node)包含所有的其他原因(miscellaneous causes)。第二个，抑制每一个父节点和子节点之间的原因是独立的，比如抑制疟疾产生发烧和抑制感冒产生发烧的原因是独立的。所以，当且仅当所有的父节点都是假的时候，发烧才一定不会发生。给出以下的假设：<br>$q<em>{cold} = P(\neg fever| cold,\neg flu, \neg malaria) = 0.6$<br>$q</em>{flu} = P(\neg fever|\neg cold, flu, \neg malaria) = 0.2$<br>$q<em>{malaria} = P(\neg fever|\neg cold,\neg flu, malaria) = 0.1$<br>根据这些信息，以及噪音或的假设，整个CPT可以被创建。一般的规则是：<br>$P(x_i|parents(X_i)) = 1 - \prod</em>{j:X_j=ture} q_j.$<br>最后生成如下的表：</p><div class="table-container"><table><thead><tr><th style="text-align:center">Cold</th><th style="text-align:center">Flu</th><th style="text-align:center">Malaria</th><th style="text-align:center">P(Fever)</th><th style="text-align:center">P($\neg$Fever)</th></tr></thead><tbody><tr><td style="text-align:center">F</td><td style="text-align:center">F</td><td style="text-align:center">F</td><td style="text-align:center">$0.0$</td><td style="text-align:center">$1.0$</td></tr><tr><td style="text-align:center">F</td><td style="text-align:center">F</td><td style="text-align:center">T</td><td style="text-align:center">$0.9$</td><td style="text-align:center">$0.1$</td></tr><tr><td style="text-align:center">F</td><td style="text-align:center">T</td><td style="text-align:center">F</td><td style="text-align:center">$0.8$</td><td style="text-align:center">$0.2$</td></tr><tr><td style="text-align:center">F</td><td style="text-align:center">T</td><td style="text-align:center">T</td><td style="text-align:center">$0.98$</td><td style="text-align:center">$0.1\times 0.2=0.02$</td></tr><tr><td style="text-align:center">T</td><td style="text-align:center">F</td><td style="text-align:center">F</td><td style="text-align:center">$0.4$</td><td style="text-align:center">$0.6$</td></tr><tr><td style="text-align:center">T</td><td style="text-align:center">F</td><td style="text-align:center">T</td><td style="text-align:center">$0.94$</td><td style="text-align:center">$0.6\times 0.1 = 0.06 $</td></tr><tr><td style="text-align:center">T</td><td style="text-align:center">T</td><td style="text-align:center">F</td><td style="text-align:center">$0.88$</td><td style="text-align:center">$0.5\times 0.2 = 0.12 $</td></tr><tr><td style="text-align:center">T</td><td style="text-align:center">T</td><td style="text-align:center">T</td><td style="text-align:center">$0.988$</td><td style="text-align:center">$0.6\times 0.2\times 0.1 = 0.012$</td></tr></tbody></table></div><p>对于这个表，感觉自己一直有点转不过来圈。就是有症状不一定发烧，也可能不发烧，没有症状一定不发烧。什么时候不发烧呢，只有某个症状表现出来不发烧，如果多个症状的话，直接把有症状表现但不发烧的概率相乘。<br>一般情况下，噪声逻辑模型中，有$k$个父节点的变量可以用$O(k)$个参数表示而不是$O(2^k)$去表示整个CPT。这让访问(assessment)和学习(learning)更容易了。</p><h3 id="连续性随机变量的贝叶斯网络-Bayesian-nets-with-continuous-variables"><a href="#连续性随机变量的贝叶斯网络-Bayesian-nets-with-continuous-variables" class="headerlink" title="连续性随机变量的贝叶斯网络(Bayesian nets with continuous variables)"></a>连续性随机变量的贝叶斯网络(Bayesian nets with continuous variables)</h3><h4 id="常用方法"><a href="#常用方法" class="headerlink" title="常用方法"></a>常用方法</h4><p>现实中很多问题都是连续型的随机变量，它们有无数可能的取值，所以显式的指定每一个条件概率行不通。常用的总共有三种方法，第一个可能的方法是离散(discretization)连续型随机变量，将随机变量的可能取值划分成固定的区间。比如，温度可以分成，小于$0$度的，$0$度到$100$度之间的，大于$100$度的。离散有时候是可行的，但是通常会造成精度的缺失和非常大的CPT。第二个方法也是最常用的方法是通过指定标准概率密度函数的参数，比如指定高斯分布的均值和方差。第三种方法是非参数化(nonparametric)表示，用隐式的距离去定义条件分布。</p><h4 id="示例-1"><a href="#示例-1" class="headerlink" title="示例"></a>示例</h4><p>一个同时拥有离散型和随机性变量的网络被称为混合贝叶斯网络(hybrid Bayesian network)。为了创建这样一个网络，我们需要两种新的分布。一种是给定离散或者连续的父节点，子节点是连续型随机变量的条件概率，另一种是给定连续的父节点，子节点是离散型随机变量的条件概率。</p><h5 id="连续型子节点"><a href="#连续型子节点" class="headerlink" title="连续型子节点"></a>连续型子节点</h5><p><img src="/2019/01/06/AI-chapter-14-Probabilistic-reasoning/" alt="figure 14.5"><br>考虑Figure 14.5的例子，一个顾客买了一些水果，买水果的量取决取水果的价格(Cost)，水果的价格取决于收成(Harvest)和政府是否有补助(Subsidy)。其中，Cost是连续型随机变量，他有连续的父节点Harvest和离散的父节点Subsidy，Buys是离散的，有一个连续型的父节点Cost。<br>对于变量Cost，我们需要指定条件概率$P(Cost|Subsidy,Harvest)$。离散的父节点通过枚举(enumeration)来表示，指定$P(Cost|subsidy,Harvest)$和$P(Cost|\neg subsidy,Harvest)$。为了表示Harvest，可以指定一个分布来表示变量Cost的值$c$取决于连续性随机变量Harvest的值$h$。换句话说，将$c$看做一个$h$的函数，然后给出这个函数的参数即可，最常用的是线性高斯分布。比如这里，我们可以用两个不同参数的高斯分布来表示有补贴和没补贴时Harvest对Cost的影响：</p><script type="math/tex; mode=display">P(c|h, subsidy) = N(a_th+b_t,\sigma_t^2)(c) = \frac{1}{\sigma_t \sqrt{2\pi} }e^{- \frac{1}{2}(\frac{c-(a_th+b_t)}{\sigma_t})^2}</script><script type="math/tex; mode=display">P(c|h,\neg subsidy) = N(a_fh+b_t,\sigma_f^2)(c) = \frac{1}{\sigma_f \sqrt{2\pi} }e^{- \frac{1}{2}(\frac{c-(a_fh+b_f)}{\sigma_f})^2}</script><p>所以，只需要给出$a_t,b_t,\sigma_t,a_f,b_f,\sigma_f$这几个参数就行了，Figure 14.6(a)和(b)就是一个示例图。注意到坡度(slope)是负的，因为随着供应的增加，cost在下降，当然，这个线性模型只有在harvest在很小的一个区间内才成立，而且cost有可能为负。假设有补贴和没补贴的两种可能性相等，是$0.5$，那么就有了Figure 14.6(c)的图$P(c|h)$。</p><h5 id="连续型父节点"><a href="#连续型父节点" class="headerlink" title="连续型父节点"></a>连续型父节点</h5><p>当离散型随机变量有连续型父节点时，如Figure 14.5中的Buys节点。我们有一个合理的假设是：当cost高的时候，不买，cost底的时候，买，在中间区域买不买是一个变化很平滑的概率。我们可以把条件分布当成一个软阈值函数(soft-threshold)，一种方式是用标准正态分布的积分(intergral)。</p><script type="math/tex; mode=display">\Phi(x) = \int_{-\infty}^{x} N(0,1)(x)dx</script><p>给定Cost买的概率可能是:</p><script type="math/tex; mode=display">P(buys|Cost = c) = \Phi((-x+\nu)/ \sigma))</script><p>其中cost的阈值在$\nu$附近，阈值的区域和正比于$\sigma$，当价格升高的时候，买的概率会下降。这个probit distribution模型如Figure 14.7(a)所示。<br>另一个可选择的模型是logit distribution，使用logistic function $1/(1+e^{-x})$来生成一个软阈值：</p><script type="math/tex; mode=display">P(buys|Cost = c) = \frac{1}{1+exp(-2\frac{-c+u}{\sigma})}.</script><p>如Figure 14.7(b)所示，这两个分布很像，但是logit有更长的尾巴。probit更符合实际情况，但是logit数学上更好算。它们都可以通过对父节点进行线性组合推广到多个连续性父节点的情况。</p><h2 id="贝叶斯网络的精确推理-Exact-inference-in-bayesian-networks"><a href="#贝叶斯网络的精确推理-Exact-inference-in-bayesian-networks" class="headerlink" title="贝叶斯网络的精确推理(Exact inference in bayesian networks)"></a>贝叶斯网络的精确推理(Exact inference in bayesian networks)</h2><p>概率推理系统的基本任务就是给出一些观察到的事件，即给证据变量(evidence variable)赋值，然后计算一系列查询变量(query variable)的后验概率。我们用$X$表示查询变量，用$\mathbf{E}$表示证据变量$E_1,\cdots,E_m$的集合，$\mathbf{e}$是一个特定的观测事件，$\mathbf{Y}$表示既不是证据变量，也不是查询变量的变量$Y_1,\cdots,Y_l$的集合（隐变量,hidden variables)。变量的所有集合是$\mathbf{X}={X}\cup \mathbf{E}\cup \mathbf{Y}$。一个典型的查询是求后验概率$P(X|\mathbf{e})$。<br>在这一节中主要讨论的是计算后验概率的精确算法以及这些算法的复杂度。事实上，在一般情况下精确推理的复杂度都是很高的，为了降低复杂度，就只能进行估计推理(approximate inference)了，这个会在下一节中介绍到。</p><h3 id="枚举实现精确推理-Inference-by-enumeration"><a href="#枚举实现精确推理-Inference-by-enumeration" class="headerlink" title="枚举实现精确推理(Inference by enumeration)"></a>枚举实现精确推理(Inference by enumeration)</h3><p>任何条件概率都可以用联合概率分布的项相加得到，即：</p><script type="math/tex; mode=display">P(X|\mathbf{e}) = \alpha P(X,\mathbf{e}) = \alpha \sum_{\mathbf{y}}P(X,\mathbf{e},\mathbf{y})</script><p>贝叶斯网络给出了所有的联合概率分布，任何项$P(x,\mathbf{e},\mathbf{y})$都可以用贝叶斯网络中的条件概率的乘积表示出来。比如警报例子中的查询$P(Burglary|JohnCalls=true,MaryCalls=true)$。隐变量是Earthquake和Alarm，我们可以算出：</p><script type="math/tex; mode=display">P(B|j,m) = \alpha P(B,j,m) = \alpha \sum_{e}\sum_{a}P(B,j,m,e,a).</script><p>贝叶斯网络已经给出了所有CPT项的表达式，比如当Burglary = true时：</p><script type="math/tex; mode=display">P(b|j,m) = \alpha \sum_e\sum_aP(b,j,m,e,a) = \alpha \sum_e\sum_aP(b)P(e)P(a|b,e)P(j|a)P(m|a).</script><p>为了计算这个表达式，我们得计算一个四项的加法，分别是e为true和false,a为true和false对应的$P(b,j,m)$的值，每一项都是五个数的乘法。最坏的情况下，所有的变量都用到了，那么拥有$n$个布尔变量的贝叶斯网络的时间复杂度是$O(n2^n)$。我们可以做一些简化，将一些重复的计算保存下来，比如将上面的式子变成：</p><script type="math/tex; mode=display">P(b|j,m) = \alpha \sum_e\sum_aP(b,j,m,e,a) = \alpha P(b) \sum_eP(e)\sum_aP(a|b,e)P(j|a)P(m|a).</script><p>这样子可以按照顺序进行计算，具体的计算过程如Figure 14.8所示。这种算法叫做ENUMERATION-ASK，它的空间复杂度是线性的，但是它的事件复杂度是$O(2^n)$比$O(n2^n)$要好，却仍然是实际上不可行的。（这里我理解的是$O(2^n)$而不是$O(n2^n)$的原因是，总共有$n$个布尔变量，所以总共有$2^n$个可能的取值，每次算一个，存一个，而原来的是算完之后不存。）<br>事实上，Figure 14.8中的计算过程还有很多重复计算，比如$P(j|a)P(m|a)$和$P(j|\neg a)P(m|\neg a)$这两项被计算了两次。我原来在想这里是不是和上面一段说的冲突了，事实上是没有的，这$2^n$个值，其中可能会有$P(b,j,m,e,a)$和$P(b,j,m,e,\neg a)$，这两个概率中都用到了$P(j|a)P(m|a)$，但是这里就会计算两次，事实上有很多值都会被重复计算很多次。下面就介绍一个避免这种运算的方法。</p><h3 id="消元法-The-variable-elimination-algorithm"><a href="#消元法-The-variable-elimination-algorithm" class="headerlink" title="消元法(The variable elimination algorithm)"></a>消元法(The variable elimination algorithm)</h3><p>上面问题的解决思路就是保存已经计算过的值，实际上这是一种动态规划。还有很多其他方法可以解决这个问题，这里介绍了最简单的消元算法。消元法对表达式进行从右至左的计算，而枚举法是自底向上的。所有的中间值被报存起来，最对和每个变量有关的表达式进行求和。例如对于下列表达式：</p><script type="math/tex; mode=display">P(B|j,m) = \alpha \underbrace{P(B)}_{f_1(B)} \sum_e\underbrace{P(e)}_{f_2(E)} \sum_a\underbrace{P(a|B,e)}_{f_3(A,B,E)} \underbrace{P(j|a)}_{f_4(A)} \underbrace{P(m|a)}_{f_5(A)}.</script><p>表达式的每一部分都是一个新的因子，每一个因子都是由它的参数变量(argument variables)决定的矩阵，参数变量指定的取值是没有固定的变量。比如因子$f_4(A)$和$f_5(A)$对应$P(j|a)$和$P(m|a)$的表达式只取决于$A$的值因为$J$和$M$在这个查询中都是固定的。它们都是两个元素的向量：</p><script type="math/tex; mode=display">f_4(A) = \begin{pmatrix}P(j|a)\\P(j|\neg a)\end{pmatrix} = \begin{pmatrix}0.90\\0.05\end{pmatrix}</script><script type="math/tex; mode=display">f_5(A) = \begin{pmatrix}P(m|a)\\P(m|\neg a)\end{pmatrix} = \begin{pmatrix}0.70\\0.01\end{pmatrix}</script><p>$f_3(A,B,E)$是一个$2\times 2\times 2$的矩阵。用因子表达的话，查询的表达式变成了：</p><script type="math/tex; mode=display">P(B|j,m) = \alpha f_1(B)\times \sum_ef_2(E)\times \sum_af_3(A,B,E)\times f_4(A)\times f_5(A)</script><p>其中$\times$不是普通的矩阵乘法，而是对应元素相乘(pointwise product)。整个表达式的计算过程可以看成从右到左变量相加的过程，将现有的因子消去产生新的因子，最后只剩下一个因子的过程。具体的步骤如下：<br>首先先利用$f_3,f_4,f_5$把变量$A$消掉，产生一个新的$2\times 2$的只含有变量$B$和$E$的新因子$f_6(B,E)$：<br>\begin{align*}<br>f_6(B,E) &amp;= \sum_af_3(A,B,E)\times f_4(A) \times f_5(A)\<br>&amp;= (f_3(a,B,E)\times f_4(a) \times f_5(a)) + (f_3(\neg a,B,E)\times f_4(\neg a)\times f_5(\neg a)<br>\end{align*}<br>这样目标变成了：</p><script type="math/tex; mode=display">P(B|j,m) = \alpha f_1(B)\times \sum_ef_2(E)\times \sum_af_6(B,E)</script><p>利用$f_2,f_6$消去$E$：<br>\begin{align*}<br>f_7(B) &amp;= \sum_ef_2(E)\times \sum_af_6(B,E)\<br>&amp; = f_2(e)\times f_6(B,e) + f_2(\neg e)\times f_6(B,\neg e)<br>\end{align*}<br>将表达式化成：</p><script type="math/tex; mode=display">P(B|j,m) = \alpha f_1(B)\times f_7(B)</script><p>显然，根据这个表达式就可以计算出我们想要的结果了。上面的过程可以总结成两步，第一步是point-wise的因子乘法，第二步是利用因子的乘法进行消元。</p><h4 id="因子运算-Operations-on-factors"><a href="#因子运算-Operations-on-factors" class="headerlink" title="因子运算(Operations on factors)"></a>因子运算(Operations on factors)</h4><p>两个因子$f_1$和$f_2$进行point-wise乘法运算产生新的因子(factor)$f$的变量是$f_1$和$f_2$变量的并，新的因子中的元素的值是$f_1$和$f_2$中对应项的积。假设两个因子有公共变量$Y_1,\cdots,Y_k$，那么就有：</p><script type="math/tex; mode=display">f(X_1,\cdots,X_j,Y_1,\cdots,Y_k,Z_1,\cdots,Z_l)=f_1(X_1,\cdots,X_j,Y_1,\cdots,Y_k)f_2(Y_1,\cdots,Y_k,Z_1,\cdots,Z_l).</script><p>如果所有的变量都是二值化的，那么$f_1$和$f_2$各有$2^{j+l}$和$2^{l+k}$项，$f$有$2^{j+l+k}$项。比如，$f_1(A,B),f_2(B,C)$，那么point-wise乘法产生的$f_3(A,B,C)=f_1\times f_2$有$8$项，如Figure 14.10所示。<br><img src="/2019/01/06/AI-chapter-14-Probabilistic-reasoning/" alt="figure 14.10"><br>根据图中给出的值，消去$f_3(A,B,C)$中的$A$：<br>\begin{align*}<br>f(B,C) &amp;= \sum_af_3(A,B,C)\<br>&amp;= f_3(a,B,C) + f_3(\neg a,B,C)\<br>&amp;= \begin{pmatrix} 0.06&amp;0.24\0.42&amp;0.28\end{pmatrix} + \begin{pmatrix}0.18&amp;0.72\0.06&amp;0.04\end{pmatrix}\<br>&amp;= \begin{pmatrix}0.24&amp;0.96\048&amp;0.32\end{pmatrix}<br>\end{align*}<br>产生新的因子用的是pointwise乘法，消元用的是累乘。给定pointwise乘法和消元函数，消元算法就变得很简单，一个消元算法如Figure 14.11所示。<br><img src="/2019/01/06/AI-chapter-14-Probabilistic-reasoning/" alt="figure 14.11"></p><h4 id="变量顺序和变量相关性-Variable-ordering-and-variable-relevance"><a href="#变量顺序和变量相关性-Variable-ordering-and-variable-relevance" class="headerlink" title="变量顺序和变量相关性(Variable ordering and variable relevance)"></a>变量顺序和变量相关性(Variable ordering and variable relevance)</h4><p>Figure 14.11中的算法包含一个没有给出具体实现的排序函数Order()对要消去的变量进行排序，每一种排序选择都会产生一组有效的算法，但是不同的消元顺序会产生不同的中间因子。一般情况下，消元法的时间和空间复杂度是由算法产生的最大因子决定的，这个最大因子是由消元的顺序和贝叶斯网络的结构决定的，选取最优的消元顺序是很困难的，但是有一些小的技巧：总是消去让新产生的因子最小的变量。<br>另一个属性是：每一个不是查询变量或者证据变量的祖先变量都和这次查询无关，在实现消元算法的时候可以把这些变量都去掉。（具体的示例可以看第十四章，在$528$页）。</p><h3 id="精确推理的复杂度-The-complexity-of-exact-inference"><a href="#精确推理的复杂度-The-complexity-of-exact-inference" class="headerlink" title="精确推理的复杂度(The complexity of exact inference)"></a>精确推理的复杂度(The complexity of exact inference)</h3><p>贝叶斯网络的精确推理跟网络的结构有很大的关系。<br>Figure 14.2中警报贝叶斯网络中的复杂度是线性的。该网络中任意两个节点只有一条路径，这种网络称为单连接的(singly-connected)或者多树(polytrees)，这种结构有一个很好的属性就是：多树结构中精确推理的时间，空间复杂度对于网络大小来说都是线性关系，这里网络大小指的是CPT项的个数。如果每一个节点的父节点都是一个有界的常数，那么复杂度和节点数之间也是线性关系。<br>对于多连接(multiply connected)的网络，如Figure 14.12(a)所示，最坏情况下，即使每一个节点的父节点个数都是有界常数，消元法的时间和空间复杂度也都是指数级别的。因为贝叶斯网络的推理也是NP难问题。<br><img src="/2019/01/06/AI-chapter-14-Probabilistic-reasoning/" alt="figure 14.12"></p><h3 id="聚类算法-clustering-algorithms"><a href="#聚类算法-clustering-algorithms" class="headerlink" title="聚类算法(clustering algorithms)"></a>聚类算法(clustering algorithms)</h3><p>用消元法来计算单个的后验概率是简单而高效的，但是如果要计算网络中所有变量的后验概率是很低效的。例如：在单连接的网络中，每一个查询都是$O(n)$，总共有$O(n)$个查询，所以总共的代价是$O(n^2)$。使用聚类算法(clustering algorithms)，代价可以降到$O(n)$，因此贝叶斯网络中的聚类算法已经被广泛商用。（这里不明白为什么？）。<br>聚类算法的基本思想是将网络中的一些节点连接成聚点(cluster nodes)，最后形成一个多树(polytree)结构。例如Figure 14.12(a)中的多连接网络可以转换成Figure 14.12(b)所示的多树，Sprinkler和Rain节点形成了SPrinkler+Rain聚点，这两个布尔变量被一个大节点(meganode)取代，这个大节点有四个可能的取值：$tt,tf,ft,ff$。一旦一个多树形式的网络生成了以后，就需要特殊的推理算法进行推理了，因为普通的推理算法不能处理共享变量的大节点，有了这样一个特殊的算法，后验概率的时间复杂度就是线性于聚类网络的大小。但是，NP问题并没有消失，如果消元需要指数级别的时间和空间复杂度，聚类网络中的CPT也是指数级别大小。</p><h2 id="贝叶斯网络的估计推理-Approximate-inference-in-bayesian-networks"><a href="#贝叶斯网络的估计推理-Approximate-inference-in-bayesian-networks" class="headerlink" title="贝叶斯网络的估计推理(Approximate inference in bayesian networks)"></a>贝叶斯网络的估计推理(Approximate inference in bayesian networks)</h2><p>因为多连接网络中的推理是不可行的，所以用估计推理取代精确推理是很有用的。这一节会介绍随机采样算法，也叫蒙特卡洛算法(Monte Carlo)，它的精确度取决于生成的样本数量。我们的目的是采样用于计算后验概率。这里给出了两类算法，直接采样(direct sampling)和马尔科夫链采样(Markov chain sampling)。变分法(variational methods)和循环传播(loopy propagation)将会在本章的最后进行介绍。</p><h3 id="直接采样-Direct-sampling-methods"><a href="#直接采样-Direct-sampling-methods" class="headerlink" title="直接采样(Direct sampling methods)"></a>直接采样(Direct sampling methods)</h3><p>任何采样算法都是通过一个已知的先验概率分布生成样本。比如一个公平的硬币，服从一个先验分布$P(coin) = <0.5,0.5> $，从这个分布中采样就像抛硬币。<br>一个最简单的从贝叶斯网络中进行随机采样的方法就是：从没有证据和它相关的网络中生成事件，即按照拓扑顺序对每一个变量进行采样。如Figure 14.13所示的算法，每一个变量的采样都取决于前之前已经采样过了的父节点变量的值。按照Figure 14.13中的算法对Figure 14.12(a)中的网络进行采样，假设一个采样顺序是[Cloudy,Sprinkler,Rain,WetGrass]：</0.5,0.5></p><ol><li>从$P(Cloudy)=<0.5,0.5>$中采样，采样值是true；</0.5,0.5></li><li>从$P(Sprinkler|Cloudy=true) = <0.1,0.9>$中采样，采样值是false； </0.1,0.9></li><li>从$P(Rain|Cloudy=true)=<0.8,0.2>$中采样，采样值是true；</0.8,0.2></li><li>从$P(WetGrass|Sprinkler=false,Rain=true)=<0.9,0.1>$中采样，采样值是true；</0.9,0.1></li></ol><p>这个例子中，PRIOR-SAMPLE算法返回事件[true,false,true,true]。可以看出来，PRIOR-SAMPLE算法根据贝叶斯网络指定的先验联合分布生成样本。假设$S_{PS}(x_1,\cdot,x_n)$是PRIOR-SAMPLE算法生成的一个样本事件，从采样过程中我们可以得出：</p><script type="math/tex; mode=display">S_{PS}(x_1,\cdots,x_n) = \prod_{i=1}^nP(x_i|parents(X_i))</script><p>即每一步采样都只取决于父节点的值。这个式子和贝叶斯网络的联合概率分布是一样的，所以，我们可以得到：</p><script type="math/tex; mode=display">S_{PS} = P(x_1,\cdots,x_n).</script><p>通过采样让这个联合分布的求解很简单。<br><img src="/2019/01/06/AI-chapter-14-Probabilistic-reasoning/" alt="figure 14.13"><br>事实上在任何采样算法中，结果都是通过对产生的样本进行计数得到的。假设生成了$N$个样本，$N<em>{PS}(x_1,\cdots,x_n)$是样本集中的一个具体事件$(x_1,\cdots,x_n)$发生的次数。我们希望这个值比上样本总数取极限和采样概率$S</em>{PS}$是一样的，即：</p><script type="math/tex; mode=display">lim_{N\rightarrow \infty}\frac{N_{PS}(x_1,\cdots,x_n)}{N} = S_{PS}(x_1,\cdots,x_n) = P(x_1,\cdots,x_n).</script><p>例如之前利用PRIOR-SAMPLE算法产生的事件[true,false,true,true]，这个事件的采样概率是：</p><script type="math/tex; mode=display">S_{PS}(true,false,true,true) = 0.5 \times 0.9 \times 0.8 \times 0.9 = 0.324.</script><p>即当$N$取极限时，我们希望有$32.4\%$的样本都是这个事件。(这里为什么要用采样进行计算呢，我的想法是因为实际情况中，采样概率$S_{PS}$是很难计算的，就通过不断的采样，计算出某个样本出现的概率。)<br>我们用$\approx$表示估计概率(estimated probability)在样本数量$N$取极限时和真实概率一样的估计，这叫一致(consistent)估计。比如，对于任意的含有隐变量的事件(partially spefified event)，$x_1,\cdots,x_m,m\le n$，会产生一个一致估计：</p><script type="math/tex; mode=display">P(x_1,\cdots,x_m)\approx N_{PS}(x_1,\cdots,x_m)/N.</script><p>这个事件的概率可以看成所有满足观测变量条件的样本事件（隐变量所有值都可以取）比上所有样本事件的比值。比如在Spinkler网络中，生成$1000$个样本，其中有$511$个样本的Rain=true，那么rain的估计概率就是$\hat{P}(Rain=true) = 0.511.$</p><h4 id="贝叶斯网络的拒绝采样-Rejection-sampling-in-Bayesian-networks"><a href="#贝叶斯网络的拒绝采样-Rejection-sampling-in-Bayesian-networks" class="headerlink" title="贝叶斯网络的拒绝采样(Rejection sampling in Bayesian networks)"></a>贝叶斯网络的拒绝采样(Rejection sampling in Bayesian networks)</h4><h5 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h5><p><img src="/2019/01/06/AI-chapter-14-Probabilistic-reasoning/" alt="figure 14.14"><br>拒绝采样(rejection sampling)利用容易采样的分布来生成难采样分布的样本，计算后验概率$P(X|\mathbf{e})$，算法流程如Figure 14.14所示，首先根据贝叶斯网络的先验分布生成样本，接下来拒绝(reject)那些和证据变量不匹配的结果，最后在剩下的样本中统计每个$X=x$出现的概率，估计$\hat{P}(X|\mathbf{e}).$<br>用$\hat{P}(X|\mathbf{e})$表示估计概率分布，利用拒绝采样算法的定义计算：</p><script type="math/tex; mode=display">\hat{P}(X|\mathbf{e}) = \alpha N_{PS}(X,\mathbf{e}) = \frac{N_{PS}(X,\mathbf{e})}{N_{PS}(\mathbf{e})}.</script><p>而根据$P(x<em>1,\cdots,x_m)\approx N</em>{PS}(x_1,\cdots,x_m)/N$，就有：</p><script type="math/tex; mode=display">\hat{P}(X|\mathbf{e}) = \alpha N_{PS}(X,\mathbf{e}) = \frac{N_{PS}(X,\mathbf{e})}{N_{PS}(\mathbf{e})} =  \frac {P(X,\mathbf{e})}{P(\mathbf{e})} = P(X|\mathbf{e}).</script><p>所以，拒绝采样产生了真实概率的一个一致估计(consistent estimate)，但是这个一致估计和无偏估计还不一样。</p><h5 id="示例-2"><a href="#示例-2" class="headerlink" title="示例"></a>示例</h5><p>举一个例子来说明，假设我们要估计概率$P(Rain|Sprinkler=true)$，生成了$100$个样本，其中$73$个是$Sprinkler=false$，$27$是$Sprinkler=true$，这$27$个中有$8$个$Rain=true$，有$19$个$Rain=false$，因此：</p><script type="math/tex; mode=display">P(Rain|Sprinkler=true)\approx NORMALIZE \lt\lt 8,19>> = <0.296,0.704>.</script><p>正确答案是$<0.3,0.7>$，可以看出来，估计值和真实值差的不多。生成的样本越多，估计值就会和正确值越接近，概率的估计误差和$1/\sqrt{n}$成比例，$n$是用来估计概率的样本数量。</0.3,0.7></p><h5 id="不足"><a href="#不足" class="headerlink" title="不足"></a>不足</h5><p>拒绝采样最大的问题是它拒绝了很多样本，随着证据变量的增加，和证据$\mathbf{e}$一致的样本指数速度减少，所以这个方法对于复杂的问题是不可行的。拒绝假设和现实生活中条件概率是很像的，比如估计观测到晚上天空是红的，第二天下雨的概率$P(Rain|RedSkyAtNight=ture)$，这个条件概率的估计就是根据日常生活的观察实现的。但是如果天空很少是红的，就需要很长时间才能估计它的值，这就是拒绝假设的缺点。</p><h4 id="可能性加权-Likelihood-weighting"><a href="#可能性加权-Likelihood-weighting" class="headerlink" title="可能性加权(Likelihood weighting)"></a>可能性加权(Likelihood weighting)</h4><h5 id="算法-1"><a href="#算法-1" class="headerlink" title="算法"></a>算法</h5><p>可能性加权(Likelihood weighting)只产生和证据$\mathbf{e}$一致的事件，因此避免了拒绝采样的低效。它是统计学中重要性采样的一个例子，专门为贝叶斯推理设计的。<br>如Figure 14.15所示，加权似然固定证据变量$\mathbf{E}$的值，只对非证据变量进行采样，这就保证了每一个事件都是和证据一致的。但是，不是所有的事件权重都是一样的。给定每一个证据变量的父节点，它的可能性(likelihood)是证据变量的条件概率的乘积，每一个事件都根据证据的可能性进行加权。</p><h5 id="示例-3"><a href="#示例-3" class="headerlink" title="示例"></a>示例</h5><p>对于Figure 14.12(a)中的例子，计算后验概率$P(Rain|Cloudy=true,WetGrass=true)$，采样顺序是Cloudy,Sprinkler,Rain,WetGrass。过程如下，首先，权重$w$设为$1$，一个事件生成过程如下：</p><ol><li>Cloudy是一个证据变量，它的值是true,因此，令：<script type="math/tex; mode=display">w\leftarrow w\times P(cloudy=true) = 0.5.</script></li><li>Sprinkler是隐变量，所以从$P(Sprinkler|Cloudy=true)=<0.1,0.9>$中采样，假设采样结果是false； </0.1,0.9></li><li>Rain是隐变量，从$P(Rain|Cloudy=true)=<0.8,0.2>$中采样，假设采样结果是true； </0.8,0.2></li><li>WetGrass是证据变量，值是true,令：<script type="math/tex; mode=display">w\leftarrow w\times P(WetGrass=true|Sprinkler=false,Rain=true) = 0.45.</script></li></ol><p>所以WEIGHTED-SAMPLE算法生成事件[true,false,true,true]，相应的权重是$0.45$。</p><h5 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h5><p>用$S_{WS}$表示WEIGHTED-SAMPLE算法中事件的采样概率，证据变量$\mathbf{E}$的取值$\mathbf{e}$是固定的，用$\mathbf{Z}$表示非证据变量，包括隐变量$\mathbf{Y}$和查询变量$\mathbf{X}$。给定变量$\mathbf{Z}$的父节点，算法对变量$\mathbf{Z}$进行采样：</p><script type="math/tex; mode=display">S_{WS}(\mathbf{z},\mathbf{e}) = \prod_{i=1}^lP(z_i|parents(Z_i)).</script><p>其中$Parents(Z<em>i)$可能同时包含证据变量和非证据变量。<br>和先验分布$P(\mathbf{z})$不同的是，每一个变量$Z_i$的取值会受到$Z_i$的祖先(ancestor)变量的影响。比如，对Sprinkler进行采样的时候，算法会受到它的父节点中的证据变量Cloudy=true的影响，而先验分布不会。另一方面，$S</em>{WS}$比后验分布$P(\mathbf{z}|\mathbf{e})$受证据的影响更小，因为对$Z_i$的采样忽略了$Z_i$的非祖先(non-ancestor)变量中的证据。比如，对Sprinkler和Rain进行采样的时候，算法忽略了子节点中的证据变量WetGrass=true，事实上这个证据已经排除了(rule out)Sprinkler=false和Rain=false的情况，但是WEIGHTED-SAMPLE还会产生很多这样的样本事件。<br>理想情况下，我们想要一个采样分布和真实的后验概率$P(\mathbf{z}|\mathbf{e})$相等，不幸的是不存在这样的多项式时间的算法。如果有这样的算法的话，我们可以用多项式数量的样本以任意精度逼近想要求的概率值。<br>可能性权重$w$弥补了实际的分布和我们想要的分布之间的差距。一个由$\mathbf{z}$和$\mathbf{e}$组成的样本$\mathbf{x}$的权重是给定了父节点的证据变量的可能性乘积：</p><script type="math/tex; mode=display">w(\mathbf{z},\mathbf{e}) = \prod_{i=1}^mP(e_i|parents(E_i)).</script><p>将上面的两个式子乘起来，可以得到一个样本的加权概率(weighted probability)是：</p><script type="math/tex; mode=display">S_{WS}(\mathbf{z},\mathbf{e})w(\mathbf{z},\mathbf{e}) = \prod_{i=1}^lP(z_i|parents(Z_i))\prod_{i=1}^mP(e_i|parents(E_i)) = P(\mathbf{z},\mathbf{e}).</script><p>可能性加权估计是一致估计。对于任意的$x$，估计的后验概率按下式计算：<br>\begin{align*}<br>\hat{P}(x|\mathbf{e}) &amp;= \alpha \sum<em>{\mathbf{y}} N</em>{WS}(x,\mathbf{y},\mathbf{e})w(x,\mathbf{y},\mathbf{e})\<br>&amp;\approx \alpha’\sum<em>{\mathbf{y}}S</em>{WS}(x,\mathbf{y},\mathbf{e})w(x,\mathbf{y},\mathbf{e})\<br>&amp;=\alpha’\sum<em>{\mathbf{y}}P(x,\mathbf{y},\mathbf{e})\<br>&amp;=\alpha’\sum</em>{\mathbf{y}}P(x,\mathbf{y},\mathbf{e})\<br>&amp;=P(x|\mathbf{e})<br>\end{align*}<br>算法中真实实现的是第一行，即统计出用WEIGHTED-SAMPLE产生的样本$(x,\mathbf{y},\mathbf{e})$数量$N<em>{WS}$，以及对应的权重$w(x,\mathbf{y},\mathbf{e})$，后面的都是理论推导，当$N$取极限的时候$lim</em>{N\rightarrow \infty}\frac{N<em>{WS}(x_1,\cdots,x_n)}{N} = S</em>{WS}(x_1,\cdots,x_n)$，后面的都是为了证明算法是一致估计。</p><h5 id="不足-1"><a href="#不足-1" class="headerlink" title="不足"></a>不足</h5><p>可能性加权算法使用了所有生成的样本，它比拒绝假设算法更高效。然而，随着证据变量的增加，算法性能会退化(degradation)，这是因为很多样本的权重都会很小，因此加权估计可能会受一小部分权重很大的样本的影响(dominated)。如果证据变量在非证据变量的后边，这个问题会加剧，因为它们的父节点或者祖先节点没有证据变量来指导样本的生成。这就意味着生成的样本和证据变量支撑的真实情况可能差距很大(bear little resemblance)。</p><h3 id="马尔科夫链仿真推理-Inference-by-Markov-chain-simulation"><a href="#马尔科夫链仿真推理-Inference-by-Markov-chain-simulation" class="headerlink" title="马尔科夫链仿真推理(Inference by Markov chain simulation)"></a>马尔科夫链仿真推理(Inference by Markov chain simulation)</h3><p>马尔科夫链蒙特卡洛(Markov chain Monte Carlo,MCMC)算法和拒绝采样以及可能性加权很不一样。那两个方法每次都从头开始生成样本，而MCMC算法在之前的样本上做一些随机的变化。可以将MCMC算法看成指定了每一个变量值的特殊当前状态(current state)，通过对当前状态(current state)做任意的改变生成下一个状态(next state)。这一节要介绍的一种MCMC算法是吉布森采样(Gibbs sampling)。</p><h4 id="贝叶斯网络中的吉布森采样-Gibbs-sampling-in-Bayesian-networks"><a href="#贝叶斯网络中的吉布森采样-Gibbs-sampling-in-Bayesian-networks" class="headerlink" title="贝叶斯网络中的吉布森采样(Gibbs sampling in Bayesian networks)"></a>贝叶斯网络中的吉布森采样(Gibbs sampling in Bayesian networks)</h4><h5 id="算法-2"><a href="#算法-2" class="headerlink" title="算法"></a>算法</h5><p>贝叶斯网络中的吉布森采样从任意一个状态开始，其中证据变量的取值固定为观测值，通过随机选取非证据变量$X_i$的值生成下一个状态。变量$X_i$的采样取决于变量$X_i$的马尔科夫毯的当前值。算法在状态空间（所有非证据变量的全部可能取值空间）中随机采样，每次采样都保持证据变量不变，一次改变一个非证据变量的值。完整的算法如Figure 14.16所示。<br><img src="/2019/01/06/AI-chapter-14-Probabilistic-reasoning/" alt="figure 14.16"></p><h5 id="示例-4"><a href="#示例-4" class="headerlink" title="示例"></a>示例</h5><p>Figure 14.12(a)中的查询(query)$P(Rain|Sprinkler=true, WetGrass=true)$，证据变量Spinkler和WetGrass取它们的观测值不变，非证据变量Cloudy和Rain随机初始化，假设取的是true和false。那么初始状态就是[true,true,false,true]，接下来对非证据变量进行重复的随机采样。<br>比如第一次对Cloudy采样（也可以对Rain采样），给定它的马尔科夫毯变量，然后从$P(Cloudy|Sprinkler=true,Rain=false)$中进行采样，假设采样结果是false，新的状态就是[false,true,false,true]。接下来随机可以对Rain采样（也可以对Cloudy采样），给定Rain的马尔科夫毯变量的取值，从$P(Rain|Cloudy=false,Sprinkler=true,WetGrass=true)$中进行采样，假设采样值是true,那么新的状态是[true,true,false,false]。接下来可以一直进行采样。。最终利用生成的样本计算出相应的概率。</p><h4 id="为什么吉布森采样有用-Why-Gibbs-sampling-works"><a href="#为什么吉布森采样有用-Why-Gibbs-sampling-works" class="headerlink" title="为什么吉布森采样有用(Why Gibbs sampling works)"></a>为什么吉布森采样有用(Why Gibbs sampling works)</h4><p>接下来给出为什么吉布森采样计算后验概率是一致估计。基本的解释是直截了当的：采样过程建立了一个动态平衡，每个状态花费的时间长期来说和它的后验概率是成比例的。<br>具体的，不想看了。。。就随缘吧</p><h2 id="关系和一阶概率模型-Relational-and-first-order-probability-models"><a href="#关系和一阶概率模型-Relational-and-first-order-probability-models" class="headerlink" title="关系和一阶概率模型(Relational and first-order probability models)"></a>关系和一阶概率模型(Relational and first-order probability models)</h2><h2 id="其他不确定性推理的方法-Other-approaches-to-uncertain-reasoning"><a href="#其他不确定性推理的方法-Other-approaches-to-uncertain-reasoning" class="headerlink" title="其他不确定性推理的方法(Other approaches to uncertain reasoning)"></a>其他不确定性推理的方法(Other approaches to uncertain reasoning)</h2><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>1.<a href="http://aima.cs.berkeley.edu/" target="_blank" rel="noopener">Artificial Intelligence A Modern Approach Third Edition,Stuart Russell,Peter Norvig.</a><br>2.<a href="https://en.wikipedia.org/wiki/Chain_rule_(probability" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Chain_rule_(probability</a>)<br>3.<a href="https://en.wikipedia.org/wiki/Consistent_estimator" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Consistent_estimator</a> </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在这里加一些自己的总结，这一章主要讲的是贝叶斯网络，首先介绍了贝叶斯网络的定义，是一个有向无环图，节点代表随机变量，边代表因果关系。这里给出了贝叶斯公式的两个意义，一个是数值意义，用贝叶斯网络表示全概率分布，另一个是拓扑意义，给定某个节点的父节点，这个节点条件独立于所有它的
      
    
    </summary>
    
      <category term="机器学习" scheme="http://mxxhcm.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="人工智能" scheme="http://mxxhcm.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="概率图模型" scheme="http://mxxhcm.github.io/tags/%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B/"/>
    
      <category term="贝叶斯网络" scheme="http://mxxhcm.github.io/tags/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BD%91%E7%BB%9C/"/>
    
      <category term="推理" scheme="http://mxxhcm.github.io/tags/%E6%8E%A8%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>PRML chapter 8 Graphical Models</title>
    <link href="http://mxxhcm.github.io/2019/01/06/PRML-chapter-8-Graphical-Models/"/>
    <id>http://mxxhcm.github.io/2019/01/06/PRML-chapter-8-Graphical-Models/</id>
    <published>2019-01-06T06:31:09.000Z</published>
    <updated>2019-05-06T16:22:27.704Z</updated>
    
    <content type="html"><![CDATA[<p>$\newcommand{\mmm}{\mathbf}$<br><strong>概率图模型</strong><br>概率论在现代模式识别中有很重要的地位。第一章中介绍了概率论可以被表示成两个简单的加法和乘法公式。事实上在这本书中讨论的所有概率推理和学习的计算（无论有多复杂）都可以看成这两个公式的重复应用。我们可以只用代数计算(algebraic manipulation)来形式化并解决复杂的概率问题。但是，使用概率分布(probability distributions)的图表示(diagrammatic representations)，即概率图模型(graphical models)会更有优势。概率图模型有以下几个有用的属性：</p><ol><li>概率图模型提供了一个简单的方式可视化(visualize)概率模型的结构，并且能够用来设计和产生新的模型。</li><li>通过观察概率图模型，可以看到模型的一些属性，包括条件独立性(conditional independence)等等。</li><li>在复杂模型上进行的需要推理和学习的复杂计算，可以被表示为图计算，底层的数据表达式隐式的被执行。</li></ol><p>一个图由节点(nodes)，有时也叫顶点(vertices)，连接顶点的连接(links)，也叫边(edges)。在一个概率图模型中，每一个节点代表一个随机变量，或者一组随机变量，边代表着变量之间的概率关系(probabilistic relationships)。所有随机变量的联合分布可以被分解成一系列部分随机变量的乘积。<br>本章从有向图(directed graphical models)中的贝叶斯网络(Beyesian networks)开始介绍，有向图中的边通过箭头表示方向。另一个主要的图模型是马尔科夫随机场(Markov random fields)，它是一个无向图模型(undirected graphical models)，没有明显的方向性。有向图用来描述随机变量之间的因果关系(causal relationships)，而无向图用来描述随机变量之间的一些软约束(soft constraints)。为了解决推理问题，将无向图和有向图转化成另一种因子图(factor graph)表示是很方便的。</p><h2 id="贝叶斯网络-Bayesian-Networks"><a href="#贝叶斯网络-Bayesian-Networks" class="headerlink" title="贝叶斯网络(Bayesian Networks)"></a>贝叶斯网络(Bayesian Networks)</h2><p>图的一个很强大的特点就是一个具体的图可以用来解释一类概率分布。给定随机变量$a,b,c$的联合概率分布$p(a,b,c)$，通过利用乘法公式，我们可以把它写成以下形式：</p><script type="math/tex; mode=display">p(a,b,c) = p(c|a,b)p(b|a)p(a).</script><p>这个公式对于任意的联合分布都成立，我们用节点$a,b,c$表示随机变量，按照上式的右边找出每个节点对应的条件分布，在图中添加一个有向箭头从依赖变量指向该变量。如Figure 8.1所示,$a$到$b$的边表示$a$是$b$的父节点。上式中左边是$a,b,c$是对称的，但是右边不是，事实上，在做分解的时候，一个隐式的顺序$a,b,c$已经被确定了，当然也可以选其他顺序，这样会得到一个新的分解和一个新的图。<br><img src="/2019/01/06/PRML-chapter-8-Graphical-Models/" alt="figure 8.1"><br>如果把三个变量可以扩展到$K$个变量，则对应的联合概率为$p(x_1,\cdots,x_k)$，写成如下形式：</p><script type="math/tex; mode=display">p(x_1,\cdots,x_K) = p(x_K|x_{K-1},\cdots,x_1)\cdots p(x_2|x_1)p(x_1).</script><p>这个式子也叫链式法则，微积分中也有链式法则，这个是概率论中的链式法则。给定$K$值，我们也能生成一个含有$K$个节点的有向图，每一个节点都对应一个条件分布，每一个节点都和比它序号小的节点全部直接相连，所以这个图也叫全连接图，因为任意两个节点都直接相连，但是只有一条有向边由小号节点指向大号节点，所以没有环。<br><img src="/2019/01/06/PRML-chapter-8-Graphical-Models/" alt="figure 8.2"><br>目前为止，所有的操作都是在完全的联合概率分布，相应的分解以及全连接网络上进行的，它们可以应用到任何分布。但是图中也可能有缺失的边，如Figure 8.2所示，它不是一个全连接的图。我们可以直接根据这个图将联合分布表示为很多条件分布的乘积。每一个条件分布的取值只跟图中对应的父节点。比如，$x_5$只取决于$x_1$和$x_3$，$7$个变量的联合概率分布可以写成：</p><script type="math/tex; mode=display">p(x_1)p(x_2)p(x_3)p(x_4|x_1,x_2,x_3)p(x_5|x_1,x_3)p(x_6|x_4)p(x_7|x_4,x_5)</script><p>从上面我们可以看出有向图和变量的条件概率之间的关系，图中定义的联合概率分布是图中所有节点给定其父节点的条件概率的乘积，即:</p><script type="math/tex; mode=display">p(\mathbf{x}) = \prod_{k=1}^Kp(x_k|pa_k).</script><p>其中$pa_k$是$x_k$节点的父节点的集合，$\mathbf{x} = {x_1,\cdots,x_k}$，这个式子给出了一个有向图的联合概率具有因式分解属性。<br>贝叶斯网络中不能存在有向的圈，即不能存在闭路，所以这种图也叫有向无环图。另一种说法是如果图中的节点有顺序的话，不能存在大号节点到小号节点的有向边。</p><h3 id="示例：多项式回归-Example-Polynomial-regression"><a href="#示例：多项式回归-Example-Polynomial-regression" class="headerlink" title="示例：多项式回归(Example: Polynomial regression)"></a>示例：多项式回归(Example: Polynomial regression)</h3><p><img src="/2019/01/06/PRML-chapter-8-Graphical-Models/" alt="figure 8.3"><br>这里给出了一个用有向图描述概率分布的例子，贝叶斯多项式回归模型。模型中的随机变量是多项式系数向量$\mathbf{w}$以及观测值$\mathbf{t}=(t_1,\cdots,t_N)^T$，此外，还有一些模型中确定的参数，它们不是随机变量，如输入数据$\mathbf{x}=(x_1,\cdots,x_N)^T$，噪音方差$\sigma^2$，还有$\mathbf{w}$上高斯分布精度的超参数$\alpha$。如果只关注随机变量，联合分布可以看成先验分布$p(\mathbf{w})$和$N$个条件分布$p(t_n|\mathbf{w}),n=1,\cdots,N$的乘积：</p><script type="math/tex; mode=display">p(\mathbf{t},\mathbf{w}) = p(\mathbf{w})\prod_{n=1}^Np(t_n|\mathbf{w}).</script><p>这个模型可以用Figure 8.3表示。<br><img src="/2019/01/06/PRML-chapter-8-Graphical-Models/" alt="figure 8.4"><br>为了方便表示，我们把$t_1,\cdots,t_N$用一个单独的节点，外面用一个盒子包着，叫做盘子(plate)，盘子上写上$N$代表有$N$个这样的节点，得到Figure 8.4中的图。如果把模型确定的参数写出来，我们可以得到下式：</p><script type="math/tex; mode=display">p(\mathbf{t},\mathbf{w}|\mathbf{x},\alpha,\sigma^2) = p(\mathbf{w}|\alpha)\prod_{n=1}^Np(t_n|\mathbf{w},x_n,\sigma^2).</script><p><img src="/2019/01/06/PRML-chapter-8-Graphical-Models/" alt="figure 8.5"><br>如果在图中把模型参数和随机变量都表示出来，用空心圆圈代表随机变量，用实心圆点代表确定性参数(deterministic parameters)，用图形表示如Figure 8.5。<br><img src="/2019/01/06/PRML-chapter-8-Graphical-Models/" alt="figure 8.6"><br>当用图模型去解决机器学习或者模型时，有时候会固定一些随机变量的值，比如在多项式拟合问题中训练集的变量${t_n}$，在图模型中，将对应节点加上阴影，表示观测变量(observed variables)。如Figure 8.6所示，变量${t_n}$是观测变量。$\mathbf{w}$没有被观测到，所以是一个隐变量(latent variable)或者是(hidden variable)。<br>利用观测到的${t_n}$的值，我们可以估计多项式系数$\mathbf{w}$，利用贝叶斯公式：</p><script type="math/tex; mode=display">p(\mathbf{w}|\mathbf{T}) \propto p(\mathbf{w}) \prod_{n=1}^Np(t_n|\mathbf{w})</script><p>为了整洁(uncluttered)，模型的确定性参数被略去了。<br><img src="/2019/01/06/PRML-chapter-8-Graphical-Models/" alt="figure 8.7"><br>一般来说，我们对于如$\mathbf{w}$之类的模型参数不感兴趣，因为我们的目标是用模型对新的输入进行预测。即在给定观测数据之后，我们给出一个新的输入$\hat{x}$，要找到对应的$\hat{t}$的概率分布，如Figure 8.7所示。给定确定性参数之后，图中所有随机变量的联合分布如下所示：</p><script type="math/tex; mode=display">p(\hat{t},\mathbf{t},\mathbf{w}|\hat{x},\mathbf{x},\alpha,\sigma^2) = \left[\prod_{n=1}^Np(t_n|x_n,\mathbf{w},\sigma^2)\right] p(\mathbf{w}|\alpha)p(\hat{t}|\hat{x},\mathbf{w},\sigma^2).</script><p>刚开始有一些不理解，但是实际上就是这样一个公式$p(a,b,c) = p(a)p(b|a)p(c|a)$，把$\hat{t}$和$\mathbf{t}$当成两个变量看就行了。<br>利用概率论的加法公式$p(X) = \sum\limits_Yp(X,Y)$，对模型的参数$\mathbf{w}$积分就得到了$\hat{t}$的预测分布：<br>\begin{align*}<br>p(\hat{t}|\hat{x},\mathbf{x},\mathbf{t},\alpha,\sigma^2) = \int p(\hat{t},\mathbf{w}|\hat{x},\mathbf{x},\mathbf{t},\alpha,\sigma^2)d\mathbf{w}<br>\propto \int p(\hat{t},\mathbf{t},\mathbf{w}|\hat{x},\mathbf{x},\alpha,\sigma^2)d\mathbf{w}<br>\end{align*}<br>其中随机变量$\mathbf{t}$被隐式的赋值为数据集中的观测值，即是一个$p(t)$是一个定值。这里刚开始有些不理解,实际上是当$p(b)$为定值的时候，$p(a|b) \propto p(ab)$。</p><h3 id="生成模型-Generative-models"><a href="#生成模型-Generative-models" class="headerlink" title="生成模型(Generative models)"></a>生成模型(Generative models)</h3><p>这里实际上介绍的是采样方法，叫祖先采样，实际上就是直接采样，AI的第十四章有讲很多采样，可以直接看那个。<br>很多时候我们需要从一个给定的分布中进行采样，十一章还会更详细的讲采样，这里要介绍一种采样分布叫祖先采样(ancestral sampling)，是一种和概率图模型相关的采样方法。给定$K$个变量的联合分布$p(x_1,\cdots,x_K)$对应的有向无环图，假设所有变量的父节点的序号都比它本身小。我们的目标是从联合分布中采样$\hat{x_1},\cdots,\hat{x_k}$。<br>首先从最小的序号根据$p(x_1)$开始采样，采样结果称为$\hat{x_1}$，接下来按顺序对第$n$个节点按照条件分布$p(x_n|pa_n)$进行采样，每个节点的父节点都取采样值，因为每个父节点都已经采完样了，所以这里不用担心。一直到第$K$个节点采样完成，就生成了一个样本。为了对某些边缘分布进行采样，对需要的节点进行采样，忽略其他节点即可，比如为了对边缘分布$p(x_2,x_4)$进行采样，从联合分布中进行采样，保留$\hat{x_2},\hat{x_4}$的值，其他的值不用管即可。<br>在概率图的实际应用中，通常小节点对应的是隐变量，大节点对应的图上的最终节点代表着一些观测变量。隐变量的目的是让观测变量的复杂概率分布可以表示成多个简单的条件概率分布的乘积。<br>我们可以把这样的模型解释为观测变量产生的过程，比如，一个模式识别任务中，每一个观测数据对应一张图片。隐变量解释为物体的位置和方向，给定一个观测图像，我们的目标是找到物体的一个后验分布，在后验分布中对所有可能的位置和方向进行积分，如Figure 8.8所示。<br>图模型通过观测数据的生成过程描述了一种因果关系过程，因为这个原因，这样的模型也叫做生成式模型(generative model)。相反，Figure 8.5中的模型不是生成式模型，因为多项式回归模型中的输入变量$x$没有概率分布，所以不能用来合成数据。通过引入一个合适的先验分布$p(x)$，我们可以把它变成一个生成式模型。<br>事实上，概率图模型中的隐变量不是必须要有显式的物理意义，它的引入只是为了方便从简单的条件概率生成复杂的联合分布。在任何一种情况下，应用到生成式模型的祖先采样模拟了观测数据的生成过程，因此产生了和观测数据分布相同（如果模型完美的表现了现实）的美好(fantasy)数据。实际应用中国，利用生成模型产生合成的观测数据，对于理解模型表达的概率分布很有帮助。</p><h3 id="离散型随机变量-Discrete-variables"><a href="#离散型随机变量-Discrete-variables" class="headerlink" title="离散型随机变量(Discrete variables)"></a>离散型随机变量(Discrete variables)</h3><p>指数分布是很重要的一类分布，它们虽然很简单，但是可以形成更复杂的概率分布，概率图的框架对于表达这些概率分布是如何连接的很有用。<br>如果我们有向图中亲本和子节点对之间的关系选择为conjugate，会发现这些模型有很好的属性。这里主要探讨两种情况，父节点和子节点都是离散的以及父节点和子节点都对应高斯变量，因为这两种关系可以分层扩展(extended hierarchically)构建任何复杂的有向无环图。首先从离散变量开始：<br>有$K$个可能状态的单个离散变量$\mathbf{x}$的概率分布是：</p><script type="math/tex; mode=display">p(\mathbf{x}|\nu) = \prod_{k=1}^k\nu_k^{x_k}</script><p>由参数$\nu = (\nu<em>1,\cdots,\nu_K)^T$控制，由于有约束条件$\sum_k\nu_k=1$，为了定义分布有$K-1$个$\nu_k$的值需要指定。<br>假设有两个离散型随机变量$\mathbf{x}_1,\mathbf{x}_2$，每个变量都有$K$个可能的取值。用$\nu</em>{kl}$表示同时观测到$x<em>{1k}=1$和$x</em>{2l}=1$，其中$x<em>{1k}$表示$\mathbf{x}_1$的第$k$个分量，$x</em>{2l}$类似。联合分布可以写成：</p><script type="math/tex; mode=display">p(\mathbf{x}_1,\mathbf{x}_2|\nu) = \prod_{k=1}^K\prod_{l=1}^K\nu_{kl}^{x_{1k}x_{2l}}.</script><p>$\nu<em>{kl}$满足约束条件$\sum_k\sum_l\nu</em>{kl} =1$，被$K^2-1$个参数控制，任意$M$个具有$K$个取值的随机变量的联合分布需要$K^M-1$个参数，随着随机变量$M$个数的增加，参数的个数以指数速度增加。<br>使用乘法公式，联合分布$p(\mathbf{x}<em>1,\mathbf{x}_2)$可以分解成$p(\mathbf{x}_2|\mathbf{x}_1)p(\mathbf{x}_1)$，对应的图如Figure 8.9(a)所示，边缘分布$p(\mathbf{x}_1)$的分布需要$K-1$个参数，$p(\mathbf{x}_2|\mathbf{x}_1)$对于$K$个可能的$\mathbf{x}_1$，每个都需要$K-1$个参数。所以，和联合分布一样，总共需要的参数为$K-1+K(K-1) = K^2-1$个。<br>假设$\mmm{x}_1$和$\mmm{x}_2$是独立的，如Figure 8.9(b)所示，每一个变量可以用分开的多峰分布(multinomial distribution)表示，所需的参数量为$2(K-1)$个。类似的，$M$个独立变量需要$M(K-1)$个参数，和变量个数之间是线性关系。从概率图的角度来看，通过在图中去掉边减少了参数的数量，同时代价是这个图只能代表有限类别的分布。<br>更普通的是，如果我们有$M$个离散型随机变量$\mmm{x}_1,\cdots,\mmm{x}_M$，我们可以用一个节点代表一个随机变量，建立一个有向图表示联合概率分布。每个节点处的条件概率由一组非负参数给出，并且需要满足归一化条件。如果图是全连接的，那么这个分布需要$K^M-1$个参数，如果图中没有连接，那么联合分布可以分解成边缘分布的乘积，需要的所有参数是$M(K-1)$个。拥有中间水平连接性的图比分解成单个边缘分布的乘积能解释更多的分布同时比普遍的联合概率分布需要更少的参数。如Figure 8.10中的节点链，边缘分布$p(\mmm{x}_1)$需要$K-1$个参数，其余的$M-1$个条件分布$p(\mmm{x}_i|\mmm{x}</em>{i-1}),i = 2,\cdots,M$，需要$K(K-1)$个参数，总共需要的参数是$K-1+(M-1)K(K-1)$个，是$K$的二次函数(quadratic)，随着链的长度$M$增加，参数个数线性增加。<br>另一个减少模型中独立参数个数的方法是共享参数。例如，Figure 8.10中的链，我们可以用共享的$K(K-1)$个参数去控制条件概率$p(\mmm{x}<em>i|\mmm{x</em>{i-1}),i=2,\cdots,M$，用$K-1$个变量去控制$\mmm{x}<em>1$的概率分布，总共需要$K^2-1$个参数需要被指定去定义联合概率分布。<br>通过引入每个参数对应的Dirichlet先验，我们可以把一个随机变量图转换成贝叶斯模型。从概率图的角度来看，每一个节点需要一个额外的父节点代表和这个离散节点相关的Dirichlet分布，如Figure 8.11所示。将控制条件分布$p(\mmm{x}_i|\mmm{x}</em>{i-1}),i=2,\cdots,M$的参数共享，得到如Figure 8.12所示的图。<br>另一种控制模型中离散变量参数指数速度增加的方法是用参数模型而不是条件概率表来表示条件分布。如Figure 8.13中，所有的节点都是一个二值变量，用参数$\nu_i$表示每一个父节点$\mmm{x}_i$取值为$1$的概率$p(x_i=1)$，总共有$M$个父节点，所以总共需要$2^M$个参数表示条件概率$p(y|x_1,\cdots,x_M)$的$2^M$可能取值，如$p(y=1)$。所以指定这个条件分布所需要的参数随着$M$指数级增长。我们可以通过使用logistic sigmoid函数作用于父节点的线性组合上，得到一个更简洁的条件概率分布：</p><script type="math/tex; mode=display">p(y=1|x_1,\cdots,x_M) = \sigma\left(w_0+\sum_{i=1}^Mw_ix_i\right)=\sigma(\mmm{w}^T\mmm{x})</script><p>其中$\sigma(a) = \frac{1}{1+exp(-a)}$是logistic sigmoid，$\mmm{x}=(x_0,x_1,\cdots,x_M)^T$是由$M$个父节点状态和一个$x_0=1$构成的$M+1$维向量，$\mmm{w}=(w_0,w_1,\cdots,w_M)^T$是$M+1$维参数项。与一般情况相比，这是一个更加严格的条件概率分布形式，但是它的参数个数随着$M$的增加线性增加。在这种情况下，类似于选择多元高斯分布的协方差矩阵的限制形式（如对角矩阵等）。</p><h3 id="线性高斯模型-Linear-Gaussian-models"><a href="#线性高斯模型-Linear-Gaussian-models" class="headerlink" title="线性高斯模型(Linear-Gaussian models)"></a>线性高斯模型(Linear-Gaussian models)</h3><h2 id="条件独立性-Conditional-Independence"><a href="#条件独立性-Conditional-Independence" class="headerlink" title="条件独立性(Conditional Independence)"></a>条件独立性(Conditional Independence)</h2><h2 id="马尔科夫随机场-Markov-Random-Fields"><a href="#马尔科夫随机场-Markov-Random-Fields" class="headerlink" title="马尔科夫随机场(Markov Random Fields)"></a>马尔科夫随机场(Markov Random Fields)</h2><h2 id="概率图模型中的推理-Inference-in-Graphical-Models"><a href="#概率图模型中的推理-Inference-in-Graphical-Models" class="headerlink" title="概率图模型中的推理(Inference in Graphical Models)"></a>概率图模型中的推理(Inference in Graphical Models)</h2><h2 id="参考文献-references"><a href="#参考文献-references" class="headerlink" title="参考文献(references)"></a>参考文献(references)</h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;$\newcommand{\mmm}{\mathbf}$&lt;br&gt;&lt;strong&gt;概率图模型&lt;/strong&gt;&lt;br&gt;概率论在现代模式识别中有很重要的地位。第一章中介绍了概率论可以被表示成两个简单的加法和乘法公式。事实上在这本书中讨论的所有概率推理和学习的计算（无论有多复杂）
      
    
    </summary>
    
      <category term="机器学习" scheme="http://mxxhcm.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://mxxhcm.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="模式识别" scheme="http://mxxhcm.github.io/tags/%E6%A8%A1%E5%BC%8F%E8%AF%86%E5%88%AB/"/>
    
      <category term="概率图模型" scheme="http://mxxhcm.github.io/tags/%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B/"/>
    
      <category term="贝叶斯网络" scheme="http://mxxhcm.github.io/tags/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>ESL chapter 1 Introduction</title>
    <link href="http://mxxhcm.github.io/2019/01/05/ESL-chapter-1-Introduction/"/>
    <id>http://mxxhcm.github.io/2019/01/05/ESL-chapter-1-Introduction/</id>
    <published>2019-01-05T01:46:39.000Z</published>
    <updated>2019-05-06T16:22:27.704Z</updated>
    
    <content type="html"><![CDATA[<h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>这本书主要介绍的是统计学习。一些典型的学习问题如下：</p><ul><li>基于一个心脏病患者的饮食，临床检测等等，去预测一个这个因为心脏病住院的人会不会第二次患心脏病。</li><li>基于一个公司的运行状况或一些经济数据，去预测未来六个月股票的价格。</li><li>从一个手写字母图像中识别出来其中的字母。</li><li>从一个糖尿病(diabetic)患者血液的红外吸收频谱去预测他的血糖(glucose)含量。</li><li>基于人口统计(demographic)和临床检测，分析前列腺癌的致病因素。 </li></ul><p>在一个典型的学习场景下，我们通常有一些定量的结果(outcome measurement)，如上面例子中的股票价格或者分类问题中问题的类别，我们希望基于一系列的特征进行预测。<br>接下来给了几个真实的学习问题的示例。下面就简要介绍一下这几个例子。</p><h3 id="邮件分类"><a href="#邮件分类" class="headerlink" title="邮件分类"></a>邮件分类</h3><p>给定一封邮件，邮件分类的目标就是根据邮件的特征去判断这封邮件是正常邮件还是垃圾邮件。这是监督学习中的二分类问题，因为该问题有ouputs，且只有两个类别。</p><h3 id="前列腺癌-prostate-cancer"><a href="#前列腺癌-prostate-cancer" class="headerlink" title="前列腺癌(prostate cancer)"></a>前列腺癌(prostate cancer)</h3><p>该问题的目标是给定一系列临床检测，如记录癌症量(log cancer volume)，去预测前列腺特异性抗原(prstate specific antigen)的数量。该问题是监督学习中的回归问题，因为结果(outcome measurement)是定量的(quatitative)。</p><h3 id="手写数字识别"><a href="#手写数字识别" class="headerlink" title="手写数字识别"></a>手写数字识别</h3><p>给定一个手写数字的图片，该问题的目标是识别出图片中的数字。</p><h3 id="DNA-Expression-Microarrays"><a href="#DNA-Expression-Microarrays" class="headerlink" title="DNA Expression Microarrays"></a>DNA Expression Microarrays</h3><p>这个问题是通过基因数组去学习基因和不同基因样本之间的关系，一些典型的问题是：</p><ol><li>哪些样本之间是相似的？在不同的基因之间都相似。</li><li>哪些基因是相似的？在不同的样本之间都相似。</li><li>一些特定的基因对于特定的癌症患者表达是达不是很明显？</li></ol><p>这个问题可以看成回归问题，或者更有可能是无监督问题。</p><h2 id="本书结构"><a href="#本书结构" class="headerlink" title="本书结构"></a>本书结构</h2><p>第一章就是本章。第二章讲监督学习的介绍。第三章和第四章介绍线性回归和分类。第五章介绍仿样(splines)，小波(wavelets)，正则化(regularization)和惩罚(penalization)。第六章介绍核方法(kernel methods)和局部回归(local regression)。第七章将模型估计和选择(model assessment and selection)，涉及到偏置(bias)和方差(variance)，过拟合(overfitting)以及交叉验证(cross-validation)等等。第八章讲模型推理。第十章讲boosting。<br>第九到十三章讲监督学习的一系列结构化方法。十四章介绍非监督学习。十五和十六章分别介绍随机森林(random forests)和集成学习(ensemble learning)。第十七章介绍无向图(undirected graphical models)。第十八章介绍高维问题。<br>第一到四章是基础最好按顺序阅读，第七章也是。其他的可以不按顺序。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;引言&quot;&gt;&lt;a href=&quot;#引言&quot; class=&quot;headerlink&quot; title=&quot;引言&quot;&gt;&lt;/a&gt;引言&lt;/h2&gt;&lt;p&gt;这本书主要介绍的是统计学习。一些典型的学习问题如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;基于一个心脏病患者的饮食，临床检测等等，去预测一个这个因为心
      
    
    </summary>
    
      <category term="机器学习" scheme="http://mxxhcm.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://mxxhcm.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="统计" scheme="http://mxxhcm.github.io/tags/%E7%BB%9F%E8%AE%A1/"/>
    
  </entry>
  
  <entry>
    <title>ESL chapter 2 Overview of supervised learning</title>
    <link href="http://mxxhcm.github.io/2019/01/05/ESL-chapter-2-Overview-of-supervides-learning/"/>
    <id>http://mxxhcm.github.io/2019/01/05/ESL-chapter-2-Overview-of-supervides-learning/</id>
    <published>2019-01-05T01:30:55.000Z</published>
    <updated>2019-05-06T16:22:27.704Z</updated>
    
    <content type="html"><![CDATA[<h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>在机器学习领域，监督学习(supervised learning)的每一个样本都由输入(inputs)和输出(outputs)组成。监督学习的目标就是根据inputs的值去预测outpus的值。<br>在统计学(statistical)中，inputs通常被称为预测器？？(predictors)，或者叫自变量(independent variables)。<br>在模式识别(pattern recognition)领域，inputs通常称为特征(features)，或者叫因变量(dependent variables)</p><h2 id="变量类型和一些术语-terminology"><a href="#变量类型和一些术语-terminology" class="headerlink" title="变量类型和一些术语(terminology)"></a>变量类型和一些术语(terminology)</h2><p>不同的问题中，输出也不一样。血糖预测问题中，输出是一个定量的(quantitative)测量。手写数字识别问题中，输出是十个不同的类，是定性的(qualitative)，定性的输出也通常被称为类别(catrgorical)，这里的类别是无序的。通常，预测定量的输出被称为回归问题(regression)，预测定性的输出被称为分类问题。这两个问题很相像，多可以看成函数拟合。第三种输出是有序类别，像小，中，大，没有合适的度量表示，因为中和小之间的差别和中和大之间的差别是不同的。<br>定性分析在代码实现中进行二值化数值表示。即如果只有两类的话，用一个二进制位$0$或者$1$表示，或者$1$和$-1$。当超过两类的时候，通常用虚拟变量(dummy variables)来表示，一个$K$级变量是一个长度为$K$的二进制位，每一个时刻只有一位被置一。<br>一些常用的表示，$X$表示inputs，$Y$表示定量outputs，$G$表示定性outputs。大写字母表示通用的表示，观测值用小写字母表示，inputs $X$的第$i$个观测值用$x_i$表示，其中$x_i$是一个标量或者向量。矩阵用粗体的大写字母表示，如具有$N$个$p$维向量$x_i, j= 1,\cdots,N$的$N\times p$矩阵$\mathbf{X}$。所有的向量都用的是列向量表示，$\mathbf{A}$的第$i$行是$x_i^T$，第$i$列的转置。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;引言&quot;&gt;&lt;a href=&quot;#引言&quot; class=&quot;headerlink&quot; title=&quot;引言&quot;&gt;&lt;/a&gt;引言&lt;/h2&gt;&lt;p&gt;在机器学习领域，监督学习(supervised learning)的每一个样本都由输入(inputs)和输出(outputs)组成。监督学习
      
    
    </summary>
    
      <category term="机器学习" scheme="http://mxxhcm.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://mxxhcm.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="监督学习" scheme="http://mxxhcm.github.io/tags/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="统计" scheme="http://mxxhcm.github.io/tags/%E7%BB%9F%E8%AE%A1/"/>
    
      <category term="非监督学习" scheme="http://mxxhcm.github.io/tags/%E9%9D%9E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>奇异值分解 singular value decomposition</title>
    <link href="http://mxxhcm.github.io/2019/01/03/%E5%A5%87%E5%BC%82%E5%80%BC%E5%88%86%E8%A7%A3-singular-value-decomposition/"/>
    <id>http://mxxhcm.github.io/2019/01/03/奇异值分解-singular-value-decomposition/</id>
    <published>2019-01-03T07:19:54.000Z</published>
    <updated>2019-05-06T16:22:27.708Z</updated>
    
    <content type="html"><![CDATA[<h2 id="特征值分解-eigen-value-decomposition"><a href="#特征值分解-eigen-value-decomposition" class="headerlink" title="特征值分解(eigen value decomposition)"></a>特征值分解(eigen value decomposition)</h2><p>要谈奇异值分解，首先要从特征值分解(eigen value decomposition, EVD)谈起。<br>矩阵的作用有三个：一个是旋转，一个是拉伸，一个是平移，都是线性操作。如果一个$n\times n$方阵$A$对某个向量$x$只产生拉伸变换，而不产生旋转和平移变换，那么这个向量就称为方阵$A$的特征向量(eigenvector)，对应的伸缩比例叫做特征值(eigenvalue)，即满足等式$Ax = \lambda x$。其中$A$是方阵，$x$是方阵$A$的一个特征向量，$\lambda$是方阵$A$对应特征向量$x$的特征值。<br>假设$S$是由方阵$A$的$n$个线性无关的特征向量构成的方阵，$\Lambda$是方阵$A$的$n$个特征值构成的对角矩阵，则$A=S\Lambda S^{-1}$，这个过程叫做对角化过程。<br>证明：<br>因为$Ax_1 = \lambda_1 x_1,\cdots,Ax_n = \lambda_n x_n$,<br>所以<br>\begin{align*}AS &amp;= A\begin{bmatrix}x_1&amp; \cdots&amp;x_n\end{bmatrix}\<br>&amp;=\begin{bmatrix} \lambda_1x_1&amp;\cdots&amp;\lambda x_n\end{bmatrix}\<br>&amp;= \begin{bmatrix}x_1&amp; \cdots&amp;x_n\end{bmatrix} \begin{bmatrix}\lambda_1&amp;&amp;&amp;\&amp;\lambda_2&amp;&amp;\&amp;&amp;\cdots&amp;\&amp;&amp;&amp;\lambda_n\end{bmatrix}\<br>&amp;= S\Lambda<br>\end{align*}<br>所以$AS=S\Lambda, A=S\Lambda S^{-1}, S^{-1}AS=\Lambda$。<br>若方阵$A$为对称矩阵，矩阵$A$的特征向量是正交的，将其单位化为$Q$，则$A=Q\Lambda Q^T$，这个过程就叫做特征值分解。</p><h2 id="奇异值分解-singular-value-decomposition"><a href="#奇异值分解-singular-value-decomposition" class="headerlink" title="奇异值分解(singular value decomposition)"></a>奇异值分解(singular value decomposition)</h2><p>特征值分解是一个非常好的分解，因为它能把一个方阵分解称两个非常好的矩阵，一个是正交阵，一个是对角阵，这些矩阵都便于进行各种计算，但是它对于原始矩阵的要求太严格了，必须要求矩阵是对称正定矩阵，这是一个很苛刻的条件。所以就产生了奇异值分解，奇异值分解可以看作特征值分解在$m\times n$维矩阵上的推广。对于对称正定矩阵来说，有特征值，对于其他一般矩阵，有奇异值。</p><p>奇异值分解可以看作将一组正交基映射到另一组正交基的变换。普通矩阵$A$不是对称正定矩阵，但是$AA^T$和$A^TA$一定是对称矩阵，且至少是半正定的。从对$A^TA$进行特征值分解开始，$A^TA=V\Sigma_1V^T$，$V$是一组正交的单位化特征向量${v_1,\cdots,v_n}$，则$Av_1,\cdots,Av_n$也是正交的。<br>证明：<br>\begin{align*}Av_1\cdot Av_2 &amp;=(Av_1)^TAv_2\<br>&amp;=v_1^TA^TAv_2\<br>&amp;=v_1^T \lambda v_2\<br>&amp;=\lambda v_1^T v_2\<br>&amp;=0<br>\end{align*}<br>所以$Av_1,Av_2$是正交的，同理可得$Av_1,\cdots,Av_n$都是正交的。<br>而：<br>\begin{align*}<br>Av_i\cdot Av_i &amp;= v_i^TA^TAv_i\<br>&amp;=v_i \lambda v_i\<br>&amp;=\lambda v_i^2\<br>&amp;=\lambda<br>\end{align*}<br>将$Av_i$单位化为$u_i$，得$u_i = \frac{Av_i}{|Av_i|} = \frac{Av_i}{\sqrt{\lambda_i}}$，所以$Av_i = \sqrt{\lambda_i}u_i$。<br>将向量组${v_1,\cdots,v_r}$扩充到$R^n$中的标准正交基${v_1,\cdots,v_n}$，将向量组${u_1,\cdots,u_r}$扩充到$R^n$中的标准正交基${u_1,\cdots,u_n}$，则$AV = U\Sigma$，$A=U\sigma V^T$。</p><p>事实上，奇异值分解可以看作将行空间的一组正交基加上零空间的一组基映射到列空间的一组正交基加上左零空间的一组基的变换。对一矩阵$A,A\in R^{m\times n}$，若$r(A)=r$，取行空间的一组特殊正交基${v_1,\cdots,v_r}$，当矩阵$A$作用到这组基上，会得到另一组正交基${u_1,\cdots,u_r}$，即$Av_i = \sigma_iu_i$。<br>矩阵表示是：<br>\begin{align*}<br>AV &amp;= A\begin{bmatrix}v_1&amp;\cdots&amp;v_r\end{bmatrix}\<br>&amp;= \begin{bmatrix}\sigma_1u_1 &amp; \cdots &amp; \sigma_ru_r\end{bmatrix}\<br>&amp;= \begin{bmatrix}u_1&amp;u_2&amp;\cdots&amp;u_r\end{bmatrix}\begin{bmatrix}\sigma_1&amp;&amp;&amp;\&amp;\sigma_2&amp;&amp;\&amp;&amp;\cdots&amp;\&amp;&amp;&amp;\sigma_n\end{bmatrix}\<br>&amp;=U\Sigma<br>\end{align*}<br>其中$A\in R^{m\times n}, V\in R^{n\times r},U\in R^{m\times r}, \Sigma \in R^{r\times n}$。<br>当有零空间的时候，行空间的一组基是$r$维，加上零空间的$n-r$维，构成$R^n$空间中的一组标准正交基。列空间的一组基也是$r$维的，加上左零空间的$m-r$维，构成$R^m$空间的一组标准正交基。零空间中的向量在对角矩阵$\Sigma$中体现为$0$，<br>则$A=U\Sigma V^{-1}$，$V$是正交的，所以$A=U\Sigma V^T$，其中$V\in R^{n\times n}, U\in R^{m\times m}, \Sigma \in R^{m\times n}$。</p><p>$A=U\Sigma V^T$<br>$A^T = V\Sigma^TU^T$<br>$AA^T = U\Sigma V^TV\Sigma^TU^T$<br>$A^TA = V\Sigma^TU^TU\Sigma V^T$<br>对$AA^T$和$A^TA$作特征值分解，则$AA^T = U\Sigma_1U^T$,$A^TA=V\Sigma_2V^T$，所以对$AA^T$作特征值分解求出来的$U$和对$A^TA$作特征值分解求出来的$V$就是对$A$作奇异值分解求出来的$U$和$V$，$AA^T$和$A^TA$作特征值分解求出来的$\Sigma$的非零值是相等的，都是对$A$作奇异值分解的$\Sigma$的平方。</p><h3 id="A-TA-和-AA-T-的非零特征值是相等的"><a href="#A-TA-和-AA-T-的非零特征值是相等的" class="headerlink" title="$A^TA$和$AA^T$的非零特征值是相等的"></a>$A^TA$和$AA^T$的非零特征值是相等的</h3><p>证明：对于任意的$m\times n$矩阵$A$，$A^TA$和$AA^T$的非零特征值相同的。 设$A^TA$的特征值为$\lambda_i$，对应的特征向量为$v_i$，即$A^TAv_i = \lambda_i v_i$。<br>则$AA^T Av_i = A\lambda_iv_i = \lambda_i Av_i$。<br>所以$AA^T$的特征值为$\lambda_i$，对应的特征向量为$Av_i$。<br>因此$A^TA$和$AA^T$的非零特征值相等。</p><h3 id="几何意义"><a href="#几何意义" class="headerlink" title="几何意义"></a>几何意义</h3><p>对于任意一个矩阵，找到其行空间(加上零空间)的一组正交向量，使得该矩阵作用在该向量序列上得到的新的向量序列保持两两正交。奇异值的几何意义就是这组变化后的新的向量序列的长度。</p><h3 id="物理意义"><a href="#物理意义" class="headerlink" title="物理意义"></a>物理意义</h3><p>奇异值往往对应着矩阵隐含的重要信息，且重要性和奇异值大小正相关。每个矩阵都可以表示为一系列秩为$1$的“小矩阵”的和，而奇异值则衡量了这些秩一矩阵对$A$的权重。<br>奇异值分解的物理意义可以通过图像压缩表现出来。给定一张$m\times n$像素的照片$A$，用奇异值分解将矩阵分解为若干个秩一矩阵之和，即：<br>\begin{align*}<br>A&amp;=\sigma_1 u_1v_1^T +\sigma_2 u_2v_2^T +\cdots+\sigma_r u_rv_r^T\<br>&amp;= \begin{bmatrix}u_1&amp;u_2&amp;\cdots&amp;u_r\end{bmatrix}\begin{bmatrix}\sigma_1&amp;&amp;&amp;\&amp;\sigma_2&amp;&amp;\&amp;&amp;\cdots&amp;\&amp;&amp;&amp;\sigma_n\end{bmatrix}\begin{bmatrix}v_1^T\v_2^T\ \vdots\v_r^T\end{bmatrix}\<br>&amp;=U\Sigma V^T<br>\end{align*}</p><p>这个也叫部分奇异值分解。其中$V\in R^{r\times n}, U\in R^{m\times r}, \Sigma \in R^{r\times r}$。因为不含有零空间和左零空间的基，如果加上零空间的$n-r$维和左零空间的$m-r$维，就是奇异值分解。<br>较大的奇异值保存了图片的主要信息，特别小的奇异值有时可能是噪声，或者对于图片的整体信息不是特别重要。做图像压缩的时候，可以只取一部分较大的奇异值，比如取前八个奇异值作为压缩后的图片：<br>$A = \sigma_1 u_1v_1^T +\sigma_2 u_2v_2^T + \cdots + \sigma_8 u_8v_8^T$。<br>现实中常用的做法有两个：</p><ol><li>保留矩阵中$90%$的信息：将奇异值平方和累加到总值的%90%为止。</li><li>当矩阵有上万个奇异值的时候，取前面的$2000$或者$3000$个奇异值。。</li></ol><h2 id="参考文献-references"><a href="#参考文献-references" class="headerlink" title="参考文献(references)"></a>参考文献(references)</h2><p>1.Gilbert Strang, MIT Open course：Linear Algebra<br>2.<a href="https://www.cnblogs.com/pinard/p/6251584.html" target="_blank" rel="noopener">https://www.cnblogs.com/pinard/p/6251584.html</a><br>3.<a href="http://www.ams.org/publicoutreach/feature-column/fcarc-svd" target="_blank" rel="noopener">http://www.ams.org/publicoutreach/feature-column/fcarc-svd</a><br>4.<a href="https://www.zhihu.com/question/22237507/answer/53804902" target="_blank" rel="noopener">https://www.zhihu.com/question/22237507/answer/53804902</a><br>5.<a href="http://charleshm.github.io/2016/03/Singularly-Valuable-Decomposition/" target="_blank" rel="noopener">http://charleshm.github.io/2016/03/Singularly-Valuable-Decomposition/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;特征值分解-eigen-value-decomposition&quot;&gt;&lt;a href=&quot;#特征值分解-eigen-value-decomposition&quot; class=&quot;headerlink&quot; title=&quot;特征值分解(eigen value decompositio
      
    
    </summary>
    
      <category term="线性代数" scheme="http://mxxhcm.github.io/categories/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/"/>
    
    
      <category term="奇异值分解" scheme="http://mxxhcm.github.io/tags/%E5%A5%87%E5%BC%82%E5%80%BC%E5%88%86%E8%A7%A3/"/>
    
      <category term="线性代数" scheme="http://mxxhcm.github.io/tags/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/"/>
    
      <category term="特征值分解" scheme="http://mxxhcm.github.io/tags/%E7%89%B9%E5%BE%81%E5%80%BC%E5%88%86%E8%A7%A3/"/>
    
  </entry>
  
  <entry>
    <title>主成分分析(Principal Component Analysis)</title>
    <link href="http://mxxhcm.github.io/2019/01/02/%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90-Principal-Component-Analysis/"/>
    <id>http://mxxhcm.github.io/2019/01/02/主成分分析-Principal-Component-Analysis/</id>
    <published>2019-01-02T12:51:19.000Z</published>
    <updated>2019-05-06T16:22:27.708Z</updated>
    
    <content type="html"><![CDATA[<h2 id="降维"><a href="#降维" class="headerlink" title="降维"></a>降维</h2><h3 id="降维的目标"><a href="#降维的目标" class="headerlink" title="降维的目标"></a>降维的目标</h3><p>降维可以看做将$p$维的数据映射到$m$维，其中$p\gt m$。</p><h3 id="降维的目的"><a href="#降维的目的" class="headerlink" title="降维的目的"></a>降维的目的</h3><ol><li>维度灾难(curse of dimensionity)</li><li>随着维度增加，精确度和效率的退化。</li><li>可视化数据</li><li>数据压缩</li><li>去噪声<br>…</li></ol><h3 id="降维的方法"><a href="#降维的方法" class="headerlink" title="降维的方法"></a>降维的方法</h3><h4 id="无监督的降维"><a href="#无监督的降维" class="headerlink" title="无监督的降维"></a>无监督的降维</h4><ol><li>线性的:PCA</li><li>非线性的: GPCA, Kernel PCA, ISOMAP, LLE</li></ol><h4 id="有监督的降维"><a href="#有监督的降维" class="headerlink" title="有监督的降维"></a>有监督的降维</h4><ol><li>线性的: LDA</li><li>非线性的: Kernel LDA</li></ol><h2 id="主成分分析-PCA"><a href="#主成分分析-PCA" class="headerlink" title="主成分分析(PCA)"></a>主成分分析(PCA)</h2><p>主成分分析(principal component analysis,PCA)是一个降维工具。PCA使用正交变换(orthogonal transformation)将可能相关的变量的一系列观测值(observation)转换成一系列不相关的变量，这些转换后不相关的变量叫做主成分(principal component)。第一个主成分有着最大的方差，后来的主成分必须和前面的主成分正交，然后最大化方差。或者PCA也可以看成根据数据拟合一个$m$维的椭球体(ellipsoid)，椭球体的每一个轴代表着一个主成分。<br>上课的时候，老师给出了五种角度来看待PCA，分别是信息保存，投影，拟合，嵌入(embedding)，mainfold learning。本文首先从保存信息的角度来给出PCA的推理过程，其他的几种方法就随缘了吧。。。</p><h3 id="信息保存-preserve-information"><a href="#信息保存-preserve-information" class="headerlink" title="信息保存(preserve information)"></a>信息保存(preserve information)</h3><h4 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h4><p>从信息保存的角度来看PCA的目标是用尽可能小的空间去存储尽可能多的信息。一般情况下，信息用信息熵$-\int p lnp$来表示，如果这里使用信息熵的话，不知道信息的概率表示，一般不知道概率分布的情况下就采用高斯分布，带入高斯分布之后得到$\frac{1}{2}log(2\pi e\sigma^2)$，其中$2\pi e$都是常量，只剩下方差。给出一堆数据，直接计算信息熵是行不通的，但是计算方差是可行的，而方差和信息熵是有联系的，所以可以考虑用方差来表示信息。考虑一下降维前的$p$维数据$x$和降维后的$m$维数据$z$方差之间的关系，$var(z)?var(x)$，这里$z$和$x$的方差维度是不同的，所以不能相等，这里我们的目标就是最大化$z$的方差。方差能解释变化，方差越大，数据的变化就越大，越能包含信息。PCA的目标就是让降维后的数据方差最大。</p><h4 id="线性PCA过程"><a href="#线性PCA过程" class="headerlink" title="线性PCA过程"></a>线性PCA过程</h4><h5 id="目标函数"><a href="#目标函数" class="headerlink" title="目标函数"></a>目标函数</h5><p>给定$n$个观测数据$x_1,x_2,\cdots,x_n \in R^p$，形成一个观测矩阵$X,X\in R^{p\times n}$，我们的目标是将这样一组$p$维的数据转换成$m$维的数据。线性PCA是通过线性变换(matrix)来实现的，也就是我们要求一个$p\times m$的矩阵$V$，将原始的$X$矩阵转换成$Z$矩阵，使得</p><script type="math/tex; mode=display">Z_{m\times n}= V_{p\times m}^{T}X_{p\times n},</script><p>其中$V\in R^{p\times m}$, $v<em>i=\begin{bmatrix}v</em>{1i}\v<em>{2i}\ \vdots\v</em>{pi}\end{bmatrix}$, $V = \begin{bmatrix}v<em>{11}&amp;v</em>{12}&amp;\cdots&amp;v<em>{1m}\v</em>{21}&amp;v<em>{22}&amp;\cdots&amp;v</em>{2m}\ \vdots&amp;\vdots&amp;\cdots&amp;\vdots\v<em>{p1}&amp;v</em>{p2}&amp;\cdots&amp;v<em>{pm}\end{bmatrix}=\begin{bmatrix}v_1&amp;v_2&amp;\cdots&amp;v_m\end{bmatrix}$, $V^T = \begin{bmatrix}v</em>{11}&amp;v<em>{21}&amp;\cdots&amp;v</em>{p1}\v<em>{12}&amp;v</em>{22}&amp;\cdots&amp;v<em>{p2}\ \vdots&amp;\vdots&amp;\cdots&amp;\vdots\v</em>{1m}&amp;v<em>{2m}&amp;\cdots&amp;v</em>{pm}\end{bmatrix}=\begin{bmatrix}v_1^T\v_2^T\ \vdots\v_m^T\end{bmatrix}$。<br>所以就有：<br>\begin{align*}<br>z_1 &amp;= v_1^Tx_j\<br>&amp;\cdots\<br>z_k &amp;= v_k^Tx_j\<br>&amp;\cdots\<br>z_m &amp;= v_m^Tx_j<br>\end{align*}<br>其中，$z_1,\cdots,z_m$是标量，$v_1^T,\cdots, v_m^T$是$1\times p$的向量，$x_j$是一个$p\times 1$维的观测向量，而我们有$n$个观测向量，所以随机变量$z_k$共有$n$个可能取值：</p><script type="math/tex; mode=display">z_{k} = v_k^Tx_i= \sum_{i=1}^{p}v_{ik}x_{ij}, j = 1,2,\cdots,n</script><p>其中$x_i$是观测矩阵$X$的第$i$列，$X\in R^{p\times n}$。</p><h5 id="协方差矩阵"><a href="#协方差矩阵" class="headerlink" title="协方差矩阵"></a>协方差矩阵</h5><p>离散型随机变量$X$($X$的取值等可能性)方差的计算公式是：</p><script type="math/tex; mode=display">var(X) = E[(X-\mu)^2] = \frac{1}{n}\sum_{i=1}^n(x_i-\mu)^2,</script><p>其中$\mu$是X的平均数，即$\mu = \frac{1}{n}\sum_{i=1}^nx_i$。</p><p>让$z<em>k$的方差最大即最大化：<br>\begin{align*}<br>var(z_1) &amp;=E(z_1,\bar{z_1})^2\<br>&amp;=\frac{1}{n}\sum</em>{i=1}^n(v<em>1^Tx_i - v_1^T\bar{x_i})^2\<br>&amp;=\frac{1}{n}\sum</em>{i=1}^n(v<em>1^Tx_i - v_1^T\bar{x_i})(v_1^Tx_i - v_1^T\bar{x_i})^T\<br>&amp;=\frac{1}{n}\sum</em>{i=1}^nv<em>1^T(x_i - \bar{x_i})(x_i - \bar{x_i})^Tv_1\<br>\end{align*}<br>其中$x_i=\begin{bmatrix}x</em>{1i}\x<em>{2i}\ \vdots\x</em>{pi}\end{bmatrix}$,$\bar{x<em>i}=\begin{bmatrix}\bar{x</em>{1i}}\\bar{x<em>{2i}}\ \vdots\\bar{x</em>{pi}}\end{bmatrix}$,$x<em>i$是$p$维的，$x_i^p$也是$p$维的，$(x_i-\bar{x_i})$是$p\times 1$维的，$(x_i -\bar{x_i})^T$是$1\times p$维的。<br>令$S=\frac{1}{n}\sum</em>{i=1}^n(x<em>i -\bar{x_i})(x_i-\bar{x_i})^T$，$S$是一个$p\times p$的对称矩阵，其实$S$是一个协方差矩阵。这个协方差矩阵可以使用矩阵$X$直接求出来，也可以通过对$X$进行奇异值分解求出来。<br>如果使用奇异值分解的话，首先对矩阵$X$进行去中心化，即$\bar{x_i}=0$，则：<br>\begin{align*}<br>S &amp;= \frac{1}{n}\sum</em>{i=1}^Tx<em>ix_i^T\<br>&amp;=\frac{1}{n}X</em>{p\times n}X_{n\times p}^T<br>\end{align*}<br>$X=U\Sigma V^T$<br>$XX^T=U\Sigma V^TV\Sigma U^T = U\Sigma_1^2U^T$<br>$X^TX =V\Sigma U^TU\Sigma V^T = V\Sigma_2^2V^T$<br>$S=\frac{1}{n}XX^T=\frac{1}{n}U\Sigma^2U^T$</p><h5 id="拉格朗日乘子法"><a href="#拉格朗日乘子法" class="headerlink" title="拉格朗日乘子法"></a>拉格朗日乘子法</h5><p>将$S$代入得：</p><script type="math/tex; mode=display">var(z_1) = v_1^TSv_1,</script><p>接下来的目标是最大化$var(z_1)$，这里要给出一个限制条件，就是$v_1^Tv_1 = 1$，否则的话$v_1$无限大，$var(z_1)$就没有最大值了。<br>使用拉格朗日乘子法，得到目标函数：</p><script type="math/tex; mode=display">L=v_1^TSv_1 - \lambda (v_1^Tv_1 -1)</script><p>求偏导，令偏导数等于零得：<br>\begin{align*}<br>\frac{\partial{L}}{\partial{v_1}}&amp;=2Sv_1 - 2\lambda v_1\<br>&amp;=2(S-\lambda) v_1\<br>&amp;=0<br>\end{align*}<br>即$Sv_1 = \lambda v_1$，所以$v_1$是矩阵$S$的一个特征向量(eigenvector)。所以：</p><script type="math/tex; mode=display">var(z_1) = v_1^TSv_1 = v_1^T\lambda v_1 = \lambda v_1^Tv_1 = \lambda,</script><p>第一个主成分$v_1$对应矩阵$S$的最大特征值。</p><h5 id="其他主成分"><a href="#其他主成分" class="headerlink" title="其他主成分"></a>其他主成分</h5><p>对于$z_2$,同理可得：<br>$var(z_2) = v_2^TSv_2$，<br>但是这里要加一些限制条件$v_2^Tv_2=1$，除此以外，第2个主成分还有和之前的主成分不相关，即$cov[z_1,z_2]=0$,或者说是$v_1^Tv_2=0$，证明如下。<br>\begin{align*}<br>cov[z_1,z_2] &amp;=E[(z_1-\bar{z_1})(z_2-\bar{z_2})]\<br>&amp;=\frac{1}{n}(v_1^Tx_i - v_1^T\bar{x_i})(v_2^Tx_i-v_2^T\bar{x_i})\<br>&amp;=\frac{1}{n}v_1^T(x_i-\bar{x_i})(x_i-\bar{x_i})v_2\<br>&amp;=\frac{1}{n}v_1^TSV_2\<br>&amp;=\frac{1}{n}\lambda v_1^Tv_2\<br>&amp;=0<br>\end{align*}<br>维基百科上是通过将数据减去第一个主成分之后再最大化方差，这两种理解方法都行。<br>所以拉格朗日目标函数就成了：</p><script type="math/tex; mode=display">L=v_1^TSv_1 - \lambda (v_1^Tv_1 -1) -\beta v_2^Tv_1</script><p>求导，令导数等于零得：</p><script type="math/tex; mode=display">\frac{\partial{L}}{\partial{v_1}}=2Sv_2 - 2\lambda v_2 - \beta v_1 = 0</script><p>而$v_1$和$v_2$不相关，所以$\beta=0$，所以$Sv_2 = \lambda v_2$，即$v_2$也是矩阵$S$的特征向量，但是最大的特征值对应的特征向量已经被$v_1$用了，所以$v_2$是第二大的特征值对应的特征向量。<br>同理可得第$k$个主成分是$S$的第$k$大特征值对应的特征向量。</p><p>但是这种理解方法没有办法推广到非线性PCA。接下来的集中理解方式可以由线性PCA开始，并且可以推广到非线性PCA。</p><h3 id="函数拟合"><a href="#函数拟合" class="headerlink" title="函数拟合"></a>函数拟合</h3><h4 id="线性PCA过程-1"><a href="#线性PCA过程-1" class="headerlink" title="线性PCA过程"></a>线性PCA过程</h4><h4 id="非线性PCA过程"><a href="#非线性PCA过程" class="headerlink" title="非线性PCA过程"></a>非线性PCA过程</h4><h5 id="广义主成分分析-Generalized-PCA-GPCA"><a href="#广义主成分分析-Generalized-PCA-GPCA" class="headerlink" title="广义主成分分析(Generalized PCA,GPCA)"></a>广义主成分分析(Generalized PCA,GPCA)</h5><p>刚才讲的PCA是线性PCA，是拟合一个超平面(hyperplane)的过程，但是如果数据不是线性的，比如说是一个曲面$x^2+y^2+z=0$，这样子线性PCA就不适用了，可以稍加变化让其依然是可以用的。比如$x+y+1=0$可以看成$\begin{bmatrix}a&amp;b&amp;c\end{bmatrix}\begin{bmatrix}x\y\1\end{bmatrix}$，而$x^2+y^2+z=0$可以看成$\begin{bmatrix}a&amp;b&amp;c\end{bmatrix}\begin{bmatrix}x^2\y^2\z\end{bmatrix}$。</p><p>如果原始数据是非线性的，我们可以通过多个特征映射函数$\Phi$从原始数据提取非线性特征（也可看成升维，变成高维空间中数据，在高维中可以看成是线性的），然后利用线性PCA对非线性特征进行降维。例如：<br>假设$x=[x_1,x_2,x_3]^T \in R^3$，按照转换函数$v(x) = [x_1^2,x_1x_2,x_1x_3,x_2^2,x_2x_3,x_3^2$将其转换成$R^6$中的特征，接下来使用线性PCA对这些非线性特征进行降维。</p><p>给定一个函数$\Phi$将$p$维数据映射到特征空间$F$中，即$\Phi:R^p\rightarrow F,\mathbf{x}\rightarrow X$。我们可以通过计算协方差矩阵$C<em>F = \frac{\Phi\Phi^T}{n}$,即$C_F = \frac{1}{n}\sum</em>{i=1}^{n}\phi(x_i)\phi(x_i)^T$，然后对协方差矩阵$C_F$进行特征值分解$C_Fx=\lambda x$就可以求解，这里我们假设空间$F$中的数据均值为$0$，即$E[\Phi(x)] = 0$。</p><h3 id="嵌入-embedding-，保距离"><a href="#嵌入-embedding-，保距离" class="headerlink" title="嵌入(embedding)，保距离"></a>嵌入(embedding)，保距离</h3><h4 id="核函数技巧-Kernel-trick"><a href="#核函数技巧-Kernel-trick" class="headerlink" title="核函数技巧(Kernel trick)"></a>核函数技巧(Kernel trick)</h4><p>在GPCA中，如果不知道$\Phi$的话，或者$\Phi$将数据映射到了无限维空间中，就没有办法求解了。这里就给出了一个假设，假设低维空间中$x<em>i,x_j$的点积(dot product)可以通过一个函数计算，将$x_i,x_j$的点积记为$K</em>{ij}$，则：</p><script type="math/tex; mode=display">K_{ij} = \lt \phi(x_i),\phi(x_j) \gt = k(x_i,x_j)</script><p>其中$k()$是一个函数，比如可以取高斯函数，$k(x,y) = e^{\frac{(\Vert x-y\Vert)^2}{2\sigma^2}}$，我们叫它核函数(kernel function)。<br>这样即使我们不知道$\Phi$，也可以计算点积，直接使用核函数计算。</p><h4 id="dot-PCA"><a href="#dot-PCA" class="headerlink" title="dot PCA"></a>dot PCA</h4><p>给定原始数据$X<em>D = [x_1,\cdots,x_n],x_i\in R^p$，假定$\hat{x}=0$，那么$X_D$的协方差矩阵：<br>\begin{align*}<br>S&amp;= \frac{\sum</em>{i=1}^n(x<em>i-\bar{x})(x_i-\bar{x})^T}{n}\<br>&amp;= \frac{\sum</em>{i=1}^n(x<em>i-0)(x_i-0)^T}{n}\<br>&amp;= \frac{\sum</em>{i=1}^n(x_i)(x_i)^T}{n}\<br>&amp;= \frac{\begin{bmatrix}x_1&amp;\cdots&amp;x_n\end{bmatrix}\begin{bmatrix}x_1\\vdots\x_n\end{bmatrix}}{n}\<br>&amp;= \frac{X_DX_D^T}{n}\<br>&amp;= Cov(X_D, X_D)<br>\end{align*}<br>即$S=\frac{X_DX_D^T}{n}$，而对$X_D$做奇异值分解，有$X_D = V\Sigma U^T$，所以$S = \frac{V\Sigma^2 V^T}{n}$，其中$U$是$S$的特征值矩阵，则：$Z’ = V^T X’$，其中$V\in R^{p\times m}$，$X’$是新的样本数据。</p><p>这里我们推导一下点积和PCA的关系，即假设我们有$K = Dot(X_D,X_D) = X_D^TX_D$，则$K=U^T\sigma^2U$，而我们根据奇异值分解$X_D = V\Sigma U^T$可以得到$U$和$V$的关系，即$V=X_DU\Sigma^{-1}$，对$K$进行特征值分解，可以求得$U$和$\Sigma$，所以来了一个新的样本$X’$，</p><script type="math/tex; mode=display">Z' = V^TX' = D^{-1}U^TX_D^TX' = D^{-1}U^T\lt X_D,X' \gt.</script><p>事实上，这里$X’$是已知的，可以直接计算协方差，但是这里是为了给Kernel PCA做引子，所以，推导的过程中是没有用到$X$的，只用到了$X$的点积，在测试的时候会用到$X’$。</p><h5 id="Kernel-PCA"><a href="#Kernel-PCA" class="headerlink" title="Kernel PCA"></a>Kernel PCA</h5><p>Kernel PCA就是将Kernel trick应用到了dot PCA中，由Kernel trick得$K = \Phi^T\Phi$，$K=U\Sigma^2U^T$，则</p><script type="math/tex; mode=display">V = \Phi U\Sigma^{-1} = \Phi U diag(1/sqrt(\lambda_1),1/sqrt(\lambda_2),\cdots)</script><p>但是我们求不出来$V$，因为$\Phi$不知道，但是可以让$V$中的$\Phi$和样本$X’$中的$\Phi$在一起，就可以计算了，即</p><script type="math/tex; mode=display">Z' = V^T\phi(X') = \Sigma^{-1}U\Phi\phi(X') = \Sigma^{-1}UK(X,X')</script><h3 id="流形学习-manifold"><a href="#流形学习-manifold" class="headerlink" title="流形学习(manifold)"></a>流形学习(manifold)</h3><h4 id="线性"><a href="#线性" class="headerlink" title="线性"></a>线性</h4><h5 id="PCA"><a href="#PCA" class="headerlink" title="PCA"></a>PCA</h5><h5 id="MDS"><a href="#MDS" class="headerlink" title="MDS"></a>MDS</h5><h4 id="非线性"><a href="#非线性" class="headerlink" title="非线性"></a>非线性</h4><h5 id="LLE"><a href="#LLE" class="headerlink" title="LLE"></a>LLE</h5><h5 id="ISOMAP"><a href="#ISOMAP" class="headerlink" title="ISOMAP"></a>ISOMAP</h5><h2 id="线性判断分析-Fisher-linear-discrimiant-analysis-LDA"><a href="#线性判断分析-Fisher-linear-discrimiant-analysis-LDA" class="headerlink" title="线性判断分析(Fisher linear discrimiant analysis,LDA)"></a>线性判断分析(Fisher linear discrimiant analysis,LDA)</h2><h3 id="线性LDA"><a href="#线性LDA" class="headerlink" title="线性LDA"></a>线性LDA</h3><h4 id="两类"><a href="#两类" class="headerlink" title="两类"></a>两类</h4><h5 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h5><h4 id="C类-C-gt-2"><a href="#C类-C-gt-2" class="headerlink" title="C类(C$\gt 2$)"></a>C类(C$\gt 2$)</h4><p>两维的问题是通过将原始数据投影到一维空间进行分类，而$C$维的问题则是将原始数据投影到$C-1$空间进行分类，通过一个投影矩阵$W=\begin{bmatrix}w<em>1&amp;\cdots&amp;w</em>{C-1}\end{bmatrix}$将$C$维的$x$投影到$C-1$维，得到$y=\begin{bmatrix}y<em>1&amp;\cdots&amp;y</em>{C-1}\end{bmatrix}$，即$y_i = w_i^Tx\Rightarrow y = W^Tx$。</p><h5 id="示例-1"><a href="#示例-1" class="headerlink" title="示例"></a>示例</h5><h3 id="不足"><a href="#不足" class="headerlink" title="不足"></a>不足</h3><ul><li>最多投影到$C-1$维特征空间。</li><li>LDA是参数化的方法，它假设数据服从单高斯分布，并且所有类的协方差都是等价的。对于多个高斯分布，线性的LDA是无法分开的。</li><li>当数据之间的差异主要通过方差而不是均值体现的话，LDA就会失败(fail)。如下图<br><img src="/2019/01/02/主成分分析-Principal-Component-Analysis/" alt="figure"></li></ul><h3 id="Kernel-LDA"><a href="#Kernel-LDA" class="headerlink" title="Kernel LDA"></a>Kernel LDA</h3><h2 id="PCA和LDA区别和联系"><a href="#PCA和LDA区别和联系" class="headerlink" title="PCA和LDA区别和联系"></a>PCA和LDA区别和联系</h2><p>PCA是一个无监督的降维方法，通过最大化降维后数据的方差实现；LDA是一个有监督的降维方法，通过最大化类可分性实现(class discrimnatory)。</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>1.<a href="https://en.wikipedia.org/wiki/Principal_component_analysis" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Principal_component_analysis</a><br>2.<a href="https://en.wikipedia.org/wiki/Variance" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Variance</a><br>3.<a href="https://sebastianraschka.com/faq/docs/lda-vs-pca.html" target="_blank" rel="noopener">https://sebastianraschka.com/faq/docs/lda-vs-pca.html</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;降维&quot;&gt;&lt;a href=&quot;#降维&quot; class=&quot;headerlink&quot; title=&quot;降维&quot;&gt;&lt;/a&gt;降维&lt;/h2&gt;&lt;h3 id=&quot;降维的目标&quot;&gt;&lt;a href=&quot;#降维的目标&quot; class=&quot;headerlink&quot; title=&quot;降维的目标&quot;&gt;&lt;/a&gt;降维的目
      
    
    </summary>
    
      <category term="机器学习" scheme="http://mxxhcm.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://mxxhcm.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="监督学习" scheme="http://mxxhcm.github.io/tags/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="主成分分析" scheme="http://mxxhcm.github.io/tags/%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90/"/>
    
      <category term="PCA" scheme="http://mxxhcm.github.io/tags/PCA/"/>
    
      <category term="降维" scheme="http://mxxhcm.github.io/tags/%E9%99%8D%E7%BB%B4/"/>
    
  </entry>
  
  <entry>
    <title>内积空间、赋范空间和希尔伯特空间</title>
    <link href="http://mxxhcm.github.io/2018/12/28/%E5%86%85%E7%A7%AF%E7%A9%BA%E9%97%B4%E3%80%81%E8%B5%8B%E8%8C%83%E7%A9%BA%E9%97%B4%E5%92%8C%E5%B8%8C%E5%B0%94%E4%BC%AF%E7%89%B9%E7%A9%BA%E9%97%B4/"/>
    <id>http://mxxhcm.github.io/2018/12/28/内积空间、赋范空间和希尔伯特空间/</id>
    <published>2018-12-28T07:15:37.000Z</published>
    <updated>2019-05-06T16:22:27.708Z</updated>
    
    <content type="html"><![CDATA[<h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>数学的空间是研究工作的对象和遵循的规则。<br>线性空间：加法和数乘<br>拓扑空间：距离，范数和内积。</p><h2 id="距离"><a href="#距离" class="headerlink" title="距离"></a>距离</h2><p>距离是用来衡量两个点有多“近”的。</p><h3 id="距离定义"><a href="#距离定义" class="headerlink" title="距离定义"></a>距离定义</h3><p>$X$是一非空集合，任给一对这一集合中的元素$x,y$，都会给定一个实数$d(x,y)$与它们对应，并且这个实数满足以下条件：</p><ol><li>$d(x,y)\ge 0, d(x,y) = 0 \Leftrightarrow x=y$；</li><li>$d(x,y) = d(y,x)$；</li><li>$d(x,y) \le d(x,z) + d(z,y)$。</li></ol><p>则$d(x,y)$为这两点$x$和$y$之间的距离。</p><h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><h4 id="向量的距离"><a href="#向量的距离" class="headerlink" title="向量的距离"></a>向量的距离</h4><p>$d_1(x,y) = \sqrt{(x_1-y_1)^2+\cdots,(x_n-y_n)^n}$<br>$d_2(x,y) = max{|x_1-y_1|,\cdots,|x_n,y_n|}$<br>$d_3(x,y) = |x_1-y_1|+\cdots+|x_n,y_n|$</p><h4 id="曲线的距离"><a href="#曲线的距离" class="headerlink" title="曲线的距离"></a>曲线的距离</h4><p>$d<em>1(f,g) = \int_a^b(f(x)-g(x))^2 dx$<br>$d_2(f,g) = max</em>{a\le x\le b}|f(x)-f(y)|$<br>$d_3(f,g) = \int_a^b(f(x)-g(x))^k dx$</p><h3 id="线性空间"><a href="#线性空间" class="headerlink" title="线性空间"></a>线性空间</h3><p>向量的加法和数乘</p><h3 id="线性空间的八个性质"><a href="#线性空间的八个性质" class="headerlink" title="线性空间的八个性质"></a>线性空间的八个性质</h3><p>加法的交换律和结合律，零元，负元，数乘的交换律，单位一，数乘与加法的结合律。</p><h2 id="范数（向量到零点的距离）定义"><a href="#范数（向量到零点的距离）定义" class="headerlink" title="范数（向量到零点的距离）定义"></a>范数（向量到零点的距离）定义</h2><p>如果$\Vert x\Vert $是$R^n$上的范数（$x$是向量），那么它需要满足以下条件：</p><ol><li>$\Vert x\Vert \ge 0, \forall x\in R, \Vert x\Vert  = 0  \Leftrightarrow x = 0$；</li><li>$\Vert \alpha x\Vert  = |\alpha|\Vert x\Vert, \forall \alpha \in R, x\in R^n$</li><li>$\Vert x+y\Vert  \le \Vert x\Vert  + \Vert y\Vert , \forall x,y\in R$</li></ol><p>可以看成是点到零点距离多了条件2。</p><h3 id="示例-1"><a href="#示例-1" class="headerlink" title="示例"></a>示例</h3><p>$\Vert x\Vert<em>2  = \sqrt{x_1^2+\cdots,x_n^n}$<br>$\Vert x\Vert</em>{\infty}  = max{|x_1|,\cdots,|x_n|}$<br>$\Vert x\Vert_1  = |x_1|+\cdots+|x_n|$</p><h3 id="距离和范数的关系"><a href="#距离和范数的关系" class="headerlink" title="距离和范数的关系"></a>距离和范数的关系</h3><p>由范数可以定义距离。$d(x,y) = \Vert  x-y\Vert$。<br>但是由距离不一定可以定义范数。如$\Vert x\Vert  = d(0,x)$,但是$\Vert \alpha x\Vert  = d(0, \alpha x) \ne |\alpha|\Vert x\Vert $。</p><h3 id="赋范空间和度量空间"><a href="#赋范空间和度量空间" class="headerlink" title="赋范空间和度量空间"></a>赋范空间和度量空间</h3><p>赋予范数的集合称为赋范空间。<br>距离的集合称为度量空间。</p><h3 id="线性赋范空间和线性度量空间"><a href="#线性赋范空间和线性度量空间" class="headerlink" title="线性赋范空间和线性度量空间"></a>线性赋范空间和线性度量空间</h3><p>赋予范数加上线性空间称为线性赋范空间。<br>距离加上线性空间称为线性度量空间。</p><h2 id="内积"><a href="#内积" class="headerlink" title="内积"></a>内积</h2><h3 id="引言-1"><a href="#引言-1" class="headerlink" title="引言"></a>引言</h3><p>赋范空间有向量的模长，即范数。但是范数只有大小，没有夹角，所以就引入了内积。</p><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p>给定$(x,y)\in R$,如果它满足：</p><ol><li>对称性；</li><li>对第一变元的线性性；</li><li>正定性。</li></ol><p>那么就称$(x,y)$为内积。</p><h3 id="示例-2"><a href="#示例-2" class="headerlink" title="示例"></a>示例</h3><ol><li>$(x,y) = \sum_{n=1}^nx_ny_n$。</li><li>$(f,g) = \int_{-\infty}^{\infty}f(x)g(x)dx$。</li></ol><h3 id="内积和范数的关系"><a href="#内积和范数的关系" class="headerlink" title="内积和范数的关系"></a>内积和范数的关系</h3><ul><li>内积可以导出范数 </li><li>范数不能导出距离 </li></ul><h3 id="内积空间"><a href="#内积空间" class="headerlink" title="内积空间"></a>内积空间</h3><p>在线性空间上定义内积，这个空间称为内积空间。<br>常见的欧几里得空间就是一个内积空间，内积空间是一个抽象的空间，而欧几里得空间是一个具象化了的内积空间。<br>希尔伯特引入了无穷维空间并定义了内积，其空间称为内积空间，再加上完备性，称为希尔伯特空间。完备性是取极限之后还在这个空间内。<br>完备的赋范空间称为巴拿赫空间。</p><h2 id="拓扑空间"><a href="#拓扑空间" class="headerlink" title="拓扑空间"></a>拓扑空间</h2><p>欧几里得几何学需要定义内积，连续的概念不需要内积，甚至不需要距离。</p><h3 id="定义-1"><a href="#定义-1" class="headerlink" title="定义"></a>定义</h3><p>给定一个集合$X$,$\tau$是$X$的一系列子集，如果$\tau$满足以下条件：</p><ol><li>空集(empty set)和全集X都是$\tau$的元素;</li><li>$\tau$中任意元素的并集(union)仍然是$\tau$的元素;</li><li>$\tau$中任意有限多个元素的交集(intersection)仍然是$\tau$中的元素。<br>则称$\tau$是$X$上的一个拓扑。</li></ol><h2 id="距离，范数和内积之间的关系"><a href="#距离，范数和内积之间的关系" class="headerlink" title="距离，范数和内积之间的关系"></a>距离，范数和内积之间的关系</h2><p>距离$\gt$范数$\gt$内积</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;引言&quot;&gt;&lt;a href=&quot;#引言&quot; class=&quot;headerlink&quot; title=&quot;引言&quot;&gt;&lt;/a&gt;引言&lt;/h2&gt;&lt;p&gt;数学的空间是研究工作的对象和遵循的规则。&lt;br&gt;线性空间：加法和数乘&lt;br&gt;拓扑空间：距离，范数和内积。&lt;/p&gt;
&lt;h2 id=&quot;距离&quot;&gt;&lt;
      
    
    </summary>
    
      <category term="线性代数" scheme="http://mxxhcm.github.io/categories/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/"/>
    
    
      <category term="内积空间" scheme="http://mxxhcm.github.io/tags/%E5%86%85%E7%A7%AF%E7%A9%BA%E9%97%B4/"/>
    
      <category term="赋范空间" scheme="http://mxxhcm.github.io/tags/%E8%B5%8B%E8%8C%83%E7%A9%BA%E9%97%B4/"/>
    
      <category term="希尔伯特空间" scheme="http://mxxhcm.github.io/tags/%E5%B8%8C%E5%B0%94%E4%BC%AF%E7%89%B9%E7%A9%BA%E9%97%B4/"/>
    
      <category term="距离" scheme="http://mxxhcm.github.io/tags/%E8%B7%9D%E7%A6%BB/"/>
    
      <category term="范数" scheme="http://mxxhcm.github.io/tags/%E8%8C%83%E6%95%B0/"/>
    
      <category term="内积" scheme="http://mxxhcm.github.io/tags/%E5%86%85%E7%A7%AF/"/>
    
  </entry>
  
  <entry>
    <title>convex optimization chapter 2 Convex sets</title>
    <link href="http://mxxhcm.github.io/2018/12/24/convex-optimization-chapter-2-Convex-sets/"/>
    <id>http://mxxhcm.github.io/2018/12/24/convex-optimization-chapter-2-Convex-sets/</id>
    <published>2018-12-24T08:28:45.000Z</published>
    <updated>2019-05-06T16:22:27.704Z</updated>
    
    <content type="html"><![CDATA[<h2 id="仿射集-affine-sets-和凸集-convex-sets"><a href="#仿射集-affine-sets-和凸集-convex-sets" class="headerlink" title="仿射集(affine sets)和凸集(convex sets)"></a>仿射集(affine sets)和凸集(convex sets)</h2><h3 id="直线-line-和线段-line-segmens"><a href="#直线-line-和线段-line-segmens" class="headerlink" title="直线(line)和线段(line segmens)"></a>直线(line)和线段(line segmens)</h3><p>假设$x_1,x_2 \in R^n$是n维空间中不重合$(x_1 \ne x_2)$的两点，给定：</p><script type="math/tex; mode=display">y = \theta x_1 + (1 - \theta)x_2,</script><p>当$\theta\in R$时，$y$是经过点$x_1$和点$x_2$的直线。当$\theta=1$时，$y=x_1$,当$\theta=0$时，$y=x_2$。当$\theta\in[0,1]$时，$y$是$x_1$和$x_2$之间的线段(line segment)。 把$y$改写成如下形式： <script type="math/tex">y = x_2 + \theta(x_1 - x_2)</script>，可以给出另一种解释，$y$是点$x_2$和方向$x_1 - x_2$(从$x_2$到$x_1$的方向)乘上一个缩放因子$\theta$的和。<br>如下图所示，可以将y看成$\theta$的函数。<br><img src="https://ws1.sinaimg.cn/large/006wtfMEly1fyhy7m4llij30mz0alwep.jpg" alt="line_line-segment"></p><h3 id="仿射集-affine-sets"><a href="#仿射集-affine-sets" class="headerlink" title="仿射集(affine sets)"></a>仿射集(affine sets)</h3><h4 id="仿射集的定义"><a href="#仿射集的定义" class="headerlink" title="仿射集的定义"></a>仿射集的定义</h4><p>给定一个集合$C\subset R^n$,如果经过$C$中任意两个不同点的直线仍然在$C$中，那么$C$就是一个仿射集。即，对于任意$x_1,x_2\in C$和$\theta\in R$，都有$\theta x_1 + (1 - \theta)x_2 \in C$。换句话说，给定线性组合的系数和为$1$，$C$中任意两点的线性组合仍然在$C$中，我们就称这样的集合是仿射的(affine)。</p><h4 id="仿射组合-affine-combination"><a href="#仿射组合-affine-combination" class="headerlink" title="仿射组合(affine combination)"></a>仿射组合(affine combination)</h4><p>我们可以把两个点的线性组合推广到多个点的线性组合，这里称它为仿射组合。<br>仿射组合的定义：给定$\theta_1+\cdots+\theta_k = 1$,则$\theta_1 x_1 + \cdots + \theta_k x_k$是点$x_1,\cdots,x_k$的仿射组合(affine combination)。<br>根据仿射集的定义，一个仿射集(affine set)包含集合中任意两个点的仿射（线性）组合，那么可以推导出仿射集包含集合中任意点（大于等于两个）的仿射组合，即：如果$C$是一个仿射集，$x_1,\cdots,x_k\in C$,且$\theta_1 x_1 + \cdots + \theta_k x_k = 1$,那么点$\theta_1 x_1 + \cdots + \theta_k x_k$仍然属于$C$。</p><h4 id="仿射集的子空间-subspce"><a href="#仿射集的子空间-subspce" class="headerlink" title="仿射集的子空间(subspce)"></a>仿射集的子空间(subspce)</h4><p>如果$C$是一个仿射集，$x_0 \in C$,那么集合</p><script type="math/tex; mode=display">V = C - x_0 = \{x - x_0\big|x \in C\}</script><p>是一个子空间(subspace),因为$V$是加法封闭和数乘封闭的。<br>证明：<br>假设$v_1, v_2 \in V$，并且$\alpha,\beta \in R$。<br>要证明V是一个子空间，那么只需要证明$\alpha v_1 + \beta v_2 \in V$即可。<br>因为$v_1, v_2 \in V$，则$v_1+x_0, v_2+x_0 \in C$。<br>而$x_0 \in C$，所以有</p><script type="math/tex; mode=display">\alpha(v_1+x_0) + \beta(v_2+x_0) + (1 - \alpha - \beta)x_0 \in C</script><p>即：<br>\begin{align*}<br>\alpha v_1 + \beta v_2 + (\alpha + \beta + 1 - \alpha - \beta)x_0 &amp;\in C\<br>\alpha v_1 + \beta v_2 + x_0 &amp;\in C<br>\end{align*}<br>所以$\alpha v_1 + \beta v_2 \in V$。<br>所以，仿射集$C$可以写成：</p><script type="math/tex; mode=display">C = V + x_0 = \{ v + x_0\big| v \in V\},</script><p>即，一个子空间加上一个偏移(offset)。而与仿射集$C$相关的子空间$V$与$x_0$的选择无关，即$x_0$可以为$C$中任意一点。</p><h4 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h4><p>线性方程组的解。一个线性方程组的解可以表示为一个仿射集:$C={x\big|Ax = b}$,其中 $A\in R^{m \times n}, b \in R^m$。<br>证明：<br>设$x_1, x_2 \in C$,即$Ax_1 = b, Ax_2 = b$。对于任意$\theta \in R$,有:<br>\begin{align*}<br>A(\theta x_1 + (1-\theta x_2) &amp;= \theta Ax_1 + (1-\theta)Ax_2\<br>&amp;= \theta b + (1 - \theta) b\<br>&amp;= b \end{align*}<br>所以线性方程组的解是一个仿射组合：$\theta x_1 + (1 - \theta) x_2$，这个仿射组合在集合$C$中，所以线性方程组的解集$C$是一个仿射集。<br>和该仿射集$C$相关的子空间$V$是$A$的零空间(nullspace)。因为仿射集$C$中的任意点都是方程$Ax = b$的解，而$V = C - x_0 = {x - x_0\big|x \in C}$，有$Ax = b, Ax_0 = b$，则$Ax - Ax_0 = A(x - x_0) = b - b = 0$，所以$V$是$A$的零空间。</p><h4 id="仿射包-affine-hull"><a href="#仿射包-affine-hull" class="headerlink" title="仿射包(affine hull)"></a>仿射包(affine hull)</h4><p>给定集合$C\subset R^n$，集合中点的仿射组合称为集合$C$的仿射包(affine hull),表示为$aff C$:<br>$aff C = {\theta_1 x_1 + \cdots + \theta_k x_k\big| x_1,\cdots,x_k \in C, \theta_1 + \cdots + \theta_k = 1}$<br>集合$C$可以是任意集合。仿射包是包含集合$C$的最小仿射集（一个集合的仿射包只有一个，是不变的）。即如果$S$是任意仿射集，满足$C\subset S$，那么有$aff C \subset S$。或者说仿射包是所有包含集合$C$的仿射集的交集。</p><h3 id="仿射纬度-affine-dimension-和相对内部-relative-interior"><a href="#仿射纬度-affine-dimension-和相对内部-relative-interior" class="headerlink" title="仿射纬度(affine dimension)和相对内部(relative interior)"></a>仿射纬度(affine dimension)和相对内部(relative interior)</h3><h4 id="拓扑-topology"><a href="#拓扑-topology" class="headerlink" title="拓扑(topology)"></a>拓扑(topology)</h4><p>拓扑(topology)，开集(open sets),闭集(close sets),内部(interior),边界(boundary),闭包(closure),邻域(neighbood),相对内部(relative interior)<br>同一个集合可以有很多个不同的拓扑。</p><h5 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h5><p>给定一个集合$X$,$\tau$是$X$的一系列子集，如果$\tau$满足以下条件：</p><ol><li>空集(empty set)和全集X都是$\tau$的元素;</li><li>$\tau$中任意元素的并集(union)仍然是$\tau$的元素;</li><li>$\tau$中任意有限多个元素的交集(intersection)仍然是$\tau$中的元素。</li></ol><p>则称$\tau$是集合$X$上的一个拓扑。<br>如果$\tau$是$X$上的一个拓扑，那么$(X,\tau)$对称为一个拓扑空间(topological space)。<br>如果$X$的一个子集在$\tau$中，这个子集被称为开集(open set)。<br>如果$X$的一个子集的补集是在$\tau$中，那么这个子集是闭集(closed set)。<br>$X$的子集可能是开集，闭集，或者都是，都不是。<br>空集和全集是开集，也是闭集（定义）。</p><h5 id="示例-1"><a href="#示例-1" class="headerlink" title="示例"></a>示例</h5><ol><li>给定集合$X={1,2,3,4}$, 集合$\tau = { {},{1,2,3,4} }$就是$X$上的一个拓扑。</li><li>给定集合$X={1,2,3,4}$, 集合$\tau = { {},{1}, {3,4},{1,3,4},{1,2,3,4} }$就是$X$上的另一个拓扑。</li><li>给定集合$X={1,2,3,4}$, $X$的幂集(power set)也是$X$上的另一个拓扑。</li></ol><p><strong>通常如果不说的话，默认是在欧式空间(1维，2维,…,n维欧式空间)的拓扑，即欧式拓扑。以下讲的一些概念是在欧式空间的拓扑（通常拓扑）上的定义和一般拓扑直观上可能不太一样，但实际上意义是相同的。</strong></p><h4 id="epsilon-disc-或-epsilon-邻域"><a href="#epsilon-disc-或-epsilon-邻域" class="headerlink" title="$\epsilon-disc$或$\epsilon$邻域"></a>$\epsilon-disc$或$\epsilon$邻域</h4><h5 id="定义-1"><a href="#定义-1" class="headerlink" title="定义"></a>定义</h5><p>给定$x\in R^n$以及$\epsilon\gt 0$，集合</p><script type="math/tex; mode=display">D(x,\epsilon) = \{y\in R^n\big|d(x,y) \lt \epsilon\}</script><p>称为关于$x$的$\epsilon-disc$或者$\epsilon$邻域(neighbood)或者$\epsilon$球(ball)。即所有离点$x$距离小于$\epsilon$的点$y$的集合。</p><h4 id="开集-open-sets"><a href="#开集-open-sets" class="headerlink" title="开集(open sets)"></a>开集(open sets)</h4><h5 id="定义-2"><a href="#定义-2" class="headerlink" title="定义"></a>定义</h5><p><strong>给定集合$A\subset R^n$，对于$A$中的所有元素，即$\forall x\in A$，都存在$\epsilon \gt 0$使得$D(x,\epsilon)\subset A$，那么就称该集合是开的。</strong><br>即集合$A$中所有元素的$spsilon$邻域都还在集合$A$中（定理$1$）。<br><strong>注意：必须满足$\epsilon \gt 0$</strong></p><h5 id="定理"><a href="#定理" class="headerlink" title="定理"></a>定理</h5><h6 id="定理-1-epsilon-邻域是开集"><a href="#定理-1-epsilon-邻域是开集" class="headerlink" title="定理$1$ $epsilon$邻域是开集"></a>定理$1$ $epsilon$邻域是开集</h6><ul><li>在$R^n$中，对于一个$\epsilon \gt 0, x\in R^n$,那么集合$x$的$\epsilon$邻域$D(x,\epsilon)$是开的，给定一个$\epsilon$，能找到一个更小的$epsilon$邻域。</li></ul><h6 id="定理-2"><a href="#定理-2" class="headerlink" title="定理$2$"></a>定理$2$</h6><ul><li>$R^n$中有限个开子集的交集是$R^n$的开子集。</li><li>$R^n$中任意个开子集的并集是$R^n$的开子集。</li></ul><p><strong>注意：任意开集的交可能不是开集，一个点不是开集，但是它是所有包含它的开集的交。</strong></p><h5 id="示例-2"><a href="#示例-2" class="headerlink" title="示例"></a>示例</h5><p><img src="/2018/12/24/convex-optimization-chapter-2-Convex-sets/unit_circle.png" alt="unit_circle"></p><ol><li>$R^2$中的不包含边界的球是开的，如图。</li><li>考虑一个$R^1$中的开区间，如$(0,1)$，它是一个开集，但是如果把它放在二维欧式空间中(是x轴上的一个线段)，它不是开的，不满足定义，所以开集是必须针对于某一个给定的集合$X$。 </li><li>$R^2$上的包含边界的单位圆$X = {x\in R^2 \big||x|\le 1}$不是开的。因为边界上的点$x$不满足$\epsilon \gt 0, D(x,\epsilon) \subset X$。</li><li>集合$S={(x,y) \in R^2\big|0 \lt x \lt 1}$是开集。对于每个点$(x,y)\in S$,我们可以画出半径$r = min{x,1-x}$的邻域并且其全部含于$S$，所以$S$是开集。</li><li>集合$S={(x,y) \in R^2\big|0 \lt x \le 1}$不是开集。因为点$(1,0) \in S$的邻域包含点$(x,0)$,其中$x\gt 1$。</li></ol><h4 id="内部-interior"><a href="#内部-interior" class="headerlink" title="内部(interior)"></a>内部(interior)</h4><h5 id="定义-3"><a href="#定义-3" class="headerlink" title="定义"></a>定义</h5><p><strong>给定集合$A\subset R^n$,点$x \in A$，如果有一个开集$U$使得$x \in U\subset A$,那么该点就称为$A$的一个内点。或者说对于$x\in A$，有一个$\epsilon \gt 0$使得$D(x,\epsilon)\subset A$。$A$的所有内点组成的集合叫做$A$的内部(interior)，记做$int(A)$。</strong><br>集合内部可能是空的，单点的内部就是空的。单位圆的内部是不包含边界的单位圆。事实上$A$的内部是$A$所有开子集的并，由开集的定理得$A$的内部是开的，且$A$的内部是$A$的最大的开集。<br>简单来说，就是集合内所有开集还在这个集合内的点 的并。</p><h5 id="示例-3"><a href="#示例-3" class="headerlink" title="示例"></a>示例</h5><ol><li>给定集合$S={(x,y)\in R^2\big| 0 \lt x \le 1}$，$int(S) = {(x,y)\big|0 \lt x \lt 1}$。因为区间$(0,1)$中的点都满足它们的$\epsilon$邻域在$S$中。</li><li>$int(A) \cup int(B) \ne int(A\cup B)$。在实数轴上，$A=[0,1],B=[1,2]$，那么$int(A) = (0,1),int(B) = (1,2)$，所以$int(A) \cup int(B) = (0,1)\cup (1,2) = (0,2)\backslash {1}$，而$int(A\cup B) = int[0,2] = (0,2)$。</li></ol><h4 id="闭集-closed-set"><a href="#闭集-closed-set" class="headerlink" title="闭集(closed set)"></a>闭集(closed set)</h4><h5 id="定义-4"><a href="#定义-4" class="headerlink" title="定义"></a>定义</h5><p><strong>对于$R^n$中的集合$B$，如果它在$R^n$的补（即集合$R^n \backslash B$）是开集，那么它是闭集。</strong><br>单点是闭集。含有边界的单位圆组成的集合是闭集，因为它的补集不包含边界。一个集合可能既不是开集也不是闭集。例如，在一维欧几里得空间，半开半闭区间（如$(0,1]$）既不是开集也不是闭集。</p><h5 id="定理-1"><a href="#定理-1" class="headerlink" title="定理"></a>定理</h5><ol><li>$R^n$中有限个闭子集的并是闭集。</li><li>$R^n$中任意个闭子集的交是闭集。</li></ol><p>这个定理是从开集的定理中得出的，在对开集取补变成闭集时候，并与交相互变换即可。</p><h5 id="示例-4"><a href="#示例-4" class="headerlink" title="示例"></a>示例</h5><ol><li>给定集合$S={(x,y) \in R^2\big| 0 \lt x \le 1, 0 \lt y \lt 1}$，$S$不是闭集。因为目标区域的下边界不在S中。</li><li>给定集合$S={(x,y) \in R^2\big| x^2+y^2\le 1}$，$S$是闭集，因为它的闭集是$R^2$中的开集。 </li><li>$R^n$中任何有限集是闭集。因为单点是闭集，有限集可以看成很多个单点的并，由定理$1$可以得出。 </li></ol><h4 id="聚点-accumulation-point"><a href="#聚点-accumulation-point" class="headerlink" title="聚点(accumulation point)"></a>聚点(accumulation point)</h4><h5 id="定义-5"><a href="#定义-5" class="headerlink" title="定义"></a>定义</h5><p>对于点$x\in R^n$，如果包含$x$的每个开集$U$包含不同于$x$但依然属于集合$A$中的点，那么就称$x$是$A$的一个聚点(accumulation points)，也叫聚类点(cluster points)。<strong>注意这里是包含集合$A$中的点，而不是全部是集合$A$中的点，所以集合的聚点不一定必须在集合中。</strong>如，在一维欧式空间中，单点集合没有聚点，开区间$(0,1)$的聚点是$[0,1]$，${0,1}$不在区间内，但是是聚点。<br>此外，$x$是聚类点等价于：对于每个$\epsilon \gt 0$，$D(x,\epsilon)$包含$A$中的某点$y$且$y\ne x$。</p><h5 id="定理-2"><a href="#定理-2" class="headerlink" title="定理"></a>定理</h5><p>当且仅当集合$S$的所有聚点属于$S$时，$S\subset R^n$是闭集。</p><h5 id="示例-5"><a href="#示例-5" class="headerlink" title="示例"></a>示例</h5><ol><li>给定集合$S={x\in R\big|x\in [0,1]且x是有理数}$，$S$的聚点为$[0,1]$中所有点。任何不属于$[0,1]$的点都不是聚点，因为这类点有一个包含它的$\epsilon$邻域与$[0,1]$不相交。</li><li>给定集合$S={(x,y)\in R^2\big| 0 \le x\le or\ x = 2}$, 它的聚点是它本身，因为它是闭集。</li><li>给定集合$S={(x,y)\in R^2\big|y \lt x^2 + 1}$，S的聚点为集合${(x,y)\in R^2\big|y \le x^2 + 1}$，</li></ol><h4 id="闭包-closure"><a href="#闭包-closure" class="headerlink" title="闭包(closure)"></a>闭包(closure)</h4><h5 id="定义-6"><a href="#定义-6" class="headerlink" title="定义"></a>定义</h5><p>给定集合$A\subset R^n$,集合$A$的闭包$cl(A)$定义成所有包含$A$的闭集的交，所以$cl(A)$是一个闭集。定价的定义是给定集合$A$，包含$A$的最小闭集叫做这个集合$X$的闭包(closure)，用$cl(A)$或者${\overline{A}}$表示。</p><h5 id="定理-3"><a href="#定理-3" class="headerlink" title="定理"></a>定理</h5><p>给定$A\subset R^n$，那么$cl(A)$由$A$和$A$的所有聚点组成。</p><h5 id="示例-6"><a href="#示例-6" class="headerlink" title="示例"></a>示例</h5><ol><li>$R$中$S=[0,1)\cup {2}$的闭包是$[0,1]$和${2}$,S聚点是$[0,1]$,所以S的闭包是$[0,1]\cup{2}$。</li><li>对于任意$S\subset R^n$，$R^n \backslash cl(S)$是开集。因为$cl(S)$是闭集，所以它的补集是开集。 </li><li>$cl(A\cap B) \ne cl(A)\cap cl(B)$。比如$A=(0,1),B(1,2),cl(A)=[0,1],cl(B)=[1,2]$,$A\cap B = \varnothing$,$cl(A\cap B) = \varnothing$,而$cl(A)\cap cl(B) = {1}$。</li></ol><h4 id="边界-boundary"><a href="#边界-boundary" class="headerlink" title="边界(boundary)"></a>边界(boundary)</h4><h5 id="定义-7"><a href="#定义-7" class="headerlink" title="定义"></a>定义</h5><p>对于$R^n$中的集合$A$，边界定义为集合：<br>$bd(A) = cl(A)\cap cl(R^n \backslash A)$<br>即集合$A$的补集的闭包和$A$的闭包的交集，所以$bd(A)$是闭集。$bd(A)$是$A$与$R^n \backslash A$之间的边界。</p><h5 id="定理-4"><a href="#定理-4" class="headerlink" title="定理"></a>定理</h5><p>给定$A\subset R^n$，当且仅当对于每个$\epsilon \gt 0$，$D(x,\epsilon)$包含$A$与$R^n\backslash A$的点，$x\in bd(A)$。</p><h5 id="示例-7"><a href="#示例-7" class="headerlink" title="示例"></a>示例</h5><ol><li>给定集合$S={x\in R\big|x\in [0,1],x是有理数}$，$bd(S) = [0,1]$。因为对于任意$\epsilon \gt 0, x\in [0,1],D(x,\epsilon) = (x-\epsilon, x+\epsilon)$包含有理数和无理数，即x是有理数和无理数之间的边界。</li><li>给定$x\in bd(S)$，$x$不一定是聚点。给定集合$S = {0} \subset R$，$bd(S) = {0}$，但是单点没有聚点。</li><li>给定集合$S={(x,y)\in R^2\big| x^2-y^2 \gt 1 }$，$bd(S)={(x,y)\big|x^2 - y^2 = 1}$。 </li></ol><h4 id="仿射维度-affine-dimension"><a href="#仿射维度-affine-dimension" class="headerlink" title="仿射维度(affine dimension)"></a>仿射维度(affine dimension)</h4><h5 id="定义-8"><a href="#定义-8" class="headerlink" title="定义"></a>定义</h5><p>给定一个仿射集$C$，仿射维度是它的仿射包的维度。<br>仿射维度和其他维度的定义不总是相同的，具体可以看以下的示例。</p><h5 id="示例-8"><a href="#示例-8" class="headerlink" title="示例"></a>示例</h5><p>给定一个二维欧几里得空间的单位圆，${x\in C\big|x_1^2+x_2^2=1}$。它的仿射包是整个$R^2$，所以二维平面的单位圆仿射维度是$2$。但是在很多定义中，二维平面的单位圆的维度是$1$。</p><h4 id="相对内部-relative-interior"><a href="#相对内部-relative-interior" class="headerlink" title="相对内部(relative interior)"></a>相对内部(relative interior)</h4><p>给定一个集合$C\subset R^n$，它的仿射维度可能小于$n$，这个时候仿射集$aff\ C \ne R^n$。</p><h5 id="定义-9"><a href="#定义-9" class="headerlink" title="定义"></a>定义</h5><p>给定集合$C$，相对内部的定义如下：<br>$relint\ C = {x\in C\big|(B(x,r)\cup aff\ C) \subset C\, \exists \ r \gt 0}.$<br>就是集合$C$内所有$\epsilon$球在$C$的仿射集内的点的集合。<br>其中$B(x,r)={y \big|\Vert y- x\Vert \le r}$，是以$x$为中心，以$r$为半径的圆。这里的范数可以是任何范数，它们定义的相对内部是相同的。</p><h5 id="示例-9"><a href="#示例-9" class="headerlink" title="示例"></a>示例</h5><p>给定一个$R^3$空间中$(x_1,x_2)$平面上的正方形，$C={x\in R^3\big|-1 \le x_1 \le 1, -1\le x_2 \le 1, x_3 = 0}$。它的仿射包是$(x_1,x_2)$平面，$aff\ C = {x\in R^3\big|x_3=0}$。$C$的内部是空的，但是相对内部是：<br>$relint\ C = {x \in R^3\big|-1 \le x_1 \le 1, -1\le x_2 \le 1,x_3=0}$。 </p><h4 id="相对边界-relative-boundary"><a href="#相对边界-relative-boundary" class="headerlink" title="相对边界(relative boundary)"></a>相对边界(relative boundary)</h4><h5 id="定义-10"><a href="#定义-10" class="headerlink" title="定义"></a>定义</h5><p>给定集合$C$，相对边界(relative boundary)定义为$cl\ C \backslash relint\ C$，其中$cl\ C$是集合$C$的闭包(closure)。</p><h5 id="示例-10"><a href="#示例-10" class="headerlink" title="示例"></a>示例</h5><p>对于上例（相对内部的示例）来说，它的边界(boundary)是它本身。它的相对内部是边框，${x\in R^3\big|max{|x_1|,|x_2|}=1,x_3=0}$。</p><h3 id="凸集-convex-sets"><a href="#凸集-convex-sets" class="headerlink" title="凸集(convex sets)"></a>凸集(convex sets)</h3><h4 id="凸集定义"><a href="#凸集定义" class="headerlink" title="凸集定义"></a>凸集定义</h4><p>给定一个集合$C$，如果集合$C$中经过任意两点的线段仍然在$C$中，这个集合就是一个凸集。<br>给定$\forall x_1,x_2 \in C, 0 \le \theta \le 1$，那么我们有$\theta x_1 + (1-\theta)x_2 \in C$。<br>每一个仿射集都是凸的，因为它包含经过任意两个不同点的直线，所以肯定就包含过那两个点的线段。</p><h4 id="凸组合-convex-combination"><a href="#凸组合-convex-combination" class="headerlink" title="凸组合(convex combination)"></a>凸组合(convex combination)</h4><p>给定$k$个点$x_1,x_2,\cdots,x_k$，如果具有$\theta_1 x_1 + \cdots, \theta_k x_k$形式且满足$\theta_1 + \cdots + \theta_k=1, \theta_i \ge 0,i=1,\cdots,k$,那么就称这是$x_1,\cdots,x_k$的一个凸组合。<br>当且仅当一个集合包含其中所有点的凸组合，这个集合是一个凸集。点的一个凸组合可以看成点的混合或者加权，$\theta_i$是第$i$个点$x_i$的权重。<br>凸组合可以推广到无限维求和，积分，概率分布等等。假设$\theta_1,\theta_2,\cdots$满足：</p><script type="math/tex; mode=display">\theta_i \le 0, i = 1,2,\cdots, \sum_{i=1}^{\infty}\theta_i = 1</script><p>并且$x<em>1,x_2,\cdots \in C$，$C\subset R^n$是凸的，如果(series)$\sum</em>{i=1}^{\infty}\theta<em>i x_i$收敛，那么$\sum</em>{i=1}^{\infty}\theta<em>i x_i \in C$。<br>更一般的，假设概率分布$p$，$R^n \rightarrow R$满足$p(x)\le 0 for\ all\ x\in C, \int</em>{C}p(x)dx = 1$,其中$C\subset R^n$是凸的，如果$\int<em>{C}p(x)xdx$存在的话，那么$\int</em>{C}p(x)xdx\in C$。</p><h4 id="凸包-convex-hull"><a href="#凸包-convex-hull" class="headerlink" title="凸包(convex hull)"></a>凸包(convex hull)</h4><p>给定一个集合$C$，凸包的定义为包含集合$C$中所有点的凸组合的结合，记为$conv\ C$，公式如下：<br>$conv\ C = {\theta_1 x_1 + \cdots + \theta_k x_k\big|x_i \in C, \theta_i \ge 0, i = 1,\cdots,k,\theta_1 +\cdots + \theta_k = 1}$<br>任意集合都是有凸包的。一个集合的凸包总是凸的。集合$C$的凸包是包含集合$C$的最小凸集。如果集合$B$是任意包含$C$的凸集，那么$conv\ C \subset B$。</p><h4 id="示例-11"><a href="#示例-11" class="headerlink" title="示例"></a>示例</h4><p><img src="/2018/12/24/convex-optimization-chapter-2-Convex-sets/figure2_2.png" alt="figure 2.2"><br><img src="/2018/12/24/convex-optimization-chapter-2-Convex-sets/figure2_3.png" alt="figure 2.3"></p><h3 id="锥-cones"><a href="#锥-cones" class="headerlink" title="锥(cones)"></a>锥(cones)</h3><h4 id="锥-cones-和凸锥-convex-cones-的定义"><a href="#锥-cones-和凸锥-convex-cones-的定义" class="headerlink" title="锥(cones)和凸锥(convex cones)的定义"></a>锥(cones)和凸锥(convex cones)的定义</h4><p>给定集合$C$，如果$\forall x \in C, \theta \ge 0$，都有$\theta x\in C$，这样的集合就称为一个锥(cone)，或者非负同质(nonnegative homogeneour)。<br>一个集合$C$如果既是锥又是凸的，那这个集合是一个凸锥(convex cone)，即：$\forall x_1,x_2 \in C, \theta_1,\theta_2 \ge 0$,那么有$\theta_1 x_1+\theta_2 x_2 \in C$。几何上可以看成经过顶点为原点，两条边分别经过点$x_1$和$x_2$的$2$维扇形。</p><h4 id="锥组合-conic-combination"><a href="#锥组合-conic-combination" class="headerlink" title="锥组合(conic combination)"></a>锥组合(conic combination)</h4><p>给定$k$个点$x_1,x_2,\cdots,x_k$，如果具有$\theta_1 x_1 + \cdots, \theta_k x_k$形式且满足$\theta_i \ge 0,i=1,\cdots,k$,那么就称这是$x_1,\cdots,x_k$的一个锥组合(conic combination)或者非负线性组合(nonnegative combination)。<br>给定集合$C$是凸锥，那么集合$C$中任意点$x_i$的锥组合仍然在集合$C$中。反过来，当且仅当集合$C$包含它的任意元素的凸组合时，这个集合是一个凸锥(convex cone)。</p><h4 id="锥包-conic-hull"><a href="#锥包-conic-hull" class="headerlink" title="锥包(conic hull)"></a>锥包(conic hull)</h4><p>给定集合$C$，它的锥包(conic hull)是集合$C$中所有点的锥组合。即：<br>$conic\ C = {\theta_1 x_1 + \cdots + \theta_k x_k\big|x_i \in C, \theta_i \ge 0, i = 1,\cdots,k}$<br>集合$C$的锥包是包含集合$C$的最小凸锥。</p><h4 id="示例-12"><a href="#示例-12" class="headerlink" title="示例"></a>示例</h4><p><img src="/2018/12/24/convex-optimization-chapter-2-Convex-sets/figure2_4.png" alt="figure 2.4"><br><img src="/2018/12/24/convex-optimization-chapter-2-Convex-sets/figure2_5.png" alt="figure 2.5"></p><h3 id="一些想法"><a href="#一些想法" class="headerlink" title="一些想法"></a>一些想法</h3><p>在我自己看来，在几何上<br>仿射集可以看成是集合中任意两个点的直线的集合。<br>凸集可以看成是集合中任意两个点的线段的集合，因为直线一定包含线段，所以仿射集一定是凸集。<br>锥集可以看成是集合中任意一个点和原点构成的射线的集合，锥集不一定是连续的（两条射线也是锥集），所以锥集不一定是凸集。<br>而凸锥既是凸集又是锥集。<br>我在stackexchange看到这样一句话觉得说的挺好的。</p><blockquote><p>What basically distinguishes the definitions of convex, affine and cone, is the domain of the coefficients and the constraints that relate them.</p></blockquote><p>区别凸集，仿射和锥的是系数的取值范围和一些其他限制。仿射集要求$\theta_1+\cdots+\theta_k = 1$，凸集要求$\theta_1 +\cdots +\theta_k = 1, 0\le \theta \le 1$，锥的要求是$\theta \ge 0$，凸锥的要求是$\theta_i \ge 0,i=1,\cdots,k$。<br>仿射集不是凸集的子集，凸集也不是仿射集的子集。所有仿射集的集合是所有凸集的集合的子集，一个仿射集是一个凸集。</p><h2 id="示例-13"><a href="#示例-13" class="headerlink" title="示例"></a>示例</h2><ul><li>$\emptyset$，单点(single point)${x_0}$，整个$R^n$空间都是$R^n$中的仿射子集，所以也是凸集，点不一定是凸锥（在原点熵是凸锥），空集是凸锥，$R^n$维空间也是凸锥。<strong>根据定义证明。</strong></li><li>任意一条直线都是仿射的，所以是凸集。如果经过原点，它是一个子空间，也就是一个凸锥，否则不是。 </li><li>任意一条线段都是凸集，不是仿射集，当它退化成一点的时候，它是仿射的，线段不是凸锥。 </li><li>一条射线${x_0 + \theta v\big| \theta \ge 0}$是凸的，但是不是仿射的，当$x_0=0$时，它是凸锥。</li><li>任意子空间都是仿射的，也是凸锥，所以是凸的。 </li></ul><p>补充最后一条，任意子空间都是仿射的，也是凸锥。<br>如果$V$是一个子空间，那么$V$中任意两个向量的线性组合还在$V$中。即如果$x<em>1,x_2\in V$，对于$\theta_1,\theta_2 \in R$，都有$\theta_1 x_1 + \theta_2 x_2 \in V$。正如前面说的，子空间是加法和数乘封闭的。<br>而根据仿射集的定义，如果$x_1,x_2$在一个仿射集$C$中，那么对于$\theta_1+\theta_2 = 1$，都有$\theta_1 x_1 + \theta_2 x_2 \in C$。我们可以看出来，如果取子空间中线性组合的系数和为$1$，那么就成了仿射集。如果取子空间中的系数$\theta_1,\theta_2 \in R</em>+$,那么就成了锥，如果同时满足$\theta<em>1+\theta_2 = 1$，那么就成凸锥。那么如果加上这些限制条件，即取子空间中线性组合的系数和为$1$，或者取子空间中的系数$\theta_1,\theta_2 \in R</em>+$,同时满足$\theta_1+\theta_2 = 1$。<br>事实上，子空间要求的条件比仿射集和凸锥的条件要更严格。仿射集和凸锥只要求在系数$\theta_i$满足相应的条件时,有$\theta_1 x_1 + \theta_2 x_2 \in R^n$；而子空间要求的是在系数$\theta_i$取任意值的时候，都有$\theta_1 x_1 + \theta_2 x_2 \in R^n$，所以子空间一定是仿射集，也一定是凸锥。（拿二维的举个例子，给定$x_1$和$x_2$，仿射集可以看成是$\theta_1$的函数，因为$\theta_2=1-\theta_1$，而子空间可以看成$\theta_1$和$\theta_2$的函数，一个是一元函数，一个是二元函数）</p><h3 id="超平面-hyperplane-和半空间-halfspace"><a href="#超平面-hyperplane-和半空间-halfspace" class="headerlink" title="超平面(hyperplane)和半空间(halfspace)"></a>超平面(hyperplane)和半空间(halfspace)</h3><p>超平面是一个仿射集，也是凸集，但不一定是锥集(过原点才是锥集，也是一个子空间)。<br>闭的半空间是一个凸集，不是仿射集。</p><h4 id="超平面-hyperplane"><a href="#超平面-hyperplane" class="headerlink" title="超平面(hyperplane)"></a>超平面(hyperplane)</h4><p>超平面通常具有以下形式：</p><script type="math/tex; mode=display">\{x\big|a^Tx=b\},</script><p>其中$a\in R^n,a\ne 0,b\in R$，它其实是一个平凡(nontrivial)线性方程组的解，因此也是一个仿射集。几何上，超平面可以解释为和一个给定向量$a$具有相同内积(inner product)的点集，或者说是法向量为$a$的一个超平面。常数$b$是超平面和原点之间的距离(offset)。<br>几何意义可以被表示成如下形式：</p><script type="math/tex; mode=display">\{x\big|a^T(x-x_0) = 0\},</script><p>其中$x_0$是超平面上的一点，即满足$a^Tx_0=0$。可以被表示成如下形式：</p><script type="math/tex; mode=display">\{x\big|a^T(x-x_0)=0\} = x_0+a^{\perp},</script><p>其中$a^{\perp}$是$a$的正交补，即所有与$a$正交的向量的集合，满足$a^{\perp}={v\big|a^Tv=0}$。所以，超平面的几何解释可以看做一个偏移(原点到这个超平面的距离)加上所有垂直于一个特定向量$a$(正交向量)的向量，即这些垂直于$a$的向量构成了一个过原点的超平面，再加上这个偏移量就是我们要的超平面。几何表示如下图所示。<br><img src="/2018/12/24/convex-optimization-chapter-2-Convex-sets/figure2_6.png" alt="figure 2.6"></p><h4 id="半空间-halfspace"><a href="#半空间-halfspace" class="headerlink" title="半空间(halfspace)"></a>半空间(halfspace)</h4><p>一个超平面将$R^n$划分为两个半空间(halfspaces)，一个是闭(closed)半空间，一个是开半空间。闭的半空间可以表示成${x\big|a^Tx\le b}$，其中$a\ne 0$，半空间是凸的，但不是仿射的。下图便是一个闭的半空间。<br><img src="/2018/12/24/convex-optimization-chapter-2-Convex-sets/figure2_7.png" alt="figure 2.7"><br>这个半空间也可以写成：</p><script type="math/tex; mode=display">\{x\big|a^T(x-x_0)\le 0\},</script><p>其中$x_0$是划分两个半空间的超平面上的一点，即满足$a^Tx_0=b$。一个几何解释是：半空间由一个偏移$x_0$加上所有和一个特定向量$a$(超平面的外(outward)法向量)成钝角(obtuse)或者直角(right)的所有向量组成。<br>这个半空间的边界是超平面${x\big|a^Tx=b}$。这个半空间${x\big|a^Tx\le b}$的内部是${x\big|a^Tx\lt b}$，也被称为一个开半平面。</p><h3 id="欧几里得球-Euclidean-ball-和椭球-ellipsoid"><a href="#欧几里得球-Euclidean-ball-和椭球-ellipsoid" class="headerlink" title="欧几里得球(Euclidean ball)和椭球(ellipsoid)"></a>欧几里得球(Euclidean ball)和椭球(ellipsoid)</h3><h4 id="欧几里得球"><a href="#欧几里得球" class="headerlink" title="欧几里得球"></a>欧几里得球</h4><p>$R^n$空间中的欧几里得球或者叫球，有如下的形式：</p><script type="math/tex; mode=display">B(x_r,r = \{x\big|\Vert x-x_c\Vert_2\le r\}=\{x \big|(x-x_c)^T(x-x_c)\le r^2\},</script><p>其中$r\gt 0$,$\Vert \cdot\Vert_2$是欧几里得范数(第二范数)，即$\Vert u\Vert_2=(u^Tu)^{\frac{1}{2}}$。向量$x_c$是球心，标量$r$是半径。$B(x_c,r)$包含所有和圆心$x_c$距离小于$r$的球。<br>欧几里得球的另一种表示形式是：</p><script type="math/tex; mode=display">B(x_c,r)=\{x_c + ru\big| \Vert u \Vert_2 \le 1\},</script><p>一个欧几里得球是凸集，如果$\Vert x_1-x_c\Vert_2 \le r,\Vert x_2-x_c\Vert_2\le r, 0\le\theta\le1$，那么：<br>\begin{align*}<br>\Vert\theta x_1 + (1-\theta)x_2 - x_c\Vert_2 &amp;= \Vert\theta(x_1-x_c)+(1-\theta)(x_2-x_c)\Vert_2\<br>&amp;\le\theta\Vert x_1-x_c\Vert_2 + (1-\theta)\Vert x_2 - x_c \Vert_2\<br>&amp;\le r<br>\end{align*}<br>用其次性和三角不等式可证明</p><h4 id="椭球"><a href="#椭球" class="headerlink" title="椭球"></a>椭球</h4><p>另一类凸集是椭球，它们有如下的形式：</p><script type="math/tex; mode=display">\varepsilon =\{x\big|(x-x_c)^TP^{-1}(x-x_c) \le 1\},</script><p>其中$P=P^T \succ 0$即$P$是对称和正定的。向量$x_c\in R^n$是椭球的中心。矩阵$P$决定了椭球从$x_c$向各个方向扩展的距离。椭球$\varepsilon$的半轴由矩阵$P$的特征值$\lambda_i$算出，$\sqrt{\lambda_i}$，球是$P=r^2I$的椭球。<br><strong>这里这种表示形式为什么要用$P^{-1}$？</strong><br>椭球的另一种表示是：</p><script type="math/tex; mode=display">\varepsilon = \{x_c + Au\big| \Vert u \Vert_2 \le 1\},</script><p>其中$A$是一个非奇异方阵。假设$A$是对称正定的，取$A=P^{\frac{1}{2}}$，这种表示就和上面的表示是一样的。第一次看到这种表示的时候，我在想，椭球的边界上有无数个点，一个方阵$A$是怎么实现对这无数个操作的，后来和球做了对比，发现自己一直都想错了，这无数个点是通过范数实现的而不是通过矩阵$A$实现的，到球心距离为$\Vert u\Vert_2\le 1$的点有无数个，$A$对这无数个点的坐标都做了仿射变换，将一个球变换成了椭球，特殊情况下就是球。当矩阵$A$是对称半正定但是是奇异的时候，这个情况下称为退化椭球(degenerate ellipsoid)，它的仿射维度和矩阵$A$的秩(rank)是相同的。退化椭球也是凸的。</p><h3 id="范数球-norm-ball-和范数锥-norm-cone"><a href="#范数球-norm-ball-和范数锥-norm-cone" class="headerlink" title="范数球(norm ball)和范数锥(norm cone)"></a>范数球(norm ball)和范数锥(norm cone)</h3><h4 id="范数球-norm-ball"><a href="#范数球-norm-ball" class="headerlink" title="范数球(norm ball)"></a>范数球(norm ball)</h4><h5 id="定义-11"><a href="#定义-11" class="headerlink" title="定义"></a>定义</h5><p>$\Vert \cdot\Vert$是$R^n$上的范数。一个范数球(norm ball)可以看成一个以$x_c$为中心，以$r$为半径的集合，但是这个$r$可以是任何范数，即${x\big|\Vert x-x_c \Vert \le r}$，它是凸的。</p><h5 id="示例-14"><a href="#示例-14" class="headerlink" title="示例"></a>示例</h5><p>我们常见的球是二范数（欧几里得范数）对应的范数球。</p><h4 id="范数锥"><a href="#范数锥" class="headerlink" title="范数锥"></a>范数锥</h4><h5 id="定义-12"><a href="#定义-12" class="headerlink" title="定义"></a>定义</h5><p>和范数相关的范数锥是集合：$C = {(x,t)\big|\Vert x\Vert \le t} \subset R^{n+1}$，它也是凸锥。</p><h5 id="示例-15"><a href="#示例-15" class="headerlink" title="示例"></a>示例</h5><p><img src="/2018/12/24/convex-optimization-chapter-2-Convex-sets/figure2_10.png" alt="figure 2.10"><br>二阶锥(second-order cone)是欧几里得范数对应的范数锥，如图所示，其表达式为：<br>\begin{align*}<br>C &amp;={(x,t)\in R^{n+1} \big| \Vert x\Vert_2 \le t}\<br>&amp;= \left{ \begin{bmatrix}x\t\end{bmatrix}\big| \begin{bmatrix}x\t\end{bmatrix}^T\begin{bmatrix}I&amp;0\0&amp;-1\end{bmatrix}\begin{bmatrix}x\t\end{bmatrix}\le 0, t \gt 0 \right}<br>\end{align*}<br>这个二阶锥也被称为二次锥(quadratic cone)，因为它是通过一个二次不等式定义的，也被叫做Lorentz cone或者冰激凌锥(ice-cream cone)。</p><h4 id="范数锥和范数球的区别"><a href="#范数锥和范数球的区别" class="headerlink" title="范数锥和范数球的区别"></a>范数锥和范数球的区别</h4><p>范数球是所有点到圆心$x_c$的范数小于一个距离$r$。<br>范数锥是很多直线组成的锥。</p><h3 id="多面体-polyhedra"><a href="#多面体-polyhedra" class="headerlink" title="多面体(polyhedra)"></a>多面体(polyhedra)</h3><h4 id="定义-13"><a href="#定义-13" class="headerlink" title="定义"></a>定义</h4><p>多面体(polyhedron)是有限个线性不等式或者线性方程组的解集的集合：<br>$P = {x\big|a_j^Tx\le b_j, j=1,\cdots,m,c_j^Tx=d_j,j=1,\cdots,p}$<br>多面体因此也是有限个半空间或者超平面的交集。仿射集(如，子空间，超平面，直线)，射线，线段，半空间等等都是多面体，多面体也是凸集。有界的polyhedron有时也被称为polytope，一些作者会把它们两个反过来叫。<br>上式的紧凑(compact)表示是：</p><script type="math/tex; mode=display">P=\{x\big|Ax\preceq b, Cx=d\}</script><p>其中$A=\begin{bmatrix}a_1^T\ \vdots\ a_m^T\end{bmatrix},C=\begin{bmatrix}c_1^T\ \vdots\c_p^T\end{bmatrix}$，$\preceq$表示$R^m$空间中的向量不等式(vector ineuqalitied)或者分量大小的不等式，$u\preceq v$代表着$u_i\le v_i, i=1,\cdots,m$。</p><h5 id="simplexes"><a href="#simplexes" class="headerlink" title="simplexes"></a>simplexes</h5><p>simplexes是另一类很重要的多面体。假设$R^n$空间中的$k+1$个点是仿射独立(affinely independent)，意味着$v_1-v_0, \cdots,v_k-v_0$是线性独立的。由$k+1$个仿射独立的点确定的simplex是：</p><script type="math/tex; mode=display">C = conv\{v_0,\cdots,v_k\} = \{\theta_0v_0+\cdots+\theta_kv_k\big| \theta \succeq 0, \mathcal{1}\theta=1 \},</script><p>其中$\mathcal{1}$是全为$1$的列向量。这个simplex的仿射维度是$k$，所以它也叫$R^n$空间中的$k$维simplex。为什么仿射维度是$k$，我的理解是simplex是凸集，而凸集不是子空间，凸集去掉其中任意一个元素才是子空间，所以就是$k$维而不是$k+1$维。<br>为了将simplex表达成一个紧凑形式的多面体。定义$y=(\theta_1,\cdots,\theta_k)$和$B=[v_1-v_0\ \cdots\ v_k-v_0]\in R^{n\times k}$，当且仅当存在$y\succeq 0, \mathcal{1}^Ty\le 1$，$x=v_0+By$有$x\in C$，<strong>疑问，这里为什么变成了$\mathcal{1}^Ty\le 1$，难道是因为少了个$v_0$吗</strong>。点$v_0,\cdots,v_k$表明矩阵$B$的秩为$k$。因此存在一个非奇异矩阵$A=(A_1,A_2)\in R^{n\times n}$使得：</p><script type="math/tex; mode=display">AB = \begin{bmatrix}A_1\\A_2\end{bmatrix}B= \begin{bmatrix}I\\0\end{bmatrix}.</script><p>对$x = v_0+By$同时左乘$A$，得到：</p><script type="math/tex; mode=display">A_1x = A_1v_0+y, A_2x=A_xv_0.</script><p>从中我们可以看出如果$A_2x=A_2v_0$，且向量$y=A_1x-A_1v_0$满足$y\succeq 0, \mathcal{1}^Ty\le1$时，$x\in C$。换句话说，当且仅当$x$满足以下等式和不等式时：</p><script type="math/tex; mode=display">A_2x = A_2v_0,A_1x\succeq A_1v_0, \mathcal{1}A_1x\le1+\mathcal{1}^TA_1v_0,</script><p>有$x\in C$。</p><h5 id="多面体的凸包描述"><a href="#多面体的凸包描述" class="headerlink" title="多面体的凸包描述"></a>多面体的凸包描述</h5><p>一个有限集合${v_1,\cdots,v_k}$的凸包是：</p><script type="math/tex; mode=display">conv\{v_1,\cdots,v_k\} = \{\theta_1 v_1 +\cdots +\theta_k v_k\big| \theta \succeq 0, \mathcal{1}^T\theta = 1\}.</script><p>这个集合是一个多面体，并且有界。但是它（除了simplex）不容易化成多面体的紧凑表示，即不等式和等式的集合。<br>一个一般化的凸包描述是：</p><script type="math/tex; mode=display">\{\theta_1 v_1 +\cdots +\theta_k v_k\big| \theta_1+\cdots + \theta_m = 1,\theta_i \ge 0,i=1,\cdots,k\}.</script><p>其中$m\le k$，它可以看做是点$v<em>1,\cdots,v_m$的凸包加上点$v</em>{m+1},\cdots,v_{k}$的锥包。这个集合定义了一个多面体，反过来，任意一个多面体可以看做凸包加上锥包。<br>一个多面体如何表示是很有技巧的。比如一个$R^n$空间上的无穷范数单位球$C$：</p><script type="math/tex; mode=display">C=\{x\big|\ |x_i|\le 1,i = 1,\cdots,n\}.</script><p>集合$C$可以被表示成$2n$个线性不等式$\pm e_i^Tx\le 1$，其中$e_i$是第$i$个单位向量。然而用凸包形式描述这个集合需要用至少$2^n$个点：</p><script type="math/tex; mode=display">C = conv\{v_{1},\cdots,v_{2^n}\},</script><p>其中$v<em>{1},\cdots,v</em>{2n}$是$2^n$个向量，每个向量的元素都是$1$或$-1$。因此凸包描述和不等式描述有很大差异，尤其是$n$很大的时候。<br>这里为什么是$2^n$个点呢？因为是无穷范数构成的单位圆，在数轴上是区间$[-1,1]$，在$R^2$是正方形${(x,)\big|-1 \le x\le 1,-1\le y\le 1}$，对应的四个点是${(1,1),(1,-1),(-1,1),(-1,-1)}$，而在$R^3$是立方体${(x,y,z)\big|-1 \le x\le 1,-1\le y\le 1\, -1\le z\le 1}$，对应的是立方体的八个顶点${(1,1,1),(1,1,-1),(1,-1,1),(1,-1,-1),(-1,1,1),(-1,1,-1),(-1,-1,1),(-1,-1,-1)}$。</p><h4 id="示例-16"><a href="#示例-16" class="headerlink" title="示例"></a>示例</h4><ol><li>如图所示，是五个半平面的交集定义的多面体。<br><img src="/2018/12/24/convex-optimization-chapter-2-Convex-sets/figure2_11.png" alt="figure 2.11"></li><li>非负象限(nonnegative orthant)是非负点的集合，即：<script type="math/tex; mode=display">R_{+}^n = \{x\in R^n\big| x_i\ge 0, i = 1,\cdots,n\} = \{x\in R^n\big| x\succeq 0\}.</script>非负象限是一个多面体，也是一个锥，所以也叫多面体锥(polyhedral cone)，也叫非负象限锥。</li><li>一个1维的simplex是一条线段。一个二维的simplex是一个三角形（包含它的内部）。一个三维的simple是一个四面体(tetrahedron)。</li><li>由$R^n$中的零向量和单位向量确定的simplex是$n$维unit simplex。它是向量集合：<script type="math/tex; mode=display">x\succeq 0, \mathcal{1}^T x \le 1.</script></li><li>由$R^n$中的单位向量确定的simplex是$n-1$维probability simplex。它是向量集合：<script type="math/tex; mode=display">x\succeq 0, \mathcal{1}^T x = 1.</script>Probability simplex是中的向量可以看成具有$n$个元素的集合的概率分布，$x_i$解释为第$i$个元素的概率。</li></ol><h3 id="半正定锥-positive-sefidefinite-cone"><a href="#半正定锥-positive-sefidefinite-cone" class="headerlink" title="半正定锥(positive sefidefinite cone)"></a>半正定锥(positive sefidefinite cone)</h3><h4 id="定义-14"><a href="#定义-14" class="headerlink" title="定义"></a>定义</h4><p>用$S^n$表示$n\times n$的对称矩阵：$S^n={X\in R^{n\times n} \big| X = X^T}$，$S^n$是一个$n(n+1)/2$维基的向量空间。比如，三维空间中对称矩阵的一组基是：</p><script type="math/tex; mode=display">\begin{bmatrix}1&0&0\\0&0&0\\0&0&0\end{bmatrix}\begin{bmatrix}0&0&0\\1&0&0\\0&0&0\end{bmatrix}\begin{bmatrix}0&0&0\\0&1&0\\0&0&0\end{bmatrix}\begin{bmatrix}0&0&0\\0&0&0\\1&0&0\end{bmatrix}\begin{bmatrix}0&0&0\\0&0&0\\0&1&0\end{bmatrix}\begin{bmatrix}0&0&0\\0&0&0\\0&0&1\end{bmatrix}.</script><p>用$S_{+}^n$表示半正定的对称矩阵集合：</p><script type="math/tex; mode=display">S_{+}^n = \{X\in S^n\big| X\succeq 0\},</script><p>用$S_{++}^n$表示正定的对称矩阵集合：</p><script type="math/tex; mode=display">S_{+}^n = \{X\in S^n\big| X\succ 0\},</script><p>集合$S<em>{+}^n$是凸锥：如果$\theta_1,\theta_2 \ge 0$且$A,B\in S</em>{+}^n$，那么$\theta<em>1 A+\theta</em>{2} B\in S<em>{+}^n$。这个可以直接从依靠半正定的定义来证明，如果$A,B\in S</em>{+}^n ,\theta_1,\theta_2\ge 0$，(<strong>这里原书中用的是$A,B\succeq 0$,我觉得应该是写错了吧</strong>)，对任意$\forall x \in R^n$，都有：</p><script type="math/tex; mode=display">x^T(\theta_1A+\theta_2B)x = \theta_1x^TAx + \theta_2x^TBx.</script><h4 id="示例-17"><a href="#示例-17" class="headerlink" title="示例"></a>示例</h4><p>对于$S^2$空间中的半正定锥，有</p><script type="math/tex; mode=display">X=\begin{bmatrix}x&y\\y&z\end{bmatrix}\in S\_{+}^2 \Leftrightarrow x\ge 0,z\ge 0, xz\ge y^2</script><p>这个锥的边界如下图所示。<br><img src="/2018/12/24/convex-optimization-chapter-2-Convex-sets/figure2_12.png" alt="figure 2.12"></p><h3 id="常见的几种锥"><a href="#常见的几种锥" class="headerlink" title="常见的几种锥"></a>常见的几种锥</h3><p>范数锥，非负象限锥，半正定锥，它们都过原点。<br>想想对应的图像是什么样的。<br>范数锥和非负象限锥图像还好理解一些，非负象限锥是$R^n$空间所有非负半轴围成的锥，范数锥的边界像一个沙漏，但是是无限延伸的。半正定锥怎么理解，还没有太好的类比。</p><h2 id="保凸运算-operations-that-preserve-convexity"><a href="#保凸运算-operations-that-preserve-convexity" class="headerlink" title="保凸运算(operations that preserve convexity)"></a>保凸运算(operations that preserve convexity)</h2><p>这一小节介绍的是一些保留集合凸性，或者从一些集合中构造凸集的运算。这些运算和simplex形成了凸集的积分去确定或者建立集合的凸性。</p><h3 id="集合交-intersection"><a href="#集合交-intersection" class="headerlink" title="集合交(intersection)"></a>集合交(intersection)</h3><p>凸集求交集可以保留凸性：如果$S<em>1$和$S_2$是凸集，那么$S_1\cup S_2$是凸集。扩展到无限个集合就是：如果$\forall \alpha \in A,S</em>{\alpha}$都是凸的，那么$\cup<em>{\alpha\in A S</em>{\alpha}$是凸的</p><h3 id="仿射函数-affine-functions"><a href="#仿射函数-affine-functions" class="headerlink" title="仿射函数(affine functions)"></a>仿射函数(affine functions)</h3><h3 id="线性分式-linear-fractional-和视角函数-perspective-functions"><a href="#线性分式-linear-fractional-和视角函数-perspective-functions" class="headerlink" title="线性分式(linear-fractional)和视角函数(perspective functions)"></a>线性分式(linear-fractional)和视角函数(perspective functions)</h3><h4 id="线性分式-linear-fractional"><a href="#线性分式-linear-fractional" class="headerlink" title="线性分式(linear-fractional)"></a>线性分式(linear-fractional)</h4><h4 id><a href="#" class="headerlink" title=" "></a> </h4><h2 id="-1"><a href="#-1" class="headerlink" title=" "></a> </h2><h2 id="-2"><a href="#-2" class="headerlink" title=" "></a> </h2><h2 id="-3"><a href="#-3" class="headerlink" title=" "></a> </h2><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>1.stephen boyd. Convex optimization<br>2.<a href="https://en.wikipedia.org/wiki/Topology" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Topology</a><br>3.<a href="https://en.wikipedia.org/wiki/Topological_space" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Topological_space</a><br>4.<a href="https://en.wikipedia.org/wiki/Power_set" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Power_set</a><br>5.<a href="https://en.wikipedia.org/wiki/Open_set" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Open_set</a><br>6.<a href="https://en.wikipedia.org/wiki/Closed_set" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Closed_set</a><br>7.<a href="https://en.wikipedia.org/wiki/Clopen_set" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Clopen_set</a><br>8.<a href="https://en.wikipedia.org/wiki/Interior_(topology" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Interior_(topology</a>)<br>9.<a href="https://en.wikipedia.org/wiki/Closure_(topology" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Closure_(topology</a>)<br>10.<a href="https://en.wikipedia.org/wiki/Boundary_(topology" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Boundary_(topology</a>)<br>11.<a href="https://en.wikipedia.org/wiki/Ball_(mathematics" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Ball_(mathematics</a>)<br>12.<a href="https://blog.csdn.net/u010182633/article/details/53792588" target="_blank" rel="noopener">https://blog.csdn.net/u010182633/article/details/53792588</a><br>13.<a href="https://blog.csdn.net/u010182633/article/details/53819910" target="_blank" rel="noopener">https://blog.csdn.net/u010182633/article/details/53819910</a><br>14.<a href="https://blog.csdn.net/u010182633/article/details/53983642" target="_blank" rel="noopener">https://blog.csdn.net/u010182633/article/details/53983642</a><br>15.<a href="https://blog.csdn.net/u010182633/article/details/53997843" target="_blank" rel="noopener">https://blog.csdn.net/u010182633/article/details/53997843</a><br>16.<a href="https://blog.csdn.net/u010182633/article/details/54093987" target="_blank" rel="noopener">https://blog.csdn.net/u010182633/article/details/54093987</a><br>17.<a href="https://blog.csdn.net/u010182633/article/details/54139896" target="_blank" rel="noopener">https://blog.csdn.net/u010182633/article/details/54139896</a><br>18.<a href="https://math.stackexchange.com/questions/1168898/why-is-any-subspace-a-convex-cone" target="_blank" rel="noopener">https://math.stackexchange.com/questions/1168898/why-is-any-subspace-a-convex-cone</a><br>19.<a href="https://www.zhihu.com/question/22799760/answer/139753685" target="_blank" rel="noopener">https://www.zhihu.com/question/22799760/answer/139753685</a><br>20.<a href="https://www.zhihu.com/question/22799760/answer/34282205" target="_blank" rel="noopener">https://www.zhihu.com/question/22799760/answer/34282205</a><br>21.<a href="https://www.zhihu.com/question/22799760/answer/137768096" target="_blank" rel="noopener">https://www.zhihu.com/question/22799760/answer/137768096</a><br>22.<a href="https://en.wikipedia.org/wiki/Positive-definite_matrix" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Positive-definite_matrix</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;仿射集-affine-sets-和凸集-convex-sets&quot;&gt;&lt;a href=&quot;#仿射集-affine-sets-和凸集-convex-sets&quot; class=&quot;headerlink&quot; title=&quot;仿射集(affine sets)和凸集(convex set
      
    
    </summary>
    
      <category term="凸优化笔记" scheme="http://mxxhcm.github.io/categories/%E5%87%B8%E4%BC%98%E5%8C%96%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="凸优化" scheme="http://mxxhcm.github.io/tags/%E5%87%B8%E4%BC%98%E5%8C%96/"/>
    
      <category term="convex sets" scheme="http://mxxhcm.github.io/tags/convex-sets/"/>
    
      <category term="affine sets" scheme="http://mxxhcm.github.io/tags/affine-sets/"/>
    
      <category term="cones" scheme="http://mxxhcm.github.io/tags/cones/"/>
    
  </entry>
  
  <entry>
    <title>熵，交叉熵，相对熵（KL散度），条件熵，互信息</title>
    <link href="http://mxxhcm.github.io/2018/12/23/%E7%86%B5%E3%80%81%E4%BA%A4%E5%8F%89%E7%86%B5%E5%92%8CK-L%E6%95%A3%E5%BA%A6/"/>
    <id>http://mxxhcm.github.io/2018/12/23/熵、交叉熵和K-L散度/</id>
    <published>2018-12-23T02:54:31.000Z</published>
    <updated>2019-05-06T16:22:27.712Z</updated>
    
    <content type="html"><![CDATA[<h2 id="乡农熵-Shannon-entropy"><a href="#乡农熵-Shannon-entropy" class="headerlink" title="乡农熵(Shannon entropy)"></a>乡农熵(Shannon entropy)</h2><p>乡农定义了一个事件的信息量是其发生概率的负对数($-log(p)$)，即乡农信息量，乡农熵是信息量的期望。</p><h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p>这里的熵都是指的信息论中的熵，也叫乡农熵(shannon entropy)。通常，熵是无序或不确定性的度量。<br>与每个变量可能的取值相关的信息熵是每个可能取值的概率质量函数的负对数：</p><script type="math/tex; mode=display">S = - \sum_i P_i lnP_i</script><p>当事件发生的概率较低时，该事件比高概率事件携带更多“信息”。这种方式定义的每个事件所携带的信息量是一个随机变量，事实上乡农熵定义的一个事件的信息量就是这个事件发生的概率的负对数，这个随机变量（信息量）的期望值是信息熵。信息熵通常以比特(或者称为shannons),自然单位(nats)或十进制数字(dits，bans或hartleys)来测量。具体的单位取决于用于定义熵的对数的基。<br>采用概率分布的对数形式作为信息的度量的原因是因为它的可加性。例如，投掷公平硬币的熵是$1$比特，投掷$m$个硬币的熵是$m$比特。以比特为单位的时候，如果$n$是$2$的指数次方，则需要$log_2n$位来表示一个具有$n$个取值的变量。如果该变量的$n$个取值发生的可能性是相等的，则熵等于$log_2n$。<br>如果一个事件发生的可能性比其他事件发生的可能性更高，观察到该事件发生的信息量少于观测到一些罕见事件，即观测到更罕见的事件时能提供更多的信息。由于小概率事件发生的可能性更低，因此最终的结果是从非均匀分布的数据接收的熵总是小于或等于$log_2n$。当一个结果一定发生时，熵为零。<br>但是熵仅仅量化考虑事件发生的概率，它封装的信息是有关概率分布的信息，事件本身的意义在这种度量方式的定义中无关紧要。<br>熵的另一种解释是最短平均编码长度。</p><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p>乡农定义了entropy, 定义离散型随机变量$X$，其可能取值为${x_1,\cdots,x_n}$，它对应的概率质量函数(probability mass function) P(X)，则熵$H$为：</p><script type="math/tex; mode=display">H(X) = E[I(X)] = E[-log(P(X))]</script><p>其中$E$是求期望，$I$是随机变量$X$的信息量, $I(X)$本身是一个随机变量。<br>它可以显示写成：</p><script type="math/tex; mode=display">H(X) = \sum_{i=1}^nP(x_i)I(x_i) = -\sum_{i=1}^nP(x_i)log_bP(x_i)</script><p>其中b是自然对数的底，$b$常取的值为$2,e,10$，对应的熵的单位是bits, nats，bans。<br>当$P(x_i)=0$的时候，对应的$PlogP$的值为$0log_b(0)$, 和极限(limit)是一致的：</p><script type="math/tex; mode=display">lim_{p\rightarrow 0_+}plog(p) = 0.</script><h4 id="连续型随机变量的熵"><a href="#连续型随机变量的熵" class="headerlink" title="连续型随机变量的熵"></a>连续型随机变量的熵</h4><p>将概率质量函数替换为概率密度函数，即可得到连续性随机变量的熵：</p><script type="math/tex; mode=display">h[f] = E[-ln(f(x))] = - \int_X f(x)ln(f(x))dx.</script><h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><p>抛一枚硬币，已知其正反两面出现的概率是不相等的，求其正面朝上的概率，该问题可以看做一个伯努利分布问题。<br>如果硬币是公平的，此时得到结果的熵是最大的。这是因为此时抛一次抛硬币的结果具有最大的不确定性。每一个抛硬币的结果会占满一整个bit位。因为<br>\begin{align*}<br>H(X) &amp;= - \sum<em>{i=1}^n P(x_i)log_bP(x_i)\<br>&amp;= - \sum</em>{i=1}^2\frac{1}{2}log<em>2\frac{1}{2}\<br>&amp;= - \sum</em>{i=1}^2\frac{1}{2}\cdot(-1)\<br>&amp;= 1<br>\end{align*}<br>如果硬币是不公平的，正面向上的概率是$p$，反面向上的概率是$q$，$p \ne q$, 则结果的不确定性更小。因为每次抛硬币，出现其中一面的可能性要比另一面要大，减小的不确定性就得到了更小的熵：每一次抛硬币得到的信息都会小于$1$bit，比如，$p=0.7$时：<br>\begin{align*}<br>H(X) &amp;= -plog_2p - qlog_2q\<br>&amp;= -0.7log_20.7 - 0.3log_20.3\<br>&amp;= -0.7\cdot(-0.515) - 0.3\cdot(-1.737)\<br>&amp;= 0.8816\<br>&amp;\le 1<br>\end{align*}<br>上面的例子证明不确定性跟变量取值的概率有关。<br>不确定性也跟变量的取值个数有关，上面例子的极端情况是正反面一样（即只有一种取值），那么熵就是0，没有不确定性。</p><h3 id="解释-rationale"><a href="#解释-rationale" class="headerlink" title="解释(rationale)"></a>解释(rationale)</h3><p>为什么乡农定义了信息量为$-log(p)$？$-\sum p_i log(p_i)$的意义是什么？<br>首先我们需要想一想信息量需要满足什么条件，然后定义一个信息函数I表示发生概率为$p_i$的事件$i$的信息量，那么这个信息函数需要满足以下条件。</p><ul><li>$I(p)$是单调下降的；</li><li>$I(p) \ge 0$, 即信息是非负的；</li><li>$I(1) = 0$, 一定发生的事件不包含信息；</li><li>$I(p_1p_2) = I(p_1) + I(p_2)$, 独立事件包含的信息是可加的。<br>最后一个条件很关键，它指出了两个独立事件的联合分布和两个分开的独立事件所包含的信息是一样多的。例如，$A$事件有$m$个等可能性的结果，$B$事件有$n$个等可能性的结果，$AB$有$mn$个等可能性的结果。$A$事件需要$log_2(m)$bits去编码，$B$事件需要用$log_2(n)$bits去编码，$AB$需要$log_2(mn) = log_2(m) + log_2(n)$bits编码。乡农发现了$log$函数能够保留可加性，即：<script type="math/tex; mode=display">I(p) = log(\frac{1}{p}) = - log(p)</script>事实上，这个函数$I$是唯一的(可以证明),选择$I$当做信息函数。如果一个分布中事件$i$发生的概率是$p_i$,那么采样$N$次，事件$i$发生的次数为$n_i = N p_i$, 所有$n_i$次的信息为<script type="math/tex">\sum_in_iI(p_i) = - \sum_iNp_ilog(p_i).</script><br>每个事件的平均信息就是：<script type="math/tex; mode=display">-\sum_ip_ilog(p_i)</script>所以$-\sum_ip_ilog(p_i)$就是信息量的期望，即信息熵。<br>在信息论中，熵的另一种解释是最短平均编码长度。</li></ul><h2 id="交叉熵-cross-entropy"><a href="#交叉熵-cross-entropy" class="headerlink" title="交叉熵(cross entropy)"></a>交叉熵(cross entropy)</h2><h3 id="介绍-1"><a href="#介绍-1" class="headerlink" title="介绍"></a>介绍</h3><p>交叉熵用于衡量估计的概率分布与真实概率分布之间的差异。<br>交叉熵是信息熵的推广。假设有两个分布$p$和$q$，$p$是真实分布，$q$是非真实分布。信息熵是用真实分布$p$来衡量识别一个事件所需要的编码长度的期望。而交叉熵是用非真实分布$q$来估计真实分布$p$的编码长度的期望，用$q$来编码的事件来自分布$p$，所以期望中使用的概率是$p(i)$。$H(p,q)$称为交叉熵。</p><h3 id="定义-1"><a href="#定义-1" class="headerlink" title="定义"></a>定义</h3><p>分布p和q在给定集合X的交叉熵定义为：</p><script type="math/tex; mode=display">H(p,q) = E_p[-logq] = H(p) + D_{KL}(p||q)</script><p>其中$H(p)$是$p$的信息熵，$D_{KL}(p||q)$是从$q$到$p$的$K-L$散度，或者说$p$相对于$q$的相对熵。</p><h3 id="示例-1"><a href="#示例-1" class="headerlink" title="示例"></a>示例</h3><p>如含有4个字母$(A,B,C,D)$的数据集中，$p=(\frac{1}{2}, \frac{1}{2}, 0, 0)$，即$A$和$B$出现的概率均为$\frac{1}{2}$，$C$和$D$出现的概率都为$0$。$H(p)$为$1$，即只需要$1$位编码即可识别$A$和$B$。如果使用分布$q=(\frac{1}{4},\frac{1}{4},\frac{1}{4},\frac{1}{4})$来编码则得到$H(p,q)=2$，即需要$2$位编码来识别$A$和$B$。</p><h3 id="解释"><a href="#解释" class="headerlink" title="解释"></a>解释</h3><p>在机器学习中，交叉熵用于衡量估计的概率分布与真实概率分布之间的差异。<br>在信息论中，Kraft-McMillan定理建立了任何可直接解码的编码方案，为了识别一个$X$的可能值$x_i$f可以看做服从一个在$X$上的隐式概率分布$q(x_i)=2^{-l_i}$,其中$l_i$是$x_i$的编码长度，单位是bits。因此，交叉熵可以被解释为当数据服从真实分布$p$时，在假设分布$q$下得到的每个信息编码长度的期望。</p><h3 id="性质"><a href="#性质" class="headerlink" title="性质"></a>性质</h3><ul><li>$H(p,q) \ge H(p)$,由吉布森不等式可以知道，该式子恒成立，当$q$等于$p$时等号成立。</li></ul><h3 id="to-do-交叉熵损失函数和logistic-regression之间的关系。"><a href="#to-do-交叉熵损失函数和logistic-regression之间的关系。" class="headerlink" title="to do ?交叉熵损失函数和logistic regression之间的关系。"></a>to do ?交叉熵损失函数和logistic regression之间的关系。</h3><h2 id="K-L-散度-Kullback-Leibler-divergence"><a href="#K-L-散度-Kullback-Leibler-divergence" class="headerlink" title="$K-L$散度(Kullback-Leibler divergence)"></a>$K-L$散度(Kullback-Leibler divergence)</h2><h3 id="介绍-2"><a href="#介绍-2" class="headerlink" title="介绍"></a>介绍</h3><p>$K-L$散度也叫相对熵(relative entropy)，是用来衡量估计分布和真实分布之间的差异性。<br>$K-L$散度也叫相对熵(relative entropy)，信息熵是用来度量信息量的，信息熵给出了最小熵是多少，但是信息熵并没有给出如何得到最小熵，$K-L$散度也没有给出来如何得到最小熵。但是$K-L$散度可以用来衡量用一个带参数的估计分布来近似真实数据分布时损失了多少信息，可以理解为根据非真实分布$q$得到的平均编码长度比由真实分布$p$得到的平均编码长度多出的长度叫做相对熵。</p><h3 id="定义-2"><a href="#定义-2" class="headerlink" title="定义"></a>定义</h3><h4 id="离散型随机变量"><a href="#离散型随机变量" class="headerlink" title="离散型随机变量"></a>离散型随机变量</h4><p>给定概率分布$P$和$Q$在相同的空间中，它们的$K-L$散度定义为：<br>\begin{align*}<br>D<em>{KL}(P||Q) &amp;= -\sum_iP(i)(logQ(i)) - (-\sum_iP(i)logP(i))\<br>D</em>{KL}(P||Q) &amp;= \sum<em>iP(i)(logP(i) - logQ(i))\<br>D</em>{KL}(P||Q) &amp;= -\sum<em>iP(i)log(\frac{Q(i)}{Q(i)})\<br>D</em>{KL}(P||Q) &amp;= \sum<em>iP(i)log(\frac{P(i)}{Q(i)})<br>\end{align*}<br>可以看出，$K-L$散度是概率分布$P$和$Q$对数差相对于概率分布$P$的期望。需要注意的是$D</em>{KL}(P||Q) \ne D_{KL}(Q||P),$因为$P$和$Q$的地位是不同的。相对熵的前半部分就是交叉熵，后半部分是相对熵。</p><h4 id="连续型随机变量"><a href="#连续型随机变量" class="headerlink" title="连续型随机变量"></a>连续型随机变量</h4><p>对于连续性随机变量的分布$P$和$Q$，$K-L$散度被定义为积分：</p><script type="math/tex; mode=display">D_{KL}(P||Q) = \int_{-\infty}^{infty}p(x)log(\frac{p(x)}{q(x)})dx,</script><p>其中$p$和$q$代表分布$P$和分布$Q$的概率密度函数。<br>更一般的，$P$和$Q$表示是同一个集合$X$的概率分布，$P$相对于$Q$是绝对连续的，从$Q$到$P$的$K-L$散度定义为：</p><script type="math/tex; mode=display">D_{KL}(P||Q) = \int_X log(\frac{dP}{dQ})dP</script><p>上式可以被写成：</p><script type="math/tex; mode=display">D_{KL}(P||Q) = \int_X log(\frac{dP}{dQ})\frac{dP}{dQ}dP</script><p>可以看成$\frac{P}{Q}$的熵。</p><h3 id="示例-2"><a href="#示例-2" class="headerlink" title="示例"></a>示例</h3><p>$P$是一个二项分布，$P~(2,0.4)$，$Q$是一个离散型均匀分布，$x = 0,1,2$, 每一个取值的概率都是$p=\frac{1}{3}$。</p><div class="table-container"><table><thead><tr><th></th><th>0</th><th>1</th><th>2</th></tr></thead><tbody><tr><td>$P$分布</td><td>0.36</td><td>0.48</td><td>0.16</td></tr><tr><td>$Q$分布</td><td>0.333</td><td>0.333</td><td>0.333</td></tr></tbody></table></div><p>$K-L$散度的计算公式如下（使用自然对数）：<br>\begin{align*}<br>D_{KL}(Q||P) &amp;= \sum_iQ(i)ln(\frac{Q(i)}{P(i)})\<br>&amp; = 0.333ln(\frac{0.333}{0.36}) + 0.333ln(\frac{0.333}{0.48}) + 0.333ln(\frac{0.333}{0.16})\<br>&amp; = -0.02596 + (-0.12176) + 0.24408\<br>&amp; = 0.09637(nats)<br>\end{align*}<br>上面计算出来的是从$P$到$Q$的K-L散度，或者$Q$相对于$P$的相对熵。</p><h3 id="解释-1"><a href="#解释-1" class="headerlink" title="解释"></a>解释</h3><p>从$Q$到$P$的$K-L$散度表示为$D<em>{KL}(P||Q)$。在机器学习中，$D</em>{KL}(P||Q)$被称为信息增益。<br>在信息论中，$K-L$散度也被称为$P$相对于$Q$的相对熵。从信息编码角度来看，$D_{KL}(P||Q)$可以看做用估计分布$q$得到的平均编码长度比用真实分布p得到的平均编码长度多出的长度。</p><h3 id="性质-1"><a href="#性质-1" class="headerlink" title="性质"></a>性质</h3><ul><li>非负性，$D_{KL}(P||Q)\ge 0$,当且仅当$P=Q$时等号成立。</li><li>可加性，如果$P_1,P_2$的分布是独立的，即$P(x,y) = P_1(x)P_2(y)$, $Q,Q_1,Q_2$类似，那么：<script type="math/tex; mode=display">D_{KL}(P||Q) = D_{KL}(P_1||Q_1) + D_{KL}(P_2||Q_2)</script></li><li>不对称性，所以K-L散度不是距离，距离需要满足对称性。</li></ul><h2 id="条件熵"><a href="#条件熵" class="headerlink" title="条件熵"></a>条件熵</h2><h3 id="定义-3"><a href="#定义-3" class="headerlink" title="定义"></a>定义</h3><p>给定$X$，$Y$的条件熵定义如下：<br>给定离散变量${\displaystyle X}$和${\displaystyle Y}$,给定${\displaystyle X}$以后，${\displaystyle Y}$的条件熵定义为每一个${\displaystyle x}$使用权值${\displaystyle p(x)}$ 的加权和${\displaystyle \mathrm {H} (Y|X=x)}$。</p><script type="math/tex; mode=display">H(Y|X) &\equiv \sum_{x\in\bold{X}}p(x)H(Y|X=x)</script><p>可以证明它等价于下式：</p><script type="math/tex; mode=display">H(Y|X) = -\sum_{X\in \bold{X},Y\in \bold{Y}}p(X,Y)log{\frac{p(X,Y)}{p(X)}}</script><h3 id="证明"><a href="#证明" class="headerlink" title="证明"></a>证明</h3><p>\begin{align*}<br>H(Y|X) &amp;\equiv \sum<em>{x\in\bold{X}}p(x)H(Y|X=x)\<br>&amp;=-\sum</em>{x\in\bold{X}}p(x)\sum<em>{y\in \bold{Y}}p(y|x)logp(y|x)\<br>&amp;=-\sum</em>{x\in\bold{X}}\sum<em>{y\in \bold{Y}}p(x)p(y|x)logp(y|x)\<br>&amp;=-\sum</em>{x\in\bold{X},y\in \bold{Y}}p(x,y)logp(y|x)\<br>&amp;=-\sum<em>{x\in\bold{X},y\in \bold{Y}}p(x,y)\frac{logp(x,y)}{logp(x)}\<br>&amp;=\sum</em>{x\in\bold{X},y\in \bold{Y}}p(x,y)\frac{logp(x)}{logp(x,y)}\<br>\end{align*}</p><h3 id="属性"><a href="#属性" class="headerlink" title="属性"></a>属性</h3><ul><li>当且仅当$Y$完全由$X$的值确定时，条件熵为$0$。</li><li>当且仅当$X$和$Y$是独立随机变量的时候，$H(Y|X) = H(Y)$。</li><li>链式法则。假设一个系统由随机变量$X,Y$确定，他们有联合熵$H(X,Y)$，我们需要$H(X,Y)$个比特去表述这个系统，如果我们已经知道了$X$的值，相当于我们已经有了$H(X)$位的信息。一旦$X$已知了，我们只需要$H(X,Y)-H(X)$位去描述整个系统。所以就有了链式法则：$H(Y|X) = H(X,Y) - H(X)$。<br>\begin{align*}<br>H(Y|X) &amp;= \sum<em>{X\in \bold{X}, Y\in \bold{Y}}p(X,Y)log{\frac{p(X)}{p(X,Y)}}\<br>&amp;= - \sum</em>{X\in \bold{X}, Y\in \bold{Y}}p(X,Y)log{p(X,Y)}+\sum<em>{X\in \bold{X}, Y\in \bold{Y}}p(X,Y)log{p(X)}\<br>&amp;=H(X,Y) +\sum</em>{X\in \bold{X}}p(X)log{p(X)}\<br>&amp;=H(X,Y) - H(X)<br>\end{align*}</li><li>贝叶斯公式。$H(Y|X) = H(X|Y) - H(X) + H(Y)$。<br>证明：$H(Y|X)=H(X,Y) - H(X),H(X|Y) = H(X,Y) - H(Y)$。两个式子相减就可以得到。</li></ul><h2 id="互信息"><a href="#互信息" class="headerlink" title="互信息"></a>互信息</h2><p>决策树中的信息增益指的是互信息不是KL散度。</p><h3 id="定义-4"><a href="#定义-4" class="headerlink" title="定义"></a>定义</h3><p>用$(X,Y)$表示空间$\bold{X}\times\bold{Y}$上的一对随机变量，他们的联合分布是$P<em>{(X,Y)}$，边缘分布是$P_X,P_Y)$，信息熵被定义为：<br>$I(X;Y) = D</em>{KL}(P<em>{(X,Y)}||P_XP_Y)$<br>对于离散变量：<br>$I(X;Y)=\sum</em>{X\in \bold{X},Y\in \bold{Y}}p(X,Y)log(\frac{p(X,Y)}{p(X)p(Y)})$<br>对于随机变量：<br>$I(X;Y)=\int_X\int_Y p(X,Y)log(\frac{p(X,Y)}{p(X)p(Y)})dxdy$</p><h2 id="信息熵，相对熵，交叉熵，条件熵，互信息之间的关系"><a href="#信息熵，相对熵，交叉熵，条件熵，互信息之间的关系" class="headerlink" title="信息熵，相对熵，交叉熵，条件熵，互信息之间的关系"></a>信息熵，相对熵，交叉熵，条件熵，互信息之间的关系</h2><h3 id="信息论"><a href="#信息论" class="headerlink" title="信息论"></a>信息论</h3><p>信息熵是对随机事件用真实的概率分布$p$进行编码的长度的期望，是最短平均编码长度。<br>交叉熵是对随机事件用估计的概率分布$q$按照其真实概率分布$p$进行编码的长度的期望（随机事件是从真实概率分布$p$中取的，但是用分布$q$进行编码），大于等于最短平均编码长度，只有$q$等于真实分布$q$时，才是最短编码长度。<br>而相对熵对随机事件用估计的概率分布$q$比用真实的概率分布$p$进行编码多用的编码长度，如果$p$和$q$相等的话，相对熵为$0$。</p><h3 id="机器学习"><a href="#机器学习" class="headerlink" title="机器学习"></a>机器学习</h3><p>在机器学习中，交叉熵通常作为一个loss函数，用来衡量真实分布$p$和估计分布$q$之间的差异。而$K-L$散度也是用来衡量两个概率分布的差异，但是多了一个信息熵项。$K-L$散度的前半部分是交叉熵，后半部分是真实分布$p$的信息熵。(一个我自己认为的不严谨的说法是相对熵算的是相对值，而交叉熵算的是绝对值)。交叉熵正比于负的对数似然估计，最小化交叉熵等价于最大化对数似然估计。<br>如果$p$是固定的，那么随着$q$的增加相对熵也在增加，但是如果$p$是不固定的，很难说相对熵是差异的绝对量度，因为它随着$p$的增长而改变。而在机器学习领域，真实分布$p$是固定的，随着$q$的改变，$H(p)$是不变的,也就是信息熵是固定的。所以，从优化的角度来说，最小化交叉熵也就是最小化了相对熵。但是在其他领域，$p$可能是变化的，最小化交叉熵和最小化相对熵就不是等价的了。</p><h3 id="互信息和条件熵，相对熵的关系"><a href="#互信息和条件熵，相对熵的关系" class="headerlink" title="互信息和条件熵，相对熵的关系"></a>互信息和条件熵，相对熵的关系</h3><p>互信息可以被等价定义为：<br>\begin{align*}<br>I(X;Y)&amp; \equiv H(X)-H(X|Y)\<br>&amp;\equiv H(Y) - H(Y|X)\<br>&amp;\equiv H(X)+H(Y)-H(X,Y)\<br>&amp;\equiv H(X,Y)-H(X|Y)-H(Y|X)\<br>\end{align*}</p><p>证明：<br>\begin{align*}<br>I(X;Y)&amp;=\sum<em>{X\in \bold{X},Y\in \bold{Y}}p(X,Y)log(\frac{p(Y,Y)}{p(X)p(Y)})\<br>&amp;=\sum</em>{X\in \bold{X},Y\in \bold{Y}}p(X,Y)log(\frac{p(Y,Y)}{p(X)})-\sum<em>{X\in \bold{X},Y\in \bold{Y}}p(X,Y)logp(Y)\<br>&amp;=\sum</em>{X\in \bold{X},Y\in \bold{Y}}p(X)P(Y|X)logp(Y|X)-\sum<em>{X\in \bold{X},Y\in \bold{Y}}p(X,Y)logp(Y)\<br>&amp;=\sum</em>{X\in \bold{X}}p(X)(\sum<em>{Y\in \bold{Y}}P(Y|X)logp(Y|X))-\sum</em>{Y\in \bold{Y}}(\sum<em>{X\in \bold{X}}p(X,Y))logp(Y)\<br>&amp;=\sum</em>{X\in \bold{X}}p(X)H(Y|X=x)-\sum_{Y\in \bold{Y}}p(Y)logp(Y)\<br>&amp;=-H(Y|X)+H(Y)\<br>&amp;=H(Y)-H(Y|X)<br>\end{align*}</p><p>互信息和KL散度的联系：<br>从联合分布$p(x,y)$到边缘分布$p(X)p(Y)$或者条件分布$p(X|Y)p(X)$的KL散度。</p><h2 id="参考文献-references"><a href="#参考文献-references" class="headerlink" title="参考文献(references)"></a>参考文献(references)</h2><p>1.<a href="https://en.wikipedia.org/wiki/Entropy_(information_theory" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Entropy_(information_theory</a>)<br>2.<a href="https://zh.wikipedia.org/wiki/熵_(信息论" target="_blank" rel="noopener">https://zh.wikipedia.org/wiki/熵_(信息论</a>)<br>3.<a href="https://www.zhihu.com/question/22178202/answer/49929786" target="_blank" rel="noopener">https://www.zhihu.com/question/22178202/answer/49929786</a><br>4.<a href="https://en.wikipedia.org/wiki/Cross_entropy" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Cross_entropy</a><br>5.<a href="https://en.wikipedia.org/wiki/Kullback-Leibler_divergence" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Kullback-Leibler_divergence</a><br>6:<a href="https://www.zhihu.com/question/41252833/answer/108777563" target="_blank" rel="noopener">https://www.zhihu.com/question/41252833/answer/108777563</a><br>7.<a href="https://www.zhihu.com/question/41252833/answer/141598211" target="_blank" rel="noopener">https://www.zhihu.com/question/41252833/answer/141598211</a><br>8.<a href="https://stats.stackexchange.com/questions/265966/why-do-we-use-kullback-leibler-divergence-rather-than-cross-entropy-in-the-t-sne" target="_blank" rel="noopener">https://stats.stackexchange.com/questions/265966/why-do-we-use-kullback-leibler-divergence-rather-than-cross-entropy-in-the-t-sne</a><br>9.<a href="https://en.wikipedia.org/wiki/Conditional_entropy" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Conditional_entropy</a><br>10.<a href="https://en.wikipedia.org/wiki/Mutual_information" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Mutual_information</a><br>11.<a href="https://zhuanlan.zhihu.com/p/26551798" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/26551798</a><br>12.<a href="https://blog.csdn.net/gangyin5071/article/details/82228827#4相对熵kl散度" target="_blank" rel="noopener">https://blog.csdn.net/gangyin5071/article/details/82228827#4相对熵kl散度</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;乡农熵-Shannon-entropy&quot;&gt;&lt;a href=&quot;#乡农熵-Shannon-entropy&quot; class=&quot;headerlink&quot; title=&quot;乡农熵(Shannon entropy)&quot;&gt;&lt;/a&gt;乡农熵(Shannon entropy)&lt;/h2&gt;&lt;p&gt;
      
    
    </summary>
    
      <category term="机器学习" scheme="http://mxxhcm.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://mxxhcm.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="熵" scheme="http://mxxhcm.github.io/tags/%E7%86%B5/"/>
    
      <category term="交叉熵" scheme="http://mxxhcm.github.io/tags/%E4%BA%A4%E5%8F%89%E7%86%B5/"/>
    
      <category term="条件熵" scheme="http://mxxhcm.github.io/tags/%E6%9D%A1%E4%BB%B6%E7%86%B5/"/>
    
      <category term="相对熵" scheme="http://mxxhcm.github.io/tags/%E7%9B%B8%E5%AF%B9%E7%86%B5/"/>
    
      <category term="KL散度" scheme="http://mxxhcm.github.io/tags/KL%E6%95%A3%E5%BA%A6/"/>
    
      <category term="互信息" scheme="http://mxxhcm.github.io/tags/%E4%BA%92%E4%BF%A1%E6%81%AF/"/>
    
  </entry>
  
  <entry>
    <title>convex optimization chapter 1 Introduction</title>
    <link href="http://mxxhcm.github.io/2018/12/22/convex-optimization-chapter-1-Introduction/"/>
    <id>http://mxxhcm.github.io/2018/12/22/convex-optimization-chapter-1-Introduction/</id>
    <published>2018-12-22T05:44:11.000Z</published>
    <updated>2019-05-06T16:22:27.704Z</updated>
    
    <content type="html"><![CDATA[<h2 id="数学优化-mathematical-optimization"><a href="#数学优化-mathematical-optimization" class="headerlink" title="数学优化(mathematical optimization)"></a>数学优化(mathematical optimization)</h2><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p>一个数学优化问题（或者称为优化问题）通常有如下的形式：<br>\begin{align*}<br>&amp;minimize \quad f_0(x)\<br>&amp;subject \ to \quad f_i(x) \le b_i, i = 1,\cdots,m.<br>\end{align*}<br>其中$x = (x_1, \cdots, x_m)$被称为优化变量(optimization variables), 或者决策变量(decision variables)。 $f_0(x):R^n\rightarrow R$是目标函数(object function), $f_i(x):R^n\rightarrow R,i =1,\cdots,m$是约束函数(constraint functions)。 常量(constraints) $b_1,\cdots,b_m$是约束的限界(limits)或者边界(bounds), $b_i$可以为0，这个可以通过移项构造出新的$f_i(x)$实现。如果向量$x$使得目标函数取得最小的值，并且满足所有的约束条件，那么这个向量被称为最优解$x^*$。 </p><h4 id="线性优化-linear-program"><a href="#线性优化-linear-program" class="headerlink" title="线性优化(linear program)"></a>线性优化(linear program)</h4><p>目标函数和约束函数$f_0,\cdots,f_m$是线性的, 它们满足不等式： </p><script type="math/tex; mode=display">f_i(\alpha x+\beta y) = \alpha f_i(x) + \beta f_i(y)</script><p>对于所有的$x,y \epsilon R^n$和所有的$\alpha, \beta \epsilon R$。<br>线性优化是凸优化的一个特殊形式, 它的目标函数和约束函数都是线性的等式或者不等式。</p><h4 id="非线性问题-non-linear-problem"><a href="#非线性问题-non-linear-problem" class="headerlink" title="非线性问题(non-linear problem)"></a>非线性问题(non-linear problem)</h4><p>如果优化问题不是线性的，就是非线性问题。只要目标函数或者约束函数至少有一个不是线性的，那么这个优化问题就是非线性优化问题。</p><h4 id="凸问题-convex-problem"><a href="#凸问题-convex-problem" class="headerlink" title="凸问题(convex problem)"></a>凸问题(convex problem)</h4><p>凸问题是目标函数和约束函数都是凸的的优化问题，它们满足：</p><script type="math/tex; mode=display">f_i(\alpha x + \beta y) \le \alpha f_i(x) + \beta f_i(y)</script><p>对于所有的$x,y \epsilon R^n$和所有的$\alpha, \beta  \epsilon R$且$\alpha + \beta = 1, \alpha \ge 0, \beta \ge 0$。<br>凸性比线性的范围更广，不等式取代了更加严格的等式，不等式只有在$\alpha$和$\beta$取一些特定值时才成立。凸优化和线性问题以及非线性问题都有交集，它是线性问题的超集(superset)，是非线性问题的子集(subset)。技术上来说，nonlinear problem包括convex optimization(除了linear programming), 可以用来描述不确定是非凸的问题。<br>Nonlinear program &gt; convex problem &gt; linear problem</p><h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><h4 id="组合优化-portfolio-optimization"><a href="#组合优化-portfolio-optimization" class="headerlink" title="组合优化(portfolio optimization)"></a>组合优化(portfolio optimization)</h4><p>变量：不同资产的投资数量<br>约束：预算，每个资产最大/最小投资数量，至少要得到的回报<br>目标：所有的风险，获利的变化</p><h4 id="电子设备的元件大小-device-sizing-in-electronic-circuits"><a href="#电子设备的元件大小-device-sizing-in-electronic-circuits" class="headerlink" title="电子设备的元件大小(device sizing in electronic circuits)"></a>电子设备的元件大小(device sizing in electronic circuits)</h4><p>变量：元件的宽度和长度<br>约束：生产工艺的炼制，时间要求，面积等<br>目标：节约能耗</p><h4 id="数据拟合-data-fitting"><a href="#数据拟合-data-fitting" class="headerlink" title="数据拟合(data fitting)"></a>数据拟合(data fitting)</h4><p>变量：模型参数<br>约束：先验知识，参数约束条件<br>目标：错误率</p><h3 id="优化问题求解-solving-optimization-problems"><a href="#优化问题求解-solving-optimization-problems" class="headerlink" title="优化问题求解(solving optimization problems)"></a>优化问题求解(solving optimization problems)</h3><p>所有的问题都是优化问题。<br>绝大部分优化问题我们解不出来。</p><h4 id="一般的优化问题-general-optimization-problem"><a href="#一般的优化问题-general-optimization-problem" class="headerlink" title="一般的优化问题(general optimization problem)"></a>一般的优化问题(general optimization problem)</h4><ul><li>很难解出来。</li><li>做一些compromise，比如要很长时间才能解出来，或者并不总能找到解。</li></ul><h4 id="一些例外-some-exceptions"><a href="#一些例外-some-exceptions" class="headerlink" title="一些例外(some exceptions)"></a>一些例外(some exceptions)</h4><ul><li>最小二乘问题(least-squares problems)</li><li>线性规划问题(linear programming problems)</li><li>凸优化问题(convex optimization problems)</li></ul><h2 id="最小二乘-least-squares-和线性规划-linear-programming"><a href="#最小二乘-least-squares-和线性规划-linear-programming" class="headerlink" title="最小二乘(least-squares)和线性规划(linear programming)"></a>最小二乘(least-squares)和线性规划(linear programming)</h2><p>least-squares和linear programming是凸优化问题中最有名的两个子问题。</p><h3 id="最小二乘问题-least-squares-problems"><a href="#最小二乘问题-least-squares-problems" class="headerlink" title="最小二乘问题(least-squares problems)"></a>最小二乘问题(least-squares problems)</h3><p>最小二乘问题是一个无约束的优化问题，它的目标函数是项$a<em>i^Tx-b_i$的平方和。<br>\begin{align*}<br>minimize \quad f_0(x) &amp;= {||Ax-b||}^2_2\<br>&amp;=\sum</em>{i=1}^k(a_i^Tx-b_i)^2<br>\end{align*}</p><h4 id="求解-solving-least-squares-problems"><a href="#求解-solving-least-squares-problems" class="headerlink" title="求解(solving least-squares problems)"></a>求解(solving least-squares problems)</h4><ul><li>最小二乘问题的解可以转换为求线性方程组$(A^TA)x = A^Tb$的解。线性代数上我们学过该方程组的解析解为$x=(A^TA)^{-1}A^Tb$。</li><li>时间复杂度是$n^2k = n*k*n+n*k+n*n*n, (k &gt; n)$(转置，求逆，矩阵乘法)。</li><li>该问题具有可靠且高效的求解算法。</li><li>是一个很成熟的算法</li></ul><h4 id="应用-using-least-squares"><a href="#应用-using-least-squares" class="headerlink" title="应用(using least-squares)"></a>应用(using least-squares)</h4><p>很容易就可以看出来一个问题是最小二乘问题，我们只需要验证目标函数是不是二次函数，以及对应的二次型是不是正定的即可。</p><h5 id="加权最小二乘-weighted-least-squares"><a href="#加权最小二乘-weighted-least-squares" class="headerlink" title="加权最小二乘(weighted least-squares)"></a>加权最小二乘(weighted least-squares)</h5><p>加权最小二乘形式如下:</p><script type="math/tex; mode=display">\sum_{i=1}^k \omega_i(a_i^Tx-b_i)^2,</script><p>其中$\omega_1,\cdots,\omega_k$是正的，被最小化。 这里选出权重$\omega$来体现不同项$a_i^Tx-b_i$的比重, 或者仅仅用来影响结果。</p><h5 id="正则化-regularization"><a href="#正则化-regularization" class="headerlink" title="正则化(regularization)"></a>正则化(regularization)</h5><p>目标函数中被加入了额外项, 形式如下：</p><script type="math/tex; mode=display">\sum_{i=1}^k(a_i^Tx-b_i)^2 + \rho \sum_{i=1}^n x_i^2,</script><p>正则项是用来惩罚大的$x$, 求出一个仅仅最小化第一个求和项的不出来的好结果。合理的选择参数$\rho$在原始的目标函数和正则化项之间做一个trade-off, 使得$\sum<em>{k=1}^i(a_i^T - b_i)^2$和$\rho \sum</em>{k=1}^n x_i^2$都很小。<br>正则化项和加权最小二乘会在第六章中讲到，它们的统计解释在第七章给出。</p><h3 id="线性规划-linear-programming"><a href="#线性规划-linear-programming" class="headerlink" title="线性规划(linear programming)"></a>线性规划(linear programming)</h3><p>线性规划问题装目标函数和约束函数都是线性的：<br>\begin{align*}<br>&amp;minimize \quad c^Tx\<br>&amp;subject \ to \quad a_i^T \le b_i, i = 1, \cdots, m.<br>\end{align*}<br>其中向量$c,a_1,\cdots,a_m \epsilon R^n$, 和标量$b_1,\cdots, b_m \epsilon R$是指定目标函数和约束函数条件的参数。</p><h4 id="求解线性规划-solving-linear-programs"><a href="#求解线性规划-solving-linear-programs" class="headerlink" title="求解线性规划(solving linear programs)"></a>求解线性规划(solving linear programs)</h4><ul><li>除了一个特例，没有解析解公式(和least-squares不同)；</li><li>有可靠且高效的算法实现；</li><li>时间复杂度是$O(n^2m)$, m是约束条件的个数, m是维度$；</li><li>是一个成熟的方法。</li></ul><h4 id="应用-using-linear-programs"><a href="#应用-using-linear-programs" class="headerlink" title="应用(using linear programs)"></a>应用(using linear programs)</h4><p>一些应用直接使用线性规划的标准形式,或者其中一个标准形式。在很多时候，原始的优化问题没有一个标准的线性规划形式，但是可以被转化为等价的线性规划形式。比如切米雪夫近似问题(Chebyshev approximation problem)。它的形式如下：</p><script type="math/tex; mode=display">minimize \quad max_{i=1,\cdots,k}|a_i^Tx-b_i|</script><p>其中$x\epsilon R^n$是变量，$a_1,\cdots,a_k \epsilon R^n, b_1,\cdots,b_k \epsilon R$是实例化的问题参数,和least-squares相似的是，它们的目标函数都是项$a^T_ix-b_i$。不同之处在于，least-squares用的是该项的平方和作为目标函数，而Chebyshev approximation中用的是绝对值的最大值。Chebyshev approximation problem的目标函数是不可导的(max operation), least-squares problem的目标函数是二次的(quadratic), 因此可导的(differentiable)。</p><h2 id="凸优化-Convex-optimization"><a href="#凸优化-Convex-optimization" class="headerlink" title="凸优化(Convex optimization)"></a>凸优化(Convex optimization)</h2><p>凸优化问题是优化问题的一种,它的目标函数和优化函数都是凸的。<br>具有以下形式的问题是一种凸优化问题：<br>\begin{align*}<br>&amp;minimize \quad f_0(x)\<br>&amp;subject \ to \quad f_i(x) \le b_i, i = 1,\cdots,m.<br>\end{align*}<br>其中函数$f_0,\cdots,f_m:R^n \rightarrow R$是凸的(convex), 如满足</p><script type="math/tex; mode=display">f_i(\alpha x+ \beta y) \le \alpha f_i(x) + \beta f_i(y)</script><p>对于所有的$x,y \epsilon R^n$和所有的$\alpha, \beta \epsilon R$且$\alpha + \beta = 1, \alpha \ge 0, \beta \ge 0$。<br>或者：</p><script type="math/tex; mode=display">f_i(\theta x+ (1-\theta) y) \le \theta f_i(x) + (1 - \theta) f_i(y)</script><p>其中$\theta \epsilon [0,1]$。<br>课上有人问这里为$\theta$是0和1, 有没有什么物理意义，Stephen Boyd回答说这是定义，就是这么定义的。<br>The least-squares和linear programming problem都是convex optimization problem的特殊形式。线性函数(linear functions)也是convex，它们正处在边界上，它们的曲率(curvature)为0。一种方式是用正曲率去描述凸性。</p><h3 id="凸优化求解-solving-convex-optimization-problems"><a href="#凸优化求解-solving-convex-optimization-problems" class="headerlink" title="凸优化求解(solving convex optimization problems)"></a>凸优化求解(solving convex optimization problems)</h3><ul><li>没有解析解；</li><li>有可靠且有效的算法；</li><li>时间复杂度正比于$max{n^3, n^2m,F},$F$是评估$f$和计算一阶导数和二阶导数的时间；</li><li>有成熟的方法，如interior-point methods。</li></ul><h3 id="凸优化的应用-using-convex-optimization"><a href="#凸优化的应用-using-convex-optimization" class="headerlink" title="凸优化的应用(using convex optimization)"></a>凸优化的应用(using convex optimization)</h3><p>将实际问题形式化称凸优化问题。</p><h2 id="非线性优化-Nonlinear-optimization"><a href="#非线性优化-Nonlinear-optimization" class="headerlink" title="非线性优化(Nonlinear optimization)"></a>非线性优化(Nonlinear optimization)</h2><h3 id="非线性优化"><a href="#非线性优化" class="headerlink" title="非线性优化"></a>非线性优化</h3><p>非线性优化用来描述目标函数和约束函数都是非线性函数(但不是凸的)优化问题。因为凸优化问题包括least-squares和linear programming, 它们是线性的。刚开始给出的优化问题就是非线性优化问题，目前没有有效的方法解该问题。目前有一些方法来解决一般的非线性问题，但是都做了一些compromise。</p><h4 id="局部优化-local-optimization"><a href="#局部优化-local-optimization" class="headerlink" title="局部优化(local optimization)"></a>局部优化(local optimization)</h4><p>局部优化是非线性优化的一种解法，compromise是寻找局部最优点，而不是全局最优点，在可行解附近最小化目标函数，不保证能得到一个最小的目标值。<br>局部优化需要随机初始化一个初值，这个初值很关键，很大程度的影响了局部解得到的目标值, 也就是说是一个初值敏感的算法。关于初始值和全局最优值距离有多远并没有很多有用的信息。局部优化对于算法的参数值很敏感，需要根据具体问题去具体调整。<br>使用局部优化的方法比解least-squares problems, linear program, convex optimization problem更有技巧性，因为它牵扯到算法的选择，算法参数的选择，以及初值的选取。</p><h4 id="全局优化-global-optimization"><a href="#全局优化-global-optimization" class="headerlink" title="全局优化(global optimization)"></a>全局优化(global optimization)</h4><p>全局优化也是非线性优化的一种解法, 在全局优化中，优化目标的全局最优解被找到， compromise是效率。</p><h4 id="凸优化问题在非凸优化问题中的应用-role-of-convex-optimization-in-nonconvex-problems"><a href="#凸优化问题在非凸优化问题中的应用-role-of-convex-optimization-in-nonconvex-problems" class="headerlink" title="凸优化问题在非凸优化问题中的应用(role of convex optimization in nonconvex problems)"></a>凸优化问题在非凸优化问题中的应用(role of convex optimization in nonconvex problems)</h4><h5 id="初始化局部优化-initialization-for-local-optimization"><a href="#初始化局部优化-initialization-for-local-optimization" class="headerlink" title="初始化局部优化(initialization for local optimization)"></a>初始化局部优化(initialization for local optimization)</h5><h5 id="用于非凸优化的凸的启发式搜索-convex-heuristics-for-nonconvex-optimization"><a href="#用于非凸优化的凸的启发式搜索-convex-heuristics-for-nonconvex-optimization" class="headerlink" title="用于非凸优化的凸的启发式搜索(convex heuristics for nonconvex optimization)"></a>用于非凸优化的凸的启发式搜索(convex heuristics for nonconvex optimization)</h5><h5 id="全局最优的边界-bounds-for-global-optimization"><a href="#全局最优的边界-bounds-for-global-optimization" class="headerlink" title="全局最优的边界(bounds for global optimization)"></a>全局最优的边界(bounds for global optimization)</h5><h2 id="大纲-outline"><a href="#大纲-outline" class="headerlink" title="大纲(outline)"></a>大纲(outline)</h2><h3 id="理论-part-one-Theory"><a href="#理论-part-one-Theory" class="headerlink" title="理论(part one: Theory)"></a>理论(part one: Theory)</h3><p>第一部分是理论，给出一些概念和定义，第一章是Introduction, 第二章和第三章分别介绍凸集(convex set)和凸函数(convex function), 第四章介绍凸优化问题， 第五章引入拉格朗日对偶性。 </p><h3 id="应用-part-two-Applications"><a href="#应用-part-two-Applications" class="headerlink" title="应用(part two: Applications)"></a>应用(part two: Applications)</h3><p>第二部分主要给出凸优化在一些领域的应用，如概率论与数理统计，经济学，计算几何以及数据拟合等领域。<br>凸优化如何应用在实践中。</p><h3 id="算法-part-three-Algorithms"><a href="#算法-part-three-Algorithms" class="headerlink" title="算法(part three: Algorithms)"></a>算法(part three: Algorithms)</h3><p>第三部分给出了凸优化的数值解法，如牛顿法(Newton’s algorithm)和内点法(interior-point)。<br>第三部分有三章，分别包含了无约束优化，等式约束优化和不等式约束优化。章节之间是递进的，解一个问题被分解为解一系列简单问题。二次优化问题(包括，如least-squares)是最底层的基石，它可以通过线性方程组精确求解。牛顿法，在第十章和第十一章介绍到，是下个层次，无约束问题或者等式约束问题被转化成一系列二次优化问题的求解。第十一章介绍了内点法，是最顶层, 这些方法将不等式约束问题转化为一系列无约束或者等式约束的问题。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;数学优化-mathematical-optimization&quot;&gt;&lt;a href=&quot;#数学优化-mathematical-optimization&quot; class=&quot;headerlink&quot; title=&quot;数学优化(mathematical optimization)&quot;
      
    
    </summary>
    
      <category term="凸优化笔记" scheme="http://mxxhcm.github.io/categories/%E5%87%B8%E4%BC%98%E5%8C%96%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="凸优化" scheme="http://mxxhcm.github.io/tags/%E5%87%B8%E4%BC%98%E5%8C%96/"/>
    
      <category term="convex optimization" scheme="http://mxxhcm.github.io/tags/convex-optimization/"/>
    
  </entry>
  
  <entry>
    <title>latex笔记</title>
    <link href="http://mxxhcm.github.io/2018/12/22/latex%E7%AC%94%E8%AE%B0/"/>
    <id>http://mxxhcm.github.io/2018/12/22/latex笔记/</id>
    <published>2018-12-22T02:08:26.000Z</published>
    <updated>2019-05-06T16:22:27.708Z</updated>
    
    <content type="html"><![CDATA[<h2 id="命令重命名"><a href="#命令重命名" class="headerlink" title="命令重命名"></a>命令重命名</h2><p>在写博客时也能用<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">\newcommand&#123;\mmm&#125;&#123;\mathbf&#125;</span><br><span class="line">\mmm&#123;x&#125;</span><br><span class="line">\bf&#123;x&#125;</span><br></pre></td></tr></table></figure></p><p>$\newcommand{\mmm}{\mathbf}$<br>$\mmm{x}$<br>$\bf{x}$</p><h2 id="常用Latex符号"><a href="#常用Latex符号" class="headerlink" title="常用Latex符号"></a>常用Latex符号</h2><h3 id="括号"><a href="#括号" class="headerlink" title="括号"></a>括号</h3><p>\left(\frac{1}{2}\right)    $\left(\frac{1}{2} \right)$<br>\left[\frac{1}{2} \right]    $\left[\frac{1}{2} \right]$<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\begin&#123;cases&#125;x=1\\y=x\end&#123;cases&#125;</span><br></pre></td></tr></table></figure></p><script type="math/tex; mode=display">\begin{cases}x=1\\y=x\end{cases}</script><h3 id="矩阵"><a href="#矩阵" class="headerlink" title="矩阵"></a>矩阵</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\begin&#123;matrix&#125;1&amp;2\\3&amp;4\end&#123;matrix&#125;</span><br></pre></td></tr></table></figure><script type="math/tex; mode=display">\begin{matrix}1&2\\3&4\end{matrix}</script><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\begin&#123;pmatrix&#125;1&amp;2\\3&amp;4\end&#123;pmatrix&#125;</span><br></pre></td></tr></table></figure><script type="math/tex; mode=display">\begin{pmatrix}1&2\\3&4\end{pmatrix}</script><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\begin&#123;bmatrix&#125;1&amp;2\\3&amp;4\end&#123;bmatrix&#125;</span><br></pre></td></tr></table></figure><script type="math/tex; mode=display">\begin{bmatrix}1&2\\3&4\end{bmatrix}</script><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\begin&#123;Bmatrix&#125;1&amp;2\\3&amp;4\end&#123;Bmatrix&#125;</span><br></pre></td></tr></table></figure><script type="math/tex; mode=display">\begin{Bmatrix}1&2\\3&4\end{Bmatrix}</script><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\begin&#123;vmatrix&#125;1&amp;2\\3&amp;4\end&#123;vmatrix&#125;</span><br></pre></td></tr></table></figure><script type="math/tex; mode=display">\begin{vmatrix}1&2\\3&4\end{vmatrix}</script><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\begin&#123;Vmatrix&#125;1&amp;2\\3&amp;4\end&#123;Vmatrix&#125;</span><br></pre></td></tr></table></figure><script type="math/tex; mode=display">\begin{Vmatrix}1&2\\3&4\end{Vmatrix}</script><h3 id="希腊字母"><a href="#希腊字母" class="headerlink" title="希腊字母"></a>希腊字母</h3><p>$\eta$ \eta<br>$\gamma$ \gamma<br>$\epsilon$ \epsilon<br>$\varepsilon$ \varepsilon<br>$\lambda$ \lambda<br>$\Lambda$ \Lambda<br>$\sigma$ \sigma<br>$\Sigma$ \Sigma<br>$\phi$ \phi<br>$\varphi$ \varphi<br>$\Phi$ \Phi<br>$\Delta$ \Delta<br>$\delta$ \delta<br>$\nabla$ \nabla</p><h3 id="字体"><a href="#字体" class="headerlink" title="字体"></a>字体</h3><p>$\mathbf{A}$ \mathbf{A}<br>$\boldsymbol{A}$ \boldsymbol{A}<br>$\mathit{A}$ \mathit{A}<br>$\mathrm{A}$ \mathrm{A}<br>$\mathcal{A}$ \mathcal{A}</p><h3 id="数学运算"><a href="#数学运算" class="headerlink" title="数学运算"></a>数学运算</h3><p>求积$\prod$ \prod<br>求和$\sum$ \sum<br>积分$\int$ \int<br>根号$\sqrt{x}$ \sqrt{x}<br>根号$\sqrt[4]{y}$ \sqrt[4]{y}<br>分数$(\frac{1}{2})$ (\frac{1}{2})<br>分数$\left(\frac{1}{2}\right)$ \left(\frac{1}{2}\right)<br>无穷$\infty$ \infty<br>期望$\mathbb{E}$ \mathbb{E}<br>$\mathbb{\pi}$ \mathbb{\pi} # 可以看出来，没有起作用，因为mathbb没有只支持大写字母。<br>$\pm$ \pm<br>$\mp$ \mp</p><h3 id="上下花括号"><a href="#上下花括号" class="headerlink" title="上下花括号"></a>上下花括号</h3><p>$\overbrace{x+y}^{1+2}=\underbrace{z}_3$ \overbrace{x+y}^{1+2}=\underbrace{z}_3</p><h3 id="集合"><a href="#集合" class="headerlink" title="集合"></a>集合</h3><p>真含于$\subset$ \subset<br>含于$\subsetneqq$ \subsetneqq<br>真包含$\supset$ \supset<br>包含$\supsetneqq$ \supsetneqq<br>交$\cap$ \cap<br>并$\cup$ \cup<br>属于$\in$ \in<br>$\succ$ \succ<br>$\succeq$ \succeq<br>$\prec$ \prec<br>$\preceq$ \preceq</p><h3 id="谓词逻辑"><a href="#谓词逻辑" class="headerlink" title="谓词逻辑"></a>谓词逻辑</h3><p>否定$\neg$ \neg<br>任意$\forall$ \forall<br>存在$\exists$ \exists<br>合取$\wedge$ \wedge<br>析取$\vee$ \vee</p><h3 id="空格"><a href="#空格" class="headerlink" title="空格"></a>空格</h3><p>$a\qquad b$ a\qquad b<br>$a\quad b$ a\quad b<br>$a\ b$ a\ b<br>$a\;b$ a\;b<br>$a\,b$ a\,b<br>$ab$ ab<br>$a!b$ a!b</p><h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><p>长竖线$\big|$ \big|<br>长竖线$\Big|$ \Big|<br>长竖线$\bigg|$ \bigg|<br>长竖线$\Bigg|$ \Bigg|<br>双箭头$\Leftrightarrow$ \Leftrightarrow<br>左箭头$\leftarrow$ \leftarrow<br>右箭头$\rightarrow$ \rightarrow<br>范数$\Vert$ \Vert<br>上划线$\overline{A}$ \overline{A}<br>下划线$\underline{A}$ \underline{A}<br>$\backslash$ \backslash<br>$\sim$ \sim</p><h2 id="列表"><a href="#列表" class="headerlink" title="列表"></a>列表</h2><h3 id="有序列表"><a href="#有序列表" class="headerlink" title="有序列表"></a>有序列表</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">\begin&#123;enumerate&#125;</span><br><span class="line"> \item First.</span><br><span class="line"> \item Second.</span><br><span class="line"> \item Third.</span><br><span class="line">\end&#123;enumerate&#125;</span><br></pre></td></tr></table></figure><p>效果如下：</p><ol><li>First.</li><li>Second.</li><li>Third.</li></ol><h3 id="无序列表"><a href="#无序列表" class="headerlink" title="无序列表"></a>无序列表</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">\begin&#123;itemize&#125;</span><br><span class="line"> \item &#123;First.&#125;</span><br><span class="line"> \item &#123;Second.&#125;</span><br><span class="line"> \item &#123;Third.&#125;</span><br><span class="line">\end&#123;itemize&#125;</span><br></pre></td></tr></table></figure><p>效果如下：</p><ul><li>First.</li><li>Second.</li><li>Third.</li></ul><h2 id="跨多行公式对齐"><a href="#跨多行公式对齐" class="headerlink" title="跨多行公式对齐"></a>跨多行公式对齐</h2><p><strong>注意：不要忘了每行后面的两个\</strong></p><h3 id="示例1"><a href="#示例1" class="headerlink" title="示例1"></a>示例1</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">\begin&#123;align*&#125;</span><br><span class="line">f(x) &amp;= (3 + 4)^2 + 4\\</span><br><span class="line">&amp;= 7^2 + 4\\</span><br><span class="line">&amp;= 49 + 4\\</span><br><span class="line">&amp;= 53</span><br><span class="line">\end&#123;align*&#125;</span><br></pre></td></tr></table></figure><p>效果如下：<br>\begin{align*}<br>f(x) &amp;= (3 + 4)^2 + 4\<br>&amp;= 7^2 + 4\<br>&amp;= 49 + 4\<br>&amp;= 53<br>\end{align*}</p><h3 id="示例2"><a href="#示例2" class="headerlink" title="示例2"></a>示例2</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">\begin&#123;align*&#125;</span><br><span class="line">v &amp;= R + \gamma Pv\\</span><br><span class="line">(1-\gamma P) &amp;= R\\</span><br><span class="line">v &amp;= (1 - \gamma P)^&#123;-1&#125; R</span><br><span class="line">\end&#123;align*&#125;</span><br></pre></td></tr></table></figure><p>\begin{align*}<br>v &amp;= R + \gamma Pv\<br>(1-\gamma P) &amp;= R\<br>v &amp;= (1 - \gamma P)^{-1} R<br>\end{align*}</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>1.<a href="http://blog.huangyuanlove.com/2018/02/27/LaTeX笔记-六/" target="_blank" rel="noopener">http://blog.huangyuanlove.com/2018/02/27/LaTeX笔记-六/</a><br>2.<a href="https://blog.csdn.net/xxzhangx/article/details/52778539" target="_blank" rel="noopener">https://blog.csdn.net/xxzhangx/article/details/52778539</a><br>3.<a href="https://blog.csdn.net/hunauchenym/article/details/7330828" target="_blank" rel="noopener">https://blog.csdn.net/hunauchenym/article/details/7330828</a><br>4.<a href="http://geowu.blogspot.com/2012/10/latex_25.html" target="_blank" rel="noopener">http://geowu.blogspot.com/2012/10/latex_25.html</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;命令重命名&quot;&gt;&lt;a href=&quot;#命令重命名&quot; class=&quot;headerlink&quot; title=&quot;命令重命名&quot;&gt;&lt;/a&gt;命令重命名&lt;/h2&gt;&lt;p&gt;在写博客时也能用&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td
      
    
    </summary>
    
      <category term="工具" scheme="http://mxxhcm.github.io/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="Latex" scheme="http://mxxhcm.github.io/tags/Latex/"/>
    
  </entry>
  
  <entry>
    <title>reinforcement learning an introduction 第3章笔记</title>
    <link href="http://mxxhcm.github.io/2018/12/21/reinforcement-learning-an-introduction-%E7%AC%AC3%E7%AB%A0%E7%AC%94%E8%AE%B0/"/>
    <id>http://mxxhcm.github.io/2018/12/21/reinforcement-learning-an-introduction-第3章笔记/</id>
    <published>2018-12-21T07:13:38.000Z</published>
    <updated>2019-05-06T16:22:27.708Z</updated>
    
    <content type="html"><![CDATA[<h2 id="马尔科夫过程-markov-process-、马尔科夫链-markov-chain"><a href="#马尔科夫过程-markov-process-、马尔科夫链-markov-chain" class="headerlink" title="马尔科夫过程(markov process)、马尔科夫链(markov chain)"></a>马尔科夫过程(markov process)、马尔科夫链(markov chain)</h2><p>马尔科夫过程或者马尔科夫链(markov chain)是一个tuple $\lt S,P\gt$,其中S是一个有限(或者无限)的状态集合,P是状态转移矩阵(transition probability matrix)或马尔科夫矩阵(markov matrix),$P<em>{ss’}= P[S</em>{t+1} = s’|S_t = s]$.</p><h2 id="马尔科夫奖励过程-markov-reward-process"><a href="#马尔科夫奖励过程-markov-reward-process" class="headerlink" title="马尔科夫奖励过程(markov reward process)"></a>马尔科夫奖励过程(markov reward process)</h2><p>马尔科夫奖励过程是一个tuple $\lt S,P,R,\gamma\gt$,和马尔科夫过程相比，它多了一个奖励R，R和某个具体的状态相关，MRP中的reward只和state有关,和action无关。<br>S是一个(有限)状态的集合。<br>P是一个状态转移概率矩阵。<br>R是一个奖励函数$R = \mathbb{E}[R_{t+1}|S_t = s]$, <strong>这里为什么是t+1时刻的reward?这仅仅是一个约定，为了描述RL问题中涉及到的observation，action，reward比较方便。这里可以理解为离开这个状态才能获得奖励而不是进入这个状态即获得奖励。如果改成$R_t$也是可以的，这时可以理解为进入这个状态获得的奖励。</strong><br>$\gamma$称为折扣因子(discount factor), $\gamma \epsilon [0,1]$.<strong>为什么引入$\gamma$，David Silver的公开课中提到了四个原因:(1)数学上便于计算回报(return)；(2)避免陷入无限循环；(3)长远利益具有一定的不确定性；(4)符合人类对眼前利益的追求。</strong></p><h3 id="奖励-reward"><a href="#奖励-reward" class="headerlink" title="奖励(reward)"></a>奖励(reward)</h3><p>每个状态s在一个时刻t立即可得到一个reward,reward的值需要由环境给出,这个值可正可负。目前的强化学习算法中reward都是人为设置的。</p><h3 id="回报-return"><a href="#回报-return" class="headerlink" title="回报(return)"></a>回报(return)</h3><p>回报是累积的未来的reward,其计算公式如下:</p><script type="math/tex; mode=display">G_t = R_{t+1} + R_{t+2} + ... = \sum_{k=0}^{\infty}{\gamma^k R_{t+k+1}} \tag{1}</script><p>它是一个马尔科夫链上从t时刻开始往后所有奖励的有衰减(带折扣因子)的总和。</p><h3 id="值函数-value-function"><a href="#值函数-value-function" class="headerlink" title="值函数(value function)"></a>值函数(value function)</h3><p>值函数是回报(return)的期望(expected return), 一个MRP过程中某一状态的value function为从该状态开始的markov charin return的期望，即$v(s) = \mathbb{E}[G_t|S_t=s]$.<br>MRP的value function和MDP的value function是不同的, MRP的value function是对于state而言的，而MDP的value function是针对tuple $\lt$state, action$\gt$的。<br>这里为什么要取期望,因为policy是stotastic的情况时，在每个state时，采取每个action都是可能的，都有一定的概率，next state也是不确定的了，所以value funciton是一个随机变量，因此就引入期望来刻画随机变量的性质。<br>为什么在当前state就知道下一时刻的state了?对于有界的RL问题来说，return是在一个回合结束时候计算的；对于无界的RL问题来说，由于有衰减系数，只要reward有界，return就可以计算出来。</p><h3 id="马尔科夫奖励过程的贝尔曼方程-bellman-equation-for-MRP"><a href="#马尔科夫奖励过程的贝尔曼方程-bellman-equation-for-MRP" class="headerlink" title="马尔科夫奖励过程的贝尔曼方程(bellman equation for MRP)"></a>马尔科夫奖励过程的贝尔曼方程(bellman equation for MRP)</h3><p>\begin{align*}<br>v(s) &amp;= \mathbb{E}[G<em>t|S_t = s]\<br>&amp;= \mathbb{E}[R</em>{t+1} + \gamma R<em>{t+2} + … | S_t = s]\<br>&amp;= \mathbb{E}[R</em>{t+1} + \gamma (R<em>{t+2} + \gamma R</em>{t+3} + …|S<em>t = s]\<br>&amp;= \mathbb{E}[R</em>{t+1} + \gamma G<em>{t+1} |S_t = s]\<br>&amp;= \mathbb{E}[R</em>{t+1} + \gamma v(S<em>{t+1})|S_t = s]\<br>v(s) &amp;= \mathbb{E}[R</em>{t+1} + \gamma v(S<em>{t+1})|S_t = s]<br>\end{align*}<br>v(s)由两部分组成，一部分是immediate reward的期望(expectation)，$\mathbb{E}[R</em>{t+1}]$, 只与当前时刻state有关；另一部分是下一时刻state的value function的expectation。如果用s’表示s状态下一时刻的state，那么bellman equation可以写成：</p><script type="math/tex; mode=display">v(s) = R_s + \gamma \sum_{s' \epsilon S} P_{ss'}v(s')</script><p>我们最终的目的是通过迭代使得t轮迭代时的v(s)和第t+1轮迭代时的v(s)相等。将其写成矩阵形式为：</p><script type="math/tex; mode=display">v_t = R + \gamma P v_{t+1}</script><script type="math/tex; mode=display">(v_1,v_2,...,v_n)^T = (R_1,R_2,...,R_n)^T + \gamma \begin{bmatrix}P_{11}&P_{12}&...&P_{1n}\\P_{21}&P_{22}&...&P_{2n}\\&&...&\\P_{n1}&P_{n2}&...&P_{nn}\end{bmatrix} (v_1,v_2,...,v_n)^T</script><p>MRP的Bellman方程组是线性的，可以直接求解:<br>\begin{align*}<br>v &amp;= R + \gamma Pv\<br>(1-\gamma P) &amp;= R\<br>v &amp;= (1 - \gamma P)^{-1} R<br>\end{align*}<br>可以直接解方程，但是复杂度为$O(n^3)$，对于大的MRP方程组不适用，可以通过迭代法求解，常用的迭代法有动态规划,蒙特卡洛算法和时序差分算法等求解(动态规划是迭代法吗？）</p><h2 id="马尔科夫决策过程-markov-decision-process"><a href="#马尔科夫决策过程-markov-decision-process" class="headerlink" title="马尔科夫决策过程(markov decision process)"></a>马尔科夫决策过程(markov decision process)</h2><p>马尔科夫决策过程，比markov reward process多了一个A,它也是一个tuple $\lt S,A,P,R,\gamma\gt$, 在MRP中奖励R仅仅和状态S相关，在MDP中奖励R和概率P对应的是某个状态S和某个动作A的组合。<br>\begin{align*}<br>P<em>{ss’}^a &amp;= P[S</em>{t+1} = s’ | S<em>t = s, A_t = a]\<br>R_s^a &amp;= \mathbb{E}[R</em>{t+1} | S_t = s, A_t = a]<br>\end{align*}<br>这里的reward不仅仅与state相关，而是与tuple $\lt state，action\gt$相关。</p><h3 id="回报"><a href="#回报" class="headerlink" title="回报"></a>回报</h3><p>MDP中的$G<em>t$和式子$(1)$的$G_t$是一样的，将$G_t$写成和后继时刻相关的形式如下：<br>\begin{align*}<br>G_t &amp;= R</em>{t+1} + \gamma R<em>{t+2} + \gamma^2 R</em>{t+3} + \gamma^3 R<em>{t+4} + …\<br>&amp;= R</em>{t+1} + \gamma (R<em>{t+2} + \gamma^1 R</em>{t+3} + \gamma^2 R<em>{t+4} + …)\<br>&amp;= R</em>{t+1} + \gamma G_{t+1} \tag{2}<br>\end{align*}<br>这里引入$\gamma$之后，即使是在continuing情况下，只要$G_t$是非零常数，$G_t$也可以通过等比数列求和公式进行计算，即:</p><script type="math/tex; mode=display">G_t = \sum_{k=1}^{\infty}\gamma^k = \frac{1}{1-\gamma} \tag{3}</script><h3 id="策略-policy"><a href="#策略-policy" class="headerlink" title="策略(policy)"></a>策略(policy)</h3><p>策略$\pi$的定义:给定状态时采取各个动作的概率分布。</p><script type="math/tex; mode=display">\pi(a|s) = P[A_t = a | S_t = a] \tag{4}</script><h3 id="值函数-value-function-1"><a href="#值函数-value-function-1" class="headerlink" title="值函数(value function)"></a>值函数(value function)</h3><p>这里给出的是值函数的定义，就是这么定义的。<br>MDP的值函数有两种，状态值函数(state value function)和动作值函数(action value function), 这两种值函数的含义其实是一样的，也可以相互转换。具体来说, 值函数定义为给定一个policy $\pi$，得到的回报的期望(expected return)。<br>一个MDP的状态s对应的值函数(state value function) $v<em>{\pi}(s)$是从状态s开始采取策略$\pi$得到的回报的期望。<br>\begin{align*}<br>v</em>{\pi}(s) &amp;= \mathbb{E}<em>{\pi}[G_t|S_t = s]\<br>&amp;=\mathbb{E}</em>{\pi}[\sum<em>{k=0}^{\infty} \gamma^{k}R</em>{t+k+1}|S<em>t=s] \tag{5}<br>\end{align*}<br>这里的$G_t$是式子(2)中的回报。<br>一个MDP过程中动作值函数(action value function) $q</em>{\pi}(s,a)$是从状态s开始,采取action a，采取策略$\pi$得到的回报的期望。</p><p><action value function $q_{\pi}(s,a)$ is the expected return starting from states, taking action a, and then following policy \pi.><br>\begin{align*}<br>q<em>{\pi}(s,a) &amp;= \mathbb{E}</em>{\pi}\left[G<em>t | S_t = s, A_t = a\right]\<br>&amp;= \mathbb{E}</em>{\pi}\left[\sum<em>{k=0}^{\infty} \gamma^{k}R</em>{t+k+1}|S_t=s, A_t=a\right] \tag{6}<br>\end{align*}</action></p><h4 id="状态值函数-state-value-function"><a href="#状态值函数-state-value-function" class="headerlink" title="状态值函数(state value function)"></a>状态值函数(state value function)</h4><p>\begin{align*}<br>v<em>{\pi}(s) &amp;= \sum</em>{a \epsilon A} \pi(a|s) q<em>{\pi} (s,a) \tag{7}\<br>v</em>{\pi}(s) &amp;= \sum<em>a \pi(a|s)\sum</em>{s’,r}p(s’,r|s,a) \left[r + \gamma v<em>{\pi}(s’) \right] \tag{8}\<br>\end{align*}<br>式子$(7)$是$v(s)$和$q(s,a)$的关系，式子$(8)$是$v(s)$和它的后继状态$v(s’)$的关系。<br>式子$(8)$的推导如下：<br>\begin{align*}<br>v</em>{\pi}(s) &amp;= \mathbb{E}<em>{\pi}[G_t|S_t = s]\<br>&amp;= \mathbb{E}</em>{\pi}\left[R<em>{t+1}+\gamma G</em>{t+1}|S<em>t = s\right]\<br>&amp;= \sum_a \pi(a|s)\sum</em>{s’}\sum<em>rp(s’,r|s,a) \left[r + \gamma \mathbb{E}</em>{\pi}\left[G<em>{t+1}|S</em>{t+1}=s’\right]\right]\<br>&amp;= \sum<em>a \pi(a|s)\sum</em>{s’,r}p(s’,r|s,a) \left[r + \gamma v_{\pi}(s’) \right]\<br>\end{align*}</p><h4 id="动作值函数-action-value-function"><a href="#动作值函数-action-value-function" class="headerlink" title="动作值函数(action value function)"></a>动作值函数(action value function)</h4><p>\begin{align*}<br>q<em>{\pi}(s,a) &amp;= \sum</em>{s’}\sum<em>r p(s’,r|s,a)(r + \gamma  v</em>{\pi}(s’)) \<br>q<em>{\pi}(s,a) &amp;= \sum</em>{s’}\sum<em>r p(s’,r|s,a)(r + \gamma  \sum</em>{a’}\pi(a’|s’)q(s’,a’)) \tag{10}\<br>\end{align*}<br>式子$(9)$是$q(s,a)$和$v(s)$的关系，式子$(10)$是$q(s,a)$和它的后继状态$q(s’,a’)$的关系。<br>以上都是针对MDP来说的，在MDP中，给定policy $\pi$下，状态s下选择a的action value function，$q_{\pi}(s,a)$类似MRP里面的v(s)，而MDP中的v(s)是要考虑在state s下采率各个action后的情况。</p><h3 id="贝尔曼期望方程-Bellmam-expectation-equation"><a href="#贝尔曼期望方程-Bellmam-expectation-equation" class="headerlink" title="贝尔曼期望方程(Bellmam expectation equation)"></a>贝尔曼期望方程(Bellmam expectation equation)</h3><p>\begin{align*}<br>v<em>{\pi}(s) &amp;= \mathbb{E}</em>{\pi}[R<em>{t+1} + \gamma v</em>{\pi}(S<em>{t+1})|S_t = s] \tag{11}\<br>v</em>{\pi}(s) &amp;= \mathbb{E}<em>{\pi}\left[q</em>{\pi}(S<em>t,A_t)|S_t=s,A_t=a\right]\tag{12}\<br>q</em>{\pi}(s,a)&amp;= \mathbb{E}<em>{\pi}\left[R+\gamma v</em>{\pi}(S<em>{t+1}) |S_t=s,A_t=a\right]\tag{13}\<br>q</em>{\pi}(s,a) &amp;= \mathbb{E}<em>{\pi}[R</em>{t+1} + \gamma q<em>{\pi}(S</em>{t+1},A_{t+1}) | S_t = s, A_t = a] \tag{14}<br>\end{align*}</p><h4 id="矩阵形式"><a href="#矩阵形式" class="headerlink" title="矩阵形式"></a>矩阵形式</h4><p>\begin{align*}<br>v<em>{\pi} &amp;= R^{\pi} + \gamma P^{\pi} v</em>{\pi}\<br>v_{\pi} &amp;= (I-\gamma P^{\pi})^{-1} R^{\pi}<br>\end{align*}</p><h2 id="最优策程的求解-how-to-find-optimal-policy"><a href="#最优策程的求解-how-to-find-optimal-policy" class="headerlink" title="最优策程的求解(how to find optimal policy)"></a>最优策程的求解(how to find optimal policy)</h2><h3 id="最优价值函数-optimal-value-function"><a href="#最优价值函数-optimal-value-function" class="headerlink" title="最优价值函数(optimal value function)"></a>最优价值函数(optimal value function)</h3><p>$v<em>{*} = max</em>{\pi}v<em>{\pi}(s)$,从所有策略产生的state value function中，选取使得state s的价值最大的函数<br>$q</em>{*}(s,a) = max<em>{\pi} q</em>{\pi}(s,a)$,从所有策略产生的action value function中，选取使$\lt s,a\gt$价值最大的函数<br>当我们得到了optimal value function，也就知道了每个state的最优价值，便认为这个MDP被解决了</p><h3 id="最优策略-optimal-policy"><a href="#最优策略-optimal-policy" class="headerlink" title="最优策略(optimal policy)"></a>最优策略(optimal policy)</h3><p>对于每一个state s，在policy $\pi$下的value 大于在policy $\pi’$的value， 就称策略$\pi$优于策略$\pi’$， $\pi \ge \pi’$ if $v<em>{\pi}(s) \ge v</em>{\pi’}(s)$, 对于任意s都成立<br>对于任何MDP，都满足以下条件：</p><ol><li>都存在一个optimal policy，它比其他策略好或者至少相等；</li><li>所有的optimal policy的optimal value function是相同的；</li><li>所有的optimal policy 都有相同的 action value function.</li></ol><h3 id="寻找最优策略"><a href="#寻找最优策略" class="headerlink" title="寻找最优策略"></a>寻找最优策略</h3><p>寻找optimal policy可以通过寻找optimal action value function来实现： </p><script type="math/tex; mode=display">{\pi}_{*}(a|s) = \begin{cases}1, &if\quad a = argmax\ q_{*}(s,a)\\0, &otherwise\end{cases}</script><h3 id="贝尔曼最优方程-bellman-optimal-equation"><a href="#贝尔曼最优方程-bellman-optimal-equation" class="headerlink" title="贝尔曼最优方程(bellman optimal equation)"></a>贝尔曼最优方程(bellman optimal equation)</h3><p>*号表示最优的策略。</p><h4 id="最优状态值函数-state-value-function"><a href="#最优状态值函数-state-value-function" class="headerlink" title="最优状态值函数(state value function)"></a>最优状态值函数(state value function)</h4><p>\begin{align*}<br>v<em>{*}(s) &amp;= max_a q</em>{*}(s,a)\<br>&amp;= max<em>a\mathbb{E}</em>{\pi<em>{*}}\left[G_t|S_t=s,A_t=a\right]\<br>&amp;= max_a\mathbb{E}</em>{\pi<em>{*}}\left[R</em>{t+1}+\gamma G<em>t|S_t=s,A_t=a\right]\<br>&amp;= max_a\mathbb{E}\left[R</em>{t+1} +\gamma v<em>{*}(S</em>{t+1})|S<em>t=s,A_t=a\right]\<br>&amp;= max_a \left[\sum</em>{s’,r} p(s’,r|s,a){*}(r+\gamma v_{*}(s’) )\right] \tag{15}\<br>\end{align*}</p><h4 id="最优动作值函数-action-value-function"><a href="#最优动作值函数-action-value-function" class="headerlink" title="最优动作值函数(action value function)"></a>最优动作值函数(action value function)</h4><p>\begin{align*}<br>q<em>{*}(s,a) &amp;= \sum</em>{s’,r} p(s’,r|s,a) (r + \gamma v<em>{*}(s’))\<br>&amp;= \sum</em>{s’,r} p(s’,r|s,a) (r + \gamma max<em>{a’} q</em>{*}(s’,a’))\<br>&amp;=\mathbb{E}\left[R<em>{t+1}+\gamma max</em>{a’}q<em>{*}(S</em>{t+1},a’)|S_t=s,A_t=a \right]\tag{16}\<br>\end{align*}</p><h3 id="贝尔曼最优方程的求解-solution-to-Bellman-optimal-equation"><a href="#贝尔曼最优方程的求解-solution-to-Bellman-optimal-equation" class="headerlink" title="贝尔曼最优方程的求解(solution to Bellman optimal equation)"></a>贝尔曼最优方程的求解(solution to Bellman optimal equation)</h3><p>Bellman equation和Bellman optimal equation相比，一个是对于给定的策略，求其对应的value function,是对一个策略的估计，而bellman optimal equation是要寻找最优策略，通过对action value function进行贪心。<br>Bellman最优方程是非线性的，没有固定的解决方案，只能通过迭代法来解决，如Policy iteration，value iteration，Q-learning，Sarsa等。</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>1.<a href="http://incompleteideas.net/book/the-book-2nd.html" target="_blank" rel="noopener">http://incompleteideas.net/book/the-book-2nd.html</a><br>2.<a href="https://www.bilibili.com/video/av32149008/?p=2" target="_blank" rel="noopener">https://www.bilibili.com/video/av32149008/?p=2</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;马尔科夫过程-markov-process-、马尔科夫链-markov-chain&quot;&gt;&lt;a href=&quot;#马尔科夫过程-markov-process-、马尔科夫链-markov-chain&quot; class=&quot;headerlink&quot; title=&quot;马尔科夫过程(mar
      
    
    </summary>
    
      <category term="强化学习" scheme="http://mxxhcm.github.io/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="强化学习" scheme="http://mxxhcm.github.io/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="MDP" scheme="http://mxxhcm.github.io/tags/MDP/"/>
    
      <category term="MRP" scheme="http://mxxhcm.github.io/tags/MRP/"/>
    
      <category term="Bellman Equation" scheme="http://mxxhcm.github.io/tags/Bellman-Equation/"/>
    
  </entry>
  
  <entry>
    <title>Undefined reference to pthread_create in Linux</title>
    <link href="http://mxxhcm.github.io/2018/12/20/Undefined-reference-to-pthread-create-in-Linux/"/>
    <id>http://mxxhcm.github.io/2018/12/20/Undefined-reference-to-pthread-create-in-Linux/</id>
    <published>2018-12-20T12:30:34.000Z</published>
    <updated>2019-05-06T16:22:27.704Z</updated>
    
    <content type="html"><![CDATA[<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>在阅读自然语言处理的一篇论文时，读到了bype pair encoding(bpe)算法。在github找到了一个实现<a href="https://github.com/glample/fastBPE" target="_blank" rel="noopener">fastBPE</a>, 算法是用C++写的，在编译的过程中遇到了问题”Undefined reference to pthread_create in Linux”, </p><h2 id="terminal下解决方案"><a href="#terminal下解决方案" class="headerlink" title="terminal下解决方案"></a>terminal下解决方案</h2><p>查阅资料了解到pthread不是Linux操作系统默认的库函数，所以需要在编译的时候将pthread链接该库函数，后来在看fastBPE的文档时发现文档中已经有说明:<br>Compile with:<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">g++ -std=c++11 -pthread -O3 fast.cc -o fast</span><br></pre></td></tr></table></figure></p><h2 id="codeblocks下解决方案"><a href="#codeblocks下解决方案" class="headerlink" title="codeblocks下解决方案"></a>codeblocks下解决方案</h2><p>上面给出的方案是使用gcc在terminal进行编译时加入静态库，但是对于不习惯在命令行使用gdb进行调试的人来说没有用。<br>在codeblocks中，如果要链接静态库,找到Settings —&gt; Compiler… —&gt; Linker settings，点击add，添加相应的库函数即可。</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>1:<a href="https://stackoverflow.com/questions/1662909/undefined-reference-to-pthread-create-in-linux" target="_blank" rel="noopener">https://stackoverflow.com/questions/1662909/undefined-reference-to-pthread-create-in-linux</a><br>2:<a href="https://blog.csdn.net/zhaoyue007101/article/details/7705753" target="_blank" rel="noopener">https://blog.csdn.net/zhaoyue007101/article/details/7705753</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;问题&quot;&gt;&lt;a href=&quot;#问题&quot; class=&quot;headerlink&quot; title=&quot;问题&quot;&gt;&lt;/a&gt;问题&lt;/h2&gt;&lt;p&gt;在阅读自然语言处理的一篇论文时，读到了bype pair encoding(bpe)算法。在github找到了一个实现&lt;a href=&quot;ht
      
    
    </summary>
    
      <category term="Error" scheme="http://mxxhcm.github.io/categories/Error/"/>
    
    
      <category term="C++" scheme="http://mxxhcm.github.io/tags/C/"/>
    
      <category term="codeblocks" scheme="http://mxxhcm.github.io/tags/codeblocks/"/>
    
      <category term="Linux" scheme="http://mxxhcm.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>随笔</title>
    <link href="http://mxxhcm.github.io/2018/12/18/%E9%9A%8F%E7%AC%94/"/>
    <id>http://mxxhcm.github.io/2018/12/18/随笔/</id>
    <published>2018-12-18T07:43:11.000Z</published>
    <updated>2019-05-06T16:22:27.712Z</updated>
    
    <content type="html"><![CDATA[<h1 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h1><p>看到别人在本科，硕士阶段记录了很多自己学到的东西，再看看自己，本科四年什么都没留下，现在进入实验室已经一年多了，没有沉淀下来，本来是很好的一手牌，被自己打的稀烂。今天就下定决心搭建一个自己的博客，用来记录自己的收获，一方面防止自己忘记，另一方面也确定自己是否已经懂了，能否把一个东西讲解出来。</p><h1 id="恩！"><a href="#恩！" class="headerlink" title="恩！"></a>恩！</h1><p>爱你呦，荟荟～</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;目的&quot;&gt;&lt;a href=&quot;#目的&quot; class=&quot;headerlink&quot; title=&quot;目的&quot;&gt;&lt;/a&gt;目的&lt;/h1&gt;&lt;p&gt;看到别人在本科，硕士阶段记录了很多自己学到的东西，再看看自己，本科四年什么都没留下，现在进入实验室已经一年多了，没有沉淀下来，本来是很好的一
      
    
    </summary>
    
      <category term="个人感想" scheme="http://mxxhcm.github.io/categories/%E4%B8%AA%E4%BA%BA%E6%84%9F%E6%83%B3/"/>
    
    
      <category term="感悟" scheme="http://mxxhcm.github.io/tags/%E6%84%9F%E6%82%9F/"/>
    
  </entry>
  
</feed>
